[2024-08-01 19:54:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/config.json
[2024-08-01 19:54:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: fullfinetune
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_conv_b_step_corss2
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-08-01 19:54:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/adapter_convnext/diffusion_ft_adapter_convnext_base_224_22kto1k_step_crosslayer_process2.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_adapter_conv_b_step_corss2", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-08-01 19:54:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 108): INFO Creating model:adapter_convnext_diffusion_finetune/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft
[2024-08-01 19:54:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 110): INFO Adapter_ConvNeXt_Diffusion_Finetune(
  (uma): UMA(filter_strategy1=18, filter_strategy2=6,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (memory_downsampling): ModuleList()
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-08-01 19:54:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 113): INFO number of params: 6284296
[2024-08-01 19:54:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2, ignoring auto resume
[2024-08-01 19:54:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth for fine-tuning......
[2024-08-01 19:54:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 127): WARNING <All keys matched successfully>
[2024-08-01 19:54:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process1/diffusion_ft_adapter_conv_b_step_corss1/ckpt_epoch_best.pth'
[2024-08-01 19:55:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 70.337 (70.337)	Loss 0.3496 (0.3496)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 3082MB
[2024-08-01 19:56:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.286 Acc@5 97.678
[2024-08-01 19:56:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 162): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 19:56:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 168): INFO Start training
[2024-08-01 19:56:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][0/2502]	eta 13:32:23 lr 0.000100	 wd 0.0000	time 19.4818 (19.4818)	loss 0.8408 (0.8408)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7964MB
[2024-08-01 19:57:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:22:00 lr 0.000100	 wd 0.0000	time 0.1863 (0.5498)	loss 0.7983 (0.8573)	grad_norm 0.4197 (nan)	loss_scale 32768.0000 (33092.4356)	mem 7964MB
[2024-08-01 19:57:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:15:56 lr 0.000100	 wd 0.0000	time 0.2105 (0.4155)	loss 0.8335 (0.8641)	grad_norm 0.4029 (nan)	loss_scale 32768.0000 (32931.0249)	mem 7964MB
[2024-08-01 19:57:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:44 lr 0.000100	 wd 0.0000	time 0.1995 (0.3471)	loss 0.8784 (0.8677)	grad_norm 0.4339 (nan)	loss_scale 32768.0000 (32876.8638)	mem 7964MB
[2024-08-01 19:58:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:56 lr 0.000100	 wd 0.0000	time 0.2131 (0.3126)	loss 1.2275 (0.8670)	grad_norm 0.3979 (nan)	loss_scale 32768.0000 (32849.7157)	mem 7964MB
[2024-08-01 19:58:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:10:41 lr 0.000100	 wd 0.0000	time 0.2708 (0.3206)	loss 0.8003 (0.8669)	grad_norm 0.3779 (nan)	loss_scale 32768.0000 (32833.4052)	mem 7964MB
[2024-08-01 19:59:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:39 lr 0.000100	 wd 0.0000	time 0.1781 (0.3044)	loss 0.9316 (0.8674)	grad_norm 0.3948 (nan)	loss_scale 32768.0000 (32822.5225)	mem 7964MB
[2024-08-01 19:59:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:45 lr 0.000100	 wd 0.0000	time 0.1872 (0.2915)	loss 0.8198 (0.8645)	grad_norm 0.3716 (nan)	loss_scale 32768.0000 (32814.7447)	mem 7964MB
[2024-08-01 19:59:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:08:00 lr 0.000100	 wd 0.0000	time 0.2365 (0.2822)	loss 0.8887 (0.8658)	grad_norm 0.3668 (nan)	loss_scale 32768.0000 (32808.9089)	mem 7964MB
[2024-08-01 20:00:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:46 lr 0.000100	 wd 0.0000	time 0.2565 (0.2913)	loss 1.0547 (0.8647)	grad_norm 0.3951 (nan)	loss_scale 32768.0000 (32804.3685)	mem 7964MB
[2024-08-01 20:00:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:07:06 lr 0.000100	 wd 0.0000	time 0.2008 (0.2841)	loss 0.8784 (0.8648)	grad_norm 0.3937 (nan)	loss_scale 32768.0000 (32800.7353)	mem 7964MB
[2024-08-01 20:01:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:29 lr 0.000100	 wd 0.0000	time 0.2095 (0.2778)	loss 0.7852 (0.8646)	grad_norm 0.4099 (nan)	loss_scale 32768.0000 (32797.7620)	mem 7964MB
[2024-08-01 20:01:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:55 lr 0.000100	 wd 0.0000	time 0.2307 (0.2729)	loss 0.7437 (0.8648)	grad_norm 0.3983 (nan)	loss_scale 32768.0000 (32795.2839)	mem 7964MB
[2024-08-01 20:02:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:26 lr 0.000100	 wd 0.0000	time 0.2062 (0.2713)	loss 0.8364 (0.8661)	grad_norm 0.4069 (nan)	loss_scale 32768.0000 (32793.1868)	mem 7964MB
[2024-08-01 20:02:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:55 lr 0.000100	 wd 0.0000	time 0.1955 (0.2679)	loss 0.8618 (0.8665)	grad_norm 0.4161 (nan)	loss_scale 32768.0000 (32791.3890)	mem 7964MB
[2024-08-01 20:02:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:24 lr 0.000100	 wd 0.0000	time 0.1960 (0.2645)	loss 0.9263 (0.8670)	grad_norm 0.4030 (nan)	loss_scale 32768.0000 (32789.8308)	mem 7964MB
[2024-08-01 20:03:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:55 lr 0.000100	 wd 0.0000	time 0.2158 (0.2614)	loss 1.0205 (0.8678)	grad_norm 0.4133 (nan)	loss_scale 32768.0000 (32788.4672)	mem 7964MB
[2024-08-01 20:03:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:29 lr 0.000100	 wd 0.0000	time 0.1839 (0.2615)	loss 0.8481 (0.8680)	grad_norm 0.3843 (nan)	loss_scale 32768.0000 (32787.2640)	mem 7964MB
[2024-08-01 20:04:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:03:02 lr 0.000100	 wd 0.0000	time 0.2307 (0.2595)	loss 0.8516 (0.8681)	grad_norm 0.4317 (nan)	loss_scale 32768.0000 (32786.1943)	mem 7964MB
[2024-08-01 20:04:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:34 lr 0.000100	 wd 0.0000	time 0.2275 (0.2572)	loss 0.9556 (0.8683)	grad_norm 0.3832 (nan)	loss_scale 32768.0000 (32785.2372)	mem 7964MB
[2024-08-01 20:04:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:02:08 lr 0.000100	 wd 0.0000	time 0.1929 (0.2551)	loss 0.9111 (0.8684)	grad_norm 0.4052 (nan)	loss_scale 32768.0000 (32784.3758)	mem 7964MB
[2024-08-01 20:05:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:42 lr 0.000100	 wd 0.0000	time 0.2173 (0.2538)	loss 0.8291 (0.8688)	grad_norm 0.3889 (nan)	loss_scale 32768.0000 (32783.5964)	mem 7964MB
[2024-08-01 20:05:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:16 lr 0.000100	 wd 0.0000	time 0.1745 (0.2539)	loss 0.9858 (0.8685)	grad_norm 0.4026 (nan)	loss_scale 32768.0000 (32782.8878)	mem 7964MB
[2024-08-01 20:05:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:50 lr 0.000100	 wd 0.0000	time 0.1935 (0.2524)	loss 0.9609 (0.8684)	grad_norm 0.4142 (nan)	loss_scale 32768.0000 (32782.2408)	mem 7964MB
[2024-08-01 20:06:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:25 lr 0.000100	 wd 0.0000	time 0.2264 (0.2509)	loss 1.0146 (0.8686)	grad_norm 0.3966 (nan)	loss_scale 32768.0000 (32781.6476)	mem 7964MB
[2024-08-01 20:06:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1611 (0.2485)	loss 0.8403 (0.8683)	grad_norm 0.3875 (nan)	loss_scale 32768.0000 (32781.1020)	mem 7964MB
[2024-08-01 20:06:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 0 training takes 0:10:25
[2024-08-01 20:06:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_0.pth saving......
[2024-08-01 20:06:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_0.pth saved !!!
[2024-08-01 20:07:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 59.041 (59.041)	Loss 0.3574 (0.3574)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 20:07:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.178 Acc@5 97.654
[2024-08-01 20:07:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 20:07:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.18%
[2024-08-01 20:07:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saving......
[2024-08-01 20:07:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saved !!!
[2024-08-01 20:08:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][0/2502]	eta 23:17:14 lr 0.000100	 wd 0.0000	time 33.5072 (33.5072)	loss 0.7480 (0.7480)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:08:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:22:07 lr 0.000100	 wd 0.0000	time 0.1648 (0.5528)	loss 0.8184 (0.8552)	grad_norm 0.4034 (0.3936)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:09:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:14:37 lr 0.000100	 wd 0.0000	time 0.1992 (0.3812)	loss 0.7861 (0.8615)	grad_norm 0.3888 (0.3935)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:09:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:51 lr 0.000100	 wd 0.0000	time 0.2090 (0.3231)	loss 0.8867 (0.8630)	grad_norm 0.3989 (0.3944)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:09:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:10:31 lr 0.000100	 wd 0.0000	time 0.2440 (0.3003)	loss 0.8779 (0.8641)	grad_norm 0.4162 (0.3957)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:10:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:09:29 lr 0.000100	 wd 0.0000	time 0.1980 (0.2843)	loss 0.7920 (0.8626)	grad_norm 0.3912 (0.3960)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:10:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:08:36 lr 0.000100	 wd 0.0000	time 0.1753 (0.2714)	loss 0.8862 (0.8641)	grad_norm 0.4075 (0.3956)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:10:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:07:53 lr 0.000100	 wd 0.0000	time 0.2104 (0.2627)	loss 0.8130 (0.8631)	grad_norm 0.3981 (0.3956)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:11:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:18 lr 0.000100	 wd 0.0000	time 0.2302 (0.2578)	loss 1.0049 (0.8643)	grad_norm 0.3923 (0.3953)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:11:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:07:11 lr 0.000099	 wd 0.0000	time 0.2048 (0.2693)	loss 0.8652 (0.8641)	grad_norm 0.3945 (0.3952)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:12:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:35 lr 0.000099	 wd 0.0000	time 0.1806 (0.2631)	loss 0.8672 (0.8644)	grad_norm 0.3985 (0.3954)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:12:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:06:02 lr 0.000099	 wd 0.0000	time 0.1913 (0.2584)	loss 0.9219 (0.8655)	grad_norm 0.4107 (0.3955)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:13:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:32 lr 0.000099	 wd 0.0000	time 0.2568 (0.2553)	loss 0.8149 (0.8655)	grad_norm 0.4045 (0.3959)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:13:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:05:07 lr 0.000099	 wd 0.0000	time 0.1845 (0.2562)	loss 0.8521 (0.8663)	grad_norm 0.3995 (0.3961)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:13:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:39 lr 0.000099	 wd 0.0000	time 0.2075 (0.2533)	loss 0.8589 (0.8666)	grad_norm 0.3996 (0.3961)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:14:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:11 lr 0.000099	 wd 0.0000	time 0.1739 (0.2507)	loss 0.8926 (0.8676)	grad_norm 0.3862 (0.3962)	loss_scale 65536.0000 (32811.6616)	mem 7964MB
[2024-08-01 20:14:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:44 lr 0.000099	 wd 0.0000	time 0.2270 (0.2488)	loss 0.8140 (0.8673)	grad_norm 0.3666 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-01 20:14:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:20 lr 0.000099	 wd 0.0000	time 0.2062 (0.2495)	loss 0.7612 (0.8674)	grad_norm 0.3994 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-01 20:15:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:54 lr 0.000099	 wd 0.0000	time 0.1906 (0.2480)	loss 0.9248 (0.8675)	grad_norm 0.3855 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-01 20:15:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:28 lr 0.000099	 wd 0.0000	time 0.2157 (0.2463)	loss 0.8955 (0.8679)	grad_norm 0.3735 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-01 20:16:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:02:02 lr 0.000099	 wd 0.0000	time 0.1723 (0.2446)	loss 0.7715 (0.8679)	grad_norm 0.4024 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-01 20:16:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:38 lr 0.000099	 wd 0.0000	time 0.3143 (0.2440)	loss 0.8223 (0.8679)	grad_norm 0.4154 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-01 20:16:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:13 lr 0.000099	 wd 0.0000	time 0.2249 (0.2440)	loss 0.7603 (0.8673)	grad_norm 0.3715 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-01 20:17:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:49 lr 0.000099	 wd 0.0000	time 0.1767 (0.2428)	loss 0.9243 (0.8681)	grad_norm 0.3957 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-01 20:17:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:24 lr 0.000099	 wd 0.0000	time 0.1947 (0.2415)	loss 0.9043 (0.8682)	grad_norm 0.4051 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-01 20:17:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1661 (0.2395)	loss 0.8862 (0.8685)	grad_norm 0.4115 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 20:17:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 1 training takes 0:10:03
[2024-08-01 20:18:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 37.414 (37.414)	Loss 0.3579 (0.3579)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 20:18:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.196 Acc@5 97.658
[2024-08-01 20:18:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 20:18:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.20%
[2024-08-01 20:18:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saving......
[2024-08-01 20:18:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saved !!!
[2024-08-01 20:19:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][0/2502]	eta 10:45:52 lr 0.000099	 wd 0.0000	time 15.4885 (15.4885)	loss 0.7744 (0.7744)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:19:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:15:03 lr 0.000099	 wd 0.0000	time 0.2004 (0.3762)	loss 0.9507 (0.8665)	grad_norm 0.3951 (0.3909)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:19:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:11:48 lr 0.000099	 wd 0.0000	time 0.2186 (0.3079)	loss 0.9087 (0.8640)	grad_norm 0.4006 (0.3924)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:20:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:06 lr 0.000099	 wd 0.0000	time 0.2178 (0.2754)	loss 0.7861 (0.8606)	grad_norm 0.4001 (0.3931)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:20:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:09:02 lr 0.000099	 wd 0.0000	time 0.2054 (0.2580)	loss 0.9424 (0.8619)	grad_norm 0.3771 (0.3938)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:20:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:27 lr 0.000099	 wd 0.0000	time 0.1898 (0.2535)	loss 0.9062 (0.8678)	grad_norm 0.4075 (0.3940)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:21:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:00 lr 0.000099	 wd 0.0000	time 0.1785 (0.2529)	loss 0.7866 (0.8678)	grad_norm 0.3969 (0.3939)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:21:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:27 lr 0.000099	 wd 0.0000	time 0.1757 (0.2482)	loss 0.8589 (0.8672)	grad_norm 0.3911 (0.3940)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:22:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:06:54 lr 0.000099	 wd 0.0000	time 0.2042 (0.2434)	loss 0.7725 (0.8656)	grad_norm 0.3947 (0.3941)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:22:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:23 lr 0.000098	 wd 0.0000	time 0.1838 (0.2397)	loss 0.9150 (0.8658)	grad_norm 0.4241 (0.3944)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:22:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:01 lr 0.000098	 wd 0.0000	time 0.2799 (0.2408)	loss 0.7783 (0.8649)	grad_norm 0.3888 (0.3943)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:23:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:41 lr 0.000098	 wd 0.0000	time 0.1761 (0.2438)	loss 0.8853 (0.8649)	grad_norm 0.4017 (0.3947)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:23:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:13 lr 0.000098	 wd 0.0000	time 0.2022 (0.2411)	loss 1.0068 (0.8654)	grad_norm 0.4106 (0.3948)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:24:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:47 lr 0.000098	 wd 0.0000	time 0.1785 (0.2388)	loss 0.8701 (0.8663)	grad_norm 0.4169 (0.3948)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:24:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:22 lr 0.000098	 wd 0.0000	time 0.2487 (0.2378)	loss 0.9185 (0.8665)	grad_norm 0.3861 (0.3948)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:24:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:03:58 lr 0.000098	 wd 0.0000	time 0.1765 (0.2382)	loss 1.0361 (0.8669)	grad_norm 0.3948 (0.3949)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:25:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:33 lr 0.000098	 wd 0.0000	time 0.1921 (0.2368)	loss 0.9189 (0.8666)	grad_norm 0.3957 (0.3952)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:25:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:08 lr 0.000098	 wd 0.0000	time 0.2156 (0.2356)	loss 0.8706 (0.8673)	grad_norm 0.4006 (0.3953)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:25:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:44 lr 0.000098	 wd 0.0000	time 0.2332 (0.2345)	loss 0.8647 (0.8671)	grad_norm 0.3776 (0.3954)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:26:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:21 lr 0.000098	 wd 0.0000	time 0.1883 (0.2357)	loss 0.7671 (0.8675)	grad_norm 0.3917 (0.3956)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:26:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:57 lr 0.000098	 wd 0.0000	time 0.1628 (0.2348)	loss 0.8711 (0.8676)	grad_norm 0.3704 (0.3956)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:27:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:34 lr 0.000098	 wd 0.0000	time 0.2309 (0.2339)	loss 0.9463 (0.8683)	grad_norm 0.3981 (0.3957)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:27:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:10 lr 0.000098	 wd 0.0000	time 0.1985 (0.2330)	loss 0.8623 (0.8682)	grad_norm 0.3973 (0.3956)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:27:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:47 lr 0.000098	 wd 0.0000	time 0.2581 (0.2329)	loss 0.8169 (0.8680)	grad_norm 0.4051 (0.3956)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:28:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:23 lr 0.000098	 wd 0.0000	time 0.2236 (0.2331)	loss 0.8584 (0.8683)	grad_norm 0.3958 (0.3957)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:28:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1596 (0.2313)	loss 0.8667 (0.8680)	grad_norm 0.4032 (0.3957)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:28:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 2 training takes 0:09:43
[2024-08-01 20:28:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 23.565 (23.565)	Loss 0.3547 (0.3547)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 20:29:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.194 Acc@5 97.652
[2024-08-01 20:29:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 20:29:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.20%
[2024-08-01 20:29:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][0/2502]	eta 1 day, 2:25:24 lr 0.000098	 wd 0.0000	time 38.0192 (38.0192)	loss 0.7295 (0.7295)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:30:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:23:20 lr 0.000098	 wd 0.0000	time 0.1857 (0.5832)	loss 0.9873 (0.8649)	grad_norm 0.4138 (0.3992)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:30:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:15:10 lr 0.000097	 wd 0.0000	time 0.1901 (0.3954)	loss 0.9917 (0.8613)	grad_norm 0.4095 (0.3977)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:30:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:12:35 lr 0.000097	 wd 0.0000	time 0.3684 (0.3433)	loss 1.0049 (0.8625)	grad_norm 0.3974 (0.3971)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:31:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:11:41 lr 0.000097	 wd 0.0000	time 0.1871 (0.3337)	loss 0.9448 (0.8620)	grad_norm 0.3761 (0.3964)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:31:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:10:17 lr 0.000097	 wd 0.0000	time 0.2233 (0.3083)	loss 0.8809 (0.8634)	grad_norm nan (nan)	loss_scale 32768.0000 (32898.8104)	mem 7964MB
[2024-08-01 20:32:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:09:14 lr 0.000097	 wd 0.0000	time 0.2024 (0.2914)	loss 0.8032 (0.8636)	grad_norm 0.4213 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7964MB
[2024-08-01 20:32:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:28 lr 0.000097	 wd 0.0000	time 0.2265 (0.2822)	loss 0.8960 (0.8647)	grad_norm 0.3938 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7964MB
[2024-08-01 20:32:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:07:51 lr 0.000097	 wd 0.0000	time 0.2107 (0.2772)	loss 0.8379 (0.8638)	grad_norm 0.4137 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7964MB
[2024-08-01 20:33:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:12 lr 0.000097	 wd 0.0000	time 0.1954 (0.2702)	loss 0.8892 (0.8645)	grad_norm 0.3990 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7964MB
[2024-08-01 20:33:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:37 lr 0.000097	 wd 0.0000	time 0.1893 (0.2644)	loss 1.0137 (0.8660)	grad_norm 0.4219 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-01 20:33:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:06:04 lr 0.000097	 wd 0.0000	time 0.2664 (0.2600)	loss 0.7754 (0.8655)	grad_norm 0.4094 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-01 20:34:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:37 lr 0.000097	 wd 0.0000	time 0.2014 (0.2594)	loss 0.9038 (0.8649)	grad_norm 0.3944 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-01 20:34:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:07 lr 0.000097	 wd 0.0000	time 0.1994 (0.2560)	loss 0.9502 (0.8662)	grad_norm 0.3794 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-01 20:35:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:38 lr 0.000097	 wd 0.0000	time 0.1751 (0.2529)	loss 0.8306 (0.8660)	grad_norm 0.3828 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-01 20:35:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:10 lr 0.000097	 wd 0.0000	time 0.1767 (0.2502)	loss 0.8076 (0.8670)	grad_norm 0.3785 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-01 20:35:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:44 lr 0.000096	 wd 0.0000	time 0.2075 (0.2489)	loss 0.8198 (0.8663)	grad_norm 0.3970 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-01 20:36:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:19 lr 0.000096	 wd 0.0000	time 0.2157 (0.2487)	loss 0.9224 (0.8663)	grad_norm 0.3974 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-01 20:36:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:53 lr 0.000096	 wd 0.0000	time 0.2342 (0.2467)	loss 0.8574 (0.8663)	grad_norm 0.3707 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-01 20:36:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:27 lr 0.000096	 wd 0.0000	time 0.1757 (0.2449)	loss 0.8799 (0.8659)	grad_norm 0.3803 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-01 20:37:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:02:02 lr 0.000096	 wd 0.0000	time 0.2013 (0.2437)	loss 0.8330 (0.8664)	grad_norm 0.3838 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-01 20:37:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:38 lr 0.000096	 wd 0.0000	time 0.2639 (0.2443)	loss 0.6924 (0.8660)	grad_norm 0.4060 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-01 20:38:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:13 lr 0.000096	 wd 0.0000	time 0.1953 (0.2430)	loss 0.8081 (0.8658)	grad_norm 0.3959 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-01 20:38:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:48 lr 0.000096	 wd 0.0000	time 0.1890 (0.2418)	loss 0.9419 (0.8661)	grad_norm 0.3975 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-01 20:38:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:24 lr 0.000096	 wd 0.0000	time 0.1899 (0.2407)	loss 0.8062 (0.8661)	grad_norm 0.3890 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-01 20:39:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1663 (0.2390)	loss 0.7939 (0.8666)	grad_norm 0.4112 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 20:39:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 3 training takes 0:10:07
[2024-08-01 20:39:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 29.427 (29.427)	Loss 0.3601 (0.3601)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 20:39:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.230 Acc@5 97.648
[2024-08-01 20:39:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 20:39:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.23%
[2024-08-01 20:39:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saving......
[2024-08-01 20:40:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saved !!!
[2024-08-01 20:40:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][0/2502]	eta 10:35:35 lr 0.000096	 wd 0.0000	time 15.2422 (15.2422)	loss 0.8760 (0.8760)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:40:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:16:10 lr 0.000096	 wd 0.0000	time 0.3698 (0.4042)	loss 0.7783 (0.8716)	grad_norm 0.4001 (0.3975)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:41:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:12:29 lr 0.000096	 wd 0.0000	time 0.1971 (0.3256)	loss 0.9009 (0.8674)	grad_norm 0.3717 (0.3968)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:41:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:29 lr 0.000095	 wd 0.0000	time 0.1809 (0.2857)	loss 0.8667 (0.8670)	grad_norm 0.4130 (0.3972)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:41:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:18 lr 0.000095	 wd 0.0000	time 0.1804 (0.2658)	loss 0.8491 (0.8627)	grad_norm 0.3774 (0.3976)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:42:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:08:36 lr 0.000095	 wd 0.0000	time 0.3830 (0.2578)	loss 0.9355 (0.8647)	grad_norm 0.3900 (0.3976)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:42:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:08:44 lr 0.000095	 wd 0.0000	time 0.2140 (0.2757)	loss 0.8330 (0.8667)	grad_norm 0.4168 (0.3978)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:43:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:08:00 lr 0.000095	 wd 0.0000	time 0.1872 (0.2666)	loss 0.9570 (0.8634)	grad_norm 0.3877 (0.3976)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:43:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:21 lr 0.000095	 wd 0.0000	time 0.1777 (0.2592)	loss 0.8379 (0.8634)	grad_norm 0.4100 (0.3976)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:43:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:51 lr 0.000095	 wd 0.0000	time 0.2356 (0.2568)	loss 0.8428 (0.8647)	grad_norm 0.4016 (0.3976)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:44:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:22 lr 0.000095	 wd 0.0000	time 0.1940 (0.2544)	loss 0.9077 (0.8647)	grad_norm 0.4022 (0.3979)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:44:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:51 lr 0.000095	 wd 0.0000	time 0.2184 (0.2505)	loss 0.9019 (0.8664)	grad_norm 0.4114 (0.3982)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:44:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:22 lr 0.000095	 wd 0.0000	time 0.1922 (0.2474)	loss 0.7246 (0.8662)	grad_norm 0.3849 (0.3980)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:45:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:54 lr 0.000095	 wd 0.0000	time 0.2427 (0.2453)	loss 0.8267 (0.8658)	grad_norm 0.3927 (0.3979)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:45:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:30 lr 0.000094	 wd 0.0000	time 0.2627 (0.2452)	loss 0.8633 (0.8653)	grad_norm 0.4051 (0.3981)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:46:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:04:03 lr 0.000094	 wd 0.0000	time 0.1933 (0.2434)	loss 0.7188 (0.8653)	grad_norm 0.3981 (0.3983)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:46:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:37 lr 0.000094	 wd 0.0000	time 0.1989 (0.2415)	loss 0.8223 (0.8651)	grad_norm 0.3873 (0.3983)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:46:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:12 lr 0.000094	 wd 0.0000	time 0.2246 (0.2398)	loss 1.0430 (0.8649)	grad_norm 0.4039 (0.3983)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:47:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:48 lr 0.000094	 wd 0.0000	time 0.4287 (0.2395)	loss 0.8965 (0.8653)	grad_norm 0.3995 (0.3983)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:47:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:24 lr 0.000094	 wd 0.0000	time 0.1748 (0.2395)	loss 0.8740 (0.8652)	grad_norm 0.3876 (0.3982)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:47:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:59 lr 0.000094	 wd 0.0000	time 0.2144 (0.2383)	loss 0.7480 (0.8648)	grad_norm nan (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-01 20:48:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:35 lr 0.000094	 wd 0.0000	time 0.1797 (0.2371)	loss 0.8184 (0.8656)	grad_norm 0.4196 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-01 20:48:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:11 lr 0.000094	 wd 0.0000	time 0.2327 (0.2366)	loss 0.9761 (0.8652)	grad_norm 0.3615 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-01 20:49:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:47 lr 0.000094	 wd 0.0000	time 0.2336 (0.2366)	loss 0.8281 (0.8656)	grad_norm 0.3981 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-01 20:49:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:24 lr 0.000093	 wd 0.0000	time 0.1948 (0.2357)	loss 0.8140 (0.8658)	grad_norm 0.3759 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-01 20:49:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1630 (0.2340)	loss 0.7598 (0.8658)	grad_norm 0.3900 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 20:49:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 4 training takes 0:09:49
[2024-08-01 20:50:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 39.818 (39.818)	Loss 0.3447 (0.3447)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 20:50:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.278 Acc@5 97.612
[2024-08-01 20:50:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 20:50:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.28%
[2024-08-01 20:50:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saving......
[2024-08-01 20:50:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saved !!!
[2024-08-01 20:51:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:06:38 lr 0.000093	 wd 0.0000	time 15.9867 (15.9867)	loss 0.8428 (0.8428)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:51:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:14:43 lr 0.000093	 wd 0.0000	time 0.2009 (0.3677)	loss 0.9146 (0.8540)	grad_norm 0.4199 (0.3998)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:51:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:11:09 lr 0.000093	 wd 0.0000	time 0.2098 (0.2907)	loss 0.7837 (0.8596)	grad_norm 0.4097 (0.4023)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:52:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:58 lr 0.000093	 wd 0.0000	time 0.1888 (0.2989)	loss 0.9624 (0.8580)	grad_norm 0.3867 (0.4010)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:52:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:40 lr 0.000093	 wd 0.0000	time 0.1681 (0.2762)	loss 0.9165 (0.8581)	grad_norm 0.4086 (0.4017)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:52:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:44 lr 0.000093	 wd 0.0000	time 0.2181 (0.2621)	loss 0.8062 (0.8586)	grad_norm 0.4142 (0.4010)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:53:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:02 lr 0.000093	 wd 0.0000	time 0.2310 (0.2536)	loss 0.8438 (0.8615)	grad_norm 0.4086 (0.4009)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:53:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:37 lr 0.000093	 wd 0.0000	time 0.1741 (0.2538)	loss 0.7612 (0.8609)	grad_norm 0.4276 (0.4007)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:54:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:03 lr 0.000093	 wd 0.0000	time 0.2009 (0.2490)	loss 0.8301 (0.8609)	grad_norm 0.4106 (0.4008)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:54:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:32 lr 0.000092	 wd 0.0000	time 0.2066 (0.2450)	loss 0.9077 (0.8612)	grad_norm 0.4023 (0.4008)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:54:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:02 lr 0.000092	 wd 0.0000	time 0.1820 (0.2416)	loss 0.9160 (0.8631)	grad_norm 0.3976 (0.4008)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:55:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:37 lr 0.000092	 wd 0.0000	time 0.2338 (0.2408)	loss 0.7993 (0.8642)	grad_norm 0.3931 (0.4010)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:55:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:14 lr 0.000092	 wd 0.0000	time 0.1808 (0.2412)	loss 0.8896 (0.8650)	grad_norm 0.3954 (0.4011)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:55:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:47 lr 0.000092	 wd 0.0000	time 0.2033 (0.2391)	loss 0.9438 (0.8645)	grad_norm 0.4089 (0.4007)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:56:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:21 lr 0.000092	 wd 0.0000	time 0.1883 (0.2371)	loss 0.8506 (0.8638)	grad_norm 0.4076 (0.4007)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:56:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:56 lr 0.000092	 wd 0.0000	time 0.2258 (0.2361)	loss 0.8394 (0.8644)	grad_norm 0.3980 (0.4006)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:57:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:33 lr 0.000092	 wd 0.0000	time 0.1812 (0.2364)	loss 0.7778 (0.8649)	grad_norm 0.4231 (0.4007)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:57:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:08 lr 0.000092	 wd 0.0000	time 0.1850 (0.2352)	loss 0.8569 (0.8655)	grad_norm 0.3946 (0.4009)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:57:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:44 lr 0.000091	 wd 0.0000	time 0.2253 (0.2340)	loss 0.8579 (0.8648)	grad_norm 0.4115 (0.4011)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:58:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:20 lr 0.000091	 wd 0.0000	time 0.2092 (0.2330)	loss 0.8301 (0.8647)	grad_norm 0.3972 (0.4012)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:58:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:57 lr 0.000091	 wd 0.0000	time 0.1858 (0.2335)	loss 0.9565 (0.8652)	grad_norm 0.4101 (0.4014)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:58:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:33 lr 0.000091	 wd 0.0000	time 0.2474 (0.2333)	loss 0.9292 (0.8647)	grad_norm 0.4083 (0.4015)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:59:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:10 lr 0.000091	 wd 0.0000	time 0.1883 (0.2325)	loss 0.9551 (0.8648)	grad_norm 0.3957 (0.4014)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 20:59:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:46 lr 0.000091	 wd 0.0000	time 0.1855 (0.2316)	loss 0.7485 (0.8646)	grad_norm 0.4300 (0.4015)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:00:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:23 lr 0.000091	 wd 0.0000	time 0.2440 (0.2314)	loss 0.7725 (0.8644)	grad_norm 0.4184 (0.4014)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:00:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1609 (0.2305)	loss 0.7427 (0.8639)	grad_norm 0.4060 (0.4014)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:00:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 5 training takes 0:09:43
[2024-08-01 21:00:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.380 (19.380)	Loss 0.3511 (0.3511)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 21:01:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.312 Acc@5 97.632
[2024-08-01 21:01:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 21:01:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.31%
[2024-08-01 21:01:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saving......
[2024-08-01 21:01:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saved !!!
[2024-08-01 21:01:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:17:04 lr 0.000091	 wd 0.0000	time 16.2367 (16.2367)	loss 0.9146 (0.9146)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:01:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:15:53 lr 0.000090	 wd 0.0000	time 0.2203 (0.3970)	loss 0.8398 (0.8739)	grad_norm 0.4251 (0.4005)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:02:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:11:58 lr 0.000090	 wd 0.0000	time 0.2041 (0.3122)	loss 0.7764 (0.8678)	grad_norm 0.4020 (0.4009)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:02:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:09 lr 0.000090	 wd 0.0000	time 0.2089 (0.2769)	loss 0.8638 (0.8678)	grad_norm 0.4038 (0.4016)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:02:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:09:05 lr 0.000090	 wd 0.0000	time 0.1953 (0.2597)	loss 0.8496 (0.8663)	grad_norm 0.3899 (0.4019)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:03:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:08:23 lr 0.000090	 wd 0.0000	time 0.2261 (0.2514)	loss 0.9014 (0.8659)	grad_norm 0.3912 (0.4022)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:03:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:07:59 lr 0.000090	 wd 0.0000	time 0.1989 (0.2522)	loss 0.8843 (0.8652)	grad_norm 0.4211 (0.4027)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:03:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:23 lr 0.000090	 wd 0.0000	time 0.1980 (0.2463)	loss 0.9780 (0.8650)	grad_norm 0.4112 (0.4032)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:04:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:06:51 lr 0.000090	 wd 0.0000	time 0.2008 (0.2417)	loss 0.7153 (0.8653)	grad_norm 0.3926 (0.4032)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:04:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:21 lr 0.000089	 wd 0.0000	time 0.2396 (0.2383)	loss 0.8682 (0.8649)	grad_norm 0.3794 (0.4033)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:05:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:02 lr 0.000089	 wd 0.0000	time 0.1923 (0.2414)	loss 0.8286 (0.8657)	grad_norm 0.3998 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-01 21:05:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:34 lr 0.000089	 wd 0.0000	time 0.1926 (0.2389)	loss 0.7969 (0.8644)	grad_norm 0.3995 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-01 21:05:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:08 lr 0.000089	 wd 0.0000	time 0.1943 (0.2367)	loss 0.8306 (0.8644)	grad_norm 0.4061 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-01 21:06:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:42 lr 0.000089	 wd 0.0000	time 0.2109 (0.2347)	loss 0.7534 (0.8639)	grad_norm 0.3956 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-01 21:06:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:19 lr 0.000089	 wd 0.0000	time 0.1966 (0.2351)	loss 0.8721 (0.8635)	grad_norm 0.3951 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-01 21:06:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:03:55 lr 0.000089	 wd 0.0000	time 0.1894 (0.2354)	loss 0.7539 (0.8633)	grad_norm 0.3931 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-01 21:07:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:31 lr 0.000089	 wd 0.0000	time 0.2297 (0.2340)	loss 0.7842 (0.8630)	grad_norm 0.3857 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-01 21:07:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:06 lr 0.000088	 wd 0.0000	time 0.1638 (0.2327)	loss 0.8350 (0.8618)	grad_norm 0.3970 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-01 21:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:42 lr 0.000088	 wd 0.0000	time 0.2030 (0.2321)	loss 0.8140 (0.8616)	grad_norm 0.3981 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-01 21:08:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:20 lr 0.000088	 wd 0.0000	time 0.1662 (0.2329)	loss 0.8760 (0.8621)	grad_norm 0.4012 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-01 21:08:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:56 lr 0.000088	 wd 0.0000	time 0.1893 (0.2324)	loss 0.9033 (0.8628)	grad_norm 0.4098 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-01 21:09:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:33 lr 0.000088	 wd 0.0000	time 0.1847 (0.2316)	loss 0.7905 (0.8627)	grad_norm 0.4038 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-01 21:09:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:09 lr 0.000088	 wd 0.0000	time 0.2377 (0.2308)	loss 0.8643 (0.8622)	grad_norm 0.4048 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-01 21:09:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:46 lr 0.000088	 wd 0.0000	time 0.2088 (0.2310)	loss 0.8096 (0.8622)	grad_norm 0.3950 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-01 21:10:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:23 lr 0.000087	 wd 0.0000	time 0.1582 (0.2306)	loss 0.8599 (0.8628)	grad_norm 0.3783 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-01 21:10:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1621 (0.2291)	loss 0.7681 (0.8634)	grad_norm 0.4171 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 21:10:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 6 training takes 0:09:37
[2024-08-01 21:10:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 20.492 (20.492)	Loss 0.3511 (0.3511)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 21:11:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.184 Acc@5 97.616
[2024-08-01 21:11:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 21:11:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.31%
[2024-08-01 21:11:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][0/2502]	eta 1 day, 0:27:26 lr 0.000087	 wd 0.0000	time 35.1903 (35.1903)	loss 0.8506 (0.8506)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:12:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:22:38 lr 0.000087	 wd 0.0000	time 0.1932 (0.5657)	loss 0.9380 (0.8612)	grad_norm 0.4042 (0.4047)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:12:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:14:49 lr 0.000087	 wd 0.0000	time 0.2268 (0.3863)	loss 0.8516 (0.8596)	grad_norm 0.3847 (0.4060)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:12:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:12:14 lr 0.000087	 wd 0.0000	time 0.3882 (0.3334)	loss 0.8286 (0.8571)	grad_norm 0.4120 (0.4054)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:13:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:10:50 lr 0.000087	 wd 0.0000	time 0.1922 (0.3093)	loss 0.8643 (0.8618)	grad_norm 0.4327 (0.4060)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:13:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:09:37 lr 0.000087	 wd 0.0000	time 0.1622 (0.2886)	loss 0.7559 (0.8595)	grad_norm 0.3704 (0.4058)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:13:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:44 lr 0.000086	 wd 0.0000	time 0.1807 (0.2756)	loss 0.9683 (0.8617)	grad_norm 0.3827 (0.4056)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:14:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:08:01 lr 0.000086	 wd 0.0000	time 0.1979 (0.2670)	loss 0.7773 (0.8614)	grad_norm 0.3731 (0.4057)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:14:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:28 lr 0.000086	 wd 0.0000	time 0.1877 (0.2637)	loss 0.8145 (0.8603)	grad_norm 0.3961 (0.4056)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:15:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:54 lr 0.000086	 wd 0.0000	time 0.1838 (0.2588)	loss 0.8193 (0.8612)	grad_norm 0.3990 (0.4056)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:15:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:21 lr 0.000086	 wd 0.0000	time 0.2375 (0.2542)	loss 0.7559 (0.8611)	grad_norm 0.4161 (0.4054)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:15:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:50 lr 0.000086	 wd 0.0000	time 0.1782 (0.2502)	loss 0.7754 (0.8606)	grad_norm 0.4069 (0.4055)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:16:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:23 lr 0.000086	 wd 0.0000	time 0.2119 (0.2484)	loss 0.8872 (0.8600)	grad_norm 0.4010 (0.4054)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:16:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:57 lr 0.000085	 wd 0.0000	time 0.2260 (0.2475)	loss 0.8984 (0.8597)	grad_norm 0.3845 (0.4055)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:16:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:29 lr 0.000085	 wd 0.0000	time 0.1933 (0.2449)	loss 0.7598 (0.8599)	grad_norm 0.4056 (0.4057)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:17:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:04:03 lr 0.000085	 wd 0.0000	time 0.2093 (0.2428)	loss 0.8340 (0.8597)	grad_norm 0.4207 (0.4058)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:17:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:37 lr 0.000085	 wd 0.0000	time 0.2113 (0.2414)	loss 0.8633 (0.8595)	grad_norm 0.3967 (0.4058)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:18:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:13 lr 0.000085	 wd 0.0000	time 0.1782 (0.2417)	loss 0.9814 (0.8592)	grad_norm 0.3811 (0.4058)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:18:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:48 lr 0.000085	 wd 0.0000	time 0.1838 (0.2404)	loss 0.8418 (0.8593)	grad_norm 0.3988 (0.4058)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:18:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:23 lr 0.000085	 wd 0.0000	time 0.2153 (0.2391)	loss 0.8926 (0.8592)	grad_norm 0.3975 (0.4059)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:19:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:59 lr 0.000084	 wd 0.0000	time 0.1924 (0.2380)	loss 0.8193 (0.8589)	grad_norm 0.4137 (0.4058)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:19:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:35 lr 0.000084	 wd 0.0000	time 0.1668 (0.2382)	loss 1.0029 (0.8599)	grad_norm 0.4212 (0.4060)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:19:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:11 lr 0.000084	 wd 0.0000	time 0.1885 (0.2374)	loss 0.6807 (0.8592)	grad_norm 0.4284 (0.4060)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:20:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:47 lr 0.000084	 wd 0.0000	time 0.1800 (0.2364)	loss 0.9365 (0.8593)	grad_norm 0.3999 (0.4061)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:20:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:24 lr 0.000084	 wd 0.0000	time 0.1995 (0.2354)	loss 0.9443 (0.8595)	grad_norm 0.4168 (0.4062)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:20:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1606 (0.2337)	loss 0.8574 (0.8601)	grad_norm 0.4214 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 21:21:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 7 training takes 0:09:49
[2024-08-01 21:21:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 37.559 (37.559)	Loss 0.3477 (0.3477)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 21:21:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.246 Acc@5 97.638
[2024-08-01 21:21:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 21:21:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.31%
[2024-08-01 21:22:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][0/2502]	eta 11:08:16 lr 0.000084	 wd 0.0000	time 16.0259 (16.0259)	loss 0.7705 (0.7705)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:22:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:15:02 lr 0.000083	 wd 0.0000	time 0.2120 (0.3758)	loss 0.8433 (0.8633)	grad_norm 0.4006 (0.4089)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:22:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:11:47 lr 0.000083	 wd 0.0000	time 0.1996 (0.3074)	loss 0.8491 (0.8619)	grad_norm 0.4069 (0.4082)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:23:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:06 lr 0.000083	 wd 0.0000	time 0.1809 (0.2754)	loss 0.8223 (0.8584)	grad_norm 0.4239 (0.4075)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:23:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:03 lr 0.000083	 wd 0.0000	time 0.2043 (0.2584)	loss 0.9512 (0.8599)	grad_norm 0.4030 (0.4069)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:23:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:08:15 lr 0.000083	 wd 0.0000	time 0.1762 (0.2475)	loss 0.8042 (0.8610)	grad_norm 0.4056 (0.4074)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:24:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:07:46 lr 0.000083	 wd 0.0000	time 0.2176 (0.2455)	loss 0.8369 (0.8609)	grad_norm 0.4335 (0.4070)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:24:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:19 lr 0.000083	 wd 0.0000	time 0.1932 (0.2440)	loss 0.8643 (0.8603)	grad_norm 0.4243 (0.4070)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:25:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:06:48 lr 0.000082	 wd 0.0000	time 0.1981 (0.2399)	loss 0.7383 (0.8597)	grad_norm 0.4051 (0.4073)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:25:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:19 lr 0.000082	 wd 0.0000	time 0.1848 (0.2366)	loss 0.9814 (0.8606)	grad_norm 0.3958 (0.4074)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:25:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:05:53 lr 0.000082	 wd 0.0000	time 0.2031 (0.2353)	loss 1.0078 (0.8614)	grad_norm 0.4026 (0.4074)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:26:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:30 lr 0.000082	 wd 0.0000	time 0.1840 (0.2358)	loss 0.9282 (0.8611)	grad_norm 0.4149 (0.4075)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:26:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:04 lr 0.000082	 wd 0.0000	time 0.2019 (0.2340)	loss 0.8086 (0.8609)	grad_norm 0.4072 (0.4075)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:26:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:39 lr 0.000082	 wd 0.0000	time 0.1996 (0.2323)	loss 0.8101 (0.8611)	grad_norm 0.4085 (0.4078)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:27:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:14 lr 0.000081	 wd 0.0000	time 0.2300 (0.2309)	loss 0.8198 (0.8610)	grad_norm 0.4056 (0.4077)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:27:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:51 lr 0.000081	 wd 0.0000	time 0.1735 (0.2313)	loss 0.8457 (0.8607)	grad_norm 0.4286 (0.4079)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:28:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:28 lr 0.000081	 wd 0.0000	time 0.1812 (0.2310)	loss 0.9355 (0.8603)	grad_norm 0.4031 (0.4078)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:28:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:04 lr 0.000081	 wd 0.0000	time 0.1932 (0.2301)	loss 0.8555 (0.8610)	grad_norm 0.3980 (0.4081)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:28:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:40 lr 0.000081	 wd 0.0000	time 0.1800 (0.2291)	loss 0.8457 (0.8615)	grad_norm 0.4181 (0.4080)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:29:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:17 lr 0.000081	 wd 0.0000	time 0.2095 (0.2289)	loss 0.7671 (0.8610)	grad_norm 0.3861 (0.4081)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:29:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:55 lr 0.000080	 wd 0.0000	time 0.1757 (0.2299)	loss 0.7808 (0.8611)	grad_norm 0.4391 (0.4081)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:29:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:32 lr 0.000080	 wd 0.0000	time 0.1796 (0.2293)	loss 0.8745 (0.8613)	grad_norm 0.4120 (0.4082)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:30:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:09 lr 0.000080	 wd 0.0000	time 0.2268 (0.2286)	loss 0.8022 (0.8609)	grad_norm 0.4092 (0.4083)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:30:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:46 lr 0.000080	 wd 0.0000	time 0.2048 (0.2282)	loss 0.9404 (0.8607)	grad_norm 0.4011 (0.4083)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:31:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:23 lr 0.000080	 wd 0.0000	time 0.1615 (0.2287)	loss 0.9604 (0.8606)	grad_norm 0.4275 (0.4085)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:31:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1616 (0.2273)	loss 0.8813 (0.8607)	grad_norm 0.4162 (0.4086)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:31:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 8 training takes 0:09:33
[2024-08-01 21:31:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.376 (21.376)	Loss 0.3513 (0.3513)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 21:31:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.308 Acc@5 97.636
[2024-08-01 21:31:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 21:31:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.31%
[2024-08-01 21:32:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][0/2502]	eta 17:11:05 lr 0.000080	 wd 0.0000	time 24.7264 (24.7264)	loss 0.8472 (0.8472)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:32:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:18:57 lr 0.000079	 wd 0.0000	time 0.2038 (0.4736)	loss 0.9609 (0.8555)	grad_norm 0.4225 (0.4082)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:33:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:13:02 lr 0.000079	 wd 0.0000	time 0.1940 (0.3401)	loss 0.7178 (0.8531)	grad_norm 0.4014 (0.4090)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:33:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:51 lr 0.000079	 wd 0.0000	time 0.1933 (0.2957)	loss 0.9038 (0.8554)	grad_norm 0.3838 (0.4092)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:33:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:40 lr 0.000079	 wd 0.0000	time 0.2326 (0.2763)	loss 0.8457 (0.8548)	grad_norm 0.3926 (0.4096)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:34:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:57 lr 0.000079	 wd 0.0000	time 0.1989 (0.2682)	loss 0.6689 (0.8599)	grad_norm 0.4200 (0.4099)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:34:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:12 lr 0.000079	 wd 0.0000	time 0.1712 (0.2587)	loss 0.6948 (0.8577)	grad_norm 0.4227 (0.4092)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:34:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:33 lr 0.000078	 wd 0.0000	time 0.1708 (0.2516)	loss 0.9155 (0.8583)	grad_norm 0.4168 (0.4093)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:35:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:06:59 lr 0.000078	 wd 0.0000	time 0.1914 (0.2464)	loss 0.8994 (0.8593)	grad_norm 0.3863 (0.4095)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:35:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:32 lr 0.000078	 wd 0.0000	time 0.1854 (0.2452)	loss 1.0068 (0.8599)	grad_norm 0.4096 (0.4094)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:36:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:07 lr 0.000078	 wd 0.0000	time 0.1774 (0.2445)	loss 0.9590 (0.8604)	grad_norm 0.4166 (0.4092)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:36:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:38 lr 0.000078	 wd 0.0000	time 0.2193 (0.2417)	loss 0.7939 (0.8604)	grad_norm 0.4278 (0.4091)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:36:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:11 lr 0.000078	 wd 0.0000	time 0.1826 (0.2389)	loss 0.9390 (0.8602)	grad_norm 0.4189 (0.4091)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:37:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:45 lr 0.000077	 wd 0.0000	time 0.2442 (0.2379)	loss 0.9385 (0.8608)	grad_norm 0.3880 (0.4090)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:37:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:22 lr 0.000077	 wd 0.0000	time 0.1696 (0.2379)	loss 0.8643 (0.8612)	grad_norm 0.3956 (0.4092)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:37:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:56 lr 0.000077	 wd 0.0000	time 0.1858 (0.2363)	loss 0.8921 (0.8613)	grad_norm 0.4279 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-01 21:38:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:31 lr 0.000077	 wd 0.0000	time 0.2218 (0.2347)	loss 0.8662 (0.8608)	grad_norm 0.3972 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-01 21:38:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:07 lr 0.000077	 wd 0.0000	time 0.2071 (0.2334)	loss 0.8115 (0.8616)	grad_norm 0.3896 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-01 21:38:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:44 lr 0.000077	 wd 0.0000	time 0.1847 (0.2338)	loss 0.7114 (0.8614)	grad_norm 0.4218 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-01 21:39:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:20 lr 0.000076	 wd 0.0000	time 0.1940 (0.2333)	loss 0.8989 (0.8617)	grad_norm 0.4071 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-01 21:39:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:56 lr 0.000076	 wd 0.0000	time 0.1880 (0.2324)	loss 0.9082 (0.8626)	grad_norm 0.4041 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-01 21:40:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:32 lr 0.000076	 wd 0.0000	time 0.1949 (0.2313)	loss 1.0039 (0.8631)	grad_norm 0.3911 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-01 21:40:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:09 lr 0.000076	 wd 0.0000	time 0.2063 (0.2310)	loss 0.8984 (0.8633)	grad_norm 0.4132 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-01 21:40:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:46 lr 0.000076	 wd 0.0000	time 0.1726 (0.2314)	loss 0.8428 (0.8629)	grad_norm 0.4424 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-01 21:41:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:23 lr 0.000075	 wd 0.0000	time 0.1917 (0.2307)	loss 0.8140 (0.8630)	grad_norm 0.4132 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-01 21:41:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1645 (0.2290)	loss 0.8564 (0.8631)	grad_norm 0.3875 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 21:41:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 9 training takes 0:09:37
[2024-08-01 21:42:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 39.139 (39.139)	Loss 0.3464 (0.3464)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 21:42:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.240 Acc@5 97.656
[2024-08-01 21:42:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-08-01 21:42:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.31%
[2024-08-01 21:42:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][0/2502]	eta 11:59:49 lr 0.000075	 wd 0.0000	time 17.2619 (17.2619)	loss 1.0010 (1.0010)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:43:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:15:00 lr 0.000075	 wd 0.0000	time 0.1784 (0.3749)	loss 0.6992 (0.8725)	grad_norm 0.4116 (0.4116)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:43:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:11:16 lr 0.000075	 wd 0.0000	time 0.2236 (0.2940)	loss 0.9263 (0.8653)	grad_norm 0.4235 (0.4117)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:43:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:57 lr 0.000075	 wd 0.0000	time 0.2046 (0.2988)	loss 0.8140 (0.8617)	grad_norm 0.4052 (0.4117)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:44:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:40 lr 0.000075	 wd 0.0000	time 0.1714 (0.2759)	loss 0.9058 (0.8602)	grad_norm 0.4295 (0.4119)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:44:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:43 lr 0.000074	 wd 0.0000	time 0.1805 (0.2617)	loss 0.7549 (0.8614)	grad_norm 0.4257 (0.4124)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:44:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:00 lr 0.000074	 wd 0.0000	time 0.1788 (0.2525)	loss 0.9268 (0.8605)	grad_norm 0.4095 (0.4119)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:45:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:51 lr 0.000074	 wd 0.0000	time 0.2337 (0.2616)	loss 0.7939 (0.8595)	grad_norm 0.3923 (0.4121)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:45:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:14 lr 0.000074	 wd 0.0000	time 0.2156 (0.2554)	loss 0.8604 (0.8600)	grad_norm 0.4045 (0.4124)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:46:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:41 lr 0.000074	 wd 0.0000	time 0.1908 (0.2505)	loss 0.8101 (0.8608)	grad_norm 0.4133 (0.4122)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:46:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:09 lr 0.000073	 wd 0.0000	time 0.2135 (0.2463)	loss 0.7959 (0.8608)	grad_norm 0.4102 (0.4123)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:46:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:43 lr 0.000073	 wd 0.0000	time 0.2245 (0.2452)	loss 0.7852 (0.8607)	grad_norm 0.4117 (0.4121)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:47:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:17 lr 0.000073	 wd 0.0000	time 0.1926 (0.2441)	loss 0.9546 (0.8604)	grad_norm 0.4015 (0.4123)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:47:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:50 lr 0.000073	 wd 0.0000	time 0.1871 (0.2417)	loss 0.8594 (0.8605)	grad_norm 0.4185 (0.4125)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:48:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:23 lr 0.000073	 wd 0.0000	time 0.1669 (0.2395)	loss 0.7725 (0.8604)	grad_norm 0.4418 (0.4124)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:48:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:58 lr 0.000073	 wd 0.0000	time 0.2104 (0.2384)	loss 0.8286 (0.8602)	grad_norm 0.4275 (0.4121)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:48:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:35 lr 0.000072	 wd 0.0000	time 0.1926 (0.2385)	loss 0.7598 (0.8605)	grad_norm 0.3938 (0.4121)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:49:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:10 lr 0.000072	 wd 0.0000	time 0.1857 (0.2372)	loss 0.8838 (0.8608)	grad_norm 0.3995 (0.4121)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:49:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:45 lr 0.000072	 wd 0.0000	time 0.1772 (0.2357)	loss 0.9326 (0.8607)	grad_norm 0.4302 (0.4122)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:49:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:21 lr 0.000072	 wd 0.0000	time 0.2579 (0.2346)	loss 0.9229 (0.8607)	grad_norm 0.4170 (0.4123)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:50:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:58 lr 0.000072	 wd 0.0000	time 0.4238 (0.2353)	loss 0.8623 (0.8611)	grad_norm 0.4172 (0.4125)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:50:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:34 lr 0.000071	 wd 0.0000	time 0.2226 (0.2348)	loss 0.8530 (0.8610)	grad_norm 0.4246 (0.4124)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:51:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:10 lr 0.000071	 wd 0.0000	time 0.1921 (0.2339)	loss 0.8677 (0.8615)	grad_norm 0.4118 (0.4124)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:51:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:47 lr 0.000071	 wd 0.0000	time 0.1745 (0.2328)	loss 0.9180 (0.8612)	grad_norm 0.4066 (0.4124)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:51:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:23 lr 0.000071	 wd 0.0000	time 0.2107 (0.2325)	loss 0.8506 (0.8616)	grad_norm 0.4014 (0.4124)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:52:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1695 (0.2313)	loss 0.9771 (0.8611)	grad_norm 0.4138 (0.4125)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:52:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 10 training takes 0:09:44
[2024-08-01 21:52:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.987 (18.987)	Loss 0.3508 (0.3508)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 21:52:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.318 Acc@5 97.630
[2024-08-01 21:52:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 21:52:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.32%
[2024-08-01 21:52:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saving......
[2024-08-01 21:52:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saved !!!
[2024-08-01 21:53:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][0/2502]	eta 10:49:06 lr 0.000071	 wd 0.0000	time 15.5662 (15.5662)	loss 0.7856 (0.7856)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:53:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:16:09 lr 0.000070	 wd 0.0000	time 0.2086 (0.4035)	loss 0.8687 (0.8556)	grad_norm 0.4139 (0.4132)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:53:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:02 lr 0.000070	 wd 0.0000	time 0.1888 (0.3139)	loss 0.8770 (0.8578)	grad_norm 0.4298 (0.4136)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:54:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:12 lr 0.000070	 wd 0.0000	time 0.2049 (0.2784)	loss 0.9639 (0.8590)	grad_norm 0.4278 (0.4144)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:54:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:09:07 lr 0.000070	 wd 0.0000	time 0.1986 (0.2605)	loss 0.9272 (0.8571)	grad_norm 0.4223 (0.4139)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 21:54:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:08:24 lr 0.000070	 wd 0.0000	time 0.2248 (0.2518)	loss 0.7490 (0.8569)	grad_norm 0.3990 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7964MB
[2024-08-01 21:55:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:10 lr 0.000069	 wd 0.0000	time 0.1897 (0.2578)	loss 1.0381 (0.8550)	grad_norm 0.4011 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7964MB
[2024-08-01 21:55:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:31 lr 0.000069	 wd 0.0000	time 0.1706 (0.2508)	loss 0.8594 (0.8574)	grad_norm 0.4139 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7964MB
[2024-08-01 21:56:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:06:58 lr 0.000069	 wd 0.0000	time 0.2060 (0.2457)	loss 0.8882 (0.8585)	grad_norm 0.4195 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7964MB
[2024-08-01 21:56:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:28 lr 0.000069	 wd 0.0000	time 0.2324 (0.2426)	loss 0.9731 (0.8587)	grad_norm 0.4251 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7964MB
[2024-08-01 21:56:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:06 lr 0.000069	 wd 0.0000	time 0.1662 (0.2439)	loss 0.8135 (0.8600)	grad_norm 0.4128 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-01 21:57:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:37 lr 0.000069	 wd 0.0000	time 0.1806 (0.2409)	loss 0.7891 (0.8603)	grad_norm 0.4138 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-01 21:57:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:10 lr 0.000068	 wd 0.0000	time 0.1778 (0.2385)	loss 0.9287 (0.8608)	grad_norm 0.4170 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-01 21:57:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:43 lr 0.000068	 wd 0.0000	time 0.2098 (0.2363)	loss 0.7373 (0.8610)	grad_norm 0.4039 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-01 21:58:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:19 lr 0.000068	 wd 0.0000	time 0.1905 (0.2358)	loss 0.8306 (0.8615)	grad_norm 0.4436 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-01 21:58:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:03:56 lr 0.000068	 wd 0.0000	time 0.2545 (0.2360)	loss 0.9551 (0.8613)	grad_norm 0.4193 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-01 21:59:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:31 lr 0.000068	 wd 0.0000	time 0.1913 (0.2343)	loss 0.9277 (0.8614)	grad_norm 0.4454 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-01 21:59:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:06 lr 0.000067	 wd 0.0000	time 0.2007 (0.2329)	loss 0.7778 (0.8617)	grad_norm 0.4160 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-01 21:59:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:43 lr 0.000067	 wd 0.0000	time 0.2358 (0.2322)	loss 1.0918 (0.8625)	grad_norm 0.4129 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-01 22:00:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:20 lr 0.000067	 wd 0.0000	time 0.1785 (0.2330)	loss 0.7661 (0.8630)	grad_norm 0.4019 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-01 22:00:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:56 lr 0.000067	 wd 0.0000	time 0.1754 (0.2322)	loss 0.9082 (0.8627)	grad_norm 0.4099 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-01 22:00:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:32 lr 0.000067	 wd 0.0000	time 0.2016 (0.2312)	loss 0.8433 (0.8625)	grad_norm 0.4338 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-01 22:01:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:09 lr 0.000066	 wd 0.0000	time 0.2030 (0.2304)	loss 0.8843 (0.8625)	grad_norm 0.4291 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-01 22:01:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:46 lr 0.000066	 wd 0.0000	time 0.1744 (0.2305)	loss 0.8638 (0.8626)	grad_norm 0.4109 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-01 22:01:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:23 lr 0.000066	 wd 0.0000	time 0.1825 (0.2306)	loss 0.8696 (0.8629)	grad_norm 0.4022 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-01 22:02:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1622 (0.2289)	loss 1.0342 (0.8623)	grad_norm 0.4231 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 22:02:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 11 training takes 0:09:36
[2024-08-01 22:02:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.086 (18.086)	Loss 0.3481 (0.3481)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 22:02:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.254 Acc@5 97.610
[2024-08-01 22:02:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 22:02:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.32%
[2024-08-01 22:03:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][0/2502]	eta 1 day, 0:51:17 lr 0.000066	 wd 0.0000	time 35.7624 (35.7624)	loss 0.8779 (0.8779)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:03:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:23:43 lr 0.000066	 wd 0.0000	time 0.2101 (0.5928)	loss 0.8057 (0.8500)	grad_norm 0.4329 (0.4169)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:04:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:15:21 lr 0.000065	 wd 0.0000	time 0.1915 (0.4003)	loss 0.8428 (0.8562)	grad_norm 0.4194 (0.4151)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:04:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:12:32 lr 0.000065	 wd 0.0000	time 0.3618 (0.3419)	loss 0.8950 (0.8655)	grad_norm 0.4532 (0.4154)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:05:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:11:30 lr 0.000065	 wd 0.0000	time 0.2038 (0.3285)	loss 0.8218 (0.8669)	grad_norm 0.4073 (0.4158)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:05:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:10:07 lr 0.000065	 wd 0.0000	time 0.1938 (0.3036)	loss 0.7563 (0.8659)	grad_norm 0.4116 (0.4156)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:05:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:09:07 lr 0.000065	 wd 0.0000	time 0.1848 (0.2877)	loss 0.7637 (0.8658)	grad_norm 0.4205 (0.4158)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:06:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:08:19 lr 0.000064	 wd 0.0000	time 0.2827 (0.2774)	loss 0.7856 (0.8653)	grad_norm 0.4053 (0.4153)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:06:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:59 lr 0.000064	 wd 0.0000	time 0.1712 (0.2815)	loss 0.8813 (0.8640)	grad_norm 0.4034 (0.4151)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:06:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:07:18 lr 0.000064	 wd 0.0000	time 0.1907 (0.2735)	loss 0.7900 (0.8634)	grad_norm 0.4302 (0.4156)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:07:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:40 lr 0.000064	 wd 0.0000	time 0.1777 (0.2668)	loss 0.9043 (0.8633)	grad_norm 0.4096 (0.4157)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:07:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:06:06 lr 0.000064	 wd 0.0000	time 0.2055 (0.2617)	loss 0.7285 (0.8633)	grad_norm 0.3999 (0.4156)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:08:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:38 lr 0.000063	 wd 0.0000	time 0.8363 (0.2601)	loss 0.8765 (0.8628)	grad_norm 0.4225 (0.4157)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:08:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:05:09 lr 0.000063	 wd 0.0000	time 0.2248 (0.2572)	loss 0.7764 (0.8629)	grad_norm 0.4295 (0.4152)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:08:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:39 lr 0.000063	 wd 0.0000	time 0.2314 (0.2540)	loss 0.9263 (0.8632)	grad_norm 0.4096 (0.4153)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:09:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:04:11 lr 0.000063	 wd 0.0000	time 0.1877 (0.2509)	loss 0.8218 (0.8640)	grad_norm 0.4161 (0.4154)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:09:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:45 lr 0.000063	 wd 0.0000	time 0.2183 (0.2495)	loss 0.8594 (0.8635)	grad_norm 0.4022 (0.4154)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:09:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:19 lr 0.000062	 wd 0.0000	time 0.2048 (0.2486)	loss 0.8296 (0.8635)	grad_norm 0.4011 (0.4156)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:10:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:53 lr 0.000062	 wd 0.0000	time 0.2163 (0.2467)	loss 0.7891 (0.8637)	grad_norm 0.4091 (0.4159)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:10:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:27 lr 0.000062	 wd 0.0000	time 0.2643 (0.2450)	loss 0.8301 (0.8634)	grad_norm 0.4148 (0.4159)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:11:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:02:02 lr 0.000062	 wd 0.0000	time 0.2425 (0.2437)	loss 0.8159 (0.8636)	grad_norm 0.4216 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-01 22:11:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:37 lr 0.000062	 wd 0.0000	time 0.1833 (0.2437)	loss 0.8359 (0.8640)	grad_norm 0.4173 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-01 22:11:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:13 lr 0.000061	 wd 0.0000	time 0.1800 (0.2424)	loss 0.8911 (0.8643)	grad_norm 0.4277 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-01 22:12:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:48 lr 0.000061	 wd 0.0000	time 0.2080 (0.2411)	loss 0.8735 (0.8640)	grad_norm 0.3868 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-01 22:12:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:24 lr 0.000061	 wd 0.0000	time 0.2059 (0.2399)	loss 0.8467 (0.8632)	grad_norm 0.4170 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-01 22:12:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1735 (0.2382)	loss 0.8853 (0.8630)	grad_norm 0.4232 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 22:12:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 12 training takes 0:10:02
[2024-08-01 22:13:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 32.445 (32.445)	Loss 0.3462 (0.3462)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 22:13:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.350 Acc@5 97.674
[2024-08-01 22:13:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-01 22:13:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.35%
[2024-08-01 22:13:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saving......
[2024-08-01 22:13:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saved !!!
[2024-08-01 22:13:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][0/2502]	eta 11:29:32 lr 0.000061	 wd 0.0000	time 16.5359 (16.5359)	loss 0.8232 (0.8232)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:14:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:15:40 lr 0.000061	 wd 0.0000	time 0.2468 (0.3914)	loss 0.7837 (0.8530)	grad_norm 0.4064 (0.4130)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:14:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:11:52 lr 0.000060	 wd 0.0000	time 0.1814 (0.3094)	loss 0.7656 (0.8607)	grad_norm 0.4249 (0.4134)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:15:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:07 lr 0.000060	 wd 0.0000	time 0.1846 (0.2760)	loss 0.7720 (0.8550)	grad_norm 0.4281 (0.4143)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:15:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:09:02 lr 0.000060	 wd 0.0000	time 0.1740 (0.2583)	loss 0.7368 (0.8564)	grad_norm 0.4307 (0.4150)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:15:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:08:16 lr 0.000060	 wd 0.0000	time 0.2176 (0.2482)	loss 0.8320 (0.8569)	grad_norm 0.4197 (0.4157)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:16:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:07:50 lr 0.000060	 wd 0.0000	time 0.1768 (0.2473)	loss 0.7910 (0.8580)	grad_norm 0.4103 (0.4166)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:16:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:17 lr 0.000059	 wd 0.0000	time 0.2006 (0.2429)	loss 1.0039 (0.8585)	grad_norm 0.4501 (0.4164)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:16:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:06:46 lr 0.000059	 wd 0.0000	time 0.2073 (0.2386)	loss 0.8843 (0.8586)	grad_norm 0.4146 (0.4167)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:17:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:17 lr 0.000059	 wd 0.0000	time 0.2047 (0.2353)	loss 0.9058 (0.8595)	grad_norm 0.4042 (0.4172)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:17:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:05:54 lr 0.000059	 wd 0.0000	time 0.3737 (0.2358)	loss 0.9341 (0.8607)	grad_norm 0.4261 (0.4176)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:18:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:34 lr 0.000059	 wd 0.0000	time 0.1760 (0.2384)	loss 0.8325 (0.8602)	grad_norm 0.4090 (0.4174)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:18:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:07 lr 0.000058	 wd 0.0000	time 0.1891 (0.2360)	loss 0.9492 (0.8604)	grad_norm 0.4293 (0.4173)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:18:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:41 lr 0.000058	 wd 0.0000	time 0.1653 (0.2340)	loss 0.8662 (0.8611)	grad_norm 0.4272 (0.4176)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:19:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:16 lr 0.000058	 wd 0.0000	time 0.2116 (0.2330)	loss 1.0195 (0.8608)	grad_norm 0.4027 (0.4177)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:19:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:54 lr 0.000058	 wd 0.0000	time 0.1852 (0.2345)	loss 0.8740 (0.8609)	grad_norm 0.4276 (0.4178)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:19:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:30 lr 0.000058	 wd 0.0000	time 0.2117 (0.2330)	loss 0.8066 (0.8612)	grad_norm 0.3942 (0.4179)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:20:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:05 lr 0.000057	 wd 0.0000	time 0.2042 (0.2317)	loss 0.8096 (0.8613)	grad_norm 0.4050 (0.4179)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:20:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:41 lr 0.000057	 wd 0.0000	time 0.2281 (0.2307)	loss 0.8345 (0.8613)	grad_norm 0.4429 (0.4180)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:21:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:19 lr 0.000057	 wd 0.0000	time 0.1744 (0.2311)	loss 0.7949 (0.8602)	grad_norm 0.4364 (0.4181)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:21:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:55 lr 0.000057	 wd 0.0000	time 0.1819 (0.2311)	loss 0.8501 (0.8610)	grad_norm 0.4067 (0.4182)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:21:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:32 lr 0.000057	 wd 0.0000	time 0.2233 (0.2303)	loss 0.8467 (0.8614)	grad_norm 0.3761 (0.4181)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:22:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:09 lr 0.000056	 wd 0.0000	time 0.1798 (0.2293)	loss 0.9355 (0.8616)	grad_norm 0.4339 (0.4181)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:22:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:46 lr 0.000056	 wd 0.0000	time 0.2198 (0.2291)	loss 0.7944 (0.8611)	grad_norm 0.4097 (0.4182)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:22:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:23 lr 0.000056	 wd 0.0000	time 0.1832 (0.2292)	loss 0.8774 (0.8615)	grad_norm 0.3916 (0.4183)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:23:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1673 (0.2276)	loss 0.8013 (0.8616)	grad_norm 0.4104 (0.4182)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:23:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 13 training takes 0:09:34
[2024-08-01 22:23:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.370 (19.370)	Loss 0.3462 (0.3462)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 22:23:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.328 Acc@5 97.674
[2024-08-01 22:23:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 22:23:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.35%
[2024-08-01 22:24:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][0/2502]	eta 22:07:54 lr 0.000056	 wd 0.0000	time 31.8442 (31.8442)	loss 0.9570 (0.9570)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:24:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:21:22 lr 0.000055	 wd 0.0000	time 0.1805 (0.5338)	loss 0.8354 (0.8589)	grad_norm 0.4232 (0.4197)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:25:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:14:15 lr 0.000055	 wd 0.0000	time 0.2062 (0.3714)	loss 0.8193 (0.8594)	grad_norm 0.4110 (0.4195)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:25:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:11:36 lr 0.000055	 wd 0.0000	time 0.2306 (0.3163)	loss 1.0957 (0.8618)	grad_norm 0.4084 (0.4185)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:25:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:10:54 lr 0.000055	 wd 0.0000	time 0.2066 (0.3111)	loss 1.0518 (0.8609)	grad_norm 0.4134 (0.4197)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:26:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:09:45 lr 0.000055	 wd 0.0000	time 0.2106 (0.2923)	loss 0.9092 (0.8609)	grad_norm 0.3969 (0.4195)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:26:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:50 lr 0.000054	 wd 0.0000	time 0.1749 (0.2788)	loss 0.8330 (0.8612)	grad_norm 0.4537 (0.4197)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:26:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:08:04 lr 0.000054	 wd 0.0000	time 0.1839 (0.2688)	loss 0.7852 (0.8601)	grad_norm 0.4225 (0.4203)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:27:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:28 lr 0.000054	 wd 0.0000	time 0.2276 (0.2638)	loss 0.7935 (0.8603)	grad_norm 0.4078 (0.4202)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:27:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:57 lr 0.000054	 wd 0.0000	time 0.1773 (0.2606)	loss 0.8511 (0.8600)	grad_norm 0.4475 (0.4203)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:28:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:24 lr 0.000054	 wd 0.0000	time 0.2072 (0.2557)	loss 0.8994 (0.8592)	grad_norm 0.4554 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-01 22:28:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:52 lr 0.000053	 wd 0.0000	time 0.2088 (0.2517)	loss 0.8232 (0.8592)	grad_norm 0.3979 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-01 22:28:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:24 lr 0.000053	 wd 0.0000	time 0.2383 (0.2489)	loss 0.8521 (0.8591)	grad_norm 0.4263 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-01 22:29:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:59 lr 0.000053	 wd 0.0000	time 0.2033 (0.2489)	loss 1.0508 (0.8589)	grad_norm 0.4271 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-01 22:29:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:31 lr 0.000053	 wd 0.0000	time 0.1831 (0.2467)	loss 0.8892 (0.8593)	grad_norm 0.3973 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-01 22:29:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:04 lr 0.000053	 wd 0.0000	time 0.1865 (0.2443)	loss 0.8384 (0.8597)	grad_norm 0.4257 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-01 22:30:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:38 lr 0.000052	 wd 0.0000	time 0.2093 (0.2422)	loss 0.8442 (0.8594)	grad_norm 0.4367 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-01 22:30:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:13 lr 0.000052	 wd 0.0000	time 0.2319 (0.2413)	loss 0.9941 (0.8600)	grad_norm 0.4542 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-01 22:31:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:49 lr 0.000052	 wd 0.0000	time 0.1673 (0.2409)	loss 0.6855 (0.8602)	grad_norm 0.4184 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-01 22:31:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:24 lr 0.000052	 wd 0.0000	time 0.2036 (0.2396)	loss 0.8203 (0.8600)	grad_norm 0.4198 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-01 22:31:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:59 lr 0.000052	 wd 0.0000	time 0.1890 (0.2382)	loss 0.7832 (0.8598)	grad_norm 0.4197 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-01 22:32:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:35 lr 0.000051	 wd 0.0000	time 0.2591 (0.2375)	loss 0.8984 (0.8600)	grad_norm 0.4144 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-01 22:32:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:11 lr 0.000051	 wd 0.0000	time 0.1892 (0.2377)	loss 0.8477 (0.8607)	grad_norm 0.4063 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-01 22:32:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:47 lr 0.000051	 wd 0.0000	time 0.1884 (0.2369)	loss 0.8394 (0.8604)	grad_norm 0.4322 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-01 22:33:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:24 lr 0.000051	 wd 0.0000	time 0.1991 (0.2359)	loss 0.9468 (0.8609)	grad_norm 0.4244 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-01 22:33:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1614 (0.2340)	loss 0.8770 (0.8612)	grad_norm 0.4312 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 22:33:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 14 training takes 0:09:50
[2024-08-01 22:34:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 39.580 (39.580)	Loss 0.3438 (0.3438)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 22:34:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.334 Acc@5 97.638
[2024-08-01 22:34:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 22:34:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.35%
[2024-08-01 22:34:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:21:27 lr 0.000051	 wd 0.0000	time 14.9030 (14.9030)	loss 0.7871 (0.7871)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:35:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:14:52 lr 0.000050	 wd 0.0000	time 0.2213 (0.3718)	loss 0.9663 (0.8658)	grad_norm 0.4271 (0.4204)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:35:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:13:59 lr 0.000050	 wd 0.0000	time 0.1815 (0.3647)	loss 1.0020 (0.8621)	grad_norm 0.4260 (0.4221)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:36:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:11:31 lr 0.000050	 wd 0.0000	time 0.2042 (0.3142)	loss 0.9150 (0.8610)	grad_norm 0.4090 (0.4222)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:36:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:10:04 lr 0.000050	 wd 0.0000	time 0.1640 (0.2876)	loss 1.0127 (0.8621)	grad_norm 0.4365 (0.4220)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:36:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:09:03 lr 0.000049	 wd 0.0000	time 0.2511 (0.2715)	loss 0.7759 (0.8638)	grad_norm 0.4281 (0.4224)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:37:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:28 lr 0.000049	 wd 0.0000	time 0.1828 (0.2672)	loss 0.8311 (0.8634)	grad_norm 0.4368 (0.4221)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:37:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:49 lr 0.000049	 wd 0.0000	time 0.1873 (0.2605)	loss 0.8057 (0.8608)	grad_norm 0.4257 (0.4224)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:37:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:12 lr 0.000049	 wd 0.0000	time 0.1905 (0.2540)	loss 1.0156 (0.8613)	grad_norm 0.4304 (0.4223)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:38:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:38 lr 0.000049	 wd 0.0000	time 0.1829 (0.2489)	loss 0.7930 (0.8614)	grad_norm 0.4389 (0.4227)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:38:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:10 lr 0.000048	 wd 0.0000	time 0.2044 (0.2466)	loss 0.9180 (0.8610)	grad_norm 0.4131 (0.4229)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:38:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:44 lr 0.000048	 wd 0.0000	time 0.2512 (0.2458)	loss 0.8984 (0.8591)	grad_norm 0.4404 (0.4224)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:39:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:16 lr 0.000048	 wd 0.0000	time 0.2010 (0.2429)	loss 0.7935 (0.8601)	grad_norm 0.4075 (0.4222)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:39:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:48 lr 0.000048	 wd 0.0000	time 0.2077 (0.2402)	loss 0.8931 (0.8596)	grad_norm 0.4148 (0.4225)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:40:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:22 lr 0.000048	 wd 0.0000	time 0.1991 (0.2383)	loss 0.7729 (0.8601)	grad_norm 0.4322 (0.4227)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:40:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:59 lr 0.000047	 wd 0.0000	time 0.1926 (0.2389)	loss 0.9053 (0.8596)	grad_norm 0.4190 (0.4229)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:40:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:34 lr 0.000047	 wd 0.0000	time 0.1728 (0.2376)	loss 0.9199 (0.8597)	grad_norm 0.4197 (0.4231)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:41:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:09 lr 0.000047	 wd 0.0000	time 0.1782 (0.2360)	loss 0.7783 (0.8599)	grad_norm 0.4107 (0.4231)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:41:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:44 lr 0.000047	 wd 0.0000	time 0.2139 (0.2347)	loss 0.9976 (0.8605)	grad_norm 0.4585 (0.4231)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:41:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:21 lr 0.000047	 wd 0.0000	time 0.2200 (0.2343)	loss 0.9487 (0.8600)	grad_norm 0.4338 (0.4231)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:42:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:57 lr 0.000046	 wd 0.0000	time 0.1967 (0.2348)	loss 1.0078 (0.8609)	grad_norm 0.4569 (0.4231)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:42:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:33 lr 0.000046	 wd 0.0000	time 0.2022 (0.2338)	loss 0.8271 (0.8608)	grad_norm 0.4177 (0.4230)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:43:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:10 lr 0.000046	 wd 0.0000	time 0.1771 (0.2327)	loss 0.9038 (0.8611)	grad_norm 0.4142 (0.4228)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:43:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:46 lr 0.000046	 wd 0.0000	time 0.2360 (0.2323)	loss 0.8770 (0.8612)	grad_norm 0.4496 (0.4229)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:43:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:23 lr 0.000046	 wd 0.0000	time 0.1795 (0.2326)	loss 0.8896 (0.8612)	grad_norm 0.4154 (0.4231)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:44:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1734 (0.2311)	loss 1.0430 (0.8615)	grad_norm 0.4258 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 22:44:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 15 training takes 0:09:42
[2024-08-01 22:44:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_15.pth saving......
[2024-08-01 22:44:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_15.pth saved !!!
[2024-08-01 22:44:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.684 (21.684)	Loss 0.3494 (0.3494)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 22:44:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.356 Acc@5 97.668
[2024-08-01 22:44:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-01 22:44:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.36%
[2024-08-01 22:44:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saving......
[2024-08-01 22:44:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saved !!!
[2024-08-01 22:45:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][0/2502]	eta 21:38:35 lr 0.000045	 wd 0.0000	time 31.1414 (31.1414)	loss 0.7451 (0.7451)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:45:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:20:39 lr 0.000045	 wd 0.0000	time 0.1725 (0.5160)	loss 0.9595 (0.8720)	grad_norm 0.4296 (0.4256)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:46:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:13:52 lr 0.000045	 wd 0.0000	time 0.1994 (0.3616)	loss 0.8491 (0.8622)	grad_norm 0.4393 (0.4242)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:46:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:11:20 lr 0.000045	 wd 0.0000	time 0.1802 (0.3092)	loss 0.9106 (0.8622)	grad_norm 0.4179 (0.4229)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:46:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:10:20 lr 0.000045	 wd 0.0000	time 0.3729 (0.2953)	loss 0.8765 (0.8615)	grad_norm 0.4298 (0.4230)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:47:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:29 lr 0.000044	 wd 0.0000	time 0.2019 (0.2844)	loss 0.9590 (0.8610)	grad_norm 0.4099 (0.4232)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:47:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:08:35 lr 0.000044	 wd 0.0000	time 0.2072 (0.2712)	loss 0.9136 (0.8616)	grad_norm 0.4143 (0.4235)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:47:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:51 lr 0.000044	 wd 0.0000	time 0.1880 (0.2619)	loss 0.8784 (0.8622)	grad_norm 0.4193 (0.4234)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:48:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:19 lr 0.000044	 wd 0.0000	time 0.3152 (0.2583)	loss 0.8579 (0.8616)	grad_norm 0.4295 (0.4234)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:48:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:07:03 lr 0.000043	 wd 0.0000	time 0.1884 (0.2644)	loss 0.7847 (0.8631)	grad_norm 0.4200 (0.4237)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:49:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:06:28 lr 0.000043	 wd 0.0000	time 0.1941 (0.2587)	loss 0.8506 (0.8632)	grad_norm 0.4313 (0.4240)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:49:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:56 lr 0.000043	 wd 0.0000	time 0.1827 (0.2540)	loss 0.9409 (0.8635)	grad_norm 0.4417 (0.4243)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:49:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:27 lr 0.000043	 wd 0.0000	time 0.2188 (0.2512)	loss 0.8936 (0.8631)	grad_norm 0.4255 (0.4240)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:50:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:05:00 lr 0.000043	 wd 0.0000	time 0.1884 (0.2502)	loss 0.9609 (0.8626)	grad_norm 0.4273 (0.4241)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:50:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:32 lr 0.000042	 wd 0.0000	time 0.1957 (0.2477)	loss 0.7720 (0.8619)	grad_norm 0.3979 (0.4241)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:50:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:04:05 lr 0.000042	 wd 0.0000	time 0.1838 (0.2453)	loss 0.8042 (0.8614)	grad_norm 0.4017 (0.4244)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:51:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:39 lr 0.000042	 wd 0.0000	time 0.2036 (0.2431)	loss 0.7739 (0.8612)	grad_norm 0.4205 (0.4242)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:51:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:14 lr 0.000042	 wd 0.0000	time 0.1739 (0.2423)	loss 0.8462 (0.8611)	grad_norm 0.4310 (0.4245)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:52:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:49 lr 0.000042	 wd 0.0000	time 0.1822 (0.2422)	loss 0.9971 (0.8613)	grad_norm 0.4020 (0.4245)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:52:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:24 lr 0.000041	 wd 0.0000	time 0.1829 (0.2407)	loss 0.9565 (0.8603)	grad_norm 0.4231 (0.4244)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:52:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:02:00 lr 0.000041	 wd 0.0000	time 0.1953 (0.2392)	loss 0.8267 (0.8601)	grad_norm 0.4262 (0.4244)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:53:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:35 lr 0.000041	 wd 0.0000	time 0.2493 (0.2384)	loss 0.6670 (0.8598)	grad_norm 0.4147 (0.4246)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:53:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:12 lr 0.000041	 wd 0.0000	time 0.2516 (0.2384)	loss 0.7773 (0.8598)	grad_norm 0.4182 (0.4246)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:53:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:47 lr 0.000041	 wd 0.0000	time 0.2315 (0.2375)	loss 0.6724 (0.8593)	grad_norm 0.4449 (0.4244)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:54:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:24 lr 0.000040	 wd 0.0000	time 0.2278 (0.2365)	loss 0.7695 (0.8593)	grad_norm 0.4326 (0.4244)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:54:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1576 (0.2346)	loss 0.8306 (0.8590)	grad_norm 0.4667 (0.4245)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:54:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 16 training takes 0:09:51
[2024-08-01 22:55:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 36.222 (36.222)	Loss 0.3481 (0.3481)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 22:55:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.306 Acc@5 97.668
[2024-08-01 22:55:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 22:55:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.36%
[2024-08-01 22:55:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][0/2502]	eta 10:51:31 lr 0.000040	 wd 0.0000	time 15.6241 (15.6241)	loss 0.7603 (0.7603)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:56:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:14:49 lr 0.000040	 wd 0.0000	time 0.1933 (0.3702)	loss 0.9600 (0.8607)	grad_norm 0.4019 (0.4231)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:56:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:11:40 lr 0.000040	 wd 0.0000	time 0.1989 (0.3042)	loss 0.8433 (0.8634)	grad_norm 0.3923 (0.4240)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:56:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:15 lr 0.000040	 wd 0.0000	time 0.1888 (0.2797)	loss 0.8691 (0.8599)	grad_norm 0.4515 (0.4248)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:57:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:09 lr 0.000039	 wd 0.0000	time 0.1674 (0.2616)	loss 0.9346 (0.8585)	grad_norm 0.4105 (0.4251)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:57:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:21 lr 0.000039	 wd 0.0000	time 0.1902 (0.2503)	loss 0.7441 (0.8564)	grad_norm 0.4627 (0.4252)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:57:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:07:47 lr 0.000039	 wd 0.0000	time 0.2478 (0.2456)	loss 0.7915 (0.8579)	grad_norm 0.4525 (0.4256)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:58:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:19 lr 0.000039	 wd 0.0000	time 0.1854 (0.2440)	loss 0.8682 (0.8570)	grad_norm 0.4321 (0.4255)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:58:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:06:48 lr 0.000039	 wd 0.0000	time 0.1965 (0.2402)	loss 0.7739 (0.8574)	grad_norm 0.4128 (0.4256)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:59:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:19 lr 0.000038	 wd 0.0000	time 0.2258 (0.2368)	loss 0.9614 (0.8579)	grad_norm 0.4156 (0.4253)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:59:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:05:51 lr 0.000038	 wd 0.0000	time 0.2239 (0.2342)	loss 0.9155 (0.8580)	grad_norm 0.4277 (0.4254)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 22:59:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:29 lr 0.000038	 wd 0.0000	time 0.2840 (0.2349)	loss 0.7412 (0.8593)	grad_norm 0.4234 (0.4255)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:00:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:04 lr 0.000038	 wd 0.0000	time 0.1901 (0.2337)	loss 0.7627 (0.8607)	grad_norm 0.4392 (0.4259)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:00:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:38 lr 0.000038	 wd 0.0000	time 0.1928 (0.2319)	loss 0.8989 (0.8601)	grad_norm 0.3979 (0.4258)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:00:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:13 lr 0.000037	 wd 0.0000	time 0.1945 (0.2303)	loss 0.8901 (0.8610)	grad_norm 0.3981 (0.4258)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:01:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:50 lr 0.000037	 wd 0.0000	time 0.2106 (0.2299)	loss 0.8457 (0.8608)	grad_norm 0.4236 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-01 23:01:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:28 lr 0.000037	 wd 0.0000	time 0.2092 (0.2307)	loss 1.0068 (0.8606)	grad_norm 0.4501 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-01 23:01:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:04 lr 0.000037	 wd 0.0000	time 0.2089 (0.2296)	loss 0.9790 (0.8608)	grad_norm 0.4244 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-01 23:02:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:40 lr 0.000037	 wd 0.0000	time 0.1836 (0.2286)	loss 0.7534 (0.8623)	grad_norm 0.4263 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-01 23:02:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:17 lr 0.000036	 wd 0.0000	time 0.2039 (0.2279)	loss 0.7427 (0.8627)	grad_norm 0.4164 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-01 23:03:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:54 lr 0.000036	 wd 0.0000	time 0.1717 (0.2291)	loss 0.7930 (0.8622)	grad_norm 0.4176 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-01 23:03:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:31 lr 0.000036	 wd 0.0000	time 0.1933 (0.2284)	loss 0.7798 (0.8617)	grad_norm 0.4160 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-01 23:03:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:08 lr 0.000036	 wd 0.0000	time 0.1971 (0.2277)	loss 0.9146 (0.8615)	grad_norm 0.4281 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-01 23:04:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:45 lr 0.000036	 wd 0.0000	time 0.2074 (0.2270)	loss 0.8965 (0.8612)	grad_norm 0.4165 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-01 23:04:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:23 lr 0.000035	 wd 0.0000	time 0.2334 (0.2270)	loss 0.8276 (0.8615)	grad_norm 0.4251 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-01 23:04:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1614 (0.2262)	loss 0.8994 (0.8618)	grad_norm 0.4159 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 23:04:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 17 training takes 0:09:31
[2024-08-01 23:05:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 18.865 (18.865)	Loss 0.3452 (0.3452)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 23:05:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.338 Acc@5 97.688
[2024-08-01 23:05:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 23:05:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.36%
[2024-08-01 23:05:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][0/2502]	eta 10:34:05 lr 0.000035	 wd 0.0000	time 15.2061 (15.2061)	loss 0.9009 (0.9009)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:06:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:16:13 lr 0.000035	 wd 0.0000	time 0.2140 (0.4055)	loss 0.9585 (0.8631)	grad_norm 0.4382 (0.4266)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:06:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:12:08 lr 0.000035	 wd 0.0000	time 0.2174 (0.3163)	loss 0.8291 (0.8598)	grad_norm 0.4401 (0.4267)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:06:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:10:15 lr 0.000035	 wd 0.0000	time 0.1988 (0.2794)	loss 0.8911 (0.8642)	grad_norm 0.4205 (0.4276)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:07:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:09:08 lr 0.000034	 wd 0.0000	time 0.1854 (0.2609)	loss 0.8027 (0.8656)	grad_norm 0.4327 (0.4273)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:07:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:08:24 lr 0.000034	 wd 0.0000	time 0.2492 (0.2521)	loss 0.6904 (0.8652)	grad_norm 0.4181 (0.4263)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:08:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:07:56 lr 0.000034	 wd 0.0000	time 0.2017 (0.2505)	loss 0.9292 (0.8620)	grad_norm 0.4372 (0.4265)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:08:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:20 lr 0.000034	 wd 0.0000	time 0.2178 (0.2447)	loss 0.9136 (0.8588)	grad_norm 0.4047 (0.4261)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:08:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:06:48 lr 0.000034	 wd 0.0000	time 0.1704 (0.2402)	loss 1.0469 (0.8572)	grad_norm 0.4138 (0.4261)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:09:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:06:19 lr 0.000033	 wd 0.0000	time 0.1942 (0.2369)	loss 0.9375 (0.8579)	grad_norm 0.4383 (0.4262)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:09:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:05:58 lr 0.000033	 wd 0.0000	time 0.1972 (0.2390)	loss 0.8291 (0.8587)	grad_norm 0.4264 (0.4263)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:09:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:31 lr 0.000033	 wd 0.0000	time 0.1829 (0.2367)	loss 0.7764 (0.8597)	grad_norm 0.4186 (0.4262)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:10:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:05 lr 0.000033	 wd 0.0000	time 0.1868 (0.2345)	loss 0.8843 (0.8592)	grad_norm 0.4185 (0.4263)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:10:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:39 lr 0.000033	 wd 0.0000	time 0.1710 (0.2325)	loss 0.8628 (0.8606)	grad_norm 0.4198 (0.4266)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:10:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:15 lr 0.000032	 wd 0.0000	time 0.2063 (0.2319)	loss 0.9683 (0.8600)	grad_norm 0.4317 (0.4267)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:11:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:03:52 lr 0.000032	 wd 0.0000	time 0.2774 (0.2323)	loss 0.8267 (0.8610)	grad_norm 0.4348 (0.4266)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:11:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:28 lr 0.000032	 wd 0.0000	time 0.2227 (0.2310)	loss 0.8550 (0.8603)	grad_norm 0.4231 (0.4268)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:12:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:04 lr 0.000032	 wd 0.0000	time 0.1966 (0.2297)	loss 0.9648 (0.8605)	grad_norm 0.4431 (0.4268)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:12:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:40 lr 0.000032	 wd 0.0000	time 0.2002 (0.2289)	loss 0.8242 (0.8605)	grad_norm 0.4442 (0.4270)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:12:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:18 lr 0.000032	 wd 0.0000	time 0.2099 (0.2301)	loss 0.8174 (0.8603)	grad_norm 0.4311 (0.4272)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:13:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:55 lr 0.000031	 wd 0.0000	time 0.1749 (0.2298)	loss 0.8701 (0.8608)	grad_norm 0.3964 (0.4273)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:13:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:32 lr 0.000031	 wd 0.0000	time 0.1644 (0.2290)	loss 0.7271 (0.8610)	grad_norm 0.4324 (0.4275)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:13:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:08 lr 0.000031	 wd 0.0000	time 0.1896 (0.2284)	loss 0.8706 (0.8608)	grad_norm 0.4181 (0.4277)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:14:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:46 lr 0.000031	 wd 0.0000	time 0.1758 (0.2284)	loss 0.7505 (0.8611)	grad_norm 0.3979 (0.4277)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:14:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:23 lr 0.000031	 wd 0.0000	time 0.1908 (0.2284)	loss 0.8589 (0.8612)	grad_norm 0.4345 (0.4280)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:14:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1611 (0.2270)	loss 0.8486 (0.8612)	grad_norm 0.4304 (0.4279)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:15:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 18 training takes 0:09:32
[2024-08-01 23:15:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 17.802 (17.802)	Loss 0.3474 (0.3474)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 23:15:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.336 Acc@5 97.650
[2024-08-01 23:15:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-08-01 23:15:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.36%
[2024-08-01 23:16:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][0/2502]	eta 21:42:31 lr 0.000030	 wd 0.0000	time 31.2355 (31.2355)	loss 0.8511 (0.8511)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:16:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:21:17 lr 0.000030	 wd 0.0000	time 0.1771 (0.5320)	loss 1.0176 (0.8523)	grad_norm 0.4306 (0.4284)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:16:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:14:08 lr 0.000030	 wd 0.0000	time 0.1892 (0.3685)	loss 0.6807 (0.8505)	grad_norm 0.4506 (0.4283)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:17:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:11:34 lr 0.000030	 wd 0.0000	time 0.1851 (0.3155)	loss 0.9614 (0.8559)	grad_norm 0.4252 (0.4280)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:17:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:10:22 lr 0.000030	 wd 0.0000	time 0.1935 (0.2962)	loss 0.8066 (0.8584)	grad_norm 0.4067 (0.4276)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:17:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:09:21 lr 0.000029	 wd 0.0000	time 0.2039 (0.2805)	loss 0.9233 (0.8582)	grad_norm 0.4312 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7964MB
[2024-08-01 23:18:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:31 lr 0.000029	 wd 0.0000	time 0.1825 (0.2687)	loss 0.7329 (0.8600)	grad_norm 0.4160 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7964MB
[2024-08-01 23:18:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:49 lr 0.000029	 wd 0.0000	time 0.1761 (0.2606)	loss 0.9595 (0.8611)	grad_norm 0.4225 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7964MB
[2024-08-01 23:19:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:07:17 lr 0.000029	 wd 0.0000	time 0.2321 (0.2570)	loss 0.8384 (0.8621)	grad_norm 0.4362 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7964MB
[2024-08-01 23:19:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:47 lr 0.000029	 wd 0.0000	time 0.1709 (0.2544)	loss 0.8506 (0.8618)	grad_norm 0.4286 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7964MB
[2024-08-01 23:19:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:15 lr 0.000028	 wd 0.0000	time 0.1915 (0.2503)	loss 0.9473 (0.8624)	grad_norm 0.4221 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-01 23:20:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:45 lr 0.000028	 wd 0.0000	time 0.1855 (0.2467)	loss 0.8193 (0.8617)	grad_norm 0.4313 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-01 23:20:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:17 lr 0.000028	 wd 0.0000	time 0.2199 (0.2440)	loss 0.8413 (0.8618)	grad_norm 0.4351 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-01 23:20:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:52 lr 0.000028	 wd 0.0000	time 0.2099 (0.2435)	loss 0.8188 (0.8625)	grad_norm 0.4205 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-01 23:21:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:26 lr 0.000028	 wd 0.0000	time 0.1798 (0.2416)	loss 0.8174 (0.8619)	grad_norm 0.4262 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-01 23:21:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:00 lr 0.000028	 wd 0.0000	time 0.1583 (0.2396)	loss 0.8760 (0.8623)	grad_norm 0.4101 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-01 23:21:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:34 lr 0.000027	 wd 0.0000	time 0.1851 (0.2377)	loss 0.8560 (0.8627)	grad_norm 0.4549 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-01 23:22:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:10 lr 0.000027	 wd 0.0000	time 0.1970 (0.2369)	loss 0.9692 (0.8626)	grad_norm 0.4244 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-01 23:22:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:46 lr 0.000027	 wd 0.0000	time 0.2397 (0.2371)	loss 0.7900 (0.8628)	grad_norm 0.4237 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-01 23:23:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:21 lr 0.000027	 wd 0.0000	time 0.2051 (0.2358)	loss 0.8281 (0.8629)	grad_norm 0.4206 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-01 23:23:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:57 lr 0.000027	 wd 0.0000	time 0.1927 (0.2347)	loss 0.8975 (0.8626)	grad_norm 0.4251 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-01 23:23:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:34 lr 0.000026	 wd 0.0000	time 0.2373 (0.2340)	loss 0.9526 (0.8623)	grad_norm 0.4269 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-01 23:24:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:10 lr 0.000026	 wd 0.0000	time 0.2045 (0.2342)	loss 0.8633 (0.8618)	grad_norm 0.4767 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-01 23:24:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:47 lr 0.000026	 wd 0.0000	time 0.2076 (0.2334)	loss 0.8872 (0.8615)	grad_norm 0.4294 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-01 23:24:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:23 lr 0.000026	 wd 0.0000	time 0.2045 (0.2325)	loss 0.9229 (0.8614)	grad_norm 0.4443 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-01 23:25:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1662 (0.2307)	loss 0.6982 (0.8614)	grad_norm 0.4263 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 23:25:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 19 training takes 0:09:42
[2024-08-01 23:25:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.866 (35.866)	Loss 0.3494 (0.3494)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 23:26:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.362 Acc@5 97.672
[2024-08-01 23:26:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-01 23:26:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.36%
[2024-08-01 23:26:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saving......
[2024-08-01 23:26:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saved !!!
[2024-08-01 23:26:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][0/2502]	eta 10:27:33 lr 0.000026	 wd 0.0000	time 15.0495 (15.0495)	loss 0.8242 (0.8242)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:26:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:14:10 lr 0.000026	 wd 0.0000	time 0.1704 (0.3541)	loss 0.9648 (0.8644)	grad_norm 0.4261 (0.4322)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:27:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:11:13 lr 0.000025	 wd 0.0000	time 0.2316 (0.2927)	loss 0.9116 (0.8560)	grad_norm 0.4370 (0.4312)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:27:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:09:59 lr 0.000025	 wd 0.0000	time 0.1917 (0.2721)	loss 0.7422 (0.8524)	grad_norm 0.4338 (0.4314)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:27:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:08:57 lr 0.000025	 wd 0.0000	time 0.1754 (0.2558)	loss 0.8530 (0.8533)	grad_norm 0.4418 (0.4310)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:28:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:12 lr 0.000025	 wd 0.0000	time 0.1896 (0.2460)	loss 0.8511 (0.8522)	grad_norm 0.4128 (0.4319)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:28:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:07:36 lr 0.000025	 wd 0.0000	time 0.2402 (0.2400)	loss 0.7690 (0.8528)	grad_norm 0.4363 (0.4313)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:28:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:13 lr 0.000025	 wd 0.0000	time 0.2474 (0.2404)	loss 0.7695 (0.8531)	grad_norm 0.4203 (0.4313)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:29:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:06:44 lr 0.000024	 wd 0.0000	time 0.2037 (0.2374)	loss 0.9648 (0.8537)	grad_norm 0.4154 (0.4313)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:29:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:15 lr 0.000024	 wd 0.0000	time 0.1933 (0.2344)	loss 0.7334 (0.8538)	grad_norm 0.4102 (0.4314)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:29:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:05:48 lr 0.000024	 wd 0.0000	time 0.1914 (0.2318)	loss 0.7856 (0.8533)	grad_norm 0.4233 (0.4310)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:30:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:24 lr 0.000024	 wd 0.0000	time 0.2294 (0.2313)	loss 0.7788 (0.8537)	grad_norm 0.4161 (0.4309)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:30:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:02 lr 0.000024	 wd 0.0000	time 0.1721 (0.2320)	loss 0.7173 (0.8535)	grad_norm 0.4149 (0.4309)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:31:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:36 lr 0.000023	 wd 0.0000	time 0.2186 (0.2304)	loss 0.8691 (0.8536)	grad_norm 0.4311 (0.4306)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:31:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:12 lr 0.000023	 wd 0.0000	time 0.2060 (0.2289)	loss 0.8994 (0.8540)	grad_norm 0.4441 (0.4307)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:31:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:48 lr 0.000023	 wd 0.0000	time 0.1980 (0.2283)	loss 0.9482 (0.8537)	grad_norm 0.4321 (0.4306)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:32:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:26 lr 0.000023	 wd 0.0000	time 0.2031 (0.2289)	loss 0.9004 (0.8531)	grad_norm 0.4420 (0.4307)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:32:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:03 lr 0.000023	 wd 0.0000	time 0.2001 (0.2282)	loss 0.9243 (0.8532)	grad_norm 0.4233 (0.4305)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:32:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:39 lr 0.000023	 wd 0.0000	time 0.2293 (0.2274)	loss 0.7871 (0.8540)	grad_norm 0.4260 (0.4306)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:33:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:16 lr 0.000022	 wd 0.0000	time 0.2013 (0.2266)	loss 0.9839 (0.8546)	grad_norm 0.4403 (0.4306)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:33:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:53 lr 0.000022	 wd 0.0000	time 0.1981 (0.2266)	loss 0.8740 (0.8545)	grad_norm 0.4166 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-01 23:34:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:31 lr 0.000022	 wd 0.0000	time 0.2353 (0.2275)	loss 0.9116 (0.8550)	grad_norm 0.4362 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-01 23:34:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:08 lr 0.000022	 wd 0.0000	time 0.1859 (0.2268)	loss 0.8569 (0.8556)	grad_norm 0.4336 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-01 23:34:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:45 lr 0.000022	 wd 0.0000	time 0.1827 (0.2261)	loss 0.8062 (0.8564)	grad_norm 0.4583 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-01 23:35:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:23 lr 0.000022	 wd 0.0000	time 0.2225 (0.2259)	loss 0.8262 (0.8565)	grad_norm 0.4325 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-01 23:35:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1643 (0.2249)	loss 0.7715 (0.8563)	grad_norm 0.4165 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 23:35:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 20 training takes 0:09:33
[2024-08-01 23:36:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 20.038 (20.038)	Loss 0.3486 (0.3486)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 23:36:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.360 Acc@5 97.700
[2024-08-01 23:36:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-01 23:36:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.36%
[2024-08-01 23:36:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][0/2502]	eta 13:32:27 lr 0.000021	 wd 0.0000	time 19.4834 (19.4834)	loss 0.8901 (0.8901)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:37:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:17:30 lr 0.000021	 wd 0.0000	time 0.2341 (0.4372)	loss 0.8687 (0.8704)	grad_norm 0.4262 (0.4316)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:37:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:12:28 lr 0.000021	 wd 0.0000	time 0.1841 (0.3253)	loss 0.9141 (0.8627)	grad_norm 0.4203 (0.4306)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:37:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:28 lr 0.000021	 wd 0.0000	time 0.2129 (0.2855)	loss 0.9043 (0.8599)	grad_norm 0.4276 (0.4312)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:38:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:17 lr 0.000021	 wd 0.0000	time 0.2011 (0.2650)	loss 0.9800 (0.8594)	grad_norm 0.4300 (0.4306)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:38:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:08:40 lr 0.000021	 wd 0.0000	time 0.3464 (0.2600)	loss 0.8110 (0.8596)	grad_norm 0.4214 (0.4309)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:38:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:22 lr 0.000020	 wd 0.0000	time 0.1991 (0.2643)	loss 0.8447 (0.8588)	grad_norm 0.4418 (0.4313)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:39:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:44 lr 0.000020	 wd 0.0000	time 0.2020 (0.2576)	loss 0.9897 (0.8590)	grad_norm 0.4525 (0.4313)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:39:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:07:07 lr 0.000020	 wd 0.0000	time 0.1700 (0.2512)	loss 0.8950 (0.8593)	grad_norm 0.4662 (0.4314)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:40:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:38 lr 0.000020	 wd 0.0000	time 0.2393 (0.2488)	loss 0.8018 (0.8604)	grad_norm 0.4281 (0.4311)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:40:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:12 lr 0.000020	 wd 0.0000	time 0.1792 (0.2477)	loss 0.8164 (0.8598)	grad_norm 0.4055 (0.4310)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:40:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:42 lr 0.000020	 wd 0.0000	time 0.1782 (0.2444)	loss 0.8657 (0.8604)	grad_norm 0.4218 (0.4311)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:41:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:14 lr 0.000019	 wd 0.0000	time 0.2000 (0.2417)	loss 0.8145 (0.8616)	grad_norm 0.4229 (0.4312)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:41:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:47 lr 0.000019	 wd 0.0000	time 0.2012 (0.2395)	loss 0.9341 (0.8612)	grad_norm 0.4168 (0.4310)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:41:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:23 lr 0.000019	 wd 0.0000	time 0.1971 (0.2395)	loss 0.8813 (0.8611)	grad_norm 0.4303 (0.4309)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:42:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:58 lr 0.000019	 wd 0.0000	time 0.2061 (0.2379)	loss 0.9170 (0.8610)	grad_norm 0.4311 (0.4308)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:42:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:32 lr 0.000019	 wd 0.0000	time 0.2131 (0.2361)	loss 0.8979 (0.8604)	grad_norm 0.4415 (0.4310)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:42:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:08 lr 0.000019	 wd 0.0000	time 0.1977 (0.2345)	loss 0.8765 (0.8611)	grad_norm 0.4243 (0.4311)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:43:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:44 lr 0.000018	 wd 0.0000	time 0.2204 (0.2341)	loss 0.8765 (0.8612)	grad_norm 0.4229 (0.4312)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:43:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:21 lr 0.000018	 wd 0.0000	time 0.2258 (0.2350)	loss 0.8887 (0.8614)	grad_norm 0.4215 (0.4314)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:44:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:57 lr 0.000018	 wd 0.0000	time 0.2147 (0.2340)	loss 0.7451 (0.8611)	grad_norm 0.4385 (0.4315)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:44:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:33 lr 0.000018	 wd 0.0000	time 0.1678 (0.2330)	loss 0.7676 (0.8605)	grad_norm 0.4136 (0.4316)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:44:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:10 lr 0.000018	 wd 0.0000	time 0.1983 (0.2325)	loss 0.7749 (0.8600)	grad_norm 0.4324 (0.4316)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:45:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:47 lr 0.000018	 wd 0.0000	time 0.2208 (0.2327)	loss 0.9326 (0.8599)	grad_norm 0.4338 (0.4317)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:45:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:23 lr 0.000018	 wd 0.0000	time 0.1962 (0.2322)	loss 0.8550 (0.8600)	grad_norm 0.4200 (0.4318)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:45:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1613 (0.2305)	loss 0.8872 (0.8601)	grad_norm 0.3979 (0.4318)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:46:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 21 training takes 0:09:43
[2024-08-01 23:46:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 23.236 (23.236)	Loss 0.3455 (0.3455)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 23:46:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.380 Acc@5 97.686
[2024-08-01 23:46:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-01 23:46:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.38%
[2024-08-01 23:46:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saving......
[2024-08-01 23:46:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saved !!!
[2024-08-01 23:47:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][0/2502]	eta 12:46:21 lr 0.000017	 wd 0.0000	time 18.3779 (18.3779)	loss 0.8091 (0.8091)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:47:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:15:31 lr 0.000017	 wd 0.0000	time 0.1661 (0.3876)	loss 0.8916 (0.8646)	grad_norm 0.4388 (0.4346)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:47:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:11:24 lr 0.000017	 wd 0.0000	time 0.1763 (0.2974)	loss 0.8052 (0.8608)	grad_norm 0.4232 (0.4328)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:48:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:21 lr 0.000017	 wd 0.0000	time 0.3257 (0.2824)	loss 0.8540 (0.8602)	grad_norm 0.4279 (0.4331)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:48:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:54 lr 0.000017	 wd 0.0000	time 0.2067 (0.2828)	loss 0.7915 (0.8653)	grad_norm 0.4226 (0.4334)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:48:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:08:57 lr 0.000017	 wd 0.0000	time 0.1864 (0.2687)	loss 0.6948 (0.8632)	grad_norm 0.4108 (0.4325)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:49:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:11 lr 0.000016	 wd 0.0000	time 0.1895 (0.2582)	loss 0.9150 (0.8645)	grad_norm 0.4109 (0.4327)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:49:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:37 lr 0.000016	 wd 0.0000	time 0.2347 (0.2539)	loss 0.9658 (0.8629)	grad_norm 0.4180 (0.4332)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:50:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:19 lr 0.000016	 wd 0.0000	time 0.1929 (0.2581)	loss 0.8784 (0.8630)	grad_norm 0.4162 (0.4329)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:50:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:44 lr 0.000016	 wd 0.0000	time 0.1907 (0.2527)	loss 0.8281 (0.8629)	grad_norm 0.4094 (0.4332)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:50:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:12 lr 0.000016	 wd 0.0000	time 0.1813 (0.2482)	loss 0.8818 (0.8626)	grad_norm 0.4173 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-01 23:51:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:43 lr 0.000016	 wd 0.0000	time 0.2450 (0.2453)	loss 0.7637 (0.8611)	grad_norm 0.4114 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-01 23:51:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:19 lr 0.000016	 wd 0.0000	time 0.1666 (0.2454)	loss 0.8320 (0.8616)	grad_norm 0.4269 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-01 23:52:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:52 lr 0.000015	 wd 0.0000	time 0.2133 (0.2430)	loss 0.8608 (0.8603)	grad_norm 0.4282 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-01 23:52:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:25 lr 0.000015	 wd 0.0000	time 0.2058 (0.2407)	loss 0.8369 (0.8599)	grad_norm 0.4299 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-01 23:52:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:59 lr 0.000015	 wd 0.0000	time 0.1717 (0.2387)	loss 0.6870 (0.8599)	grad_norm 0.4202 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-01 23:53:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:35 lr 0.000015	 wd 0.0000	time 0.2296 (0.2384)	loss 0.8052 (0.8601)	grad_norm 0.4306 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-01 23:53:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:11 lr 0.000015	 wd 0.0000	time 0.1864 (0.2384)	loss 0.8789 (0.8596)	grad_norm 0.4438 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-01 23:53:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:46 lr 0.000015	 wd 0.0000	time 0.1910 (0.2369)	loss 0.9023 (0.8596)	grad_norm 0.4299 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-01 23:54:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:21 lr 0.000015	 wd 0.0000	time 0.1809 (0.2357)	loss 0.8745 (0.8601)	grad_norm 0.4295 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-01 23:54:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:58 lr 0.000014	 wd 0.0000	time 0.2397 (0.2351)	loss 0.9434 (0.8598)	grad_norm 0.3968 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-01 23:55:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:34 lr 0.000014	 wd 0.0000	time 0.1863 (0.2359)	loss 0.7979 (0.8601)	grad_norm 0.4339 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-01 23:55:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:10 lr 0.000014	 wd 0.0000	time 0.2165 (0.2350)	loss 0.6865 (0.8601)	grad_norm 0.4297 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-01 23:55:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:47 lr 0.000014	 wd 0.0000	time 0.1733 (0.2340)	loss 0.9243 (0.8600)	grad_norm 0.4296 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-01 23:56:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:23 lr 0.000014	 wd 0.0000	time 0.2279 (0.2334)	loss 0.7603 (0.8601)	grad_norm 0.4316 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-01 23:56:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1691 (0.2320)	loss 0.8184 (0.8596)	grad_norm 0.4411 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-01 23:56:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 22 training takes 0:09:55
[2024-08-01 23:57:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 28.810 (28.810)	Loss 0.3442 (0.3442)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-01 23:57:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.402 Acc@5 97.712
[2024-08-01 23:57:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-01 23:57:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.40%
[2024-08-01 23:57:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saving......
[2024-08-01 23:57:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_best.pth saved !!!
[2024-08-01 23:57:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][0/2502]	eta 15:24:43 lr 0.000014	 wd 0.0000	time 22.1757 (22.1757)	loss 0.7666 (0.7666)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:58:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:18:55 lr 0.000014	 wd 0.0000	time 0.1984 (0.4726)	loss 0.8745 (0.8598)	grad_norm 0.4431 (0.4367)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:58:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:13:00 lr 0.000013	 wd 0.0000	time 0.1851 (0.3389)	loss 0.9307 (0.8572)	grad_norm 0.4630 (0.4344)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:58:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:10:48 lr 0.000013	 wd 0.0000	time 0.1799 (0.2947)	loss 0.7627 (0.8560)	grad_norm 0.4235 (0.4341)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:59:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:37 lr 0.000013	 wd 0.0000	time 0.2086 (0.2749)	loss 0.9658 (0.8572)	grad_norm 0.4330 (0.4346)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-01 23:59:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:08:52 lr 0.000013	 wd 0.0000	time 0.1751 (0.2661)	loss 0.8711 (0.8610)	grad_norm 0.4212 (0.4349)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:00:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:08:09 lr 0.000013	 wd 0.0000	time 0.1893 (0.2573)	loss 0.8892 (0.8617)	grad_norm 0.4432 (0.4350)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:00:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:31 lr 0.000013	 wd 0.0000	time 0.1980 (0.2505)	loss 0.9526 (0.8626)	grad_norm 0.4141 (0.4344)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:00:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:06:57 lr 0.000013	 wd 0.0000	time 0.2008 (0.2452)	loss 0.9712 (0.8622)	grad_norm 0.4289 (0.4341)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:01:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:31 lr 0.000012	 wd 0.0000	time 0.2563 (0.2441)	loss 1.0879 (0.8606)	grad_norm 0.4296 (0.4339)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:01:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:06:04 lr 0.000012	 wd 0.0000	time 0.1680 (0.2427)	loss 0.7344 (0.8610)	grad_norm 0.4348 (0.4339)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:01:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:36 lr 0.000012	 wd 0.0000	time 0.1956 (0.2399)	loss 0.7080 (0.8601)	grad_norm 0.4439 (0.4339)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:02:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:09 lr 0.000012	 wd 0.0000	time 0.1805 (0.2374)	loss 0.9209 (0.8605)	grad_norm 0.4086 (0.4338)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:02:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:43 lr 0.000012	 wd 0.0000	time 0.2059 (0.2361)	loss 0.9185 (0.8607)	grad_norm 0.4539 (0.4339)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:03:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:21 lr 0.000012	 wd 0.0000	time 0.2370 (0.2370)	loss 0.9307 (0.8610)	grad_norm 0.4319 (0.4339)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:03:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:55 lr 0.000012	 wd 0.0000	time 0.1738 (0.2353)	loss 0.7397 (0.8618)	grad_norm 0.4455 (0.4339)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:03:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:30 lr 0.000012	 wd 0.0000	time 0.1896 (0.2337)	loss 0.8755 (0.8619)	grad_norm 0.4242 (0.4340)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:04:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:06 lr 0.000011	 wd 0.0000	time 0.2247 (0.2324)	loss 0.7852 (0.8616)	grad_norm 0.4270 (0.4341)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:04:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:42 lr 0.000011	 wd 0.0000	time 0.2748 (0.2321)	loss 0.8750 (0.8619)	grad_norm 0.4201 (0.4342)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:04:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:19 lr 0.000011	 wd 0.0000	time 0.1704 (0.2325)	loss 0.7861 (0.8614)	grad_norm 0.4262 (0.4340)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:05:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:56 lr 0.000011	 wd 0.0000	time 0.1938 (0.2316)	loss 0.9658 (0.8611)	grad_norm 0.4259 (0.4340)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:05:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:32 lr 0.000011	 wd 0.0000	time 0.1938 (0.2306)	loss 1.0244 (0.8612)	grad_norm 0.3959 (0.4340)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:05:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:09 lr 0.000011	 wd 0.0000	time 0.2171 (0.2303)	loss 0.9395 (0.8606)	grad_norm 0.4534 (0.4338)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:06:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:46 lr 0.000011	 wd 0.0000	time 0.2711 (0.2308)	loss 0.8535 (0.8608)	grad_norm 0.4308 (0.4338)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:06:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:23 lr 0.000011	 wd 0.0000	time 0.2069 (0.2301)	loss 0.8555 (0.8609)	grad_norm 0.4246 (0.4338)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:06:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1679 (0.2284)	loss 0.7876 (0.8607)	grad_norm 0.4368 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 00:07:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 23 training takes 0:09:40
[2024-08-02 00:07:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 38.133 (38.133)	Loss 0.3459 (0.3459)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 00:08:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.394 Acc@5 97.688
[2024-08-02 00:08:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-02 00:08:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.40%
[2024-08-02 00:08:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][0/2502]	eta 11:54:09 lr 0.000010	 wd 0.0000	time 17.1260 (17.1260)	loss 0.8643 (0.8643)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:08:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:14:55 lr 0.000010	 wd 0.0000	time 0.1902 (0.3730)	loss 0.9604 (0.8556)	grad_norm 0.4112 (0.4338)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:09:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:11:54 lr 0.000010	 wd 0.0000	time 0.3674 (0.3105)	loss 0.8784 (0.8576)	grad_norm 0.4403 (0.4329)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:09:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:11:28 lr 0.000010	 wd 0.0000	time 0.2233 (0.3126)	loss 0.7822 (0.8607)	grad_norm 0.4602 (0.4333)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:10:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:10:00 lr 0.000010	 wd 0.0000	time 0.1927 (0.2858)	loss 0.7227 (0.8621)	grad_norm 0.4218 (0.4332)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:10:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:09:03 lr 0.000010	 wd 0.0000	time 0.2097 (0.2717)	loss 0.8706 (0.8640)	grad_norm 0.4736 (0.4333)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:10:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:22 lr 0.000010	 wd 0.0000	time 0.2578 (0.2641)	loss 0.8848 (0.8620)	grad_norm 0.4056 (0.4337)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:11:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:51 lr 0.000010	 wd 0.0000	time 0.1745 (0.2614)	loss 0.8145 (0.8616)	grad_norm 0.4204 (0.4330)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:11:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:14 lr 0.000010	 wd 0.0000	time 0.1858 (0.2551)	loss 0.7964 (0.8607)	grad_norm 0.4403 (0.4330)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:11:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:40 lr 0.000009	 wd 0.0000	time 0.2072 (0.2502)	loss 0.9248 (0.8614)	grad_norm 0.4403 (0.4328)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:12:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:10 lr 0.000009	 wd 0.0000	time 0.1937 (0.2468)	loss 0.8008 (0.8622)	grad_norm 0.4294 (0.4329)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:12:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:47 lr 0.000009	 wd 0.0000	time 0.1896 (0.2477)	loss 0.8032 (0.8620)	grad_norm 0.4267 (0.4332)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:13:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:19 lr 0.000009	 wd 0.0000	time 0.1987 (0.2453)	loss 0.8228 (0.8618)	grad_norm 0.4051 (0.4334)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:13:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:51 lr 0.000009	 wd 0.0000	time 0.1942 (0.2426)	loss 0.7246 (0.8603)	grad_norm 0.4355 (0.4331)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:13:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:24 lr 0.000009	 wd 0.0000	time 0.2357 (0.2401)	loss 0.7646 (0.8607)	grad_norm 0.4145 (0.4331)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:14:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:04:00 lr 0.000009	 wd 0.0000	time 0.1913 (0.2396)	loss 0.8120 (0.8608)	grad_norm 0.4288 (0.4332)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:14:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:36 lr 0.000009	 wd 0.0000	time 0.1913 (0.2398)	loss 0.8945 (0.8608)	grad_norm 0.4152 (0.4333)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:14:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:10 lr 0.000008	 wd 0.0000	time 0.1851 (0.2381)	loss 0.9336 (0.8610)	grad_norm 0.4507 (0.4333)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:15:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:45 lr 0.000008	 wd 0.0000	time 0.1944 (0.2364)	loss 0.7632 (0.8613)	grad_norm 0.4205 (0.4333)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:15:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:21 lr 0.000008	 wd 0.0000	time 0.2101 (0.2356)	loss 0.7412 (0.8609)	grad_norm 0.4108 (0.4334)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:15:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:58 lr 0.000008	 wd 0.0000	time 0.2497 (0.2358)	loss 0.7119 (0.8608)	grad_norm 0.4391 (0.4336)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:16:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:34 lr 0.000008	 wd 0.0000	time 0.1904 (0.2348)	loss 0.9541 (0.8606)	grad_norm 0.4351 (0.4336)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:16:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:10 lr 0.000008	 wd 0.0000	time 0.1861 (0.2337)	loss 0.8564 (0.8605)	grad_norm 0.4257 (0.4337)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:17:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:47 lr 0.000008	 wd 0.0000	time 0.2155 (0.2329)	loss 0.8931 (0.8606)	grad_norm 0.4116 (0.4336)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:17:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:23 lr 0.000008	 wd 0.0000	time 0.1921 (0.2333)	loss 1.0283 (0.8605)	grad_norm 0.4231 (0.4334)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:17:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1605 (0.2318)	loss 0.9727 (0.8604)	grad_norm 0.4187 (0.4334)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:17:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 24 training takes 0:09:47
[2024-08-02 00:18:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 19.655 (19.655)	Loss 0.3462 (0.3462)	Acc@1 92.578 (92.578)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 00:18:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.378 Acc@5 97.696
[2024-08-02 00:18:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-02 00:18:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.40%
[2024-08-02 00:18:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][0/2502]	eta 19:18:28 lr 0.000008	 wd 0.0000	time 27.7811 (27.7811)	loss 0.8594 (0.8594)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:19:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:20:52 lr 0.000008	 wd 0.0000	time 0.1945 (0.5215)	loss 0.8232 (0.8756)	grad_norm 0.4178 (0.4355)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:19:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:13:56 lr 0.000007	 wd 0.0000	time 0.2185 (0.3634)	loss 0.8101 (0.8726)	grad_norm 0.4318 (0.4340)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:20:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:11:25 lr 0.000007	 wd 0.0000	time 0.1997 (0.3112)	loss 0.8706 (0.8648)	grad_norm 0.4332 (0.4334)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:20:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:10:09 lr 0.000007	 wd 0.0000	time 0.1999 (0.2901)	loss 0.7310 (0.8651)	grad_norm 0.4307 (0.4337)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:20:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:17 lr 0.000007	 wd 0.0000	time 0.2198 (0.2783)	loss 0.8433 (0.8645)	grad_norm 0.4031 (0.4336)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:21:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:26 lr 0.000007	 wd 0.0000	time 0.1961 (0.2662)	loss 0.7212 (0.8640)	grad_norm 0.4580 (0.4337)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:21:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:45 lr 0.000007	 wd 0.0000	time 0.1992 (0.2583)	loss 0.8120 (0.8629)	grad_norm 0.4325 (0.4335)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:21:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:10 lr 0.000007	 wd 0.0000	time 0.2403 (0.2528)	loss 0.9663 (0.8626)	grad_norm 0.4277 (0.4336)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:22:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:06:45 lr 0.000007	 wd 0.0000	time 0.2068 (0.2529)	loss 0.7202 (0.8624)	grad_norm 0.4287 (0.4336)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:22:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:13 lr 0.000007	 wd 0.0000	time 0.1937 (0.2488)	loss 0.9077 (0.8627)	grad_norm 0.4603 (0.4340)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:23:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:43 lr 0.000007	 wd 0.0000	time 0.2115 (0.2453)	loss 0.9849 (0.8623)	grad_norm 0.4405 (0.4340)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:23:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:15 lr 0.000006	 wd 0.0000	time 0.2136 (0.2424)	loss 0.9932 (0.8630)	grad_norm 0.4394 (0.4339)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:23:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:49 lr 0.000006	 wd 0.0000	time 0.1864 (0.2411)	loss 0.8657 (0.8619)	grad_norm 0.4210 (0.4340)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:24:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:26 lr 0.000006	 wd 0.0000	time 0.1834 (0.2415)	loss 0.9321 (0.8617)	grad_norm 0.4170 (0.4338)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:24:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:03:59 lr 0.000006	 wd 0.0000	time 0.1790 (0.2394)	loss 0.9531 (0.8625)	grad_norm 0.4280 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-02 00:24:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:34 lr 0.000006	 wd 0.0000	time 0.1774 (0.2376)	loss 0.7290 (0.8620)	grad_norm 0.4158 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 00:25:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:09 lr 0.000006	 wd 0.0000	time 0.2102 (0.2364)	loss 0.8101 (0.8627)	grad_norm 0.4188 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 00:25:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:46 lr 0.000006	 wd 0.0000	time 0.1623 (0.2370)	loss 0.8940 (0.8622)	grad_norm 0.4136 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 00:26:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:22 lr 0.000006	 wd 0.0000	time 0.1651 (0.2360)	loss 0.9878 (0.8622)	grad_norm 0.4225 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 00:26:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:57 lr 0.000006	 wd 0.0000	time 0.1990 (0.2348)	loss 0.9888 (0.8621)	grad_norm 0.4326 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 00:26:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:33 lr 0.000006	 wd 0.0000	time 0.2033 (0.2338)	loss 0.8936 (0.8617)	grad_norm 0.4221 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 00:27:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:10 lr 0.000006	 wd 0.0000	time 0.2885 (0.2334)	loss 0.8174 (0.8615)	grad_norm 0.4086 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 00:27:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:47 lr 0.000005	 wd 0.0000	time 0.1768 (0.2338)	loss 0.7729 (0.8613)	grad_norm 0.4238 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 00:27:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:23 lr 0.000005	 wd 0.0000	time 0.2385 (0.2329)	loss 0.8184 (0.8613)	grad_norm 0.4228 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 00:28:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1599 (0.2312)	loss 0.8691 (0.8616)	grad_norm 0.4350 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 00:28:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 25 training takes 0:09:44
[2024-08-02 00:28:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 37.145 (37.145)	Loss 0.3462 (0.3462)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 00:29:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.354 Acc@5 97.708
[2024-08-02 00:29:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-02 00:29:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.40%
[2024-08-02 00:29:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][0/2502]	eta 11:17:03 lr 0.000005	 wd 0.0000	time 16.2363 (16.2363)	loss 1.0166 (1.0166)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:29:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:14:44 lr 0.000005	 wd 0.0000	time 0.1722 (0.3682)	loss 0.7642 (0.8698)	grad_norm 0.4316 (0.4400)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:30:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:11:45 lr 0.000005	 wd 0.0000	time 0.3045 (0.3066)	loss 0.8403 (0.8656)	grad_norm 0.4443 (0.4377)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:30:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:40 lr 0.000005	 wd 0.0000	time 0.1869 (0.2909)	loss 0.8545 (0.8670)	grad_norm 0.4567 (0.4371)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:31:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:26 lr 0.000005	 wd 0.0000	time 0.2349 (0.2696)	loss 0.8862 (0.8642)	grad_norm 0.4339 (0.4360)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:31:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:08:34 lr 0.000005	 wd 0.0000	time 0.1951 (0.2570)	loss 0.8091 (0.8624)	grad_norm 0.3974 (0.4351)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:31:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:07:57 lr 0.000005	 wd 0.0000	time 0.2357 (0.2510)	loss 0.8364 (0.8633)	grad_norm 0.4395 (0.4353)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:32:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:29 lr 0.000005	 wd 0.0000	time 0.2571 (0.2493)	loss 0.8081 (0.8615)	grad_norm 0.4222 (0.4347)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:32:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:06:56 lr 0.000005	 wd 0.0000	time 0.1894 (0.2449)	loss 0.8428 (0.8626)	grad_norm 0.4473 (0.4347)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:32:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:25 lr 0.000005	 wd 0.0000	time 0.1678 (0.2409)	loss 0.7783 (0.8611)	grad_norm 0.4378 (0.4349)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:33:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:05:57 lr 0.000004	 wd 0.0000	time 0.2050 (0.2380)	loss 0.9502 (0.8615)	grad_norm 0.4208 (0.4349)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:33:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:35 lr 0.000004	 wd 0.0000	time 0.5120 (0.2393)	loss 0.9512 (0.8621)	grad_norm 0.4165 (0.4348)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:33:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:09 lr 0.000004	 wd 0.0000	time 0.2233 (0.2375)	loss 0.8896 (0.8619)	grad_norm 0.4389 (0.4349)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:34:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:43 lr 0.000004	 wd 0.0000	time 0.1926 (0.2355)	loss 0.7329 (0.8622)	grad_norm 0.4224 (0.4349)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:34:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:17 lr 0.000004	 wd 0.0000	time 0.2249 (0.2336)	loss 0.9585 (0.8619)	grad_norm 0.4313 (0.4349)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:35:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:53 lr 0.000004	 wd 0.0000	time 0.2331 (0.2333)	loss 0.8433 (0.8622)	grad_norm 0.4177 (0.4349)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:35:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:31 lr 0.000004	 wd 0.0000	time 0.2161 (0.2340)	loss 0.7363 (0.8613)	grad_norm 0.4052 (0.4348)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:35:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:03:06 lr 0.000004	 wd 0.0000	time 0.1779 (0.2328)	loss 0.8408 (0.8619)	grad_norm 0.4228 (0.4347)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:36:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:42 lr 0.000004	 wd 0.0000	time 0.2051 (0.2315)	loss 0.9009 (0.8625)	grad_norm 0.4253 (0.4348)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:36:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:18 lr 0.000004	 wd 0.0000	time 0.1994 (0.2307)	loss 0.8457 (0.8618)	grad_norm 0.4244 (0.4346)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:36:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:56 lr 0.000004	 wd 0.0000	time 0.1860 (0.2314)	loss 0.9072 (0.8616)	grad_norm 0.4379 (0.4346)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:37:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:32 lr 0.000004	 wd 0.0000	time 0.1924 (0.2306)	loss 0.8945 (0.8619)	grad_norm 0.4481 (0.4347)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:37:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:09 lr 0.000004	 wd 0.0000	time 0.1947 (0.2299)	loss 0.9307 (0.8618)	grad_norm 0.4300 (0.4346)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:37:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:46 lr 0.000004	 wd 0.0000	time 0.1960 (0.2290)	loss 0.8364 (0.8616)	grad_norm 0.4414 (0.4345)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:38:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:23 lr 0.000003	 wd 0.0000	time 0.2310 (0.2290)	loss 0.8496 (0.8620)	grad_norm 0.4503 (0.4346)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:38:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1728 (0.2282)	loss 0.9209 (0.8620)	grad_norm 0.4268 (0.4346)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:38:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 26 training takes 0:09:39
[2024-08-02 00:39:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 20.525 (20.525)	Loss 0.3459 (0.3459)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 00:39:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.376 Acc@5 97.692
[2024-08-02 00:39:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-02 00:39:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.40%
[2024-08-02 00:39:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][0/2502]	eta 19:44:28 lr 0.000003	 wd 0.0000	time 28.4045 (28.4045)	loss 0.9004 (0.9004)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:40:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:20:29 lr 0.000003	 wd 0.0000	time 0.1898 (0.5117)	loss 0.8696 (0.8651)	grad_norm 0.4340 (0.4334)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:40:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:13:45 lr 0.000003	 wd 0.0000	time 0.1838 (0.3587)	loss 0.7153 (0.8610)	grad_norm 0.4484 (0.4337)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:41:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:11:18 lr 0.000003	 wd 0.0000	time 0.2032 (0.3080)	loss 0.8755 (0.8611)	grad_norm 0.4587 (0.4344)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:41:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:10:04 lr 0.000003	 wd 0.0000	time 0.2098 (0.2874)	loss 0.8052 (0.8599)	grad_norm 0.4269 (0.4346)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:41:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:09:10 lr 0.000003	 wd 0.0000	time 0.1933 (0.2748)	loss 0.7407 (0.8591)	grad_norm 0.4701 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7964MB
[2024-08-02 00:42:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:22 lr 0.000003	 wd 0.0000	time 0.1824 (0.2640)	loss 0.7998 (0.8616)	grad_norm 0.4432 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7964MB
[2024-08-02 00:42:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:41 lr 0.000003	 wd 0.0000	time 0.2132 (0.2564)	loss 0.8218 (0.8611)	grad_norm 0.4569 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7964MB
[2024-08-02 00:42:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:07:06 lr 0.000003	 wd 0.0000	time 0.2136 (0.2506)	loss 0.8901 (0.8606)	grad_norm 0.4159 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7964MB
[2024-08-02 00:43:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:42 lr 0.000003	 wd 0.0000	time 0.2151 (0.2514)	loss 0.7090 (0.8602)	grad_norm 0.4190 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7964MB
[2024-08-02 00:43:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:12 lr 0.000003	 wd 0.0000	time 0.1923 (0.2478)	loss 0.8745 (0.8598)	grad_norm 0.4203 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7964MB
[2024-08-02 00:44:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:42 lr 0.000003	 wd 0.0000	time 0.1849 (0.2443)	loss 0.7632 (0.8599)	grad_norm 0.4430 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7964MB
[2024-08-02 00:44:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:14 lr 0.000003	 wd 0.0000	time 0.1991 (0.2415)	loss 0.8843 (0.8592)	grad_norm 0.4245 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7964MB
[2024-08-02 00:44:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:49 lr 0.000003	 wd 0.0000	time 0.2124 (0.2407)	loss 0.8418 (0.8593)	grad_norm 0.4450 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7964MB
[2024-08-02 00:45:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:24 lr 0.000003	 wd 0.0000	time 0.1805 (0.2403)	loss 0.8047 (0.8592)	grad_norm 0.4321 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7964MB
[2024-08-02 00:45:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:03:58 lr 0.000003	 wd 0.0000	time 0.1913 (0.2384)	loss 0.9443 (0.8594)	grad_norm 0.4207 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7964MB
[2024-08-02 00:45:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:33 lr 0.000003	 wd 0.0000	time 0.1749 (0.2367)	loss 0.8848 (0.8594)	grad_norm 0.4234 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7964MB
[2024-08-02 00:46:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:03:08 lr 0.000002	 wd 0.0000	time 0.1948 (0.2355)	loss 0.8730 (0.8596)	grad_norm 0.4349 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7964MB
[2024-08-02 00:46:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:45 lr 0.000002	 wd 0.0000	time 0.1633 (0.2360)	loss 0.7495 (0.8600)	grad_norm 0.4350 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7964MB
[2024-08-02 00:46:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:21 lr 0.000002	 wd 0.0000	time 0.1942 (0.2352)	loss 0.7925 (0.8601)	grad_norm 0.4280 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7964MB
[2024-08-02 00:47:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:57 lr 0.000002	 wd 0.0000	time 0.1853 (0.2340)	loss 0.7534 (0.8598)	grad_norm 0.4140 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 00:47:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:33 lr 0.000002	 wd 0.0000	time 0.2193 (0.2330)	loss 0.9883 (0.8606)	grad_norm 0.4570 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 00:48:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:10 lr 0.000002	 wd 0.0000	time 0.1906 (0.2327)	loss 0.7393 (0.8601)	grad_norm 0.4337 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 00:48:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.1747 (0.2325)	loss 0.8242 (0.8603)	grad_norm 0.4304 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 00:48:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:23 lr 0.000002	 wd 0.0000	time 0.1609 (0.2317)	loss 0.8662 (0.8600)	grad_norm 0.4443 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 00:49:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1624 (0.2300)	loss 0.8418 (0.8603)	grad_norm 0.4236 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 00:49:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 27 training takes 0:09:43
[2024-08-02 00:49:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 38.205 (38.205)	Loss 0.3469 (0.3469)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 00:50:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.384 Acc@5 97.684
[2024-08-02 00:50:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-02 00:50:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.40%
[2024-08-02 00:50:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][0/2502]	eta 9:59:44 lr 0.000002	 wd 0.0000	time 14.3822 (14.3822)	loss 0.8418 (0.8418)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:50:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:14:38 lr 0.000002	 wd 0.0000	time 0.1776 (0.3656)	loss 0.8833 (0.8569)	grad_norm 0.4490 (0.4353)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:51:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:11:44 lr 0.000002	 wd 0.0000	time 0.3688 (0.3060)	loss 0.8105 (0.8627)	grad_norm 0.4430 (0.4350)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:51:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:45 lr 0.000002	 wd 0.0000	time 0.2175 (0.2933)	loss 0.9771 (0.8640)	grad_norm 0.4384 (0.4351)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:52:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:31 lr 0.000002	 wd 0.0000	time 0.1888 (0.2717)	loss 0.7715 (0.8589)	grad_norm 0.4302 (0.4351)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:52:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:08:37 lr 0.000002	 wd 0.0000	time 0.1756 (0.2587)	loss 0.8608 (0.8614)	grad_norm 0.4335 (0.4354)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:52:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:01 lr 0.000002	 wd 0.0000	time 0.2190 (0.2530)	loss 0.8965 (0.8626)	grad_norm 0.4237 (0.4348)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:53:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:44 lr 0.000002	 wd 0.0000	time 0.1881 (0.2575)	loss 0.8394 (0.8614)	grad_norm 0.4265 (0.4346)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:53:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:07 lr 0.000002	 wd 0.0000	time 0.1743 (0.2514)	loss 0.8364 (0.8620)	grad_norm 0.4193 (0.4349)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:53:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:35 lr 0.000002	 wd 0.0000	time 0.1755 (0.2467)	loss 0.8022 (0.8620)	grad_norm 0.4358 (0.4348)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:54:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:06 lr 0.000002	 wd 0.0000	time 0.2076 (0.2438)	loss 0.8164 (0.8618)	grad_norm 0.4104 (0.4348)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:54:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:42 lr 0.000002	 wd 0.0000	time 0.3224 (0.2441)	loss 0.8013 (0.8600)	grad_norm 0.4407 (0.4347)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:55:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:14 lr 0.000002	 wd 0.0000	time 0.1856 (0.2416)	loss 0.8345 (0.8601)	grad_norm 0.4417 (0.4349)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:55:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:47 lr 0.000002	 wd 0.0000	time 0.1938 (0.2391)	loss 0.9399 (0.8605)	grad_norm 0.4417 (0.4348)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:55:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:21 lr 0.000002	 wd 0.0000	time 0.2459 (0.2371)	loss 0.7764 (0.8598)	grad_norm 0.4283 (0.4348)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:56:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:57 lr 0.000002	 wd 0.0000	time 0.1953 (0.2367)	loss 0.7764 (0.8599)	grad_norm 0.4484 (0.4349)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:56:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:33 lr 0.000002	 wd 0.0000	time 0.1771 (0.2368)	loss 0.9995 (0.8603)	grad_norm 0.4460 (0.4347)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:56:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:08 lr 0.000001	 wd 0.0000	time 0.2322 (0.2352)	loss 0.9141 (0.8604)	grad_norm 0.4577 (0.4346)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:57:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:44 lr 0.000001	 wd 0.0000	time 0.1794 (0.2339)	loss 0.7476 (0.8600)	grad_norm 0.4542 (0.4348)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:57:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:20 lr 0.000001	 wd 0.0000	time 0.2231 (0.2333)	loss 0.8491 (0.8610)	grad_norm 0.4269 (0.4351)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 00:58:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:57 lr 0.000001	 wd 0.0000	time 0.1798 (0.2338)	loss 0.7827 (0.8602)	grad_norm 0.4302 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7964MB
[2024-08-02 00:58:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:33 lr 0.000001	 wd 0.0000	time 0.1869 (0.2330)	loss 0.8345 (0.8600)	grad_norm 0.4619 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7964MB
[2024-08-02 00:58:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:10 lr 0.000001	 wd 0.0000	time 0.1997 (0.2321)	loss 0.8765 (0.8595)	grad_norm 0.4461 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7964MB
[2024-08-02 00:59:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.1942 (0.2313)	loss 0.8052 (0.8592)	grad_norm 0.4246 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7964MB
[2024-08-02 00:59:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:23 lr 0.000001	 wd 0.0000	time 0.1940 (0.2316)	loss 0.9521 (0.8588)	grad_norm 0.4364 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7964MB
[2024-08-02 00:59:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1584 (0.2301)	loss 0.8242 (0.8589)	grad_norm 0.4187 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7964MB
[2024-08-02 00:59:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 28 training takes 0:09:45
[2024-08-02 01:00:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 21.605 (21.605)	Loss 0.3469 (0.3469)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 01:00:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.374 Acc@5 97.682
[2024-08-02 01:00:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-02 01:00:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.40%
[2024-08-02 01:01:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][0/2502]	eta 22:25:54 lr 0.000001	 wd 0.0000	time 32.2762 (32.2762)	loss 0.9219 (0.9219)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:01:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:21:17 lr 0.000001	 wd 0.0000	time 0.1978 (0.5317)	loss 0.8271 (0.8681)	grad_norm 0.4445 (0.4366)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:01:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:14:09 lr 0.000001	 wd 0.0000	time 0.1769 (0.3691)	loss 0.8682 (0.8675)	grad_norm 0.4542 (0.4356)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:02:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:11:30 lr 0.000001	 wd 0.0000	time 0.1765 (0.3135)	loss 0.8311 (0.8676)	grad_norm 0.4304 (0.4346)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:02:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:11:09 lr 0.000001	 wd 0.0000	time 0.1844 (0.3186)	loss 0.8579 (0.8673)	grad_norm 0.4261 (0.4346)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:03:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:09:58 lr 0.000001	 wd 0.0000	time 0.1985 (0.2989)	loss 0.8188 (0.8667)	grad_norm 0.4466 (0.4358)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:03:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:59 lr 0.000001	 wd 0.0000	time 0.2133 (0.2838)	loss 0.7290 (0.8660)	grad_norm 0.4496 (0.4350)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:03:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:08:10 lr 0.000001	 wd 0.0000	time 0.2307 (0.2724)	loss 0.8286 (0.8650)	grad_norm 0.4205 (0.4352)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:04:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:49 lr 0.000001	 wd 0.0000	time 3.9116 (0.2759)	loss 0.7993 (0.8652)	grad_norm 0.4119 (0.4351)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:04:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:07:11 lr 0.000001	 wd 0.0000	time 0.1955 (0.2696)	loss 0.8550 (0.8654)	grad_norm 0.4417 (0.4353)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:05:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:35 lr 0.000001	 wd 0.0000	time 0.1930 (0.2636)	loss 0.8076 (0.8658)	grad_norm 0.4585 (0.4351)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:05:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:06:02 lr 0.000001	 wd 0.0000	time 0.1774 (0.2586)	loss 0.9658 (0.8654)	grad_norm 0.4185 (0.4350)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:05:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:05:33 lr 0.000001	 wd 0.0000	time 0.2175 (0.2563)	loss 0.7451 (0.8642)	grad_norm 0.4446 (0.4353)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:06:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:05:06 lr 0.000001	 wd 0.0000	time 0.1796 (0.2549)	loss 0.8696 (0.8641)	grad_norm 0.4509 (0.4354)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:06:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:04:37 lr 0.000001	 wd 0.0000	time 0.1976 (0.2517)	loss 0.9482 (0.8639)	grad_norm 0.4495 (0.4353)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:06:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:04:09 lr 0.000001	 wd 0.0000	time 0.1893 (0.2489)	loss 0.7993 (0.8625)	grad_norm 0.4400 (0.4354)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:07:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:42 lr 0.000001	 wd 0.0000	time 0.2442 (0.2469)	loss 0.8921 (0.8619)	grad_norm 0.4371 (0.4353)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:07:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:03:18 lr 0.000001	 wd 0.0000	time 0.2235 (0.2469)	loss 0.9048 (0.8608)	grad_norm 0.4433 (0.4352)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:52 lr 0.000001	 wd 0.0000	time 0.2074 (0.2456)	loss 0.7500 (0.8602)	grad_norm 0.4126 (0.4351)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:08:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:26 lr 0.000001	 wd 0.0000	time 0.2212 (0.2440)	loss 0.7026 (0.8603)	grad_norm 0.4512 (0.4352)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:08:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:02:01 lr 0.000001	 wd 0.0000	time 0.1982 (0.2423)	loss 0.8262 (0.8606)	grad_norm 0.4448 (0.4350)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:09:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:37 lr 0.000001	 wd 0.0000	time 0.2251 (0.2414)	loss 0.7920 (0.8607)	grad_norm 0.4123 (0.4350)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:09:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:13 lr 0.000001	 wd 0.0000	time 0.2038 (0.2417)	loss 0.7505 (0.8602)	grad_norm 0.4329 (0.4350)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:09:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:48 lr 0.000001	 wd 0.0000	time 0.1829 (0.2406)	loss 0.7065 (0.8605)	grad_norm 0.4541 (0.4351)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:10:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:24 lr 0.000001	 wd 0.0000	time 0.2159 (0.2395)	loss 0.7627 (0.8604)	grad_norm 0.4538 (0.4352)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:10:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1594 (0.2375)	loss 0.9434 (0.8603)	grad_norm 0.4412 (0.4352)	loss_scale 32768.0000 (32768.0000)	mem 7964MB
[2024-08-02 01:10:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 249): INFO EPOCH 29 training takes 0:10:02
[2024-08-02 01:10:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_29.pth saving......
[2024-08-02 01:10:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft/diffusion_ft_adapter_conv_b_step_corss2/ckpt_epoch_29.pth saved !!!
[2024-08-02 01:11:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 289): INFO Test: [0/98]	Time 35.045 (35.045)	Loss 0.3472 (0.3472)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 7964MB
[2024-08-02 01:11:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 296): INFO  * Acc@1 85.364 Acc@5 97.684
[2024-08-02 01:11:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.4%
[2024-08-02 01:11:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 182): INFO Max accuracy: 85.40%
[2024-08-02 01:11:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_crosslayer_process2-efficient-ft] (main.py 189): INFO Training time 5:15:21
