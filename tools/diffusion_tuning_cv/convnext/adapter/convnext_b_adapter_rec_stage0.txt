[2024-07-29 16:53:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/config.json
[2024-07-29 16:53:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/convnext-b/convnext_base_22k_224.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_conv_b_sequence_stage0
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-29 16:53:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/adapter_convnext/diffusion_ft_adapter_convnext_base_224_22kto1k_step_stage_process0.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/convnext-b/convnext_base_22k_224.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_adapter_conv_b_sequence_stage0", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-29 16:53:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 108): INFO Creating model:adapter_convnext_diffusion_finetune/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0
[2024-07-29 16:53:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 110): INFO Adapter_ConvNeXt_Diffusion_Finetune(
  (uma): UMA(filter_strategy1=18, filter_strategy2=6,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (memory_downsampling): ModuleList()
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-29 16:53:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 113): INFO number of params: 1052104
[2024-07-29 16:53:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0, ignoring auto resume
[2024-07-29 16:53:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/convnext-b/convnext_base_22k_224.pth for fine-tuning......
[2024-07-29 16:53:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 112): INFO loading ImageNet-22K weight to ImageNet-1K ......
[2024-07-29 16:53:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 127): WARNING _IncompatibleKeys(missing_keys=['stages.0.0.adapter.down.weight', 'stages.0.0.adapter.down.bias', 'stages.0.0.adapter.up.weight', 'stages.0.0.adapter.up.bias', 'stages.0.1.adapter.down.weight', 'stages.0.1.adapter.down.bias', 'stages.0.1.adapter.up.weight', 'stages.0.1.adapter.up.bias', 'stages.0.2.adapter.down.weight', 'stages.0.2.adapter.down.bias', 'stages.0.2.adapter.up.weight', 'stages.0.2.adapter.up.bias', 'stages.1.0.adapter.down.weight', 'stages.1.0.adapter.down.bias', 'stages.1.0.adapter.up.weight', 'stages.1.0.adapter.up.bias', 'stages.1.1.adapter.down.weight', 'stages.1.1.adapter.down.bias', 'stages.1.1.adapter.up.weight', 'stages.1.1.adapter.up.bias', 'stages.1.2.adapter.down.weight', 'stages.1.2.adapter.down.bias', 'stages.1.2.adapter.up.weight', 'stages.1.2.adapter.up.bias', 'stages.2.0.adapter.down.weight', 'stages.2.0.adapter.down.bias', 'stages.2.0.adapter.up.weight', 'stages.2.0.adapter.up.bias', 'stages.2.1.adapter.down.weight', 'stages.2.1.adapter.down.bias', 'stages.2.1.adapter.up.weight', 'stages.2.1.adapter.up.bias', 'stages.2.2.adapter.down.weight', 'stages.2.2.adapter.down.bias', 'stages.2.2.adapter.up.weight', 'stages.2.2.adapter.up.bias', 'stages.2.3.adapter.down.weight', 'stages.2.3.adapter.down.bias', 'stages.2.3.adapter.up.weight', 'stages.2.3.adapter.up.bias', 'stages.2.4.adapter.down.weight', 'stages.2.4.adapter.down.bias', 'stages.2.4.adapter.up.weight', 'stages.2.4.adapter.up.bias', 'stages.2.5.adapter.down.weight', 'stages.2.5.adapter.down.bias', 'stages.2.5.adapter.up.weight', 'stages.2.5.adapter.up.bias', 'stages.2.6.adapter.down.weight', 'stages.2.6.adapter.down.bias', 'stages.2.6.adapter.up.weight', 'stages.2.6.adapter.up.bias', 'stages.2.7.adapter.down.weight', 'stages.2.7.adapter.down.bias', 'stages.2.7.adapter.up.weight', 'stages.2.7.adapter.up.bias', 'stages.2.8.adapter.down.weight', 'stages.2.8.adapter.down.bias', 'stages.2.8.adapter.up.weight', 'stages.2.8.adapter.up.bias', 'stages.2.9.adapter.down.weight', 'stages.2.9.adapter.down.bias', 'stages.2.9.adapter.up.weight', 'stages.2.9.adapter.up.bias', 'stages.2.10.adapter.down.weight', 'stages.2.10.adapter.down.bias', 'stages.2.10.adapter.up.weight', 'stages.2.10.adapter.up.bias', 'stages.2.11.adapter.down.weight', 'stages.2.11.adapter.down.bias', 'stages.2.11.adapter.up.weight', 'stages.2.11.adapter.up.bias', 'stages.2.12.adapter.down.weight', 'stages.2.12.adapter.down.bias', 'stages.2.12.adapter.up.weight', 'stages.2.12.adapter.up.bias', 'stages.2.13.adapter.down.weight', 'stages.2.13.adapter.down.bias', 'stages.2.13.adapter.up.weight', 'stages.2.13.adapter.up.bias', 'stages.2.14.adapter.down.weight', 'stages.2.14.adapter.down.bias', 'stages.2.14.adapter.up.weight', 'stages.2.14.adapter.up.bias', 'stages.2.15.adapter.down.weight', 'stages.2.15.adapter.down.bias', 'stages.2.15.adapter.up.weight', 'stages.2.15.adapter.up.bias', 'stages.2.16.adapter.down.weight', 'stages.2.16.adapter.down.bias', 'stages.2.16.adapter.up.weight', 'stages.2.16.adapter.up.bias', 'stages.2.17.adapter.down.weight', 'stages.2.17.adapter.down.bias', 'stages.2.17.adapter.up.weight', 'stages.2.17.adapter.up.bias', 'stages.2.18.adapter.down.weight', 'stages.2.18.adapter.down.bias', 'stages.2.18.adapter.up.weight', 'stages.2.18.adapter.up.bias', 'stages.2.19.adapter.down.weight', 'stages.2.19.adapter.down.bias', 'stages.2.19.adapter.up.weight', 'stages.2.19.adapter.up.bias', 'stages.2.20.adapter.down.weight', 'stages.2.20.adapter.down.bias', 'stages.2.20.adapter.up.weight', 'stages.2.20.adapter.up.bias', 'stages.2.21.adapter.down.weight', 'stages.2.21.adapter.down.bias', 'stages.2.21.adapter.up.weight', 'stages.2.21.adapter.up.bias', 'stages.2.22.adapter.down.weight', 'stages.2.22.adapter.down.bias', 'stages.2.22.adapter.up.weight', 'stages.2.22.adapter.up.bias', 'stages.2.23.adapter.down.weight', 'stages.2.23.adapter.down.bias', 'stages.2.23.adapter.up.weight', 'stages.2.23.adapter.up.bias', 'stages.2.24.adapter.down.weight', 'stages.2.24.adapter.down.bias', 'stages.2.24.adapter.up.weight', 'stages.2.24.adapter.up.bias', 'stages.2.25.adapter.down.weight', 'stages.2.25.adapter.down.bias', 'stages.2.25.adapter.up.weight', 'stages.2.25.adapter.up.bias', 'stages.2.26.adapter.down.weight', 'stages.2.26.adapter.down.bias', 'stages.2.26.adapter.up.weight', 'stages.2.26.adapter.up.bias', 'stages.3.0.adapter.down.weight', 'stages.3.0.adapter.down.bias', 'stages.3.0.adapter.up.weight', 'stages.3.0.adapter.up.bias', 'stages.3.1.adapter.down.weight', 'stages.3.1.adapter.down.bias', 'stages.3.1.adapter.up.weight', 'stages.3.1.adapter.up.bias', 'stages.3.2.adapter.down.weight', 'stages.3.2.adapter.down.bias', 'stages.3.2.adapter.up.weight', 'stages.3.2.adapter.up.bias'], unexpected_keys=[])
[2024-07-29 16:53:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/convnext-b/convnext_base_22k_224.pth'
[2024-07-29 16:54:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 70.524 (70.524)	Loss 0.3735 (0.3735)	Acc@1 91.016 (91.016)	Acc@5 98.828 (98.828)	Mem 3054MB
[2024-07-29 16:55:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 65.002 Acc@5 77.592
[2024-07-29 16:55:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 162): INFO Accuracy of the network on the 50000 test images: 65.0%
[2024-07-29 16:55:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 168): INFO Start training
[2024-07-29 16:56:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][0/2502]	eta 17:03:19 lr 0.000100	 wd 0.0000	time 24.5401 (24.5401)	loss 1.6934 (1.6934)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 7424MB
[2024-07-29 16:56:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:17:29 lr 0.000100	 wd 0.0000	time 0.2904 (0.4370)	loss 1.4512 (1.5865)	grad_norm 0.3749 (nan)	loss_scale 32768.0000 (33092.4356)	mem 7424MB
[2024-07-29 16:57:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:16:48 lr 0.000100	 wd 0.0000	time 0.2432 (0.4381)	loss 1.2451 (1.5606)	grad_norm 0.3491 (nan)	loss_scale 32768.0000 (32931.0249)	mem 7424MB
[2024-07-29 16:57:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:59 lr 0.000100	 wd 0.0000	time 0.1804 (0.3541)	loss 1.8320 (1.5415)	grad_norm 0.3500 (nan)	loss_scale 32768.0000 (32876.8638)	mem 7424MB
[2024-07-29 16:57:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:52 lr 0.000100	 wd 0.0000	time 0.1802 (0.3103)	loss 1.6514 (1.5130)	grad_norm 0.3471 (nan)	loss_scale 32768.0000 (32849.7157)	mem 7424MB
[2024-07-29 16:58:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:09:36 lr 0.000100	 wd 0.0000	time 0.2862 (0.2879)	loss 1.3389 (1.4920)	grad_norm 0.3387 (nan)	loss_scale 32768.0000 (32833.4052)	mem 7424MB
[2024-07-29 16:58:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:09:35 lr 0.000100	 wd 0.0000	time 0.1743 (0.3027)	loss 1.4697 (1.4673)	grad_norm 0.3315 (nan)	loss_scale 32768.0000 (32822.5225)	mem 7424MB
[2024-07-29 16:58:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:34 lr 0.000100	 wd 0.0000	time 0.1556 (0.2853)	loss 1.3164 (1.4456)	grad_norm 0.3488 (nan)	loss_scale 32768.0000 (32814.7447)	mem 7424MB
[2024-07-29 16:59:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:43 lr 0.000100	 wd 0.0000	time 0.1619 (0.2720)	loss 1.2012 (1.4259)	grad_norm 0.3280 (nan)	loss_scale 32768.0000 (32808.9089)	mem 7424MB
[2024-07-29 16:59:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:07:00 lr 0.000100	 wd 0.0000	time 0.1890 (0.2626)	loss 1.4619 (1.4048)	grad_norm 0.3334 (nan)	loss_scale 32768.0000 (32804.3685)	mem 7424MB
[2024-07-29 17:00:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:06:50 lr 0.000100	 wd 0.0000	time 0.1834 (0.2736)	loss 1.1133 (1.3849)	grad_norm 0.3336 (nan)	loss_scale 32768.0000 (32800.7353)	mem 7424MB
[2024-07-29 17:00:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:06:12 lr 0.000100	 wd 0.0000	time 0.1780 (0.2656)	loss 1.2314 (1.3670)	grad_norm 0.3436 (nan)	loss_scale 32768.0000 (32797.7620)	mem 7424MB
[2024-07-29 17:00:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:36 lr 0.000100	 wd 0.0000	time 0.1799 (0.2585)	loss 1.1279 (1.3497)	grad_norm 0.3292 (nan)	loss_scale 32768.0000 (32795.2839)	mem 7424MB
[2024-07-29 17:01:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:05:03 lr 0.000100	 wd 0.0000	time 0.2373 (0.2524)	loss 1.1504 (1.3344)	grad_norm 0.3330 (nan)	loss_scale 32768.0000 (32793.1868)	mem 7424MB
[2024-07-29 17:01:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:42 lr 0.000100	 wd 0.0000	time 0.1896 (0.2565)	loss 1.1436 (1.3191)	grad_norm 0.3210 (nan)	loss_scale 32768.0000 (32791.3890)	mem 7424MB
[2024-07-29 17:01:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:04:12 lr 0.000100	 wd 0.0000	time 0.1506 (0.2517)	loss 1.1914 (1.3052)	grad_norm 0.3216 (nan)	loss_scale 32768.0000 (32789.8308)	mem 7424MB
[2024-07-29 17:02:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:43 lr 0.000100	 wd 0.0000	time 0.1661 (0.2473)	loss 1.2217 (1.2917)	grad_norm 0.3194 (nan)	loss_scale 32768.0000 (32788.4672)	mem 7424MB
[2024-07-29 17:02:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:03:15 lr 0.000100	 wd 0.0000	time 0.1774 (0.2435)	loss 0.9810 (1.2786)	grad_norm 0.2958 (nan)	loss_scale 32768.0000 (32787.2640)	mem 7424MB
[2024-07-29 17:02:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:48 lr 0.000100	 wd 0.0000	time 0.1758 (0.2405)	loss 0.9683 (1.2657)	grad_norm 0.3422 (nan)	loss_scale 32768.0000 (32786.1943)	mem 7424MB
[2024-07-29 17:03:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:25 lr 0.000100	 wd 0.0000	time 0.2018 (0.2409)	loss 1.1807 (1.2541)	grad_norm 0.2999 (nan)	loss_scale 32768.0000 (32785.2372)	mem 7424MB
[2024-07-29 17:03:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:01:59 lr 0.000100	 wd 0.0000	time 0.1948 (0.2387)	loss 1.0586 (1.2434)	grad_norm 0.3186 (nan)	loss_scale 32768.0000 (32784.3758)	mem 7424MB
[2024-07-29 17:03:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:34 lr 0.000100	 wd 0.0000	time 0.1841 (0.2362)	loss 1.0410 (1.2333)	grad_norm 0.3100 (nan)	loss_scale 32768.0000 (32783.5964)	mem 7424MB
[2024-07-29 17:04:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:10 lr 0.000100	 wd 0.0000	time 0.1596 (0.2337)	loss 1.1074 (1.2232)	grad_norm 0.3052 (nan)	loss_scale 32768.0000 (32782.8878)	mem 7424MB
[2024-07-29 17:04:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:46 lr 0.000100	 wd 0.0000	time 0.2420 (0.2326)	loss 1.1582 (1.2138)	grad_norm 0.3213 (nan)	loss_scale 32768.0000 (32782.2408)	mem 7424MB
[2024-07-29 17:04:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:23 lr 0.000100	 wd 0.0000	time 0.1674 (0.2320)	loss 1.1943 (1.2053)	grad_norm 0.2975 (nan)	loss_scale 32768.0000 (32781.6476)	mem 7424MB
[2024-07-29 17:05:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.1490 (0.2296)	loss 1.0137 (1.1970)	grad_norm 0.2924 (nan)	loss_scale 32768.0000 (32781.1020)	mem 7424MB
[2024-07-29 17:05:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 0 training takes 0:09:39
[2024-07-29 17:05:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_0.pth saving......
[2024-07-29 17:05:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_0.pth saved !!!
[2024-07-29 17:06:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 57.707 (57.707)	Loss 0.3936 (0.3936)	Acc@1 91.016 (91.016)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 17:06:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 82.016 Acc@5 96.266
[2024-07-29 17:06:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 82.0%
[2024-07-29 17:06:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 82.02%
[2024-07-29 17:06:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 17:06:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 17:07:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][0/2502]	eta 11:59:36 lr 0.000100	 wd 0.0000	time 17.2567 (17.2567)	loss 0.8535 (0.8535)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:07:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:14:20 lr 0.000100	 wd 0.0000	time 0.1689 (0.3584)	loss 0.9141 (0.9808)	grad_norm 0.2932 (0.2953)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:07:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:11:38 lr 0.000100	 wd 0.0000	time 0.3445 (0.3036)	loss 0.8486 (0.9875)	grad_norm 0.2834 (0.2942)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:08:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:36 lr 0.000100	 wd 0.0000	time 0.2049 (0.3162)	loss 1.0469 (0.9864)	grad_norm 0.2913 (0.2939)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:08:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:09:53 lr 0.000100	 wd 0.0000	time 0.1563 (0.2823)	loss 0.9619 (0.9865)	grad_norm 0.3180 (0.2944)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:08:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:08:42 lr 0.000100	 wd 0.0000	time 0.1769 (0.2612)	loss 0.8716 (0.9824)	grad_norm 0.2907 (0.2942)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:09:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:07:58 lr 0.000100	 wd 0.0000	time 0.3663 (0.2515)	loss 1.0410 (0.9832)	grad_norm 0.2956 (0.2938)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:09:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:08:11 lr 0.000100	 wd 0.0000	time 0.1859 (0.2727)	loss 0.8799 (0.9808)	grad_norm 0.2927 (0.2932)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:10:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:07:25 lr 0.000100	 wd 0.0000	time 0.1671 (0.2617)	loss 1.1006 (0.9813)	grad_norm 0.2908 (0.2927)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:10:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:06:45 lr 0.000099	 wd 0.0000	time 0.1860 (0.2529)	loss 0.9155 (0.9792)	grad_norm 0.2873 (0.2921)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:10:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:11 lr 0.000099	 wd 0.0000	time 0.2441 (0.2475)	loss 0.9790 (0.9781)	grad_norm 0.2928 (0.2918)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:11:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:05:58 lr 0.000099	 wd 0.0000	time 0.1856 (0.2559)	loss 1.1045 (0.9778)	grad_norm 0.2885 (0.2915)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:11:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:25 lr 0.000099	 wd 0.0000	time 0.1802 (0.2497)	loss 0.9927 (0.9771)	grad_norm 0.3002 (0.2913)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:12:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:04:53 lr 0.000099	 wd 0.0000	time 0.1635 (0.2444)	loss 0.9404 (0.9769)	grad_norm 0.2875 (0.2910)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:12:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:24 lr 0.000099	 wd 0.0000	time 0.2105 (0.2398)	loss 0.9790 (0.9761)	grad_norm 0.2809 (0.2906)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:12:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:04:07 lr 0.000099	 wd 0.0000	time 0.2000 (0.2467)	loss 0.9604 (0.9761)	grad_norm 0.2795 (0.2903)	loss_scale 65536.0000 (32811.6616)	mem 7424MB
[2024-07-29 17:13:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:39 lr 0.000099	 wd 0.0000	time 0.2035 (0.2429)	loss 0.8521 (0.9752)	grad_norm 0.2708 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7424MB
[2024-07-29 17:13:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:12 lr 0.000099	 wd 0.0000	time 0.1940 (0.2394)	loss 0.8213 (0.9745)	grad_norm 0.2840 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7424MB
[2024-07-29 17:13:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:45 lr 0.000099	 wd 0.0000	time 0.2196 (0.2364)	loss 1.0801 (0.9739)	grad_norm 0.2743 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7424MB
[2024-07-29 17:14:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:21 lr 0.000099	 wd 0.0000	time 0.2071 (0.2354)	loss 1.0117 (0.9735)	grad_norm 0.2860 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7424MB
[2024-07-29 17:14:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:01:58 lr 0.000099	 wd 0.0000	time 0.1633 (0.2352)	loss 0.8462 (0.9730)	grad_norm 0.2915 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 17:14:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:33 lr 0.000099	 wd 0.0000	time 0.1871 (0.2331)	loss 0.9233 (0.9722)	grad_norm 0.2923 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 17:15:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:09 lr 0.000099	 wd 0.0000	time 0.1737 (0.2309)	loss 0.8252 (0.9709)	grad_norm 0.2700 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 17:15:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:46 lr 0.000099	 wd 0.0000	time 0.1725 (0.2290)	loss 1.0205 (0.9711)	grad_norm 0.2789 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 17:15:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:23 lr 0.000099	 wd 0.0000	time 0.1857 (0.2282)	loss 0.9678 (0.9705)	grad_norm 0.2839 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 17:16:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.1485 (0.2266)	loss 0.9580 (0.9703)	grad_norm 0.2866 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 17:16:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 1 training takes 0:09:33
[2024-07-29 17:16:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 27.476 (27.476)	Loss 0.3894 (0.3894)	Acc@1 91.016 (91.016)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 17:16:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.532 Acc@5 96.888
[2024-07-29 17:16:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 83.5%
[2024-07-29 17:16:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.53%
[2024-07-29 17:16:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 17:16:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 17:17:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][0/2502]	eta 13:12:24 lr 0.000099	 wd 0.0000	time 19.0027 (19.0027)	loss 0.8657 (0.8657)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:17:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:18:28 lr 0.000099	 wd 0.0000	time 0.1868 (0.4615)	loss 1.0508 (0.9552)	grad_norm 0.2972 (0.2804)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:18:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:12:21 lr 0.000099	 wd 0.0000	time 0.1851 (0.3221)	loss 1.0527 (0.9516)	grad_norm 0.2900 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:18:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:06 lr 0.000099	 wd 0.0000	time 0.1622 (0.2753)	loss 0.8931 (0.9467)	grad_norm 0.3010 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:18:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:08:47 lr 0.000099	 wd 0.0000	time 0.1701 (0.2511)	loss 1.0410 (0.9472)	grad_norm 0.2723 (0.2799)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:19:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:08:13 lr 0.000099	 wd 0.0000	time 0.4668 (0.2466)	loss 0.9805 (0.9533)	grad_norm 0.2863 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:19:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:29 lr 0.000099	 wd 0.0000	time 0.1990 (0.2681)	loss 0.8643 (0.9532)	grad_norm 0.2849 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:19:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:41 lr 0.000099	 wd 0.0000	time 0.1852 (0.2561)	loss 0.9341 (0.9530)	grad_norm 0.2741 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:20:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:07:00 lr 0.000099	 wd 0.0000	time 0.1847 (0.2468)	loss 0.8594 (0.9509)	grad_norm 0.2824 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:20:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:29 lr 0.000098	 wd 0.0000	time 0.3561 (0.2434)	loss 0.9980 (0.9506)	grad_norm 0.2920 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:21:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:06:14 lr 0.000098	 wd 0.0000	time 0.1737 (0.2496)	loss 0.8828 (0.9491)	grad_norm 0.2725 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:21:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:41 lr 0.000098	 wd 0.0000	time 0.1817 (0.2432)	loss 0.9702 (0.9489)	grad_norm 0.2807 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:21:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:05:09 lr 0.000098	 wd 0.0000	time 0.1907 (0.2380)	loss 1.1221 (0.9489)	grad_norm 0.2947 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:22:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:41 lr 0.000098	 wd 0.0000	time 0.2188 (0.2344)	loss 0.9766 (0.9494)	grad_norm 0.2835 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:22:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:28 lr 0.000098	 wd 0.0000	time 0.1966 (0.2437)	loss 1.0137 (0.9494)	grad_norm 0.2669 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:22:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:04:00 lr 0.000098	 wd 0.0000	time 0.1762 (0.2398)	loss 1.1162 (0.9497)	grad_norm 0.2686 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:23:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:32 lr 0.000098	 wd 0.0000	time 0.1973 (0.2361)	loss 0.9712 (0.9489)	grad_norm 0.2793 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:23:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:03:06 lr 0.000098	 wd 0.0000	time 0.1875 (0.2329)	loss 0.9595 (0.9494)	grad_norm 0.2820 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:23:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:42 lr 0.000098	 wd 0.0000	time 0.1576 (0.2318)	loss 0.9062 (0.9491)	grad_norm 0.2573 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:24:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:19 lr 0.000098	 wd 0.0000	time 0.1634 (0.2317)	loss 0.8438 (0.9493)	grad_norm 0.2714 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:24:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:55 lr 0.000098	 wd 0.0000	time 0.1502 (0.2294)	loss 0.9331 (0.9490)	grad_norm 0.2616 (0.2780)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:24:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:31 lr 0.000098	 wd 0.0000	time 0.2091 (0.2273)	loss 1.0215 (0.9495)	grad_norm 0.2727 (0.2779)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:25:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:08 lr 0.000098	 wd 0.0000	time 0.1866 (0.2255)	loss 0.9360 (0.9491)	grad_norm 0.2765 (0.2777)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:25:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:45 lr 0.000098	 wd 0.0000	time 0.1610 (0.2263)	loss 0.8838 (0.9487)	grad_norm 0.2909 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:26:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:22 lr 0.000098	 wd 0.0000	time 0.1652 (0.2251)	loss 0.9194 (0.9487)	grad_norm 0.2863 (0.2777)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:26:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.1487 (0.2227)	loss 0.9517 (0.9480)	grad_norm 0.2796 (0.2777)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:26:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 2 training takes 0:09:21
[2024-07-29 17:26:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 23.167 (23.167)	Loss 0.3840 (0.3840)	Acc@1 90.820 (90.820)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 17:26:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 83.984 Acc@5 97.072
[2024-07-29 17:26:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.0%
[2024-07-29 17:26:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 83.98%
[2024-07-29 17:26:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 17:26:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 17:27:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][0/2502]	eta 1 day, 3:21:09 lr 0.000098	 wd 0.0000	time 39.3562 (39.3562)	loss 0.7817 (0.7817)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:27:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:23:03 lr 0.000098	 wd 0.0000	time 0.1815 (0.5759)	loss 1.0557 (0.9387)	grad_norm 0.2890 (0.2777)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:28:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:14:31 lr 0.000097	 wd 0.0000	time 0.1649 (0.3785)	loss 1.0889 (0.9348)	grad_norm 0.2769 (0.2768)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:28:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:38 lr 0.000097	 wd 0.0000	time 0.3382 (0.3171)	loss 1.0928 (0.9360)	grad_norm 0.2779 (0.2765)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:29:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:11:46 lr 0.000097	 wd 0.0000	time 0.1929 (0.3360)	loss 1.0625 (0.9354)	grad_norm 0.2625 (0.2760)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:29:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:10:11 lr 0.000097	 wd 0.0000	time 0.1801 (0.3053)	loss 0.9927 (0.9369)	grad_norm nan (nan)	loss_scale 32768.0000 (32898.8104)	mem 7424MB
[2024-07-29 17:29:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:09:01 lr 0.000097	 wd 0.0000	time 0.1604 (0.2849)	loss 0.8950 (0.9375)	grad_norm 0.2999 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7424MB
[2024-07-29 17:30:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:08:08 lr 0.000097	 wd 0.0000	time 0.2057 (0.2709)	loss 0.9829 (0.9384)	grad_norm 0.2779 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7424MB
[2024-07-29 17:30:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:08:00 lr 0.000097	 wd 0.0000	time 0.2173 (0.2822)	loss 0.9321 (0.9371)	grad_norm 0.2764 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7424MB
[2024-07-29 17:31:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:07:15 lr 0.000097	 wd 0.0000	time 0.1842 (0.2720)	loss 0.9849 (0.9374)	grad_norm 0.2741 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7424MB
[2024-07-29 17:31:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:06:34 lr 0.000097	 wd 0.0000	time 0.1640 (0.2628)	loss 1.1123 (0.9392)	grad_norm 0.2906 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7424MB
[2024-07-29 17:31:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:57 lr 0.000097	 wd 0.0000	time 0.1843 (0.2551)	loss 0.8296 (0.9384)	grad_norm 0.2882 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7424MB
[2024-07-29 17:32:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:05:43 lr 0.000097	 wd 0.0000	time 0.1841 (0.2641)	loss 0.9834 (0.9375)	grad_norm 0.2709 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7424MB
[2024-07-29 17:32:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:05:10 lr 0.000097	 wd 0.0000	time 0.1658 (0.2584)	loss 1.0283 (0.9384)	grad_norm 0.2642 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7424MB
[2024-07-29 17:32:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:38 lr 0.000097	 wd 0.0000	time 0.1770 (0.2529)	loss 0.9023 (0.9380)	grad_norm 0.2671 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7424MB
[2024-07-29 17:33:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:04:08 lr 0.000097	 wd 0.0000	time 0.1896 (0.2479)	loss 0.8555 (0.9389)	grad_norm 0.2620 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7424MB
[2024-07-29 17:33:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:41 lr 0.000096	 wd 0.0000	time 0.2539 (0.2456)	loss 0.9082 (0.9379)	grad_norm 0.2850 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7424MB
[2024-07-29 17:33:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:03:16 lr 0.000096	 wd 0.0000	time 0.2002 (0.2452)	loss 0.9507 (0.9376)	grad_norm 0.2781 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7424MB
[2024-07-29 17:34:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:49 lr 0.000096	 wd 0.0000	time 0.1587 (0.2422)	loss 0.9570 (0.9374)	grad_norm 0.2629 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7424MB
[2024-07-29 17:34:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:24 lr 0.000096	 wd 0.0000	time 0.1734 (0.2393)	loss 0.9497 (0.9369)	grad_norm 0.2651 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7424MB
[2024-07-29 17:34:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:58 lr 0.000096	 wd 0.0000	time 0.2103 (0.2366)	loss 0.8945 (0.9371)	grad_norm 0.2649 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 17:35:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:34 lr 0.000096	 wd 0.0000	time 0.1749 (0.2355)	loss 0.7593 (0.9366)	grad_norm 0.2744 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 17:35:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:11 lr 0.000096	 wd 0.0000	time 0.2298 (0.2354)	loss 0.8804 (0.9360)	grad_norm 0.2764 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 17:35:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:47 lr 0.000096	 wd 0.0000	time 0.1640 (0.2334)	loss 1.0244 (0.9361)	grad_norm 0.2685 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 17:36:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:23 lr 0.000096	 wd 0.0000	time 0.1842 (0.2314)	loss 0.8540 (0.9360)	grad_norm 0.2703 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 17:36:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.1492 (0.2287)	loss 0.8564 (0.9364)	grad_norm 0.2818 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 17:36:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 3 training takes 0:09:36
[2024-07-29 17:37:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 44.205 (44.205)	Loss 0.3813 (0.3813)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 17:37:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.216 Acc@5 97.190
[2024-07-29 17:37:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.2%
[2024-07-29 17:37:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.22%
[2024-07-29 17:37:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 17:37:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 17:37:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][0/2502]	eta 9:46:07 lr 0.000096	 wd 0.0000	time 14.0556 (14.0556)	loss 0.9624 (0.9624)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:38:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:13:24 lr 0.000096	 wd 0.0000	time 0.1849 (0.3350)	loss 0.8369 (0.9354)	grad_norm 0.2677 (0.2727)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:38:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:12:56 lr 0.000096	 wd 0.0000	time 0.7979 (0.3372)	loss 0.9336 (0.9345)	grad_norm 0.2554 (0.2728)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:39:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:10:50 lr 0.000095	 wd 0.0000	time 0.1893 (0.2956)	loss 0.9258 (0.9348)	grad_norm 0.2778 (0.2732)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:39:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:20 lr 0.000095	 wd 0.0000	time 0.1835 (0.2667)	loss 0.9097 (0.9296)	grad_norm 0.2708 (0.2734)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:39:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:08:19 lr 0.000095	 wd 0.0000	time 0.1850 (0.2496)	loss 0.9805 (0.9308)	grad_norm 0.2680 (0.2735)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:40:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:07:58 lr 0.000095	 wd 0.0000	time 0.4376 (0.2516)	loss 0.8999 (0.9334)	grad_norm 0.2876 (0.2736)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:40:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:07:55 lr 0.000095	 wd 0.0000	time 0.1609 (0.2637)	loss 1.0576 (0.9301)	grad_norm 0.2716 (0.2734)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:40:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:07:11 lr 0.000095	 wd 0.0000	time 0.1785 (0.2534)	loss 0.8994 (0.9304)	grad_norm 0.2908 (0.2732)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:41:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:33 lr 0.000095	 wd 0.0000	time 0.1633 (0.2455)	loss 0.8896 (0.9315)	grad_norm 0.2748 (0.2729)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:41:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:06:04 lr 0.000095	 wd 0.0000	time 0.2846 (0.2424)	loss 0.9297 (0.9314)	grad_norm 0.2742 (0.2729)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:42:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:05:47 lr 0.000095	 wd 0.0000	time 0.1981 (0.2479)	loss 1.0098 (0.9329)	grad_norm 0.2803 (0.2730)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:42:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:05:15 lr 0.000095	 wd 0.0000	time 0.1958 (0.2424)	loss 0.7720 (0.9327)	grad_norm 0.2663 (0.2728)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:42:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:45 lr 0.000095	 wd 0.0000	time 0.1737 (0.2375)	loss 0.8657 (0.9317)	grad_norm 0.2683 (0.2726)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:43:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:04:17 lr 0.000094	 wd 0.0000	time 0.2314 (0.2340)	loss 0.9316 (0.9310)	grad_norm 0.2774 (0.2727)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:43:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:03:58 lr 0.000094	 wd 0.0000	time 0.2000 (0.2384)	loss 0.7949 (0.9312)	grad_norm 0.2702 (0.2727)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:43:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:31 lr 0.000094	 wd 0.0000	time 0.1650 (0.2350)	loss 0.8516 (0.9309)	grad_norm 0.2683 (0.2726)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:44:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:03:05 lr 0.000094	 wd 0.0000	time 0.1885 (0.2318)	loss 1.0996 (0.9306)	grad_norm 0.2705 (0.2725)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:44:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:40 lr 0.000094	 wd 0.0000	time 0.1746 (0.2291)	loss 0.9619 (0.9311)	grad_norm 0.2692 (0.2725)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:44:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:17 lr 0.000094	 wd 0.0000	time 0.2136 (0.2278)	loss 0.9385 (0.9310)	grad_norm 0.2658 (0.2724)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:45:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:54 lr 0.000094	 wd 0.0000	time 0.2468 (0.2283)	loss 0.7939 (0.9305)	grad_norm nan (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 17:45:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:31 lr 0.000094	 wd 0.0000	time 0.1725 (0.2266)	loss 0.8359 (0.9314)	grad_norm 0.2828 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 17:45:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:07 lr 0.000094	 wd 0.0000	time 0.1758 (0.2248)	loss 1.0254 (0.9308)	grad_norm 0.2486 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 17:46:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:45 lr 0.000094	 wd 0.0000	time 0.1797 (0.2229)	loss 0.9053 (0.9309)	grad_norm 0.2672 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 17:46:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:22 lr 0.000093	 wd 0.0000	time 0.1960 (0.2223)	loss 0.8677 (0.9310)	grad_norm 0.2611 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 17:46:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.1490 (0.2215)	loss 0.7837 (0.9309)	grad_norm 0.2692 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 17:46:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 4 training takes 0:09:20
[2024-07-29 17:47:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 20.181 (20.181)	Loss 0.3735 (0.3735)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 17:47:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.354 Acc@5 97.262
[2024-07-29 17:47:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.4%
[2024-07-29 17:47:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.35%
[2024-07-29 17:47:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 17:47:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 17:47:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][0/2502]	eta 11:03:36 lr 0.000093	 wd 0.0000	time 15.9139 (15.9139)	loss 0.9229 (0.9229)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:48:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:20:20 lr 0.000093	 wd 0.0000	time 0.2369 (0.5083)	loss 0.9492 (0.9208)	grad_norm 0.2785 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:48:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:13:48 lr 0.000093	 wd 0.0000	time 0.1637 (0.3598)	loss 0.8481 (0.9231)	grad_norm 0.2689 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:48:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:11:00 lr 0.000093	 wd 0.0000	time 0.1861 (0.3001)	loss 1.0518 (0.9217)	grad_norm 0.2720 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:49:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:09:27 lr 0.000093	 wd 0.0000	time 0.1884 (0.2701)	loss 0.9907 (0.9207)	grad_norm 0.2742 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:49:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:08:39 lr 0.000093	 wd 0.0000	time 0.3913 (0.2596)	loss 0.8960 (0.9203)	grad_norm 0.2830 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:50:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:39 lr 0.000093	 wd 0.0000	time 0.2042 (0.2732)	loss 0.8936 (0.9231)	grad_norm 0.2729 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:50:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:49 lr 0.000093	 wd 0.0000	time 0.2059 (0.2604)	loss 0.8330 (0.9225)	grad_norm 0.2856 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:50:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:07:06 lr 0.000093	 wd 0.0000	time 0.1953 (0.2505)	loss 0.8921 (0.9224)	grad_norm 0.2723 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:51:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:30 lr 0.000092	 wd 0.0000	time 0.3251 (0.2438)	loss 0.9517 (0.9230)	grad_norm 0.2676 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:51:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:24 lr 0.000092	 wd 0.0000	time 0.2309 (0.2560)	loss 0.9429 (0.9248)	grad_norm 0.2645 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:52:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:50 lr 0.000092	 wd 0.0000	time 0.1851 (0.2497)	loss 0.8721 (0.9261)	grad_norm 0.2753 (0.2711)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:52:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:05:17 lr 0.000092	 wd 0.0000	time 0.1685 (0.2441)	loss 0.9272 (0.9265)	grad_norm 0.3367 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:52:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:47 lr 0.000092	 wd 0.0000	time 0.2001 (0.2394)	loss 1.0186 (0.9257)	grad_norm 0.2851 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:53:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:30 lr 0.000092	 wd 0.0000	time 0.5420 (0.2458)	loss 0.8706 (0.9249)	grad_norm 0.2851 (0.2711)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:53:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:04:03 lr 0.000092	 wd 0.0000	time 0.1645 (0.2425)	loss 0.9028 (0.9255)	grad_norm 0.2705 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:53:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:35 lr 0.000092	 wd 0.0000	time 0.1718 (0.2388)	loss 0.8228 (0.9261)	grad_norm 0.2769 (0.2711)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:54:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:03:08 lr 0.000092	 wd 0.0000	time 0.1740 (0.2353)	loss 0.9180 (0.9264)	grad_norm 0.2541 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:54:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:43 lr 0.000091	 wd 0.0000	time 0.2047 (0.2335)	loss 0.9536 (0.9258)	grad_norm 0.2736 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:54:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:20 lr 0.000091	 wd 0.0000	time 0.1779 (0.2336)	loss 0.9058 (0.9255)	grad_norm 0.2697 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:55:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:56 lr 0.000091	 wd 0.0000	time 0.1792 (0.2316)	loss 0.9941 (0.9261)	grad_norm 0.2767 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:55:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:32 lr 0.000091	 wd 0.0000	time 0.1646 (0.2294)	loss 1.0410 (0.9256)	grad_norm 0.2785 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:55:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:08 lr 0.000091	 wd 0.0000	time 0.2060 (0.2275)	loss 1.0303 (0.9256)	grad_norm 0.2721 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:56:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:45 lr 0.000091	 wd 0.0000	time 0.2050 (0.2268)	loss 0.7974 (0.9254)	grad_norm 0.2847 (0.2714)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:56:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:23 lr 0.000091	 wd 0.0000	time 0.1708 (0.2268)	loss 0.8403 (0.9249)	grad_norm 0.2813 (0.2714)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:56:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.1487 (0.2244)	loss 0.8213 (0.9244)	grad_norm 0.2716 (0.2714)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:56:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 5 training takes 0:09:25
[2024-07-29 17:57:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 20.866 (20.866)	Loss 0.3691 (0.3691)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 17:57:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.436 Acc@5 97.312
[2024-07-29 17:57:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.4%
[2024-07-29 17:57:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.44%
[2024-07-29 17:57:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 17:57:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 17:58:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][0/2502]	eta 1 day, 2:45:28 lr 0.000091	 wd 0.0000	time 38.5006 (38.5006)	loss 0.9634 (0.9634)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:58:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:22:30 lr 0.000090	 wd 0.0000	time 0.1929 (0.5623)	loss 0.8965 (0.9298)	grad_norm 0.2872 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:58:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:14:15 lr 0.000090	 wd 0.0000	time 0.1626 (0.3714)	loss 0.8423 (0.9240)	grad_norm 0.2786 (0.2715)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:58:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:11:16 lr 0.000090	 wd 0.0000	time 0.1782 (0.3073)	loss 0.9712 (0.9259)	grad_norm 0.2718 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:59:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:10:20 lr 0.000090	 wd 0.0000	time 0.5077 (0.2952)	loss 0.9087 (0.9248)	grad_norm 0.2649 (0.2711)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 17:59:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:10:09 lr 0.000090	 wd 0.0000	time 0.1795 (0.3047)	loss 0.9575 (0.9246)	grad_norm 0.2531 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:00:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:09:00 lr 0.000090	 wd 0.0000	time 0.1933 (0.2842)	loss 0.9087 (0.9246)	grad_norm 0.2853 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:00:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:08:05 lr 0.000090	 wd 0.0000	time 0.1834 (0.2693)	loss 1.0127 (0.9242)	grad_norm 0.2742 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:00:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:07:31 lr 0.000090	 wd 0.0000	time 0.3349 (0.2654)	loss 0.7656 (0.9242)	grad_norm 0.2763 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:01:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:07:16 lr 0.000089	 wd 0.0000	time 0.1980 (0.2722)	loss 0.9058 (0.9237)	grad_norm 0.2579 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:01:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:06:35 lr 0.000089	 wd 0.0000	time 0.1791 (0.2632)	loss 0.8760 (0.9248)	grad_norm 0.2759 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7424MB
[2024-07-29 18:02:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:58 lr 0.000089	 wd 0.0000	time 0.1634 (0.2557)	loss 0.8438 (0.9233)	grad_norm 0.2645 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7424MB
[2024-07-29 18:02:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:05:25 lr 0.000089	 wd 0.0000	time 0.1839 (0.2503)	loss 0.8901 (0.9234)	grad_norm 0.2652 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7424MB
[2024-07-29 18:02:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:58 lr 0.000089	 wd 0.0000	time 0.1727 (0.2487)	loss 0.8135 (0.9228)	grad_norm 0.2637 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7424MB
[2024-07-29 18:03:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:04:29 lr 0.000089	 wd 0.0000	time 0.1756 (0.2444)	loss 0.9785 (0.9224)	grad_norm 0.2717 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7424MB
[2024-07-29 18:03:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:04:00 lr 0.000089	 wd 0.0000	time 0.1792 (0.2403)	loss 0.8018 (0.9224)	grad_norm 0.2677 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7424MB
[2024-07-29 18:03:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:33 lr 0.000089	 wd 0.0000	time 0.1644 (0.2368)	loss 0.8330 (0.9217)	grad_norm 0.2618 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7424MB
[2024-07-29 18:04:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:03:08 lr 0.000088	 wd 0.0000	time 0.2032 (0.2345)	loss 0.8970 (0.9204)	grad_norm 0.2552 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7424MB
[2024-07-29 18:04:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:44 lr 0.000088	 wd 0.0000	time 1.3175 (0.2345)	loss 0.8647 (0.9204)	grad_norm 0.2640 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7424MB
[2024-07-29 18:04:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:19 lr 0.000088	 wd 0.0000	time 0.2078 (0.2322)	loss 0.9443 (0.9207)	grad_norm 0.2654 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7424MB
[2024-07-29 18:05:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:55 lr 0.000088	 wd 0.0000	time 0.1969 (0.2300)	loss 0.9673 (0.9211)	grad_norm 0.2655 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 18:05:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:31 lr 0.000088	 wd 0.0000	time 0.1876 (0.2279)	loss 0.8149 (0.9210)	grad_norm 0.2732 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 18:05:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:08 lr 0.000088	 wd 0.0000	time 0.2289 (0.2269)	loss 0.9482 (0.9204)	grad_norm 0.2769 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 18:06:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:45 lr 0.000088	 wd 0.0000	time 0.1979 (0.2274)	loss 0.8525 (0.9203)	grad_norm 0.2662 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 18:06:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:23 lr 0.000087	 wd 0.0000	time 0.1572 (0.2257)	loss 0.9248 (0.9208)	grad_norm 0.2679 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 18:06:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.1488 (0.2232)	loss 0.8374 (0.9214)	grad_norm 0.2697 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 18:06:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 6 training takes 0:09:22
[2024-07-29 18:07:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 24.468 (24.468)	Loss 0.3694 (0.3694)	Acc@1 91.211 (91.211)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 18:07:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.502 Acc@5 97.334
[2024-07-29 18:07:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-29 18:07:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.50%
[2024-07-29 18:07:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 18:07:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 18:08:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][0/2502]	eta 13:29:29 lr 0.000087	 wd 0.0000	time 19.4124 (19.4124)	loss 0.9204 (0.9204)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:08:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:14:59 lr 0.000087	 wd 0.0000	time 0.1714 (0.3744)	loss 1.0068 (0.9202)	grad_norm 0.2634 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:08:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:10:37 lr 0.000087	 wd 0.0000	time 0.1558 (0.2770)	loss 0.9092 (0.9175)	grad_norm 0.2657 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:09:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:11 lr 0.000087	 wd 0.0000	time 0.4114 (0.2775)	loss 0.8823 (0.9143)	grad_norm 0.2688 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:09:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:10:18 lr 0.000087	 wd 0.0000	time 0.1828 (0.2941)	loss 0.9053 (0.9188)	grad_norm 0.2844 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:09:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:09:05 lr 0.000087	 wd 0.0000	time 0.2007 (0.2724)	loss 0.7896 (0.9163)	grad_norm 0.2562 (0.2702)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:10:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:09 lr 0.000086	 wd 0.0000	time 0.1662 (0.2573)	loss 1.0537 (0.9185)	grad_norm 0.2561 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:10:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:33 lr 0.000086	 wd 0.0000	time 0.2949 (0.2518)	loss 0.8511 (0.9180)	grad_norm 0.2565 (0.2699)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:11:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:07:16 lr 0.000086	 wd 0.0000	time 0.2101 (0.2566)	loss 0.8579 (0.9170)	grad_norm 0.2607 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:11:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:37 lr 0.000086	 wd 0.0000	time 0.1974 (0.2481)	loss 0.8970 (0.9179)	grad_norm 0.2757 (0.2699)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:11:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:06:02 lr 0.000086	 wd 0.0000	time 0.1702 (0.2413)	loss 0.8018 (0.9178)	grad_norm 0.2749 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:12:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:31 lr 0.000086	 wd 0.0000	time 0.2145 (0.2363)	loss 0.7988 (0.9174)	grad_norm 0.2760 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:12:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:05:20 lr 0.000086	 wd 0.0000	time 0.2198 (0.2465)	loss 0.9424 (0.9166)	grad_norm 0.2785 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:12:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:50 lr 0.000085	 wd 0.0000	time 0.1728 (0.2417)	loss 0.9639 (0.9160)	grad_norm 0.2617 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:13:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:21 lr 0.000085	 wd 0.0000	time 0.1910 (0.2373)	loss 0.8032 (0.9164)	grad_norm 0.2723 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:13:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:03:53 lr 0.000085	 wd 0.0000	time 0.2124 (0.2334)	loss 0.8618 (0.9159)	grad_norm 0.2870 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:13:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:29 lr 0.000085	 wd 0.0000	time 0.1921 (0.2318)	loss 0.9185 (0.9157)	grad_norm 0.2721 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:14:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:03:05 lr 0.000085	 wd 0.0000	time 0.1763 (0.2312)	loss 1.0410 (0.9153)	grad_norm 0.2612 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:14:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:40 lr 0.000085	 wd 0.0000	time 0.2061 (0.2287)	loss 0.8594 (0.9153)	grad_norm 0.2605 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:14:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:16 lr 0.000085	 wd 0.0000	time 0.1640 (0.2265)	loss 0.9326 (0.9152)	grad_norm 0.2625 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:15:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:52 lr 0.000084	 wd 0.0000	time 0.2462 (0.2245)	loss 0.8760 (0.9147)	grad_norm 0.2701 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:15:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:29 lr 0.000084	 wd 0.0000	time 0.1777 (0.2236)	loss 1.0430 (0.9158)	grad_norm 0.2712 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:15:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:07 lr 0.000084	 wd 0.0000	time 0.2175 (0.2238)	loss 0.7363 (0.9150)	grad_norm 0.2798 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:16:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:44 lr 0.000084	 wd 0.0000	time 0.1793 (0.2222)	loss 1.0166 (0.9151)	grad_norm 0.2774 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:16:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:22 lr 0.000084	 wd 0.0000	time 0.1617 (0.2206)	loss 0.9946 (0.9153)	grad_norm 0.2778 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:16:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.1484 (0.2183)	loss 0.9189 (0.9157)	grad_norm 0.2822 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 18:16:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 7 training takes 0:09:10
[2024-07-29 18:17:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 45.573 (45.573)	Loss 0.3643 (0.3643)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 18:17:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.522 Acc@5 97.368
[2024-07-29 18:17:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.5%
[2024-07-29 18:17:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.52%
[2024-07-29 18:17:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 18:17:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 18:18:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][0/2502]	eta 10:50:36 lr 0.000084	 wd 0.0000	time 15.6021 (15.6021)	loss 0.8496 (0.8496)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:18:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:13:50 lr 0.000083	 wd 0.0000	time 0.2026 (0.3456)	loss 0.8945 (0.9206)	grad_norm 0.2641 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:19:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:14:02 lr 0.000083	 wd 0.0000	time 0.2000 (0.3659)	loss 0.9038 (0.9196)	grad_norm 0.2583 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:19:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:11:14 lr 0.000083	 wd 0.0000	time 0.1766 (0.3064)	loss 0.9082 (0.9154)	grad_norm 0.2828 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:19:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:09:37 lr 0.000083	 wd 0.0000	time 0.1658 (0.2749)	loss 1.0273 (0.9160)	grad_norm 0.2629 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:20:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:08:32 lr 0.000083	 wd 0.0000	time 0.1881 (0.2561)	loss 0.8433 (0.9169)	grad_norm 0.2700 (0.2690)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:20:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:08:53 lr 0.000083	 wd 0.0000	time 0.2244 (0.2807)	loss 0.8892 (0.9164)	grad_norm 0.2898 (0.2689)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:21:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:08:03 lr 0.000083	 wd 0.0000	time 0.1810 (0.2682)	loss 0.9253 (0.9158)	grad_norm 0.2812 (0.2689)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:21:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:07:18 lr 0.000082	 wd 0.0000	time 0.1824 (0.2575)	loss 0.8047 (0.9155)	grad_norm 0.2790 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:21:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:39 lr 0.000082	 wd 0.0000	time 0.2043 (0.2492)	loss 1.0605 (0.9167)	grad_norm 0.2601 (0.2690)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:22:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:06:27 lr 0.000082	 wd 0.0000	time 0.2240 (0.2582)	loss 1.0781 (0.9170)	grad_norm 0.2614 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:22:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:52 lr 0.000082	 wd 0.0000	time 0.1704 (0.2517)	loss 1.0127 (0.9169)	grad_norm 0.2784 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:22:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:05:19 lr 0.000082	 wd 0.0000	time 0.1564 (0.2457)	loss 0.8857 (0.9167)	grad_norm 0.2657 (0.2690)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:23:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:49 lr 0.000082	 wd 0.0000	time 0.2029 (0.2404)	loss 0.8433 (0.9167)	grad_norm 0.2666 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:23:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:04:23 lr 0.000081	 wd 0.0000	time 0.2994 (0.2392)	loss 0.8662 (0.9164)	grad_norm 0.2633 (0.2690)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:23:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:04:04 lr 0.000081	 wd 0.0000	time 0.1575 (0.2440)	loss 0.8740 (0.9162)	grad_norm 0.2844 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:24:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:36 lr 0.000081	 wd 0.0000	time 0.1676 (0.2400)	loss 1.0166 (0.9155)	grad_norm 0.2646 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:24:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:03:09 lr 0.000081	 wd 0.0000	time 0.1977 (0.2367)	loss 0.8862 (0.9162)	grad_norm 0.2597 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:24:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:44 lr 0.000081	 wd 0.0000	time 0.1867 (0.2339)	loss 0.9102 (0.9165)	grad_norm 0.2805 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:25:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:20 lr 0.000081	 wd 0.0000	time 0.1725 (0.2335)	loss 0.8071 (0.9159)	grad_norm 0.2497 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:25:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:56 lr 0.000080	 wd 0.0000	time 0.1704 (0.2321)	loss 0.8647 (0.9161)	grad_norm 0.3026 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:25:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:32 lr 0.000080	 wd 0.0000	time 0.1946 (0.2300)	loss 0.9307 (0.9162)	grad_norm 0.2795 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:26:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:08 lr 0.000080	 wd 0.0000	time 0.1544 (0.2280)	loss 0.8892 (0.9157)	grad_norm 0.2780 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:26:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:45 lr 0.000080	 wd 0.0000	time 0.1965 (0.2265)	loss 1.0127 (0.9155)	grad_norm 0.2636 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:26:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:23 lr 0.000080	 wd 0.0000	time 0.1675 (0.2259)	loss 0.9814 (0.9154)	grad_norm 0.2737 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:27:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.1488 (0.2237)	loss 0.9756 (0.9154)	grad_norm 0.2657 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:27:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 8 training takes 0:09:25
[2024-07-29 18:27:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 18.612 (18.612)	Loss 0.3682 (0.3682)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 18:27:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.622 Acc@5 97.416
[2024-07-29 18:27:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-29 18:27:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.62%
[2024-07-29 18:27:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 18:27:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 18:28:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][0/2502]	eta 15:51:19 lr 0.000080	 wd 0.0000	time 22.8134 (22.8134)	loss 0.9199 (0.9199)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:28:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:19:19 lr 0.000079	 wd 0.0000	time 0.1738 (0.4826)	loss 0.9746 (0.9096)	grad_norm 0.2728 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:28:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:12:47 lr 0.000079	 wd 0.0000	time 0.1734 (0.3332)	loss 0.8062 (0.9080)	grad_norm 0.2625 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:29:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:10:23 lr 0.000079	 wd 0.0000	time 0.1474 (0.2830)	loss 0.9731 (0.9097)	grad_norm 0.2502 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:29:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:09:00 lr 0.000079	 wd 0.0000	time 0.1979 (0.2572)	loss 0.8979 (0.9096)	grad_norm 0.2537 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:29:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:08:24 lr 0.000079	 wd 0.0000	time 0.3748 (0.2519)	loss 0.7051 (0.9139)	grad_norm 0.2733 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:30:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:23 lr 0.000079	 wd 0.0000	time 0.2260 (0.2649)	loss 0.7466 (0.9115)	grad_norm 0.2770 (0.2702)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:30:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:36 lr 0.000078	 wd 0.0000	time 0.1764 (0.2531)	loss 0.9839 (0.9123)	grad_norm 0.2682 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:31:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:06:55 lr 0.000078	 wd 0.0000	time 0.1845 (0.2442)	loss 0.9463 (0.9135)	grad_norm 0.2549 (0.2699)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:31:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:21 lr 0.000078	 wd 0.0000	time 0.1769 (0.2382)	loss 1.0918 (0.9142)	grad_norm 0.2687 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:31:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:06:07 lr 0.000078	 wd 0.0000	time 0.1819 (0.2445)	loss 0.9614 (0.9144)	grad_norm 0.2736 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:32:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:34 lr 0.000078	 wd 0.0000	time 0.1693 (0.2388)	loss 0.8213 (0.9143)	grad_norm 0.2859 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:32:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:05:04 lr 0.000078	 wd 0.0000	time 0.1843 (0.2340)	loss 0.9893 (0.9140)	grad_norm 0.2718 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:32:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:36 lr 0.000077	 wd 0.0000	time 0.1566 (0.2300)	loss 0.9448 (0.9140)	grad_norm 0.2571 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:33:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:04:13 lr 0.000077	 wd 0.0000	time 0.3100 (0.2297)	loss 0.9507 (0.9145)	grad_norm 0.2610 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:33:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:53 lr 0.000077	 wd 0.0000	time 0.1866 (0.2330)	loss 1.0225 (0.9148)	grad_norm 0.2694 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7424MB
[2024-07-29 18:33:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:27 lr 0.000077	 wd 0.0000	time 0.1921 (0.2296)	loss 0.9341 (0.9143)	grad_norm 0.2565 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7424MB
[2024-07-29 18:34:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:03:02 lr 0.000077	 wd 0.0000	time 0.1727 (0.2269)	loss 0.8604 (0.9150)	grad_norm 0.2548 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7424MB
[2024-07-29 18:34:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:37 lr 0.000077	 wd 0.0000	time 0.1980 (0.2248)	loss 0.7495 (0.9147)	grad_norm 0.2750 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7424MB
[2024-07-29 18:35:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:16 lr 0.000076	 wd 0.0000	time 0.1500 (0.2259)	loss 0.9561 (0.9147)	grad_norm 0.2688 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7424MB
[2024-07-29 18:35:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:52 lr 0.000076	 wd 0.0000	time 0.1927 (0.2242)	loss 0.9185 (0.9155)	grad_norm 0.2587 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 18:35:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:29 lr 0.000076	 wd 0.0000	time 0.2254 (0.2224)	loss 1.0654 (0.9158)	grad_norm 0.2610 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 18:35:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:06 lr 0.000076	 wd 0.0000	time 0.1489 (0.2206)	loss 0.9263 (0.9161)	grad_norm 0.2589 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 18:36:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:44 lr 0.000076	 wd 0.0000	time 0.2065 (0.2195)	loss 0.9160 (0.9157)	grad_norm 0.2785 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 18:36:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:22 lr 0.000075	 wd 0.0000	time 0.1617 (0.2196)	loss 0.8311 (0.9157)	grad_norm 0.2737 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 18:36:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.1484 (0.2178)	loss 0.8818 (0.9157)	grad_norm 0.2614 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 18:37:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 9 training takes 0:09:09
[2024-07-29 18:37:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 22.231 (22.231)	Loss 0.3625 (0.3625)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 18:37:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.624 Acc@5 97.426
[2024-07-29 18:37:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-29 18:37:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.62%
[2024-07-29 18:37:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 18:37:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 18:38:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][0/2502]	eta 19:31:44 lr 0.000075	 wd 0.0000	time 28.0992 (28.0992)	loss 1.0664 (1.0664)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:38:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:20:30 lr 0.000075	 wd 0.0000	time 0.1705 (0.5124)	loss 0.7788 (0.9283)	grad_norm 0.2636 (0.2689)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:38:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:13:17 lr 0.000075	 wd 0.0000	time 0.1628 (0.3467)	loss 1.0078 (0.9203)	grad_norm 0.2778 (0.2685)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:39:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:10:40 lr 0.000075	 wd 0.0000	time 0.1813 (0.2910)	loss 0.9106 (0.9151)	grad_norm 0.2594 (0.2684)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:39:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:14 lr 0.000075	 wd 0.0000	time 0.1899 (0.2639)	loss 0.9312 (0.9135)	grad_norm 0.2709 (0.2685)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:40:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:09:44 lr 0.000074	 wd 0.0000	time 0.1840 (0.2920)	loss 0.7993 (0.9146)	grad_norm 0.2764 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:40:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:08:41 lr 0.000074	 wd 0.0000	time 0.1778 (0.2743)	loss 0.9658 (0.9133)	grad_norm 0.2747 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:40:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:50 lr 0.000074	 wd 0.0000	time 0.1449 (0.2610)	loss 0.8306 (0.9120)	grad_norm 0.2658 (0.2689)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:40:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:07:07 lr 0.000074	 wd 0.0000	time 0.1797 (0.2510)	loss 0.8887 (0.9122)	grad_norm 0.2628 (0.2690)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:41:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:51 lr 0.000074	 wd 0.0000	time 0.1665 (0.2566)	loss 0.8838 (0.9125)	grad_norm 0.2644 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:41:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:06:14 lr 0.000073	 wd 0.0000	time 0.2041 (0.2495)	loss 0.8574 (0.9129)	grad_norm 0.2656 (0.2689)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:42:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:05:40 lr 0.000073	 wd 0.0000	time 0.2245 (0.2431)	loss 0.8149 (0.9128)	grad_norm 0.2536 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:42:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:05:09 lr 0.000073	 wd 0.0000	time 0.1962 (0.2379)	loss 1.0625 (0.9128)	grad_norm 0.2592 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:42:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:41 lr 0.000073	 wd 0.0000	time 0.1998 (0.2343)	loss 0.9189 (0.9128)	grad_norm 0.2639 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:43:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:04:24 lr 0.000073	 wd 0.0000	time 0.1826 (0.2399)	loss 0.8105 (0.9127)	grad_norm 0.2782 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:43:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:56 lr 0.000073	 wd 0.0000	time 0.1701 (0.2361)	loss 0.8779 (0.9124)	grad_norm 0.2727 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:43:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:29 lr 0.000072	 wd 0.0000	time 0.1769 (0.2328)	loss 0.8076 (0.9126)	grad_norm 0.2616 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:44:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:03:04 lr 0.000072	 wd 0.0000	time 0.2098 (0.2298)	loss 0.8882 (0.9129)	grad_norm 0.2549 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:44:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:40 lr 0.000072	 wd 0.0000	time 0.1930 (0.2281)	loss 0.9702 (0.9129)	grad_norm 0.2822 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:44:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:17 lr 0.000072	 wd 0.0000	time 0.1866 (0.2283)	loss 0.9902 (0.9128)	grad_norm 0.2758 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:45:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:53 lr 0.000072	 wd 0.0000	time 0.1881 (0.2265)	loss 0.8892 (0.9132)	grad_norm 0.2649 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:45:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:30 lr 0.000071	 wd 0.0000	time 0.1661 (0.2246)	loss 0.8818 (0.9133)	grad_norm 0.2831 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:45:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:01:07 lr 0.000071	 wd 0.0000	time 0.1907 (0.2227)	loss 0.8774 (0.9138)	grad_norm 0.2602 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:46:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:44 lr 0.000071	 wd 0.0000	time 0.2516 (0.2225)	loss 0.9604 (0.9132)	grad_norm 0.2601 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:46:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:22 lr 0.000071	 wd 0.0000	time 0.1773 (0.2222)	loss 0.9253 (0.9138)	grad_norm 0.2612 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:46:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.1488 (0.2199)	loss 1.0059 (0.9131)	grad_norm 0.2698 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:46:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 10 training takes 0:09:14
[2024-07-29 18:47:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 21.196 (21.196)	Loss 0.3691 (0.3691)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 18:47:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.628 Acc@5 97.452
[2024-07-29 18:47:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.6%
[2024-07-29 18:47:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.63%
[2024-07-29 18:47:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 18:47:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 18:47:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][0/2502]	eta 22:00:12 lr 0.000071	 wd 0.0000	time 31.6597 (31.6597)	loss 0.8140 (0.8140)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:48:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:20:18 lr 0.000070	 wd 0.0000	time 0.1614 (0.5074)	loss 0.9302 (0.9060)	grad_norm 0.2663 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:48:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:13:12 lr 0.000070	 wd 0.0000	time 0.1840 (0.3441)	loss 0.9453 (0.9087)	grad_norm 0.2826 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:48:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:10:36 lr 0.000070	 wd 0.0000	time 0.1780 (0.2891)	loss 1.0391 (0.9095)	grad_norm 0.2674 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:49:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:09:28 lr 0.000070	 wd 0.0000	time 0.3902 (0.2702)	loss 0.9790 (0.9080)	grad_norm 0.2817 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:49:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:09:29 lr 0.000070	 wd 0.0000	time 0.1533 (0.2845)	loss 0.8232 (0.9075)	grad_norm 0.2577 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7424MB
[2024-07-29 18:50:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:08:28 lr 0.000069	 wd 0.0000	time 0.1785 (0.2674)	loss 1.1025 (0.9059)	grad_norm 0.2706 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7424MB
[2024-07-29 18:50:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:39 lr 0.000069	 wd 0.0000	time 0.1711 (0.2552)	loss 0.8940 (0.9088)	grad_norm 0.2721 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7424MB
[2024-07-29 18:50:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:06:59 lr 0.000069	 wd 0.0000	time 0.1917 (0.2462)	loss 0.9507 (0.9096)	grad_norm 0.2663 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7424MB
[2024-07-29 18:51:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:06:47 lr 0.000069	 wd 0.0000	time 0.2264 (0.2544)	loss 1.0391 (0.9101)	grad_norm 0.2834 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7424MB
[2024-07-29 18:51:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:06:11 lr 0.000069	 wd 0.0000	time 0.1741 (0.2476)	loss 0.8477 (0.9111)	grad_norm 0.2668 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7424MB
[2024-07-29 18:51:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:38 lr 0.000069	 wd 0.0000	time 0.1779 (0.2415)	loss 0.8384 (0.9115)	grad_norm 0.2695 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7424MB
[2024-07-29 18:52:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:05:07 lr 0.000068	 wd 0.0000	time 0.1677 (0.2361)	loss 0.9805 (0.9116)	grad_norm 0.2657 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7424MB
[2024-07-29 18:52:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:40 lr 0.000068	 wd 0.0000	time 0.2082 (0.2333)	loss 0.7812 (0.9118)	grad_norm 0.2625 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7424MB
[2024-07-29 18:52:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:04:16 lr 0.000068	 wd 0.0000	time 0.1788 (0.2332)	loss 0.8662 (0.9125)	grad_norm 0.2775 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7424MB
[2024-07-29 18:53:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:03:50 lr 0.000068	 wd 0.0000	time 0.2160 (0.2304)	loss 0.9648 (0.9121)	grad_norm 0.2759 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7424MB
[2024-07-29 18:53:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:25 lr 0.000068	 wd 0.0000	time 0.1678 (0.2275)	loss 0.9521 (0.9123)	grad_norm 0.2787 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7424MB
[2024-07-29 18:53:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:03:00 lr 0.000067	 wd 0.0000	time 0.1955 (0.2248)	loss 0.8091 (0.9123)	grad_norm 0.2683 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7424MB
[2024-07-29 18:54:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:36 lr 0.000067	 wd 0.0000	time 0.1773 (0.2235)	loss 1.1279 (0.9131)	grad_norm 0.2652 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7424MB
[2024-07-29 18:54:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:14 lr 0.000067	 wd 0.0000	time 0.1774 (0.2236)	loss 0.8091 (0.9135)	grad_norm 0.2577 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7424MB
[2024-07-29 18:54:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:51 lr 0.000067	 wd 0.0000	time 0.1589 (0.2221)	loss 0.9282 (0.9132)	grad_norm 0.2592 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 18:55:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:28 lr 0.000067	 wd 0.0000	time 0.2043 (0.2204)	loss 0.8818 (0.9130)	grad_norm 0.2817 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 18:55:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:06 lr 0.000066	 wd 0.0000	time 0.2026 (0.2187)	loss 0.9331 (0.9129)	grad_norm 0.2700 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 18:55:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:44 lr 0.000066	 wd 0.0000	time 0.1656 (0.2182)	loss 0.8931 (0.9128)	grad_norm 0.2689 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 18:56:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:22 lr 0.000066	 wd 0.0000	time 0.2066 (0.2185)	loss 0.9014 (0.9131)	grad_norm 0.2681 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 18:56:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.1499 (0.2166)	loss 1.1035 (0.9123)	grad_norm 0.2662 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 18:56:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 11 training takes 0:09:06
[2024-07-29 18:56:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 20.739 (20.739)	Loss 0.3660 (0.3660)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 7424MB
[2024-07-29 18:57:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.678 Acc@5 97.440
[2024-07-29 18:57:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-29 18:57:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.68%
[2024-07-29 18:57:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 18:57:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 18:57:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][0/2502]	eta 22:44:06 lr 0.000066	 wd 0.0000	time 32.7124 (32.7124)	loss 0.9531 (0.9531)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:57:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:20:51 lr 0.000066	 wd 0.0000	time 0.1782 (0.5210)	loss 0.8584 (0.8996)	grad_norm 0.2706 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:58:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:13:29 lr 0.000065	 wd 0.0000	time 0.1890 (0.3515)	loss 0.8877 (0.9055)	grad_norm 0.2625 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:58:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:47 lr 0.000065	 wd 0.0000	time 0.1625 (0.2942)	loss 0.9399 (0.9157)	grad_norm 0.2887 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:58:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:09:45 lr 0.000065	 wd 0.0000	time 0.3070 (0.2787)	loss 0.8818 (0.9175)	grad_norm 0.2654 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:59:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:09:33 lr 0.000065	 wd 0.0000	time 0.1742 (0.2865)	loss 0.8047 (0.9158)	grad_norm 0.2699 (0.2683)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 18:59:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:08:32 lr 0.000065	 wd 0.0000	time 0.2431 (0.2695)	loss 0.8179 (0.9160)	grad_norm 0.2740 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:00:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:42 lr 0.000064	 wd 0.0000	time 0.1843 (0.2568)	loss 0.8486 (0.9157)	grad_norm 0.2647 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:00:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:07:02 lr 0.000064	 wd 0.0000	time 0.2207 (0.2482)	loss 0.9683 (0.9145)	grad_norm 0.2512 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:00:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:06:52 lr 0.000064	 wd 0.0000	time 0.1923 (0.2578)	loss 0.8452 (0.9138)	grad_norm 0.2756 (0.2689)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:01:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:06:15 lr 0.000064	 wd 0.0000	time 0.1828 (0.2501)	loss 0.9595 (0.9142)	grad_norm 0.2629 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:01:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:05:41 lr 0.000064	 wd 0.0000	time 0.1725 (0.2437)	loss 0.7783 (0.9140)	grad_norm 0.2625 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:01:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:05:10 lr 0.000063	 wd 0.0000	time 0.2146 (0.2382)	loss 0.9214 (0.9131)	grad_norm 0.2826 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:02:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:46 lr 0.000063	 wd 0.0000	time 0.4561 (0.2387)	loss 0.8149 (0.9131)	grad_norm 0.2850 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:02:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:04:24 lr 0.000063	 wd 0.0000	time 0.1776 (0.2399)	loss 0.9697 (0.9132)	grad_norm 0.2682 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:03:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:56 lr 0.000063	 wd 0.0000	time 0.1963 (0.2360)	loss 0.8921 (0.9139)	grad_norm 0.2761 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:03:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:29 lr 0.000063	 wd 0.0000	time 0.1511 (0.2325)	loss 0.8765 (0.9133)	grad_norm 0.2573 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:03:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:03:04 lr 0.000062	 wd 0.0000	time 0.2210 (0.2298)	loss 0.8706 (0.9132)	grad_norm 0.2684 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:04:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:41 lr 0.000062	 wd 0.0000	time 0.1605 (0.2300)	loss 0.8257 (0.9134)	grad_norm 0.2889 (0.2689)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:04:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:17 lr 0.000062	 wd 0.0000	time 0.1642 (0.2281)	loss 0.8682 (0.9131)	grad_norm 0.2582 (0.2689)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:04:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:53 lr 0.000062	 wd 0.0000	time 0.1926 (0.2261)	loss 0.8579 (0.9133)	grad_norm 0.2774 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 19:04:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:30 lr 0.000062	 wd 0.0000	time 0.1821 (0.2242)	loss 0.8677 (0.9138)	grad_norm 0.2689 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 19:05:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:01:07 lr 0.000061	 wd 0.0000	time 0.2455 (0.2228)	loss 0.9375 (0.9138)	grad_norm 0.2784 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 19:05:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:45 lr 0.000061	 wd 0.0000	time 0.1719 (0.2232)	loss 0.8843 (0.9136)	grad_norm 0.2544 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 19:06:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:22 lr 0.000061	 wd 0.0000	time 0.1968 (0.2220)	loss 0.9028 (0.9128)	grad_norm 0.2689 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 19:06:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.1481 (0.2198)	loss 0.9214 (0.9127)	grad_norm 0.2669 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 19:06:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 12 training takes 0:09:17
[2024-07-29 19:06:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 18.415 (18.415)	Loss 0.3628 (0.3628)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 19:07:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.746 Acc@5 97.438
[2024-07-29 19:07:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-29 19:07:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.75%
[2024-07-29 19:07:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 19:07:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 19:07:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][0/2502]	eta 1 day, 0:42:28 lr 0.000061	 wd 0.0000	time 35.5511 (35.5511)	loss 0.8833 (0.8833)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:07:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:21:34 lr 0.000061	 wd 0.0000	time 0.1760 (0.5387)	loss 0.8081 (0.9034)	grad_norm 0.2582 (0.2680)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:08:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:13:45 lr 0.000060	 wd 0.0000	time 0.1776 (0.3586)	loss 0.8149 (0.9122)	grad_norm 0.2750 (0.2685)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:08:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:11:20 lr 0.000060	 wd 0.0000	time 0.2707 (0.3089)	loss 0.8042 (0.9061)	grad_norm 0.2751 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:09:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:11:03 lr 0.000060	 wd 0.0000	time 0.2092 (0.3155)	loss 0.8013 (0.9071)	grad_norm 0.2686 (0.2690)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:09:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:37 lr 0.000060	 wd 0.0000	time 0.1779 (0.2886)	loss 0.8667 (0.9071)	grad_norm 0.2692 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:09:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:35 lr 0.000060	 wd 0.0000	time 0.2229 (0.2709)	loss 0.8247 (0.9084)	grad_norm 0.2685 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:10:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:45 lr 0.000059	 wd 0.0000	time 0.2276 (0.2585)	loss 1.0264 (0.9087)	grad_norm 0.2854 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:10:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:07:33 lr 0.000059	 wd 0.0000	time 0.2162 (0.2663)	loss 0.9707 (0.9086)	grad_norm 0.2691 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:10:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:52 lr 0.000059	 wd 0.0000	time 0.1927 (0.2575)	loss 0.9453 (0.9094)	grad_norm 0.2756 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:11:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:06:14 lr 0.000059	 wd 0.0000	time 0.1626 (0.2496)	loss 1.0215 (0.9105)	grad_norm 0.2705 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:11:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:40 lr 0.000059	 wd 0.0000	time 0.1860 (0.2429)	loss 0.8794 (0.9099)	grad_norm 0.2670 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:11:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:05:15 lr 0.000058	 wd 0.0000	time 0.3809 (0.2421)	loss 1.0098 (0.9101)	grad_norm 0.2766 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:12:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:59 lr 0.000058	 wd 0.0000	time 0.1996 (0.2492)	loss 0.9150 (0.9106)	grad_norm 0.2706 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:12:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:29 lr 0.000058	 wd 0.0000	time 0.1671 (0.2444)	loss 1.0898 (0.9104)	grad_norm 0.2628 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:13:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:04:00 lr 0.000058	 wd 0.0000	time 0.1629 (0.2399)	loss 0.9214 (0.9106)	grad_norm 0.2749 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:13:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:33 lr 0.000058	 wd 0.0000	time 0.1674 (0.2367)	loss 0.8794 (0.9110)	grad_norm 0.2773 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:13:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:03:13 lr 0.000057	 wd 0.0000	time 0.1800 (0.2407)	loss 0.8799 (0.9111)	grad_norm 0.2616 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:14:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:46 lr 0.000057	 wd 0.0000	time 0.1877 (0.2373)	loss 0.8691 (0.9111)	grad_norm 0.2825 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:14:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:21 lr 0.000057	 wd 0.0000	time 0.1679 (0.2347)	loss 0.8271 (0.9098)	grad_norm 0.2751 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:14:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:56 lr 0.000057	 wd 0.0000	time 0.1975 (0.2323)	loss 0.8994 (0.9104)	grad_norm 0.2654 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:15:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:33 lr 0.000057	 wd 0.0000	time 0.1825 (0.2315)	loss 0.9121 (0.9110)	grad_norm 0.2486 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:15:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:09 lr 0.000056	 wd 0.0000	time 0.1921 (0.2318)	loss 0.9878 (0.9109)	grad_norm 0.2797 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:15:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:46 lr 0.000056	 wd 0.0000	time 0.1862 (0.2298)	loss 0.8340 (0.9105)	grad_norm 0.2733 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:16:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:23 lr 0.000056	 wd 0.0000	time 0.2262 (0.2280)	loss 0.9067 (0.9109)	grad_norm 0.2602 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:16:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.1497 (0.2254)	loss 0.8545 (0.9109)	grad_norm 0.2642 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:16:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 13 training takes 0:09:32
[2024-07-29 19:17:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 42.036 (42.036)	Loss 0.3638 (0.3638)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 19:17:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.740 Acc@5 97.452
[2024-07-29 19:17:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-29 19:17:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.75%
[2024-07-29 19:17:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][0/2502]	eta 11:15:50 lr 0.000056	 wd 0.0000	time 16.2071 (16.2071)	loss 1.0010 (1.0010)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:18:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:16:25 lr 0.000055	 wd 0.0000	time 0.4399 (0.4101)	loss 0.8755 (0.9050)	grad_norm 0.2710 (0.2672)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:18:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:13:35 lr 0.000055	 wd 0.0000	time 0.1948 (0.3542)	loss 0.8828 (0.9081)	grad_norm 0.2604 (0.2671)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:19:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:52 lr 0.000055	 wd 0.0000	time 0.1689 (0.2963)	loss 1.1826 (0.9112)	grad_norm 0.2644 (0.2674)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:19:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:09:22 lr 0.000055	 wd 0.0000	time 0.1768 (0.2676)	loss 1.1309 (0.9100)	grad_norm 0.2611 (0.2680)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:19:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:08:23 lr 0.000055	 wd 0.0000	time 0.2144 (0.2516)	loss 0.9517 (0.9095)	grad_norm 0.2481 (0.2678)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:20:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:38 lr 0.000054	 wd 0.0000	time 0.2102 (0.2725)	loss 0.8848 (0.9101)	grad_norm 0.2926 (0.2680)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:20:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:48 lr 0.000054	 wd 0.0000	time 0.1593 (0.2598)	loss 0.8218 (0.9093)	grad_norm 0.2674 (0.2684)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:20:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:07:05 lr 0.000054	 wd 0.0000	time 0.1742 (0.2499)	loss 0.8184 (0.9093)	grad_norm 0.2596 (0.2684)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:21:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:06:28 lr 0.000054	 wd 0.0000	time 0.2199 (0.2427)	loss 0.9150 (0.9092)	grad_norm 0.2840 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:21:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:06:21 lr 0.000054	 wd 0.0000	time 0.2973 (0.2539)	loss 0.9419 (0.9084)	grad_norm 0.2826 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7424MB
[2024-07-29 19:22:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:48 lr 0.000053	 wd 0.0000	time 0.1879 (0.2488)	loss 0.8467 (0.9081)	grad_norm 0.2563 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7424MB
[2024-07-29 19:22:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:05:16 lr 0.000053	 wd 0.0000	time 0.1780 (0.2431)	loss 0.9136 (0.9081)	grad_norm 0.2805 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7424MB
[2024-07-29 19:22:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:46 lr 0.000053	 wd 0.0000	time 0.1583 (0.2382)	loss 1.1084 (0.9078)	grad_norm 0.2726 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7424MB
[2024-07-29 19:23:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:21 lr 0.000053	 wd 0.0000	time 0.3265 (0.2371)	loss 0.9097 (0.9080)	grad_norm 0.2555 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7424MB
[2024-07-29 19:23:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:04:00 lr 0.000053	 wd 0.0000	time 0.1912 (0.2397)	loss 0.8833 (0.9083)	grad_norm 0.2684 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7424MB
[2024-07-29 19:23:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:32 lr 0.000052	 wd 0.0000	time 0.1721 (0.2360)	loss 0.9082 (0.9077)	grad_norm 0.2702 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7424MB
[2024-07-29 19:24:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:03:06 lr 0.000052	 wd 0.0000	time 0.1756 (0.2328)	loss 1.1074 (0.9083)	grad_norm 0.2860 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7424MB
[2024-07-29 19:24:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:41 lr 0.000052	 wd 0.0000	time 0.2013 (0.2304)	loss 0.7129 (0.9084)	grad_norm 0.2729 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7424MB
[2024-07-29 19:24:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:19 lr 0.000052	 wd 0.0000	time 0.1956 (0.2309)	loss 0.8379 (0.9082)	grad_norm 0.2675 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7424MB
[2024-07-29 19:25:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:55 lr 0.000052	 wd 0.0000	time 0.1692 (0.2295)	loss 0.8447 (0.9081)	grad_norm 0.2704 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 19:25:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:31 lr 0.000051	 wd 0.0000	time 0.2016 (0.2274)	loss 0.9463 (0.9080)	grad_norm 0.2582 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 19:25:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:08 lr 0.000051	 wd 0.0000	time 0.1688 (0.2254)	loss 0.9077 (0.9086)	grad_norm 0.2596 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 19:26:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:45 lr 0.000051	 wd 0.0000	time 0.2081 (0.2240)	loss 0.8662 (0.9083)	grad_norm 0.2726 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 19:26:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:22 lr 0.000051	 wd 0.0000	time 0.3144 (0.2240)	loss 1.0039 (0.9089)	grad_norm 0.2768 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 19:26:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.1489 (0.2220)	loss 0.9429 (0.9092)	grad_norm 0.2740 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 19:27:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 14 training takes 0:09:24
[2024-07-29 19:27:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 19.240 (19.240)	Loss 0.3616 (0.3616)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 19:27:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.728 Acc@5 97.466
[2024-07-29 19:27:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.7%
[2024-07-29 19:27:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.75%
[2024-07-29 19:28:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][0/2502]	eta 1 day, 0:40:37 lr 0.000051	 wd 0.0000	time 35.5067 (35.5067)	loss 0.8379 (0.8379)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:28:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:22:09 lr 0.000050	 wd 0.0000	time 0.1651 (0.5537)	loss 0.9941 (0.9180)	grad_norm 0.2643 (0.2685)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:28:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:14:03 lr 0.000050	 wd 0.0000	time 0.1662 (0.3665)	loss 1.0020 (0.9128)	grad_norm 0.2656 (0.2690)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:29:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:11:09 lr 0.000050	 wd 0.0000	time 0.1914 (0.3039)	loss 0.9590 (0.9096)	grad_norm 0.2562 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:29:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:10:14 lr 0.000050	 wd 0.0000	time 0.4233 (0.2923)	loss 1.0273 (0.9108)	grad_norm 0.2753 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:30:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:10:05 lr 0.000049	 wd 0.0000	time 0.1654 (0.3026)	loss 0.8242 (0.9127)	grad_norm 0.2741 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:30:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:08:57 lr 0.000049	 wd 0.0000	time 0.1719 (0.2825)	loss 0.8521 (0.9121)	grad_norm 0.2821 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:30:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:08:02 lr 0.000049	 wd 0.0000	time 0.1886 (0.2678)	loss 0.8501 (0.9092)	grad_norm 0.2705 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:31:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:07:23 lr 0.000049	 wd 0.0000	time 0.3222 (0.2607)	loss 1.0410 (0.9097)	grad_norm 0.2772 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:31:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:07:03 lr 0.000049	 wd 0.0000	time 0.1793 (0.2644)	loss 0.8296 (0.9099)	grad_norm 0.2697 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:31:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:06:24 lr 0.000048	 wd 0.0000	time 0.2011 (0.2561)	loss 0.9443 (0.9095)	grad_norm 0.2681 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:32:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:05:49 lr 0.000048	 wd 0.0000	time 0.1827 (0.2491)	loss 0.9619 (0.9074)	grad_norm 0.2756 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:32:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:05:17 lr 0.000048	 wd 0.0000	time 0.2040 (0.2440)	loss 0.8276 (0.9084)	grad_norm 0.2603 (0.2690)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:33:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:05:01 lr 0.000048	 wd 0.0000	time 0.1929 (0.2507)	loss 0.9253 (0.9080)	grad_norm 0.2674 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:33:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:04:30 lr 0.000048	 wd 0.0000	time 0.1831 (0.2457)	loss 0.8423 (0.9083)	grad_norm 0.2736 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:33:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:04:01 lr 0.000047	 wd 0.0000	time 0.1702 (0.2412)	loss 0.9775 (0.9078)	grad_norm 0.2567 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:34:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:34 lr 0.000047	 wd 0.0000	time 0.2063 (0.2376)	loss 0.9766 (0.9079)	grad_norm 0.2650 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:34:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:03:09 lr 0.000047	 wd 0.0000	time 0.2718 (0.2357)	loss 0.8408 (0.9082)	grad_norm 0.2639 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:34:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:45 lr 0.000047	 wd 0.0000	time 0.1987 (0.2356)	loss 1.0664 (0.9088)	grad_norm 0.2796 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:35:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:20 lr 0.000047	 wd 0.0000	time 0.1744 (0.2333)	loss 0.9922 (0.9082)	grad_norm 0.2881 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:35:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:55 lr 0.000046	 wd 0.0000	time 0.1816 (0.2309)	loss 1.0488 (0.9090)	grad_norm 0.2924 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:35:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:31 lr 0.000046	 wd 0.0000	time 0.2144 (0.2287)	loss 0.8809 (0.9089)	grad_norm 0.2616 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:36:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:01:08 lr 0.000046	 wd 0.0000	time 0.2286 (0.2278)	loss 0.9272 (0.9091)	grad_norm 0.2661 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:36:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:46 lr 0.000046	 wd 0.0000	time 0.1859 (0.2278)	loss 0.9561 (0.9091)	grad_norm 0.2885 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:36:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:23 lr 0.000046	 wd 0.0000	time 0.1635 (0.2262)	loss 0.9570 (0.9091)	grad_norm 0.2758 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:37:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.1493 (0.2238)	loss 1.1318 (0.9094)	grad_norm 0.2699 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 19:37:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 15 training takes 0:09:29
[2024-07-29 19:37:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_15.pth saving......
[2024-07-29 19:37:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_15.pth saved !!!
[2024-07-29 19:37:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 38.619 (38.619)	Loss 0.3630 (0.3630)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 19:38:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.766 Acc@5 97.468
[2024-07-29 19:38:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 19:38:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.77%
[2024-07-29 19:38:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 19:38:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 19:38:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][0/2502]	eta 11:41:02 lr 0.000045	 wd 0.0000	time 16.8117 (16.8117)	loss 0.7617 (0.7617)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:38:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:14:05 lr 0.000045	 wd 0.0000	time 0.1820 (0.3521)	loss 1.0225 (0.9234)	grad_norm 0.2761 (0.2718)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:39:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:10:30 lr 0.000045	 wd 0.0000	time 0.2466 (0.2739)	loss 0.9121 (0.9102)	grad_norm 0.2845 (0.2702)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:39:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:43 lr 0.000045	 wd 0.0000	time 0.2079 (0.2923)	loss 0.9863 (0.9120)	grad_norm 0.2647 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:39:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:09:16 lr 0.000045	 wd 0.0000	time 0.1847 (0.2646)	loss 0.9526 (0.9115)	grad_norm 0.2801 (0.2692)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:40:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:08:15 lr 0.000044	 wd 0.0000	time 0.1836 (0.2477)	loss 1.0166 (0.9111)	grad_norm 0.2657 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:40:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:07:34 lr 0.000044	 wd 0.0000	time 0.2291 (0.2387)	loss 0.9673 (0.9111)	grad_norm 0.2740 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:41:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:43 lr 0.000044	 wd 0.0000	time 0.2101 (0.2572)	loss 0.9404 (0.9111)	grad_norm 0.2652 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:41:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:07:04 lr 0.000044	 wd 0.0000	time 0.1833 (0.2492)	loss 0.9155 (0.9108)	grad_norm 0.2625 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:41:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:26 lr 0.000043	 wd 0.0000	time 0.1737 (0.2415)	loss 0.8135 (0.9120)	grad_norm 0.2854 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:42:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:05:53 lr 0.000043	 wd 0.0000	time 0.1796 (0.2352)	loss 0.8945 (0.9122)	grad_norm 0.2707 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:42:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:27 lr 0.000043	 wd 0.0000	time 0.3147 (0.2334)	loss 0.9971 (0.9123)	grad_norm 0.2779 (0.2699)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:42:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:05:11 lr 0.000043	 wd 0.0000	time 0.1838 (0.2390)	loss 0.9204 (0.9118)	grad_norm 0.2729 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:43:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:41 lr 0.000043	 wd 0.0000	time 0.1806 (0.2345)	loss 0.9893 (0.9111)	grad_norm 0.2714 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:43:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:14 lr 0.000042	 wd 0.0000	time 0.1732 (0.2309)	loss 0.8330 (0.9105)	grad_norm 0.2629 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:43:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:48 lr 0.000042	 wd 0.0000	time 0.1918 (0.2279)	loss 0.8569 (0.9100)	grad_norm 0.2502 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:44:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:25 lr 0.000042	 wd 0.0000	time 0.1632 (0.2275)	loss 0.8271 (0.9099)	grad_norm 0.2682 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:44:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:03:01 lr 0.000042	 wd 0.0000	time 0.1678 (0.2258)	loss 0.8896 (0.9096)	grad_norm 0.2750 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:44:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:36 lr 0.000042	 wd 0.0000	time 0.1856 (0.2235)	loss 1.0869 (0.9098)	grad_norm 0.2556 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:45:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:13 lr 0.000041	 wd 0.0000	time 0.1729 (0.2215)	loss 1.0400 (0.9087)	grad_norm 0.2785 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:45:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:50 lr 0.000041	 wd 0.0000	time 0.2058 (0.2199)	loss 0.8853 (0.9083)	grad_norm 0.2782 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:45:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:28 lr 0.000041	 wd 0.0000	time 0.1759 (0.2202)	loss 0.6973 (0.9079)	grad_norm 0.2670 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:46:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:06 lr 0.000041	 wd 0.0000	time 0.1788 (0.2193)	loss 0.7896 (0.9078)	grad_norm 0.2703 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:46:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:43 lr 0.000041	 wd 0.0000	time 0.1824 (0.2178)	loss 0.7100 (0.9072)	grad_norm 0.2803 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:46:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:22 lr 0.000040	 wd 0.0000	time 0.1852 (0.2164)	loss 0.8076 (0.9071)	grad_norm 0.2717 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:47:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.1501 (0.2143)	loss 0.8843 (0.9068)	grad_norm 0.3006 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:47:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 16 training takes 0:09:04
[2024-07-29 19:47:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 43.212 (43.212)	Loss 0.3628 (0.3628)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 19:48:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.758 Acc@5 97.450
[2024-07-29 19:48:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 19:48:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.77%
[2024-07-29 19:48:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][0/2502]	eta 11:08:59 lr 0.000040	 wd 0.0000	time 16.0431 (16.0431)	loss 0.7930 (0.7930)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:48:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:15:37 lr 0.000040	 wd 0.0000	time 0.3008 (0.3904)	loss 0.9858 (0.9090)	grad_norm 0.2598 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:49:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:13:08 lr 0.000040	 wd 0.0000	time 0.1628 (0.3424)	loss 0.8926 (0.9121)	grad_norm 0.2610 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:49:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:34 lr 0.000040	 wd 0.0000	time 0.1706 (0.2880)	loss 0.8975 (0.9082)	grad_norm 0.2891 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:50:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:09:09 lr 0.000039	 wd 0.0000	time 0.1818 (0.2617)	loss 0.9678 (0.9067)	grad_norm 0.2664 (0.2701)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:50:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:08:13 lr 0.000039	 wd 0.0000	time 0.1897 (0.2463)	loss 0.7861 (0.9045)	grad_norm 0.2876 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:50:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:37 lr 0.000039	 wd 0.0000	time 0.2250 (0.2722)	loss 0.8276 (0.9061)	grad_norm 0.2814 (0.2701)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:51:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:47 lr 0.000039	 wd 0.0000	time 0.1853 (0.2596)	loss 0.9336 (0.9054)	grad_norm 0.2693 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:51:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:07:05 lr 0.000039	 wd 0.0000	time 0.2172 (0.2498)	loss 0.8257 (0.9053)	grad_norm 0.2633 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:51:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:06:29 lr 0.000038	 wd 0.0000	time 0.2368 (0.2429)	loss 1.0000 (0.9056)	grad_norm 0.2663 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:52:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:06:14 lr 0.000038	 wd 0.0000	time 0.2111 (0.2495)	loss 0.9482 (0.9057)	grad_norm 0.2783 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:52:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:41 lr 0.000038	 wd 0.0000	time 0.1760 (0.2433)	loss 0.7749 (0.9070)	grad_norm 0.2652 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:53:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:05:09 lr 0.000038	 wd 0.0000	time 0.2113 (0.2378)	loss 0.8032 (0.9082)	grad_norm 0.2847 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:53:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:40 lr 0.000038	 wd 0.0000	time 0.1737 (0.2336)	loss 0.9326 (0.9073)	grad_norm 0.2597 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:53:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:04:15 lr 0.000037	 wd 0.0000	time 0.1936 (0.2315)	loss 0.9365 (0.9081)	grad_norm 0.2536 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:54:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:51 lr 0.000037	 wd 0.0000	time 0.1529 (0.2312)	loss 0.9043 (0.9080)	grad_norm 0.2794 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7424MB
[2024-07-29 19:54:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:26 lr 0.000037	 wd 0.0000	time 0.1686 (0.2286)	loss 1.0801 (0.9078)	grad_norm 0.2747 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7424MB
[2024-07-29 19:54:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:03:01 lr 0.000037	 wd 0.0000	time 0.1684 (0.2260)	loss 1.0801 (0.9080)	grad_norm 0.2708 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7424MB
[2024-07-29 19:54:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:36 lr 0.000037	 wd 0.0000	time 0.1676 (0.2236)	loss 0.8394 (0.9092)	grad_norm 0.2844 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7424MB
[2024-07-29 19:55:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:13 lr 0.000036	 wd 0.0000	time 0.2211 (0.2224)	loss 0.7754 (0.9097)	grad_norm 0.2667 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7424MB
[2024-07-29 19:55:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:51 lr 0.000036	 wd 0.0000	time 0.2798 (0.2229)	loss 0.8223 (0.9092)	grad_norm 0.2625 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 19:56:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:29 lr 0.000036	 wd 0.0000	time 0.1631 (0.2216)	loss 0.8428 (0.9086)	grad_norm 0.2565 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 19:56:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:06 lr 0.000036	 wd 0.0000	time 0.1732 (0.2201)	loss 0.9995 (0.9085)	grad_norm 0.2653 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 19:56:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:44 lr 0.000036	 wd 0.0000	time 0.1730 (0.2184)	loss 0.9541 (0.9080)	grad_norm 0.2667 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 19:56:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:22 lr 0.000035	 wd 0.0000	time 0.1882 (0.2178)	loss 0.8379 (0.9084)	grad_norm 0.2678 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 19:57:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.1479 (0.2167)	loss 0.9521 (0.9086)	grad_norm 0.2746 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 19:57:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 17 training takes 0:09:12
[2024-07-29 19:57:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 19.042 (19.042)	Loss 0.3608 (0.3608)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 19:58:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.772 Acc@5 97.458
[2024-07-29 19:58:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 19:58:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.77%
[2024-07-29 19:58:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 19:58:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 19:58:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][0/2502]	eta 14:38:39 lr 0.000035	 wd 0.0000	time 21.0708 (21.0708)	loss 0.9297 (0.9297)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:58:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:19:56 lr 0.000035	 wd 0.0000	time 0.1850 (0.4983)	loss 1.0293 (0.9141)	grad_norm 0.2825 (0.2722)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:59:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:13:04 lr 0.000035	 wd 0.0000	time 0.2038 (0.3409)	loss 0.8716 (0.9070)	grad_norm 0.2781 (0.2715)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:59:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:10:33 lr 0.000035	 wd 0.0000	time 0.1692 (0.2878)	loss 0.9482 (0.9103)	grad_norm 0.2616 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 19:59:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:09:09 lr 0.000034	 wd 0.0000	time 0.2020 (0.2613)	loss 0.8081 (0.9124)	grad_norm 0.2870 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:00:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:09:40 lr 0.000034	 wd 0.0000	time 0.3169 (0.2899)	loss 0.7344 (0.9123)	grad_norm 0.2656 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:00:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:08:49 lr 0.000034	 wd 0.0000	time 0.1612 (0.2782)	loss 0.9702 (0.9082)	grad_norm 0.2710 (0.2701)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:01:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:07:56 lr 0.000034	 wd 0.0000	time 0.2199 (0.2645)	loss 0.9780 (0.9056)	grad_norm 0.2589 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:01:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:07:12 lr 0.000034	 wd 0.0000	time 0.1862 (0.2540)	loss 1.0996 (0.9038)	grad_norm 0.2609 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:02:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:07:03 lr 0.000033	 wd 0.0000	time 0.2279 (0.2641)	loss 0.9800 (0.9044)	grad_norm 0.2800 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:02:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:06:26 lr 0.000033	 wd 0.0000	time 0.1749 (0.2573)	loss 0.8735 (0.9052)	grad_norm 0.2805 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:02:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:05:51 lr 0.000033	 wd 0.0000	time 0.1854 (0.2505)	loss 0.8296 (0.9065)	grad_norm 0.2564 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:03:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:05:18 lr 0.000033	 wd 0.0000	time 0.1712 (0.2444)	loss 0.9224 (0.9062)	grad_norm 0.2675 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:03:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:50 lr 0.000033	 wd 0.0000	time 0.2965 (0.2415)	loss 0.9033 (0.9075)	grad_norm 0.2647 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:03:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:04:34 lr 0.000032	 wd 0.0000	time 0.1762 (0.2490)	loss 1.0488 (0.9068)	grad_norm 0.2831 (0.2697)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:04:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:04:04 lr 0.000032	 wd 0.0000	time 0.1802 (0.2443)	loss 0.8965 (0.9077)	grad_norm 0.2810 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:04:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:36 lr 0.000032	 wd 0.0000	time 0.1966 (0.2404)	loss 0.9058 (0.9069)	grad_norm 0.2729 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:04:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:03:10 lr 0.000032	 wd 0.0000	time 0.1962 (0.2372)	loss 0.9805 (0.9071)	grad_norm 0.2713 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:05:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:46 lr 0.000032	 wd 0.0000	time 0.1754 (0.2373)	loss 0.8477 (0.9070)	grad_norm 0.2861 (0.2699)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:05:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:21 lr 0.000032	 wd 0.0000	time 0.1514 (0.2355)	loss 0.8491 (0.9067)	grad_norm 0.2816 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:05:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:56 lr 0.000031	 wd 0.0000	time 0.1765 (0.2331)	loss 0.9131 (0.9073)	grad_norm 0.2683 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:06:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:32 lr 0.000031	 wd 0.0000	time 0.1958 (0.2307)	loss 0.7651 (0.9075)	grad_norm 0.2777 (0.2701)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:06:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:01:09 lr 0.000031	 wd 0.0000	time 0.2241 (0.2291)	loss 0.9229 (0.9074)	grad_norm 0.2714 (0.2701)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:06:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:46 lr 0.000031	 wd 0.0000	time 0.1598 (0.2286)	loss 0.7852 (0.9078)	grad_norm 0.2735 (0.2701)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:07:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:23 lr 0.000031	 wd 0.0000	time 0.1704 (0.2273)	loss 0.9170 (0.9079)	grad_norm 0.2720 (0.2702)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:07:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.1490 (0.2249)	loss 0.8789 (0.9079)	grad_norm 0.2693 (0.2702)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:07:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 18 training takes 0:09:29
[2024-07-29 20:07:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 18.402 (18.402)	Loss 0.3606 (0.3606)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 20:08:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.820 Acc@5 97.462
[2024-07-29 20:08:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 20:08:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 20:08:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saving......
[2024-07-29 20:08:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0/diffusion_ft_adapter_conv_b_sequence_stage0/ckpt_epoch_best.pth saved !!!
[2024-07-29 20:08:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][0/2502]	eta 1 day, 4:02:39 lr 0.000030	 wd 0.0000	time 40.3514 (40.3514)	loss 0.8843 (0.8843)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:09:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:23:36 lr 0.000030	 wd 0.0000	time 0.1803 (0.5899)	loss 1.0361 (0.8985)	grad_norm 0.2668 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:09:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:14:44 lr 0.000030	 wd 0.0000	time 0.1970 (0.3844)	loss 0.7329 (0.8958)	grad_norm 0.2838 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:10:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:13:56 lr 0.000030	 wd 0.0000	time 0.2685 (0.3798)	loss 0.9946 (0.9014)	grad_norm 0.2760 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:10:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:12:02 lr 0.000030	 wd 0.0000	time 0.1869 (0.3435)	loss 0.8472 (0.9032)	grad_norm 0.2606 (0.2699)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:10:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:10:23 lr 0.000029	 wd 0.0000	time 0.1648 (0.3113)	loss 0.9692 (0.9030)	grad_norm 0.2676 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7424MB
[2024-07-29 20:11:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:09:10 lr 0.000029	 wd 0.0000	time 0.2042 (0.2892)	loss 0.7910 (0.9045)	grad_norm 0.2841 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7424MB
[2024-07-29 20:11:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:08:29 lr 0.000029	 wd 0.0000	time 0.3363 (0.2825)	loss 1.0283 (0.9057)	grad_norm 0.2704 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7424MB
[2024-07-29 20:12:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:08:01 lr 0.000029	 wd 0.0000	time 0.1809 (0.2830)	loss 0.8828 (0.9073)	grad_norm 0.2702 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7424MB
[2024-07-29 20:12:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:07:15 lr 0.000029	 wd 0.0000	time 0.1710 (0.2717)	loss 0.9043 (0.9073)	grad_norm 0.2771 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7424MB
[2024-07-29 20:12:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:06:34 lr 0.000028	 wd 0.0000	time 0.1740 (0.2623)	loss 0.9536 (0.9080)	grad_norm 0.2634 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7424MB
[2024-07-29 20:12:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:58 lr 0.000028	 wd 0.0000	time 0.3018 (0.2558)	loss 0.8374 (0.9076)	grad_norm 0.2708 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7424MB
[2024-07-29 20:13:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:05:41 lr 0.000028	 wd 0.0000	time 0.1936 (0.2621)	loss 0.8799 (0.9079)	grad_norm 0.2670 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7424MB
[2024-07-29 20:13:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:05:07 lr 0.000028	 wd 0.0000	time 0.1891 (0.2558)	loss 0.8608 (0.9084)	grad_norm 0.2795 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7424MB
[2024-07-29 20:14:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:04:36 lr 0.000028	 wd 0.0000	time 0.1850 (0.2505)	loss 0.8682 (0.9080)	grad_norm 0.2666 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7424MB
[2024-07-29 20:14:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:04:06 lr 0.000028	 wd 0.0000	time 0.2125 (0.2459)	loss 0.9048 (0.9084)	grad_norm 0.2516 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7424MB
[2024-07-29 20:14:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:39 lr 0.000027	 wd 0.0000	time 0.1863 (0.2429)	loss 0.9248 (0.9089)	grad_norm 0.2860 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7424MB
[2024-07-29 20:15:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:03:14 lr 0.000027	 wd 0.0000	time 0.1663 (0.2420)	loss 1.0195 (0.9089)	grad_norm 0.2659 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7424MB
[2024-07-29 20:15:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:47 lr 0.000027	 wd 0.0000	time 0.1857 (0.2390)	loss 0.8540 (0.9093)	grad_norm 0.2634 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7424MB
[2024-07-29 20:15:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:22 lr 0.000027	 wd 0.0000	time 0.1722 (0.2364)	loss 0.8799 (0.9094)	grad_norm 0.2765 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7424MB
[2024-07-29 20:16:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:57 lr 0.000027	 wd 0.0000	time 0.1743 (0.2339)	loss 0.9849 (0.9092)	grad_norm 0.2684 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 20:16:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:33 lr 0.000026	 wd 0.0000	time 0.1799 (0.2326)	loss 1.0186 (0.9089)	grad_norm 0.2651 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 20:16:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:10 lr 0.000026	 wd 0.0000	time 0.1889 (0.2318)	loss 0.8853 (0.9083)	grad_norm 0.2943 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 20:17:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:46 lr 0.000026	 wd 0.0000	time 0.1789 (0.2299)	loss 0.9453 (0.9079)	grad_norm 0.2709 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 20:17:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:23 lr 0.000026	 wd 0.0000	time 0.1862 (0.2280)	loss 0.9868 (0.9077)	grad_norm 0.2868 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 20:17:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.1497 (0.2255)	loss 0.7246 (0.9078)	grad_norm 0.2754 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 20:17:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 19 training takes 0:09:32
[2024-07-29 20:18:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 43.988 (43.988)	Loss 0.3608 (0.3608)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 20:18:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.818 Acc@5 97.460
[2024-07-29 20:18:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 20:18:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 20:19:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][0/2502]	eta 11:27:01 lr 0.000026	 wd 0.0000	time 16.4755 (16.4755)	loss 0.8623 (0.8623)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:19:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:14:29 lr 0.000026	 wd 0.0000	time 0.2434 (0.3618)	loss 1.0547 (0.9118)	grad_norm 0.2715 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:19:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:12:39 lr 0.000025	 wd 0.0000	time 0.1941 (0.3298)	loss 0.9585 (0.9021)	grad_norm 0.2703 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:20:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:16 lr 0.000025	 wd 0.0000	time 0.1738 (0.2801)	loss 0.7676 (0.8983)	grad_norm 0.2757 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:20:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:08:56 lr 0.000025	 wd 0.0000	time 0.1786 (0.2551)	loss 0.8940 (0.8991)	grad_norm 0.2677 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:20:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:08:00 lr 0.000025	 wd 0.0000	time 0.1914 (0.2399)	loss 0.8735 (0.8987)	grad_norm 0.2617 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:21:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:07:37 lr 0.000025	 wd 0.0000	time 0.4012 (0.2404)	loss 0.8350 (0.8995)	grad_norm 0.2670 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:21:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:30 lr 0.000025	 wd 0.0000	time 0.1795 (0.2499)	loss 0.8086 (0.9001)	grad_norm 0.2684 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:22:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:06:50 lr 0.000024	 wd 0.0000	time 0.1764 (0.2412)	loss 1.0234 (0.9006)	grad_norm 0.2677 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:22:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:06:15 lr 0.000024	 wd 0.0000	time 0.1750 (0.2346)	loss 0.7812 (0.9005)	grad_norm 0.2707 (0.2702)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:22:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:05:45 lr 0.000024	 wd 0.0000	time 0.2644 (0.2299)	loss 0.8423 (0.9001)	grad_norm 0.2710 (0.2699)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:23:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:37 lr 0.000024	 wd 0.0000	time 0.1866 (0.2407)	loss 0.8169 (0.9002)	grad_norm 0.2649 (0.2699)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:23:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:05:06 lr 0.000024	 wd 0.0000	time 0.2017 (0.2357)	loss 0.7661 (0.9001)	grad_norm 0.2624 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:23:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:38 lr 0.000023	 wd 0.0000	time 0.1691 (0.2316)	loss 0.9038 (0.8999)	grad_norm 0.2705 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:24:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:04:11 lr 0.000023	 wd 0.0000	time 0.1705 (0.2278)	loss 0.9478 (0.9004)	grad_norm 0.2833 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:24:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:55 lr 0.000023	 wd 0.0000	time 0.1963 (0.2351)	loss 0.9766 (0.8999)	grad_norm 0.2826 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:24:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:29 lr 0.000023	 wd 0.0000	time 0.1879 (0.2321)	loss 0.9419 (0.8994)	grad_norm 0.2764 (0.2701)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:25:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:03:03 lr 0.000023	 wd 0.0000	time 0.1754 (0.2290)	loss 0.9912 (0.8993)	grad_norm 0.2792 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:25:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:38 lr 0.000023	 wd 0.0000	time 0.1842 (0.2264)	loss 0.8296 (0.8999)	grad_norm 0.2773 (0.2700)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:25:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:15 lr 0.000022	 wd 0.0000	time 0.2138 (0.2251)	loss 1.0137 (0.9007)	grad_norm 0.2794 (0.2701)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:26:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:53 lr 0.000022	 wd 0.0000	time 0.2509 (0.2254)	loss 0.9258 (0.9006)	grad_norm 0.2708 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 20:26:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:29 lr 0.000022	 wd 0.0000	time 0.1782 (0.2237)	loss 0.9482 (0.9011)	grad_norm 0.2841 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 20:26:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:07 lr 0.000022	 wd 0.0000	time 0.1618 (0.2219)	loss 0.9214 (0.9016)	grad_norm 0.2737 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 20:27:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:44 lr 0.000022	 wd 0.0000	time 0.1794 (0.2203)	loss 0.8164 (0.9024)	grad_norm 0.2909 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 20:27:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:22 lr 0.000022	 wd 0.0000	time 0.2163 (0.2197)	loss 0.8628 (0.9026)	grad_norm 0.2689 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 20:27:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.1483 (0.2185)	loss 0.8066 (0.9024)	grad_norm 0.2530 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 20:28:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 20 training takes 0:09:19
[2024-07-29 20:28:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 19.985 (19.985)	Loss 0.3608 (0.3608)	Acc@1 91.602 (91.602)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 20:28:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.800 Acc@5 97.450
[2024-07-29 20:28:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 20:28:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 20:29:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][0/2502]	eta 16:05:56 lr 0.000021	 wd 0.0000	time 23.1642 (23.1642)	loss 0.9419 (0.9419)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:29:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:17:52 lr 0.000021	 wd 0.0000	time 0.1507 (0.4464)	loss 0.9282 (0.9141)	grad_norm 0.2711 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:29:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:12:04 lr 0.000021	 wd 0.0000	time 0.1829 (0.3146)	loss 0.9404 (0.9080)	grad_norm 0.2688 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:30:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:09:54 lr 0.000021	 wd 0.0000	time 0.1765 (0.2701)	loss 0.9521 (0.9057)	grad_norm 0.2755 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:30:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:08:41 lr 0.000021	 wd 0.0000	time 0.1648 (0.2479)	loss 1.0127 (0.9056)	grad_norm 0.2650 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:30:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:08:09 lr 0.000021	 wd 0.0000	time 0.3845 (0.2443)	loss 0.8281 (0.9057)	grad_norm 0.2770 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:31:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:08:24 lr 0.000020	 wd 0.0000	time 0.1724 (0.2653)	loss 0.9238 (0.9052)	grad_norm 0.2767 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:31:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:07:36 lr 0.000020	 wd 0.0000	time 0.1765 (0.2532)	loss 1.0205 (0.9052)	grad_norm 0.2831 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:32:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:06:55 lr 0.000020	 wd 0.0000	time 0.1691 (0.2439)	loss 0.9478 (0.9051)	grad_norm 0.2845 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:32:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:22 lr 0.000020	 wd 0.0000	time 0.2575 (0.2389)	loss 0.8643 (0.9060)	grad_norm 0.2630 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:32:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:06:09 lr 0.000020	 wd 0.0000	time 0.1860 (0.2462)	loss 0.8716 (0.9056)	grad_norm 0.2582 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:33:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:05:36 lr 0.000020	 wd 0.0000	time 0.1727 (0.2403)	loss 0.9375 (0.9061)	grad_norm 0.2610 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:33:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:05:06 lr 0.000019	 wd 0.0000	time 0.1567 (0.2351)	loss 0.8892 (0.9075)	grad_norm 0.2694 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:33:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:38 lr 0.000019	 wd 0.0000	time 0.2262 (0.2313)	loss 0.9766 (0.9071)	grad_norm 0.2585 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:34:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:04:27 lr 0.000019	 wd 0.0000	time 0.3248 (0.2423)	loss 0.9204 (0.9071)	grad_norm 0.2558 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:34:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:59 lr 0.000019	 wd 0.0000	time 0.1682 (0.2389)	loss 0.9521 (0.9069)	grad_norm 0.2667 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:35:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:32 lr 0.000019	 wd 0.0000	time 0.1695 (0.2352)	loss 0.9424 (0.9064)	grad_norm 0.2784 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:35:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:03:05 lr 0.000019	 wd 0.0000	time 0.1691 (0.2318)	loss 0.8940 (0.9069)	grad_norm 0.2631 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:35:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:41 lr 0.000018	 wd 0.0000	time 0.1788 (0.2303)	loss 0.9004 (0.9068)	grad_norm 0.2674 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:36:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:18 lr 0.000018	 wd 0.0000	time 0.1853 (0.2302)	loss 0.9023 (0.9069)	grad_norm 0.2633 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:36:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:54 lr 0.000018	 wd 0.0000	time 0.1969 (0.2281)	loss 0.7754 (0.9067)	grad_norm 0.2766 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:36:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:30 lr 0.000018	 wd 0.0000	time 0.1661 (0.2261)	loss 0.7935 (0.9062)	grad_norm 0.2642 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:36:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:07 lr 0.000018	 wd 0.0000	time 0.2453 (0.2242)	loss 0.8218 (0.9056)	grad_norm 0.2787 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:37:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:45 lr 0.000018	 wd 0.0000	time 0.1803 (0.2233)	loss 0.9541 (0.9056)	grad_norm 0.2638 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:37:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:22 lr 0.000018	 wd 0.0000	time 0.1920 (0.2232)	loss 0.8867 (0.9055)	grad_norm 0.2709 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:37:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.1489 (0.2209)	loss 0.9214 (0.9058)	grad_norm 0.2503 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:38:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 21 training takes 0:09:20
[2024-07-29 20:38:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 18.952 (18.952)	Loss 0.3601 (0.3601)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 20:38:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.784 Acc@5 97.450
[2024-07-29 20:38:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 20:38:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 20:39:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][0/2502]	eta 1 day, 1:15:11 lr 0.000017	 wd 0.0000	time 36.3355 (36.3355)	loss 0.8623 (0.8623)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:39:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:22:10 lr 0.000017	 wd 0.0000	time 0.2003 (0.5537)	loss 0.9370 (0.9101)	grad_norm 0.2731 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:39:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:14:07 lr 0.000017	 wd 0.0000	time 0.1556 (0.3680)	loss 0.8096 (0.9058)	grad_norm 0.2615 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:40:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:11:17 lr 0.000017	 wd 0.0000	time 0.2709 (0.3077)	loss 0.9014 (0.9046)	grad_norm 0.2654 (0.2699)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:40:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:11:32 lr 0.000017	 wd 0.0000	time 0.2000 (0.3296)	loss 0.8394 (0.9094)	grad_norm 0.2601 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:41:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:10:01 lr 0.000017	 wd 0.0000	time 0.1840 (0.3004)	loss 0.7227 (0.9073)	grad_norm 0.2597 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:41:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:53 lr 0.000016	 wd 0.0000	time 0.1748 (0.2807)	loss 0.9561 (0.9084)	grad_norm 0.2614 (0.2698)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:41:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:08:00 lr 0.000016	 wd 0.0000	time 0.2010 (0.2667)	loss 1.0000 (0.9069)	grad_norm 0.2642 (0.2702)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:42:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:07:55 lr 0.000016	 wd 0.0000	time 0.2849 (0.2797)	loss 0.9292 (0.9071)	grad_norm 0.2617 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:42:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:07:12 lr 0.000016	 wd 0.0000	time 0.1805 (0.2699)	loss 0.8721 (0.9070)	grad_norm 0.2587 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:43:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:06:31 lr 0.000016	 wd 0.0000	time 0.1706 (0.2609)	loss 0.9297 (0.9068)	grad_norm 0.2578 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7424MB
[2024-07-29 20:43:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:55 lr 0.000016	 wd 0.0000	time 0.1948 (0.2533)	loss 0.8125 (0.9056)	grad_norm 0.2646 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7424MB
[2024-07-29 20:43:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:05:28 lr 0.000016	 wd 0.0000	time 0.3207 (0.2523)	loss 0.8638 (0.9058)	grad_norm 0.2689 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7424MB
[2024-07-29 20:44:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:05:03 lr 0.000015	 wd 0.0000	time 0.1751 (0.2523)	loss 0.9019 (0.9045)	grad_norm 0.2675 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7424MB
[2024-07-29 20:44:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:32 lr 0.000015	 wd 0.0000	time 0.1724 (0.2470)	loss 0.8867 (0.9044)	grad_norm 0.2711 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7424MB
[2024-07-29 20:44:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:04:03 lr 0.000015	 wd 0.0000	time 0.1914 (0.2429)	loss 0.7012 (0.9045)	grad_norm 0.2658 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7424MB
[2024-07-29 20:45:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:36 lr 0.000015	 wd 0.0000	time 0.1840 (0.2396)	loss 0.8867 (0.9048)	grad_norm 0.2726 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7424MB
[2024-07-29 20:45:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:03:11 lr 0.000015	 wd 0.0000	time 0.1920 (0.2392)	loss 0.9194 (0.9043)	grad_norm 0.2792 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7424MB
[2024-07-29 20:45:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:46 lr 0.000015	 wd 0.0000	time 0.1921 (0.2370)	loss 0.9971 (0.9042)	grad_norm 0.2685 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7424MB
[2024-07-29 20:46:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:21 lr 0.000015	 wd 0.0000	time 0.1659 (0.2343)	loss 0.9399 (0.9047)	grad_norm 0.2679 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7424MB
[2024-07-29 20:46:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:56 lr 0.000014	 wd 0.0000	time 0.1912 (0.2319)	loss 1.0049 (0.9044)	grad_norm 0.2448 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 20:46:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:32 lr 0.000014	 wd 0.0000	time 0.1939 (0.2301)	loss 0.8486 (0.9049)	grad_norm 0.2698 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 20:47:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:09 lr 0.000014	 wd 0.0000	time 0.9086 (0.2313)	loss 0.6982 (0.9047)	grad_norm 0.2723 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 20:47:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:46 lr 0.000014	 wd 0.0000	time 0.1877 (0.2295)	loss 0.9541 (0.9047)	grad_norm 0.2705 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 20:47:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:23 lr 0.000014	 wd 0.0000	time 0.2001 (0.2278)	loss 0.7866 (0.9049)	grad_norm 0.2707 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 20:48:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.1476 (0.2252)	loss 0.8633 (0.9045)	grad_norm 0.2785 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 20:48:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 22 training takes 0:09:31
[2024-07-29 20:48:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 40.903 (40.903)	Loss 0.3604 (0.3604)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 20:49:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.794 Acc@5 97.470
[2024-07-29 20:49:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 20:49:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 20:49:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][0/2502]	eta 11:00:03 lr 0.000014	 wd 0.0000	time 15.8287 (15.8287)	loss 0.7852 (0.7852)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:49:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:13:41 lr 0.000014	 wd 0.0000	time 0.1920 (0.3419)	loss 0.8843 (0.9031)	grad_norm 0.2716 (0.2717)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:50:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:13:40 lr 0.000013	 wd 0.0000	time 0.2318 (0.3564)	loss 0.9609 (0.9007)	grad_norm 0.2835 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:50:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:11:04 lr 0.000013	 wd 0.0000	time 0.1807 (0.3018)	loss 0.8052 (0.8992)	grad_norm 0.2627 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:51:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:09:30 lr 0.000013	 wd 0.0000	time 0.1739 (0.2716)	loss 1.0205 (0.9010)	grad_norm 0.2728 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:51:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:08:26 lr 0.000013	 wd 0.0000	time 0.1922 (0.2530)	loss 0.9282 (0.9053)	grad_norm 0.2689 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:51:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:07:54 lr 0.000013	 wd 0.0000	time 0.3476 (0.2497)	loss 0.9150 (0.9063)	grad_norm 0.2695 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:52:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:40 lr 0.000013	 wd 0.0000	time 0.1689 (0.2558)	loss 0.9653 (0.9069)	grad_norm 0.2577 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:52:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:06:59 lr 0.000013	 wd 0.0000	time 0.1899 (0.2466)	loss 1.0117 (0.9063)	grad_norm 0.2835 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:52:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:06:23 lr 0.000012	 wd 0.0000	time 0.1882 (0.2392)	loss 1.1465 (0.9047)	grad_norm 0.2800 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:53:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:05:51 lr 0.000012	 wd 0.0000	time 0.1972 (0.2337)	loss 0.7651 (0.9052)	grad_norm 0.2694 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:53:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:43 lr 0.000012	 wd 0.0000	time 0.1925 (0.2453)	loss 0.7612 (0.9043)	grad_norm 0.2772 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:54:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:05:12 lr 0.000012	 wd 0.0000	time 0.2000 (0.2399)	loss 0.9478 (0.9046)	grad_norm 0.2621 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:54:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:43 lr 0.000012	 wd 0.0000	time 0.1679 (0.2355)	loss 0.9805 (0.9046)	grad_norm 0.2884 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:54:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:04:15 lr 0.000012	 wd 0.0000	time 0.1517 (0.2315)	loss 0.9766 (0.9049)	grad_norm 0.2740 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:55:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:57 lr 0.000012	 wd 0.0000	time 0.1789 (0.2372)	loss 0.7886 (0.9057)	grad_norm 0.2769 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:55:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:31 lr 0.000012	 wd 0.0000	time 0.1885 (0.2340)	loss 0.9155 (0.9056)	grad_norm 0.2603 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:55:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:03:05 lr 0.000011	 wd 0.0000	time 0.1876 (0.2310)	loss 0.8076 (0.9054)	grad_norm 0.2731 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:56:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:40 lr 0.000011	 wd 0.0000	time 0.1753 (0.2284)	loss 0.9199 (0.9057)	grad_norm 0.2730 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:56:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:02:16 lr 0.000011	 wd 0.0000	time 0.1959 (0.2264)	loss 0.8105 (0.9053)	grad_norm 0.2622 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:56:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:55 lr 0.000011	 wd 0.0000	time 0.1799 (0.2295)	loss 0.9937 (0.9050)	grad_norm 0.2667 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:57:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:31 lr 0.000011	 wd 0.0000	time 0.1666 (0.2273)	loss 1.0371 (0.9051)	grad_norm 0.2553 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:57:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:01:08 lr 0.000011	 wd 0.0000	time 0.1665 (0.2254)	loss 0.9956 (0.9046)	grad_norm 0.2728 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:57:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:45 lr 0.000011	 wd 0.0000	time 0.1852 (0.2236)	loss 0.9077 (0.9047)	grad_norm 0.2715 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:58:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:22 lr 0.000011	 wd 0.0000	time 0.1998 (0.2228)	loss 0.9014 (0.9048)	grad_norm 0.2666 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 20:58:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.1497 (0.2220)	loss 0.8296 (0.9046)	grad_norm 0.2722 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 20:58:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 23 training takes 0:09:25
[2024-07-29 20:59:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 19.960 (19.960)	Loss 0.3599 (0.3599)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 20:59:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.770 Acc@5 97.462
[2024-07-29 20:59:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 20:59:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 20:59:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][0/2502]	eta 17:36:28 lr 0.000010	 wd 0.0000	time 25.3353 (25.3353)	loss 0.9360 (0.9360)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:00:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:20:05 lr 0.000010	 wd 0.0000	time 0.2056 (0.5019)	loss 1.0225 (0.9020)	grad_norm 0.2582 (0.2714)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:00:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:13:05 lr 0.000010	 wd 0.0000	time 0.1594 (0.3411)	loss 0.9048 (0.9033)	grad_norm 0.2681 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:00:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:32 lr 0.000010	 wd 0.0000	time 0.1752 (0.2873)	loss 0.8506 (0.9060)	grad_norm 0.2867 (0.2701)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:01:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:09:07 lr 0.000010	 wd 0.0000	time 0.1793 (0.2603)	loss 0.7607 (0.9074)	grad_norm 0.2721 (0.2703)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:01:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:09:18 lr 0.000010	 wd 0.0000	time 0.2412 (0.2792)	loss 0.9277 (0.9094)	grad_norm 0.2849 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:02:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:08:32 lr 0.000010	 wd 0.0000	time 0.1745 (0.2692)	loss 0.9346 (0.9069)	grad_norm 0.2660 (0.2711)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:02:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:07:42 lr 0.000010	 wd 0.0000	time 0.1729 (0.2568)	loss 0.8584 (0.9057)	grad_norm 0.2691 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:02:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:07:00 lr 0.000010	 wd 0.0000	time 0.1698 (0.2469)	loss 0.8213 (0.9050)	grad_norm 0.2773 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:03:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:29 lr 0.000009	 wd 0.0000	time 0.2692 (0.2432)	loss 0.9390 (0.9055)	grad_norm 0.2682 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:03:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:06:12 lr 0.000009	 wd 0.0000	time 0.1580 (0.2479)	loss 0.8521 (0.9063)	grad_norm 0.2807 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:03:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:05:38 lr 0.000009	 wd 0.0000	time 0.1621 (0.2417)	loss 0.8555 (0.9061)	grad_norm 0.2688 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:04:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:05:07 lr 0.000009	 wd 0.0000	time 0.1665 (0.2364)	loss 0.8574 (0.9058)	grad_norm 0.2508 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:04:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:39 lr 0.000009	 wd 0.0000	time 0.1967 (0.2326)	loss 0.7627 (0.9043)	grad_norm 0.2737 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:04:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:04:25 lr 0.000009	 wd 0.0000	time 0.2042 (0.2413)	loss 0.8091 (0.9045)	grad_norm 0.2647 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:05:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:03:57 lr 0.000009	 wd 0.0000	time 0.1848 (0.2375)	loss 0.8462 (0.9045)	grad_norm 0.2624 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:05:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:30 lr 0.000009	 wd 0.0000	time 0.1563 (0.2338)	loss 0.9229 (0.9044)	grad_norm 0.2618 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:05:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:03:05 lr 0.000008	 wd 0.0000	time 0.1719 (0.2308)	loss 1.0166 (0.9049)	grad_norm 0.2683 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:06:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:40 lr 0.000008	 wd 0.0000	time 0.1905 (0.2290)	loss 0.8130 (0.9053)	grad_norm 0.2621 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:06:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:17 lr 0.000008	 wd 0.0000	time 0.1599 (0.2291)	loss 0.7554 (0.9049)	grad_norm 0.2612 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:06:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:54 lr 0.000008	 wd 0.0000	time 0.1832 (0.2272)	loss 0.7378 (0.9050)	grad_norm 0.2734 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:07:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:30 lr 0.000008	 wd 0.0000	time 0.1687 (0.2252)	loss 1.0068 (0.9047)	grad_norm 0.2735 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:07:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:01:07 lr 0.000008	 wd 0.0000	time 0.2000 (0.2234)	loss 0.8853 (0.9044)	grad_norm 0.2647 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:07:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:45 lr 0.000008	 wd 0.0000	time 0.1945 (0.2230)	loss 0.9668 (0.9047)	grad_norm 0.2608 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:08:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:22 lr 0.000008	 wd 0.0000	time 0.1611 (0.2231)	loss 1.1240 (0.9046)	grad_norm 0.2589 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:08:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.1497 (0.2208)	loss 1.0117 (0.9044)	grad_norm 0.2613 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:08:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 24 training takes 0:09:19
[2024-07-29 21:09:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 19.042 (19.042)	Loss 0.3608 (0.3608)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 21:09:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.780 Acc@5 97.458
[2024-07-29 21:09:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 21:09:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 21:09:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][0/2502]	eta 1 day, 1:59:42 lr 0.000008	 wd 0.0000	time 37.4030 (37.4030)	loss 0.8843 (0.8843)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:10:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:22:17 lr 0.000008	 wd 0.0000	time 0.2074 (0.5567)	loss 0.8667 (0.9191)	grad_norm 0.2588 (0.2720)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:10:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:14:09 lr 0.000007	 wd 0.0000	time 0.1805 (0.3692)	loss 0.8569 (0.9162)	grad_norm 0.2670 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:10:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:11:17 lr 0.000007	 wd 0.0000	time 0.1729 (0.3078)	loss 0.9297 (0.9082)	grad_norm 0.2741 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:11:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:11:39 lr 0.000007	 wd 0.0000	time 0.2312 (0.3330)	loss 0.7764 (0.9091)	grad_norm 0.2779 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:11:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:10:07 lr 0.000007	 wd 0.0000	time 0.1850 (0.3034)	loss 0.8828 (0.9085)	grad_norm 0.2603 (0.2711)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:12:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:58 lr 0.000007	 wd 0.0000	time 0.1875 (0.2833)	loss 0.7778 (0.9078)	grad_norm 0.2742 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:12:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:08:05 lr 0.000007	 wd 0.0000	time 0.2103 (0.2692)	loss 0.8613 (0.9071)	grad_norm 0.2765 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:12:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:07:51 lr 0.000007	 wd 0.0000	time 0.2441 (0.2771)	loss 0.9946 (0.9066)	grad_norm 0.2758 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:13:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:07:09 lr 0.000007	 wd 0.0000	time 0.2108 (0.2678)	loss 0.7383 (0.9065)	grad_norm 0.2668 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:13:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:06:29 lr 0.000007	 wd 0.0000	time 0.1550 (0.2592)	loss 0.9902 (0.9069)	grad_norm 0.2844 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:13:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:52 lr 0.000007	 wd 0.0000	time 0.1972 (0.2518)	loss 1.0488 (0.9063)	grad_norm 0.2859 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:14:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:05:23 lr 0.000006	 wd 0.0000	time 0.3456 (0.2485)	loss 1.0283 (0.9074)	grad_norm 0.2772 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:14:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:05:03 lr 0.000006	 wd 0.0000	time 0.1844 (0.2528)	loss 0.9038 (0.9065)	grad_norm 0.2636 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:15:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:04:33 lr 0.000006	 wd 0.0000	time 0.1818 (0.2477)	loss 0.9404 (0.9061)	grad_norm 0.2564 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:15:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:04:03 lr 0.000006	 wd 0.0000	time 0.1696 (0.2433)	loss 1.0098 (0.9070)	grad_norm 0.2654 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7424MB
[2024-07-29 21:15:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:36 lr 0.000006	 wd 0.0000	time 0.1872 (0.2398)	loss 0.7734 (0.9065)	grad_norm 0.2562 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7424MB
[2024-07-29 21:16:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:03:10 lr 0.000006	 wd 0.0000	time 0.2014 (0.2375)	loss 0.8613 (0.9073)	grad_norm 0.2686 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7424MB
[2024-07-29 21:16:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:45 lr 0.000006	 wd 0.0000	time 0.1922 (0.2364)	loss 0.9390 (0.9068)	grad_norm 0.2605 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7424MB
[2024-07-29 21:16:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:20 lr 0.000006	 wd 0.0000	time 0.1546 (0.2337)	loss 1.0557 (0.9069)	grad_norm 0.2597 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7424MB
[2024-07-29 21:17:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:56 lr 0.000006	 wd 0.0000	time 0.2115 (0.2314)	loss 1.0586 (0.9068)	grad_norm 0.2622 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 21:17:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:32 lr 0.000006	 wd 0.0000	time 0.2227 (0.2293)	loss 0.9194 (0.9062)	grad_norm 0.2583 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 21:17:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:09 lr 0.000006	 wd 0.0000	time 0.1750 (0.2291)	loss 0.8467 (0.9057)	grad_norm 0.2527 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 21:18:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:46 lr 0.000005	 wd 0.0000	time 0.2465 (0.2278)	loss 0.7964 (0.9055)	grad_norm 0.2684 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 21:18:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:23 lr 0.000005	 wd 0.0000	time 0.1838 (0.2260)	loss 0.8589 (0.9055)	grad_norm 0.2581 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 21:18:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.1481 (0.2236)	loss 0.8892 (0.9059)	grad_norm 0.2763 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 21:18:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 25 training takes 0:09:28
[2024-07-29 21:19:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 41.348 (41.348)	Loss 0.3606 (0.3606)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 21:19:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.788 Acc@5 97.466
[2024-07-29 21:19:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 21:19:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 21:20:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][0/2502]	eta 11:02:10 lr 0.000005	 wd 0.0000	time 15.8796 (15.8796)	loss 1.0439 (1.0439)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:20:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:13:43 lr 0.000005	 wd 0.0000	time 0.1765 (0.3426)	loss 0.8027 (0.9145)	grad_norm 0.2634 (0.2728)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:20:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:11:08 lr 0.000005	 wd 0.0000	time 0.3089 (0.2904)	loss 0.9116 (0.9114)	grad_norm 0.2735 (0.2723)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:21:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:48 lr 0.000005	 wd 0.0000	time 0.1639 (0.2944)	loss 0.8740 (0.9119)	grad_norm 0.2875 (0.2721)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:21:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:09:19 lr 0.000005	 wd 0.0000	time 0.1799 (0.2660)	loss 0.9224 (0.9099)	grad_norm 0.2849 (0.2719)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:21:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:08:18 lr 0.000005	 wd 0.0000	time 0.1563 (0.2488)	loss 0.8589 (0.9079)	grad_norm 0.2602 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:22:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:07:34 lr 0.000005	 wd 0.0000	time 0.2711 (0.2391)	loss 0.8823 (0.9086)	grad_norm 0.2705 (0.2717)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:22:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:30 lr 0.000005	 wd 0.0000	time 0.2028 (0.2501)	loss 0.8623 (0.9062)	grad_norm 0.2656 (0.2717)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:23:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:06:51 lr 0.000005	 wd 0.0000	time 0.1691 (0.2417)	loss 0.9004 (0.9073)	grad_norm 0.2793 (0.2715)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:23:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:06:16 lr 0.000005	 wd 0.0000	time 0.1851 (0.2350)	loss 0.7935 (0.9057)	grad_norm 0.2792 (0.2715)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:23:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:05:44 lr 0.000004	 wd 0.0000	time 0.1835 (0.2294)	loss 0.9482 (0.9061)	grad_norm 0.2703 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:24:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:25 lr 0.000004	 wd 0.0000	time 0.4386 (0.2324)	loss 1.0010 (0.9068)	grad_norm 0.2638 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:24:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:05:07 lr 0.000004	 wd 0.0000	time 0.1663 (0.2358)	loss 0.9414 (0.9065)	grad_norm 0.2648 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:24:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:38 lr 0.000004	 wd 0.0000	time 0.1811 (0.2316)	loss 0.7876 (0.9069)	grad_norm 0.2696 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:25:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:04:11 lr 0.000004	 wd 0.0000	time 0.1735 (0.2278)	loss 0.9971 (0.9065)	grad_norm 0.2726 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:25:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:46 lr 0.000004	 wd 0.0000	time 0.1929 (0.2256)	loss 0.8906 (0.9068)	grad_norm 0.2690 (0.2714)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:25:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:23 lr 0.000004	 wd 0.0000	time 0.1630 (0.2254)	loss 0.7710 (0.9057)	grad_norm 0.2593 (0.2714)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:26:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:02:59 lr 0.000004	 wd 0.0000	time 0.1789 (0.2238)	loss 0.8760 (0.9065)	grad_norm 0.2644 (0.2714)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:26:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:35 lr 0.000004	 wd 0.0000	time 0.1908 (0.2215)	loss 0.9424 (0.9069)	grad_norm 0.2668 (0.2714)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:26:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:12 lr 0.000004	 wd 0.0000	time 0.1972 (0.2195)	loss 0.9111 (0.9062)	grad_norm 0.2706 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:27:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:49 lr 0.000004	 wd 0.0000	time 0.2038 (0.2181)	loss 0.9531 (0.9062)	grad_norm 0.2736 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:27:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:27 lr 0.000004	 wd 0.0000	time 0.1988 (0.2185)	loss 0.9053 (0.9064)	grad_norm 0.2782 (0.2713)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:27:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:05 lr 0.000004	 wd 0.0000	time 0.1957 (0.2179)	loss 0.9517 (0.9063)	grad_norm 0.2722 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:28:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:43 lr 0.000004	 wd 0.0000	time 0.1808 (0.2165)	loss 0.8687 (0.9060)	grad_norm 0.2743 (0.2711)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:28:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:21 lr 0.000003	 wd 0.0000	time 0.1722 (0.2151)	loss 0.8960 (0.9064)	grad_norm 0.2778 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:28:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.1476 (0.2131)	loss 0.9663 (0.9065)	grad_norm 0.2657 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:28:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 26 training takes 0:09:02
[2024-07-29 21:29:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 43.848 (43.848)	Loss 0.3606 (0.3606)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 21:29:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.790 Acc@5 97.458
[2024-07-29 21:29:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 21:29:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 21:30:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][0/2502]	eta 13:09:28 lr 0.000003	 wd 0.0000	time 18.9321 (18.9321)	loss 0.9619 (0.9619)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:30:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:19:45 lr 0.000003	 wd 0.0000	time 0.1675 (0.4934)	loss 0.9326 (0.9116)	grad_norm 0.2709 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:31:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:12:58 lr 0.000003	 wd 0.0000	time 0.1831 (0.3382)	loss 0.7227 (0.9055)	grad_norm 0.2778 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:31:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:29 lr 0.000003	 wd 0.0000	time 0.2209 (0.2860)	loss 0.9258 (0.9059)	grad_norm 0.2780 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:31:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:09:04 lr 0.000003	 wd 0.0000	time 0.1722 (0.2592)	loss 0.8491 (0.9050)	grad_norm 0.2675 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:32:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:08:26 lr 0.000003	 wd 0.0000	time 0.3226 (0.2531)	loss 0.7891 (0.9046)	grad_norm 0.2917 (nan)	loss_scale 32768.0000 (32898.8104)	mem 7424MB
[2024-07-29 21:32:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:08:29 lr 0.000003	 wd 0.0000	time 0.1893 (0.2680)	loss 0.8350 (0.9066)	grad_norm 0.2709 (nan)	loss_scale 32768.0000 (32877.0449)	mem 7424MB
[2024-07-29 21:32:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:40 lr 0.000003	 wd 0.0000	time 0.1829 (0.2557)	loss 0.8247 (0.9061)	grad_norm 0.2776 (nan)	loss_scale 32768.0000 (32861.4893)	mem 7424MB
[2024-07-29 21:33:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:06:59 lr 0.000003	 wd 0.0000	time 0.1633 (0.2462)	loss 0.9297 (0.9052)	grad_norm 0.2644 (nan)	loss_scale 32768.0000 (32849.8177)	mem 7424MB
[2024-07-29 21:33:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:06:24 lr 0.000003	 wd 0.0000	time 0.1770 (0.2403)	loss 0.7886 (0.9045)	grad_norm 0.2631 (nan)	loss_scale 32768.0000 (32840.7370)	mem 7424MB
[2024-07-29 21:33:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:06:00 lr 0.000003	 wd 0.0000	time 0.1609 (0.2399)	loss 0.9180 (0.9040)	grad_norm 0.2579 (nan)	loss_scale 32768.0000 (32833.4705)	mem 7424MB
[2024-07-29 21:34:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:05:29 lr 0.000003	 wd 0.0000	time 0.1983 (0.2349)	loss 0.7852 (0.9039)	grad_norm 0.2829 (nan)	loss_scale 32768.0000 (32827.5241)	mem 7424MB
[2024-07-29 21:34:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:05:00 lr 0.000003	 wd 0.0000	time 0.1705 (0.2307)	loss 0.9106 (0.9029)	grad_norm 0.2669 (nan)	loss_scale 32768.0000 (32822.5679)	mem 7424MB
[2024-07-29 21:34:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:32 lr 0.000003	 wd 0.0000	time 0.1845 (0.2270)	loss 0.8584 (0.9031)	grad_norm 0.2713 (nan)	loss_scale 32768.0000 (32818.3736)	mem 7424MB
[2024-07-29 21:35:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:04:07 lr 0.000003	 wd 0.0000	time 0.2271 (0.2247)	loss 0.8281 (0.9032)	grad_norm 0.2670 (nan)	loss_scale 32768.0000 (32814.7780)	mem 7424MB
[2024-07-29 21:35:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:03:45 lr 0.000003	 wd 0.0000	time 0.1717 (0.2249)	loss 1.0127 (0.9033)	grad_norm 0.2717 (nan)	loss_scale 32768.0000 (32811.6616)	mem 7424MB
[2024-07-29 21:35:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:20 lr 0.000003	 wd 0.0000	time 0.1792 (0.2227)	loss 0.9146 (0.9034)	grad_norm 0.2675 (nan)	loss_scale 32768.0000 (32808.9344)	mem 7424MB
[2024-07-29 21:36:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:02:56 lr 0.000002	 wd 0.0000	time 0.1820 (0.2204)	loss 0.8882 (0.9036)	grad_norm 0.2768 (nan)	loss_scale 32768.0000 (32806.5279)	mem 7424MB
[2024-07-29 21:36:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:33 lr 0.000002	 wd 0.0000	time 0.1612 (0.2182)	loss 0.8018 (0.9040)	grad_norm 0.2676 (nan)	loss_scale 32768.0000 (32804.3887)	mem 7424MB
[2024-07-29 21:36:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:10 lr 0.000002	 wd 0.0000	time 0.2663 (0.2175)	loss 0.8257 (0.9041)	grad_norm 0.2699 (nan)	loss_scale 32768.0000 (32802.4745)	mem 7424MB
[2024-07-29 21:37:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:49 lr 0.000002	 wd 0.0000	time 0.1650 (0.2188)	loss 0.7676 (0.9038)	grad_norm 0.2599 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 21:37:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:27 lr 0.000002	 wd 0.0000	time 0.1825 (0.2174)	loss 1.0596 (0.9048)	grad_norm 0.2849 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 21:37:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:05 lr 0.000002	 wd 0.0000	time 0.1733 (0.2160)	loss 0.7505 (0.9044)	grad_norm 0.2663 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 21:38:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:43 lr 0.000002	 wd 0.0000	time 0.1758 (0.2146)	loss 0.8628 (0.9047)	grad_norm 0.2858 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 21:38:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:21 lr 0.000002	 wd 0.0000	time 0.2137 (0.2140)	loss 0.9141 (0.9044)	grad_norm 0.2729 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 21:38:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.1488 (0.2130)	loss 0.9038 (0.9046)	grad_norm 0.2684 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 21:38:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 27 training takes 0:09:03
[2024-07-29 21:39:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 19.948 (19.948)	Loss 0.3599 (0.3599)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 21:39:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.774 Acc@5 97.454
[2024-07-29 21:39:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 21:39:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 21:39:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][0/2502]	eta 15:35:37 lr 0.000002	 wd 0.0000	time 22.4372 (22.4372)	loss 0.8755 (0.8755)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:40:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:20:05 lr 0.000002	 wd 0.0000	time 0.1762 (0.5018)	loss 0.9116 (0.8979)	grad_norm 0.2766 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:40:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:13:09 lr 0.000002	 wd 0.0000	time 0.1701 (0.3429)	loss 0.8813 (0.9054)	grad_norm 0.2817 (0.2712)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:41:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:10:36 lr 0.000002	 wd 0.0000	time 0.1702 (0.2890)	loss 0.9902 (0.9078)	grad_norm 0.2642 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:41:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:09:09 lr 0.000002	 wd 0.0000	time 0.1975 (0.2614)	loss 0.8066 (0.9029)	grad_norm 0.2693 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:41:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:09:29 lr 0.000002	 wd 0.0000	time 0.1833 (0.2845)	loss 0.9028 (0.9051)	grad_norm 0.2656 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:42:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:08:39 lr 0.000002	 wd 0.0000	time 0.1724 (0.2731)	loss 0.9424 (0.9065)	grad_norm 0.2804 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:42:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:07:48 lr 0.000002	 wd 0.0000	time 0.1798 (0.2599)	loss 0.8848 (0.9058)	grad_norm 0.2694 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:42:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:07:05 lr 0.000002	 wd 0.0000	time 0.1835 (0.2499)	loss 0.8755 (0.9067)	grad_norm 0.2727 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:43:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:06:37 lr 0.000002	 wd 0.0000	time 0.4527 (0.2479)	loss 0.8638 (0.9065)	grad_norm 0.2750 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:43:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:06:22 lr 0.000002	 wd 0.0000	time 0.1799 (0.2545)	loss 0.9053 (0.9064)	grad_norm 0.2577 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:44:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:05:47 lr 0.000002	 wd 0.0000	time 0.1540 (0.2478)	loss 0.8340 (0.9048)	grad_norm 0.2801 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:44:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:05:15 lr 0.000002	 wd 0.0000	time 0.1745 (0.2420)	loss 0.9204 (0.9050)	grad_norm 0.2858 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:44:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:04:45 lr 0.000002	 wd 0.0000	time 0.2150 (0.2379)	loss 0.9956 (0.9054)	grad_norm 0.2806 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:45:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:04:28 lr 0.000002	 wd 0.0000	time 0.1710 (0.2434)	loss 0.8159 (0.9046)	grad_norm 0.2660 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:45:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:59 lr 0.000002	 wd 0.0000	time 0.1619 (0.2392)	loss 0.7939 (0.9048)	grad_norm 0.2839 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:45:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:03:32 lr 0.000002	 wd 0.0000	time 0.1782 (0.2356)	loss 1.0537 (0.9051)	grad_norm 0.2862 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:46:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:03:06 lr 0.000001	 wd 0.0000	time 0.1939 (0.2325)	loss 0.9429 (0.9050)	grad_norm 0.2824 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:46:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:42 lr 0.000001	 wd 0.0000	time 0.1865 (0.2309)	loss 0.7939 (0.9046)	grad_norm 0.2715 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:46:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:02:18 lr 0.000001	 wd 0.0000	time 0.2014 (0.2308)	loss 0.9106 (0.9054)	grad_norm 0.2635 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:47:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:54 lr 0.000001	 wd 0.0000	time 0.1641 (0.2288)	loss 0.8345 (0.9045)	grad_norm 0.2658 (nan)	loss_scale 32768.0000 (32800.7516)	mem 7424MB
[2024-07-29 21:47:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:31 lr 0.000001	 wd 0.0000	time 0.1806 (0.2266)	loss 0.8555 (0.9043)	grad_norm 0.2774 (nan)	loss_scale 32768.0000 (32799.1928)	mem 7424MB
[2024-07-29 21:47:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:01:07 lr 0.000001	 wd 0.0000	time 0.1728 (0.2248)	loss 0.9214 (0.9038)	grad_norm 0.2816 (nan)	loss_scale 32768.0000 (32797.7756)	mem 7424MB
[2024-07-29 21:48:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 0.2083 (0.2240)	loss 0.8169 (0.9036)	grad_norm 0.2637 (nan)	loss_scale 32768.0000 (32796.4815)	mem 7424MB
[2024-07-29 21:48:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:22 lr 0.000001	 wd 0.0000	time 0.1752 (0.2235)	loss 0.9927 (0.9032)	grad_norm 0.2854 (nan)	loss_scale 32768.0000 (32795.2953)	mem 7424MB
[2024-07-29 21:48:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.1489 (0.2211)	loss 0.8877 (0.9033)	grad_norm 0.2571 (nan)	loss_scale 32768.0000 (32794.2039)	mem 7424MB
[2024-07-29 21:48:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 249): INFO EPOCH 28 training takes 0:09:20
[2024-07-29 21:49:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 289): INFO Test: [0/98]	Time 18.876 (18.876)	Loss 0.3604 (0.3604)	Acc@1 91.406 (91.406)	Acc@5 98.828 (98.828)	Mem 7424MB
[2024-07-29 21:49:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 296): INFO  * Acc@1 84.782 Acc@5 97.452
[2024-07-29 21:49:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 180): INFO Accuracy of the network on the 50000 test images: 84.8%
[2024-07-29 21:49:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 182): INFO Max accuracy: 84.82%
[2024-07-29 21:50:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][0/2502]	eta 1 day, 2:58:21 lr 0.000001	 wd 0.0000	time 38.8096 (38.8096)	loss 0.9883 (0.9883)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:50:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:22:50 lr 0.000001	 wd 0.0000	time 0.1731 (0.5704)	loss 0.8926 (0.9137)	grad_norm 0.2804 (0.2711)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:50:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:14:25 lr 0.000001	 wd 0.0000	time 0.1853 (0.3759)	loss 0.9214 (0.9138)	grad_norm 0.2858 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:51:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:11:25 lr 0.000001	 wd 0.0000	time 0.1817 (0.3113)	loss 0.8604 (0.9135)	grad_norm 0.2783 (0.2702)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:51:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:11:41 lr 0.000001	 wd 0.0000	time 0.2326 (0.3338)	loss 0.8701 (0.9124)	grad_norm 0.2705 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:52:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:10:09 lr 0.000001	 wd 0.0000	time 0.1738 (0.3047)	loss 0.8555 (0.9119)	grad_norm 0.2700 (0.2711)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:52:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:09:00 lr 0.000001	 wd 0.0000	time 0.1799 (0.2844)	loss 0.7725 (0.9106)	grad_norm 0.2778 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:52:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:08:05 lr 0.000001	 wd 0.0000	time 0.1890 (0.2696)	loss 0.8809 (0.9095)	grad_norm 0.2621 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:53:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:07:50 lr 0.000001	 wd 0.0000	time 0.1886 (0.2763)	loss 0.8374 (0.9097)	grad_norm 0.2671 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:53:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:07:06 lr 0.000001	 wd 0.0000	time 0.2002 (0.2663)	loss 0.8784 (0.9099)	grad_norm 0.2769 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
[2024-07-29 21:53:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process0] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:06:27 lr 0.000001	 wd 0.0000	time 0.1852 (0.2577)	loss 0.8496 (0.9100)	grad_norm 0.2730 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 7424MB
