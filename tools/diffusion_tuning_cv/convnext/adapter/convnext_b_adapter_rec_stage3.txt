[2024-07-30 18:48:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 366): INFO Full config saved to pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/config.json
[2024-07-30 18:48:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 369): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 64
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/data/ImageNet1k/
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 32
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3
  NUM_CLASSES: 1000
  PRETRAINED: /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth
  RESUME: ''
  SWIN:
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    FINETUNE_MODE: stage0
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: adapter_convnext_diffusion_finetune
  VCNU_CONVNEXT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    DEPTHS:
    - 3
    - 3
    - 27
    - 3
    DIMS:
    - 128
    - 256
    - 512
    - 1024
    FILTER_STRATEGY1: 18
    FILTER_STRATEGY2: 6
    FINETUNE_MODE: stage3
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MODEL_STYLE: trans
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
  VCNU_SMT:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    CA_ATTENTIONS:
    - 1
    - 1
    - 1
    - 0
    CA_NUM_HEADS:
    - 4
    - 4
    - 4
    - -1
    DEPTHS:
    - 2
    - 2
    - 8
    - 1
    EMBED_DIMS:
    - 64
    - 128
    - 256
    - 512
    EXPAND_RATIO: 2
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    HEAD_CONV: 3
    IN_CHANS: 3
    LAYERSCALE_VALUE: 0.0001
    MLP_RATIOS:
    - 8
    - 6
    - 4
    - 2
    MODEL_STYLE: trans
    NUM_SCALE: 4
    NUM_STAGES: 4
    OUT_DIM: null
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    SA_NUM_HEADS:
    - -1
    - -1
    - 8
    - 16
    USE_LAYERSCALE: false
  VCNU_SWIN:
    AB_NORM_ATTN: true
    AB_NORM_LTM: false
    ADD_EXTRA_ADAPTER: true
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 84
    FILTER_STRATEGY1: 23
    FILTER_STRATEGY2: 7
    FINETUNE_MODE: full
    IN_CHANS: 3
    LAYER_SCALE_INIT_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_SCALE: 4
    OUT_DIM: null
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    TRAINING_MODE: tfs
    USE_LAYERSCALE: false
    WINDOW_SIZE: 7
  generalVCNUS:
    ABLATION_STRATEGY: UMA
    AB_AGGREGATION_ATTN: cat
    AB_AGGREGATION_LTM: add
    AB_DOWNSAMPLING_STRATEGY: max
    AB_MEMORY_CREATION_STRATEGY: UMA
    AB_NORM_ATTN: true
    AB_NORM_ATTN_NAME: BN
    AB_NORM_LTM: true
    AB_NORM_LTM_NAME: BN
    AB_PATCH_NORM_NAME: BN
    AB_STRATEGY: statistic
    AB_USE_SEQUENCEFUNC: UMA
    AB_WM: l
    APE: false
    DEPTHS:
    - 3
    - 3
    - 12
    - 3
    EMBED_CONV: 7
    EMBED_DIM: 64
    FILTER_STRATEGY1: 12
    FILTER_STRATEGY2: 4
    IN_CHANS: 3
    KERNAL_SIZE: 11
    LAYERSCALE_VALUE: 1.0e-06
    MLP_RATIO: 4.0
    MODEL_STYLE: trans
    NUM_SCALE: 4
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMAGE_SIZE: 224
    RECE_FIELD: 7
    SAVE_FREQ: 30
    USE_BIAS: true
    USE_FIBONACCI: true
    USE_LAYERSCALE: false
    USE_SEQUENCEFUNC: statistic
OUTPUT: pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3
PRINT_FREQ: 100
SAVE_FREQ: 15
SEED: 0
TAG: diffusion_ft_adapter_conv_b_sequence_stage3
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: true
  BASE_LR: 0.0001
  CLIP_GRAD: 5.0
  EFFICIENT_FINETUNE: true
  EPOCHS: 30
  LAYER_DECAY: 0.8
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.0e-06
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 1.0e-08

[2024-07-30 18:48:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 370): INFO {"cfg": "/mnt/data/vcnu_expansibility_v2/configs/diffusion_finetune/diffusion_finetune/convnext/adapter_convnext/diffusion_ft_adapter_convnext_base_224_22kto1k_step_stage_process3.yaml", "opts": null, "batch_size": 64, "data_path": "/mnt/data/ImageNet1k/", "zip": false, "cache_mode": "part", "pretrained": "/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth", "resume": null, "accumulation_steps": 2, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "pretrain/diffusion-ft", "tag": "diffusion_ft_adapter_conv_b_sequence_stage3", "eval": false, "throughput": false, "local_rank": 0, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2024-07-30 18:48:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 108): INFO Creating model:adapter_convnext_diffusion_finetune/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3
[2024-07-30 18:48:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 110): INFO Adapter_ConvNeXt_Diffusion_Finetune(
  (uma): UMA(filter_strategy1=18, filter_strategy2=6,ablation_strategy=UMA, use_sequencefunc=linear,fftscale=4,)
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): Identity()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=128, out_features=512, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=512, out_features=128, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=128, emb_dim=32, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=128, out_features=32, bias=True)
          (up): Linear(in_features=32, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=256, emb_dim=64, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=256, out_features=64, bias=True)
          (up): Linear(in_features=64, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (3): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (4): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (5): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (6): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (7): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (8): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (9): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (10): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (11): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (12): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (13): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (14): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (15): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (16): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (17): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (18): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (19): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (20): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (21): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (22): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (23): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (24): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (25): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (26): Block(
        (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=512, emb_dim=128, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=512, out_features=128, bias=True)
          (up): Linear(in_features=128, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (1): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
      (2): Block(
        (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop_path): DropPath()
        (adapter): Adapter(
          dim=1024, emb_dim=256, model_style=trans, 
          (activation): GELU()
          (down): Linear(in_features=1024, out_features=256, bias=True)
          (up): Linear(in_features=256, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (memory_downsampling): ModuleList()
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=1000, bias=True)
)
[2024-07-30 18:48:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 113): INFO number of params: 2603752
[2024-07-30 18:48:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 150): INFO no checkpoint found in pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3, ignoring auto resume
[2024-07-30 18:48:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 46): INFO ==============> Loading weight /mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth for fine-tuning......
[2024-07-30 18:48:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 127): WARNING <All keys matched successfully>
[2024-07-30 18:48:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 129): INFO => loaded successfully '/mnt/data/vcnu_expansibility_v2/pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process2/diffusion_ft_adapter_conv_b_sequence_stage2/ckpt_epoch_best.pth'
[2024-07-30 18:50:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 74.821 (74.821)	Loss 0.3550 (0.3550)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 3061MB
[2024-07-30 18:50:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.268 Acc@5 97.624
[2024-07-30 18:50:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 162): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 18:50:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 168): INFO Start training
[2024-07-30 18:50:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][0/2502]	eta 16:42:43 lr 0.000100	 wd 0.0000	time 24.0460 (24.0460)	loss 0.8447 (0.8447)	grad_norm 0.0000 (0.0000)	loss_scale 65536.0000 (65536.0000)	mem 3061MB
[2024-07-30 18:51:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][100/2502]	eta 0:15:46 lr 0.000100	 wd 0.0000	time 0.2091 (0.3942)	loss 0.7949 (0.8591)	grad_norm 0.2686 (nan)	loss_scale 32768.0000 (33092.4356)	mem 3061MB
[2024-07-30 18:51:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][200/2502]	eta 0:16:33 lr 0.000100	 wd 0.0000	time 0.1799 (0.4315)	loss 0.8403 (0.8663)	grad_norm 0.2645 (nan)	loss_scale 32768.0000 (32931.0249)	mem 3061MB
[2024-07-30 18:52:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][300/2502]	eta 0:12:26 lr 0.000100	 wd 0.0000	time 0.1335 (0.3390)	loss 0.8950 (0.8699)	grad_norm 0.2721 (nan)	loss_scale 32768.0000 (32876.8638)	mem 3061MB
[2024-07-30 18:52:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][400/2502]	eta 0:10:15 lr 0.000100	 wd 0.0000	time 0.1010 (0.2928)	loss 1.2129 (0.8697)	grad_norm 0.2608 (nan)	loss_scale 32768.0000 (32849.7157)	mem 3061MB
[2024-07-30 18:52:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][500/2502]	eta 0:08:49 lr 0.000100	 wd 0.0000	time 0.2051 (0.2644)	loss 0.8096 (0.8697)	grad_norm 0.2499 (nan)	loss_scale 32768.0000 (32833.4052)	mem 3061MB
[2024-07-30 18:53:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][600/2502]	eta 0:08:16 lr 0.000100	 wd 0.0000	time 0.3795 (0.2612)	loss 0.9297 (0.8698)	grad_norm 0.2544 (nan)	loss_scale 32768.0000 (32822.5225)	mem 3061MB
[2024-07-30 18:53:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][700/2502]	eta 0:08:11 lr 0.000100	 wd 0.0000	time 0.1350 (0.2726)	loss 0.8188 (0.8667)	grad_norm 0.2468 (nan)	loss_scale 32768.0000 (32814.7447)	mem 3061MB
[2024-07-30 18:53:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][800/2502]	eta 0:07:19 lr 0.000100	 wd 0.0000	time 0.1434 (0.2582)	loss 0.8994 (0.8679)	grad_norm 0.2414 (nan)	loss_scale 32768.0000 (32808.9089)	mem 3061MB
[2024-07-30 18:54:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][900/2502]	eta 0:06:35 lr 0.000100	 wd 0.0000	time 0.1299 (0.2468)	loss 1.0410 (0.8667)	grad_norm 0.2592 (nan)	loss_scale 32768.0000 (32804.3685)	mem 3061MB
[2024-07-30 18:54:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1000/2502]	eta 0:05:58 lr 0.000100	 wd 0.0000	time 0.1480 (0.2387)	loss 0.8774 (0.8668)	grad_norm 0.2520 (nan)	loss_scale 32768.0000 (32800.7353)	mem 3061MB
[2024-07-30 18:54:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1100/2502]	eta 0:05:42 lr 0.000100	 wd 0.0000	time 0.1649 (0.2443)	loss 0.7949 (0.8665)	grad_norm 0.2649 (nan)	loss_scale 32768.0000 (32797.7620)	mem 3061MB
[2024-07-30 18:55:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1200/2502]	eta 0:05:09 lr 0.000100	 wd 0.0000	time 0.1996 (0.2373)	loss 0.7422 (0.8667)	grad_norm 0.2517 (nan)	loss_scale 32768.0000 (32795.2839)	mem 3061MB
[2024-07-30 18:55:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1300/2502]	eta 0:04:37 lr 0.000100	 wd 0.0000	time 0.1985 (0.2311)	loss 0.8540 (0.8680)	grad_norm 0.2644 (nan)	loss_scale 32768.0000 (32793.1868)	mem 3061MB
[2024-07-30 18:55:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1400/2502]	eta 0:04:08 lr 0.000100	 wd 0.0000	time 0.1970 (0.2256)	loss 0.8540 (0.8684)	grad_norm 0.2666 (nan)	loss_scale 32768.0000 (32791.3890)	mem 3061MB
[2024-07-30 18:55:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1500/2502]	eta 0:03:42 lr 0.000100	 wd 0.0000	time 0.2640 (0.2217)	loss 0.9478 (0.8689)	grad_norm 0.2580 (nan)	loss_scale 32768.0000 (32789.8308)	mem 3061MB
[2024-07-30 18:56:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1600/2502]	eta 0:03:24 lr 0.000100	 wd 0.0000	time 0.1858 (0.2267)	loss 1.0225 (0.8697)	grad_norm 0.2601 (nan)	loss_scale 32768.0000 (32788.4672)	mem 3061MB
[2024-07-30 18:56:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1700/2502]	eta 0:02:58 lr 0.000100	 wd 0.0000	time 0.1064 (0.2231)	loss 0.8447 (0.8699)	grad_norm 0.2544 (nan)	loss_scale 32768.0000 (32787.2640)	mem 3061MB
[2024-07-30 18:56:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1800/2502]	eta 0:02:34 lr 0.000100	 wd 0.0000	time 0.1521 (0.2194)	loss 0.8418 (0.8699)	grad_norm 0.2680 (nan)	loss_scale 32768.0000 (32786.1943)	mem 3061MB
[2024-07-30 18:57:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][1900/2502]	eta 0:02:10 lr 0.000100	 wd 0.0000	time 0.1911 (0.2170)	loss 0.9575 (0.8701)	grad_norm 0.2519 (nan)	loss_scale 32768.0000 (32785.2372)	mem 3061MB
[2024-07-30 18:57:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2000/2502]	eta 0:01:47 lr 0.000100	 wd 0.0000	time 0.2015 (0.2148)	loss 0.9189 (0.8702)	grad_norm 0.2691 (nan)	loss_scale 32768.0000 (32784.3758)	mem 3061MB
[2024-07-30 18:58:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2100/2502]	eta 0:01:28 lr 0.000100	 wd 0.0000	time 0.1808 (0.2204)	loss 0.8354 (0.8705)	grad_norm 0.2522 (nan)	loss_scale 32768.0000 (32783.5964)	mem 3061MB
[2024-07-30 18:58:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2200/2502]	eta 0:01:05 lr 0.000100	 wd 0.0000	time 0.1454 (0.2177)	loss 0.9785 (0.8703)	grad_norm 0.2557 (nan)	loss_scale 32768.0000 (32782.8878)	mem 3061MB
[2024-07-30 18:58:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2300/2502]	eta 0:00:43 lr 0.000100	 wd 0.0000	time 0.1344 (0.2153)	loss 0.9761 (0.8701)	grad_norm 0.2661 (nan)	loss_scale 32768.0000 (32782.2408)	mem 3061MB
[2024-07-30 18:58:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2400/2502]	eta 0:00:21 lr 0.000100	 wd 0.0000	time 0.1647 (0.2131)	loss 1.0225 (0.8703)	grad_norm 0.2538 (nan)	loss_scale 32768.0000 (32781.6476)	mem 3061MB
[2024-07-30 18:59:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [0/30][2500/2502]	eta 0:00:00 lr 0.000100	 wd 0.0000	time 0.0822 (0.2092)	loss 0.8281 (0.8701)	grad_norm 0.2422 (nan)	loss_scale 32768.0000 (32781.1020)	mem 3061MB
[2024-07-30 18:59:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 0 training takes 0:08:47
[2024-07-30 18:59:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_0.pth saving......
[2024-07-30 18:59:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_0.pth saved !!!
[2024-07-30 19:00:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 62.249 (62.249)	Loss 0.3643 (0.3643)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 19:00:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.212 Acc@5 97.636
[2024-07-30 19:00:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 19:00:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.21%
[2024-07-30 19:00:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_best.pth saving......
[2024-07-30 19:00:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_best.pth saved !!!
[2024-07-30 19:00:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][0/2502]	eta 12:13:55 lr 0.000100	 wd 0.0000	time 17.6003 (17.6003)	loss 0.7485 (0.7485)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:01:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][100/2502]	eta 0:23:48 lr 0.000100	 wd 0.0000	time 0.1957 (0.5947)	loss 0.8135 (0.8573)	grad_norm 0.2590 (0.2530)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:01:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][200/2502]	eta 0:14:27 lr 0.000100	 wd 0.0000	time 0.1757 (0.3769)	loss 0.7803 (0.8633)	grad_norm 0.2442 (0.2529)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:02:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][300/2502]	eta 0:11:05 lr 0.000100	 wd 0.0000	time 0.1560 (0.3021)	loss 0.8848 (0.8652)	grad_norm 0.2527 (0.2532)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:02:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][400/2502]	eta 0:09:15 lr 0.000100	 wd 0.0000	time 0.1857 (0.2644)	loss 0.8779 (0.8662)	grad_norm 0.2640 (0.2538)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:02:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][500/2502]	eta 0:08:41 lr 0.000100	 wd 0.0000	time 0.4349 (0.2605)	loss 0.8081 (0.8647)	grad_norm 0.2482 (0.2540)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:03:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][600/2502]	eta 0:08:45 lr 0.000100	 wd 0.0000	time 0.1428 (0.2761)	loss 0.8770 (0.8663)	grad_norm 0.2569 (0.2541)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:03:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][700/2502]	eta 0:07:46 lr 0.000100	 wd 0.0000	time 0.1297 (0.2591)	loss 0.8154 (0.8654)	grad_norm 0.2510 (0.2541)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:03:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][800/2502]	eta 0:06:59 lr 0.000100	 wd 0.0000	time 0.1583 (0.2462)	loss 1.0000 (0.8666)	grad_norm 0.2512 (0.2541)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:04:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][900/2502]	eta 0:06:20 lr 0.000099	 wd 0.0000	time 0.1927 (0.2373)	loss 0.8643 (0.8665)	grad_norm 0.2587 (0.2540)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:04:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1000/2502]	eta 0:06:13 lr 0.000099	 wd 0.0000	time 0.1469 (0.2485)	loss 0.8652 (0.8669)	grad_norm 0.2530 (0.2542)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:04:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1100/2502]	eta 0:05:37 lr 0.000099	 wd 0.0000	time 0.1213 (0.2406)	loss 0.9248 (0.8677)	grad_norm 0.2653 (0.2544)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:05:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1200/2502]	eta 0:05:04 lr 0.000099	 wd 0.0000	time 0.1422 (0.2338)	loss 0.8140 (0.8676)	grad_norm 0.2547 (0.2544)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:05:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1300/2502]	eta 0:04:33 lr 0.000099	 wd 0.0000	time 0.1512 (0.2276)	loss 0.8491 (0.8683)	grad_norm 0.2565 (0.2544)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:05:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1400/2502]	eta 0:04:06 lr 0.000099	 wd 0.0000	time 0.3908 (0.2240)	loss 0.8491 (0.8686)	grad_norm 0.2553 (0.2544)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:06:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1500/2502]	eta 0:03:55 lr 0.000099	 wd 0.0000	time 0.1299 (0.2353)	loss 0.8770 (0.8696)	grad_norm 0.2546 (0.2545)	loss_scale 65536.0000 (32811.6616)	mem 3061MB
[2024-07-30 19:06:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1600/2502]	eta 0:03:27 lr 0.000099	 wd 0.0000	time 0.1768 (0.2305)	loss 0.8159 (0.8693)	grad_norm 0.2447 (nan)	loss_scale 32768.0000 (32808.9344)	mem 3061MB
[2024-07-30 19:06:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1700/2502]	eta 0:03:01 lr 0.000099	 wd 0.0000	time 0.1284 (0.2263)	loss 0.7627 (0.8694)	grad_norm 0.2571 (nan)	loss_scale 32768.0000 (32806.5279)	mem 3061MB
[2024-07-30 19:07:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1800/2502]	eta 0:02:36 lr 0.000099	 wd 0.0000	time 0.1848 (0.2227)	loss 0.9321 (0.8693)	grad_norm 0.2483 (nan)	loss_scale 32768.0000 (32804.3887)	mem 3061MB
[2024-07-30 19:07:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][1900/2502]	eta 0:02:13 lr 0.000099	 wd 0.0000	time 0.1565 (0.2216)	loss 0.8984 (0.8697)	grad_norm 0.2462 (nan)	loss_scale 32768.0000 (32802.4745)	mem 3061MB
[2024-07-30 19:07:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2000/2502]	eta 0:01:51 lr 0.000099	 wd 0.0000	time 0.1836 (0.2214)	loss 0.7686 (0.8697)	grad_norm 0.2594 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 19:08:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2100/2502]	eta 0:01:28 lr 0.000099	 wd 0.0000	time 0.1280 (0.2190)	loss 0.8223 (0.8696)	grad_norm 0.2678 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 19:08:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2200/2502]	eta 0:01:05 lr 0.000099	 wd 0.0000	time 0.1513 (0.2167)	loss 0.7476 (0.8691)	grad_norm 0.2421 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 19:08:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2300/2502]	eta 0:00:43 lr 0.000099	 wd 0.0000	time 0.1386 (0.2145)	loss 0.9214 (0.8698)	grad_norm 0.2557 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 19:09:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2400/2502]	eta 0:00:21 lr 0.000099	 wd 0.0000	time 0.2684 (0.2138)	loss 0.9053 (0.8699)	grad_norm 0.2650 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 19:09:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [1/30][2500/2502]	eta 0:00:00 lr 0.000099	 wd 0.0000	time 0.0818 (0.2149)	loss 0.8804 (0.8702)	grad_norm 0.2598 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 19:09:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 1 training takes 0:09:01
[2024-07-30 19:09:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 21.157 (21.157)	Loss 0.3628 (0.3628)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 3061MB
[2024-07-30 19:10:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.240 Acc@5 97.608
[2024-07-30 19:10:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 19:10:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.24%
[2024-07-30 19:10:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_best.pth saving......
[2024-07-30 19:10:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_best.pth saved !!!
[2024-07-30 19:10:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][0/2502]	eta 11:22:26 lr 0.000099	 wd 0.0000	time 16.3655 (16.3655)	loss 0.7847 (0.7847)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:11:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][100/2502]	eta 0:21:15 lr 0.000099	 wd 0.0000	time 0.1872 (0.5310)	loss 0.9692 (0.8689)	grad_norm 0.2475 (0.2514)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:11:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][200/2502]	eta 0:13:30 lr 0.000099	 wd 0.0000	time 0.1245 (0.3522)	loss 0.9189 (0.8670)	grad_norm 0.2529 (0.2526)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:11:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][300/2502]	eta 0:10:28 lr 0.000099	 wd 0.0000	time 0.1536 (0.2854)	loss 0.7964 (0.8628)	grad_norm 0.2575 (0.2526)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:11:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][400/2502]	eta 0:08:50 lr 0.000099	 wd 0.0000	time 0.2011 (0.2523)	loss 0.9526 (0.8643)	grad_norm 0.2440 (0.2531)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:12:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][500/2502]	eta 0:07:46 lr 0.000099	 wd 0.0000	time 0.1979 (0.2332)	loss 0.9121 (0.8700)	grad_norm 0.2620 (0.2532)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:12:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][600/2502]	eta 0:08:06 lr 0.000099	 wd 0.0000	time 0.1700 (0.2560)	loss 0.7778 (0.8700)	grad_norm 0.2517 (0.2532)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:12:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][700/2502]	eta 0:07:22 lr 0.000099	 wd 0.0000	time 0.1040 (0.2454)	loss 0.8545 (0.8695)	grad_norm 0.2540 (0.2533)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:13:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][800/2502]	eta 0:06:38 lr 0.000099	 wd 0.0000	time 0.1208 (0.2340)	loss 0.7720 (0.8679)	grad_norm 0.2541 (0.2533)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:13:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][900/2502]	eta 0:06:00 lr 0.000098	 wd 0.0000	time 0.1049 (0.2249)	loss 0.9131 (0.8680)	grad_norm 0.2745 (0.2535)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:13:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1000/2502]	eta 0:05:28 lr 0.000098	 wd 0.0000	time 0.1738 (0.2186)	loss 0.7798 (0.8672)	grad_norm 0.2535 (0.2535)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:14:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1100/2502]	eta 0:05:28 lr 0.000098	 wd 0.0000	time 0.1034 (0.2346)	loss 0.8872 (0.8674)	grad_norm 0.2567 (0.2536)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:14:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1200/2502]	eta 0:04:58 lr 0.000098	 wd 0.0000	time 0.1066 (0.2291)	loss 1.0186 (0.8678)	grad_norm 0.2589 (0.2537)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:14:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1300/2502]	eta 0:04:28 lr 0.000098	 wd 0.0000	time 0.1846 (0.2237)	loss 0.8677 (0.8687)	grad_norm 0.2626 (0.2537)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:15:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1400/2502]	eta 0:04:00 lr 0.000098	 wd 0.0000	time 0.1187 (0.2185)	loss 0.9194 (0.8688)	grad_norm 0.2465 (0.2538)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:15:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1500/2502]	eta 0:03:36 lr 0.000098	 wd 0.0000	time 0.2596 (0.2162)	loss 1.0508 (0.8693)	grad_norm 0.2541 (0.2538)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:15:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1600/2502]	eta 0:03:18 lr 0.000098	 wd 0.0000	time 0.1558 (0.2198)	loss 0.9243 (0.8689)	grad_norm 0.2557 (0.2540)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:16:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1700/2502]	eta 0:02:53 lr 0.000098	 wd 0.0000	time 0.1346 (0.2161)	loss 0.8804 (0.8696)	grad_norm 0.2532 (0.2540)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:16:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1800/2502]	eta 0:02:29 lr 0.000098	 wd 0.0000	time 0.2007 (0.2134)	loss 0.8687 (0.8694)	grad_norm 0.2319 (0.2540)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:16:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][1900/2502]	eta 0:02:06 lr 0.000098	 wd 0.0000	time 0.1910 (0.2108)	loss 0.7881 (0.8698)	grad_norm 0.2542 (0.2542)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:17:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2000/2502]	eta 0:01:45 lr 0.000098	 wd 0.0000	time 0.1369 (0.2099)	loss 0.8770 (0.8699)	grad_norm 0.2472 (0.2542)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:17:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2100/2502]	eta 0:01:24 lr 0.000098	 wd 0.0000	time 0.1369 (0.2102)	loss 0.9478 (0.8705)	grad_norm 0.2595 (0.2542)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:17:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2200/2502]	eta 0:01:03 lr 0.000098	 wd 0.0000	time 0.1795 (0.2087)	loss 0.8701 (0.8704)	grad_norm 0.2568 (0.2542)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:18:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2300/2502]	eta 0:00:41 lr 0.000098	 wd 0.0000	time 0.1212 (0.2068)	loss 0.8159 (0.8702)	grad_norm 0.2551 (0.2542)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:18:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2400/2502]	eta 0:00:20 lr 0.000098	 wd 0.0000	time 0.1169 (0.2050)	loss 0.8540 (0.8706)	grad_norm 0.2549 (0.2542)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:18:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [2/30][2500/2502]	eta 0:00:00 lr 0.000098	 wd 0.0000	time 0.0820 (0.2015)	loss 0.8867 (0.8703)	grad_norm 0.2586 (0.2543)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:18:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 2 training takes 0:08:28
[2024-07-30 19:19:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 42.986 (42.986)	Loss 0.3623 (0.3623)	Acc@1 92.188 (92.188)	Acc@5 98.633 (98.633)	Mem 3061MB
[2024-07-30 19:19:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.320 Acc@5 97.638
[2024-07-30 19:19:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 19:19:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 19:19:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_best.pth saving......
[2024-07-30 19:19:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_best.pth saved !!!
[2024-07-30 19:19:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][0/2502]	eta 11:01:31 lr 0.000098	 wd 0.0000	time 15.8638 (15.8638)	loss 0.7222 (0.7222)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:20:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][100/2502]	eta 0:12:16 lr 0.000098	 wd 0.0000	time 0.1342 (0.3068)	loss 0.9888 (0.8673)	grad_norm 0.2576 (0.2550)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:20:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][200/2502]	eta 0:13:57 lr 0.000097	 wd 0.0000	time 9.7660 (0.3639)	loss 0.9917 (0.8639)	grad_norm 0.2669 (0.2550)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:21:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][300/2502]	eta 0:11:07 lr 0.000097	 wd 0.0000	time 0.1206 (0.3033)	loss 0.9990 (0.8649)	grad_norm 0.2515 (0.2549)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:21:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][400/2502]	eta 0:09:21 lr 0.000097	 wd 0.0000	time 0.1664 (0.2671)	loss 0.9580 (0.8645)	grad_norm 0.2467 (0.2546)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:21:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][500/2502]	eta 0:08:08 lr 0.000097	 wd 0.0000	time 0.1431 (0.2440)	loss 0.8838 (0.8658)	grad_norm nan (nan)	loss_scale 32768.0000 (32898.8104)	mem 3061MB
[2024-07-30 19:21:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][600/2502]	eta 0:07:21 lr 0.000097	 wd 0.0000	time 0.2109 (0.2323)	loss 0.8110 (0.8660)	grad_norm 0.2683 (nan)	loss_scale 32768.0000 (32877.0449)	mem 3061MB
[2024-07-30 19:22:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][700/2502]	eta 0:07:41 lr 0.000097	 wd 0.0000	time 0.1693 (0.2562)	loss 0.9038 (0.8671)	grad_norm 0.2569 (nan)	loss_scale 32768.0000 (32861.4893)	mem 3061MB
[2024-07-30 19:22:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][800/2502]	eta 0:06:54 lr 0.000097	 wd 0.0000	time 0.1479 (0.2436)	loss 0.8384 (0.8662)	grad_norm 0.2656 (nan)	loss_scale 32768.0000 (32849.8177)	mem 3061MB
[2024-07-30 19:23:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][900/2502]	eta 0:06:14 lr 0.000097	 wd 0.0000	time 0.1458 (0.2340)	loss 0.8940 (0.8669)	grad_norm 0.2603 (nan)	loss_scale 32768.0000 (32840.7370)	mem 3061MB
[2024-07-30 19:23:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1000/2502]	eta 0:05:39 lr 0.000097	 wd 0.0000	time 0.1219 (0.2259)	loss 1.0215 (0.8684)	grad_norm 0.2539 (nan)	loss_scale 32768.0000 (32833.4705)	mem 3061MB
[2024-07-30 19:23:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1100/2502]	eta 0:05:13 lr 0.000097	 wd 0.0000	time 0.4056 (0.2233)	loss 0.7700 (0.8681)	grad_norm 0.2681 (nan)	loss_scale 32768.0000 (32827.5241)	mem 3061MB
[2024-07-30 19:24:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1200/2502]	eta 0:04:59 lr 0.000097	 wd 0.0000	time 0.2055 (0.2298)	loss 0.9224 (0.8675)	grad_norm 0.2501 (nan)	loss_scale 32768.0000 (32822.5679)	mem 3061MB
[2024-07-30 19:24:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1300/2502]	eta 0:04:29 lr 0.000097	 wd 0.0000	time 0.2071 (0.2241)	loss 0.9546 (0.8688)	grad_norm 0.2454 (nan)	loss_scale 32768.0000 (32818.3736)	mem 3061MB
[2024-07-30 19:24:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1400/2502]	eta 0:04:01 lr 0.000097	 wd 0.0000	time 0.1121 (0.2191)	loss 0.8442 (0.8686)	grad_norm 0.2445 (nan)	loss_scale 32768.0000 (32814.7780)	mem 3061MB
[2024-07-30 19:24:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1500/2502]	eta 0:03:35 lr 0.000097	 wd 0.0000	time 0.1124 (0.2149)	loss 0.8057 (0.8696)	grad_norm 0.2457 (nan)	loss_scale 32768.0000 (32811.6616)	mem 3061MB
[2024-07-30 19:25:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1600/2502]	eta 0:03:13 lr 0.000096	 wd 0.0000	time 0.2092 (0.2146)	loss 0.8447 (0.8688)	grad_norm 0.2623 (nan)	loss_scale 32768.0000 (32808.9344)	mem 3061MB
[2024-07-30 19:25:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1700/2502]	eta 0:02:54 lr 0.000096	 wd 0.0000	time 0.1113 (0.2174)	loss 0.9175 (0.8687)	grad_norm 0.2520 (nan)	loss_scale 32768.0000 (32806.5279)	mem 3061MB
[2024-07-30 19:25:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1800/2502]	eta 0:02:30 lr 0.000096	 wd 0.0000	time 0.1307 (0.2142)	loss 0.8696 (0.8687)	grad_norm 0.2428 (nan)	loss_scale 32768.0000 (32804.3887)	mem 3061MB
[2024-07-30 19:26:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][1900/2502]	eta 0:02:07 lr 0.000096	 wd 0.0000	time 0.1968 (0.2118)	loss 0.8672 (0.8682)	grad_norm 0.2471 (nan)	loss_scale 32768.0000 (32802.4745)	mem 3061MB
[2024-07-30 19:26:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2000/2502]	eta 0:01:45 lr 0.000096	 wd 0.0000	time 0.2007 (0.2093)	loss 0.8550 (0.8687)	grad_norm 0.2480 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 19:26:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2100/2502]	eta 0:01:24 lr 0.000096	 wd 0.0000	time 0.3290 (0.2097)	loss 0.7041 (0.8683)	grad_norm 0.2502 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 19:27:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2200/2502]	eta 0:01:03 lr 0.000096	 wd 0.0000	time 0.1456 (0.2113)	loss 0.8174 (0.8680)	grad_norm 0.2532 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 19:27:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2300/2502]	eta 0:00:42 lr 0.000096	 wd 0.0000	time 0.2948 (0.2091)	loss 0.9443 (0.8683)	grad_norm 0.2562 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 19:27:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2400/2502]	eta 0:00:21 lr 0.000096	 wd 0.0000	time 0.1737 (0.2074)	loss 0.8208 (0.8684)	grad_norm 0.2503 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 19:28:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [3/30][2500/2502]	eta 0:00:00 lr 0.000096	 wd 0.0000	time 0.0819 (0.2038)	loss 0.7988 (0.8689)	grad_norm 0.2597 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 19:28:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 3 training takes 0:08:34
[2024-07-30 19:28:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 37.138 (37.138)	Loss 0.3660 (0.3660)	Acc@1 91.406 (91.406)	Acc@5 98.633 (98.633)	Mem 3061MB
[2024-07-30 19:28:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.200 Acc@5 97.624
[2024-07-30 19:28:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 19:28:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 19:29:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][0/2502]	eta 11:16:08 lr 0.000096	 wd 0.0000	time 16.2145 (16.2145)	loss 0.8643 (0.8643)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:29:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][100/2502]	eta 0:12:29 lr 0.000096	 wd 0.0000	time 0.1415 (0.3119)	loss 0.7783 (0.8740)	grad_norm 0.2550 (0.2546)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:29:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][200/2502]	eta 0:08:54 lr 0.000096	 wd 0.0000	time 0.1665 (0.2320)	loss 0.9126 (0.8703)	grad_norm 0.2386 (0.2549)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:30:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][300/2502]	eta 0:08:40 lr 0.000095	 wd 0.0000	time 0.3874 (0.2363)	loss 0.8701 (0.8700)	grad_norm 0.2566 (0.2552)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:30:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][400/2502]	eta 0:09:11 lr 0.000095	 wd 0.0000	time 0.1262 (0.2623)	loss 0.8623 (0.8655)	grad_norm 0.2449 (0.2553)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:30:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][500/2502]	eta 0:08:03 lr 0.000095	 wd 0.0000	time 0.1935 (0.2417)	loss 0.9341 (0.8674)	grad_norm 0.2548 (0.2552)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:31:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][600/2502]	eta 0:07:11 lr 0.000095	 wd 0.0000	time 0.1766 (0.2268)	loss 0.8296 (0.8692)	grad_norm 0.2593 (0.2551)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:31:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][700/2502]	eta 0:06:31 lr 0.000095	 wd 0.0000	time 0.2155 (0.2175)	loss 0.9678 (0.8661)	grad_norm 0.2495 (0.2549)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:32:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][800/2502]	eta 0:06:40 lr 0.000095	 wd 0.0000	time 0.1670 (0.2353)	loss 0.8467 (0.8664)	grad_norm 0.2639 (0.2548)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:32:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][900/2502]	eta 0:06:03 lr 0.000095	 wd 0.0000	time 0.1460 (0.2271)	loss 0.8428 (0.8677)	grad_norm 0.2619 (0.2549)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:32:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1000/2502]	eta 0:05:30 lr 0.000095	 wd 0.0000	time 0.1691 (0.2202)	loss 0.8989 (0.8678)	grad_norm 0.2583 (0.2550)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:32:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1100/2502]	eta 0:04:59 lr 0.000095	 wd 0.0000	time 0.1927 (0.2139)	loss 0.9053 (0.8694)	grad_norm 0.2612 (0.2552)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:33:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1200/2502]	eta 0:04:33 lr 0.000095	 wd 0.0000	time 0.1999 (0.2100)	loss 0.7217 (0.8692)	grad_norm 0.2531 (0.2551)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:33:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1300/2502]	eta 0:04:20 lr 0.000095	 wd 0.0000	time 0.1879 (0.2166)	loss 0.8223 (0.8686)	grad_norm 0.2539 (0.2551)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:33:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1400/2502]	eta 0:03:54 lr 0.000094	 wd 0.0000	time 0.1560 (0.2125)	loss 0.8770 (0.8683)	grad_norm 0.2631 (0.2552)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:34:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1500/2502]	eta 0:03:29 lr 0.000094	 wd 0.0000	time 0.1344 (0.2087)	loss 0.7358 (0.8684)	grad_norm 0.2566 (0.2553)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:34:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1600/2502]	eta 0:03:05 lr 0.000094	 wd 0.0000	time 0.1816 (0.2059)	loss 0.8257 (0.8682)	grad_norm 0.2488 (0.2553)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:34:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1700/2502]	eta 0:02:43 lr 0.000094	 wd 0.0000	time 0.1768 (0.2034)	loss 1.0635 (0.8680)	grad_norm 0.2589 (0.2552)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:35:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1800/2502]	eta 0:02:28 lr 0.000094	 wd 0.0000	time 0.1973 (0.2120)	loss 0.8916 (0.8684)	grad_norm 0.2471 (0.2553)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:35:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][1900/2502]	eta 0:02:06 lr 0.000094	 wd 0.0000	time 0.1564 (0.2094)	loss 0.8716 (0.8683)	grad_norm 0.2524 (0.2553)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:35:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2000/2502]	eta 0:01:43 lr 0.000094	 wd 0.0000	time 0.1926 (0.2072)	loss 0.7588 (0.8678)	grad_norm nan (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 19:36:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2100/2502]	eta 0:01:22 lr 0.000094	 wd 0.0000	time 0.1483 (0.2051)	loss 0.8120 (0.8685)	grad_norm 0.2666 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 19:36:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2200/2502]	eta 0:01:01 lr 0.000094	 wd 0.0000	time 0.2032 (0.2043)	loss 0.9683 (0.8680)	grad_norm 0.2337 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 19:36:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2300/2502]	eta 0:00:41 lr 0.000094	 wd 0.0000	time 0.1332 (0.2049)	loss 0.8413 (0.8684)	grad_norm 0.2485 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 19:37:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2400/2502]	eta 0:00:20 lr 0.000093	 wd 0.0000	time 0.1460 (0.2034)	loss 0.8203 (0.8687)	grad_norm 0.2418 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 19:37:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [4/30][2500/2502]	eta 0:00:00 lr 0.000093	 wd 0.0000	time 0.0803 (0.1999)	loss 0.7583 (0.8687)	grad_norm 0.2621 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 19:37:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 4 training takes 0:08:24
[2024-07-30 19:37:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.565 (19.565)	Loss 0.3564 (0.3564)	Acc@1 92.773 (92.773)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 19:37:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.274 Acc@5 97.622
[2024-07-30 19:37:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 19:37:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 19:38:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][0/2502]	eta 1 day, 1:43:08 lr 0.000093	 wd 0.0000	time 37.0057 (37.0057)	loss 0.8374 (0.8374)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:38:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][100/2502]	eta 0:20:54 lr 0.000093	 wd 0.0000	time 0.1279 (0.5223)	loss 0.9023 (0.8583)	grad_norm 0.2635 (0.2555)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:39:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][200/2502]	eta 0:12:54 lr 0.000093	 wd 0.0000	time 0.1497 (0.3363)	loss 0.7842 (0.8636)	grad_norm 0.2593 (0.2566)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:39:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][300/2502]	eta 0:10:07 lr 0.000093	 wd 0.0000	time 0.1565 (0.2761)	loss 0.9702 (0.8621)	grad_norm 0.2483 (0.2561)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:39:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][400/2502]	eta 0:08:39 lr 0.000093	 wd 0.0000	time 0.1891 (0.2471)	loss 0.9219 (0.8622)	grad_norm 0.2657 (0.2565)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:40:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][500/2502]	eta 0:09:20 lr 0.000093	 wd 0.0000	time 0.1481 (0.2798)	loss 0.8169 (0.8623)	grad_norm 0.2651 (0.2561)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:40:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][600/2502]	eta 0:08:12 lr 0.000093	 wd 0.0000	time 0.1616 (0.2589)	loss 0.8403 (0.8652)	grad_norm 0.2605 (0.2562)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:40:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][700/2502]	eta 0:07:20 lr 0.000093	 wd 0.0000	time 0.1410 (0.2444)	loss 0.7798 (0.8646)	grad_norm 0.2719 (0.2562)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:40:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][800/2502]	eta 0:06:35 lr 0.000093	 wd 0.0000	time 0.1309 (0.2324)	loss 0.8271 (0.8643)	grad_norm 0.2570 (0.2562)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:41:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][900/2502]	eta 0:06:02 lr 0.000092	 wd 0.0000	time 0.2121 (0.2262)	loss 0.9199 (0.8647)	grad_norm 0.2564 (0.2563)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:41:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1000/2502]	eta 0:06:03 lr 0.000092	 wd 0.0000	time 0.1311 (0.2423)	loss 0.9077 (0.8668)	grad_norm 0.2522 (0.2564)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:42:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1100/2502]	eta 0:05:28 lr 0.000092	 wd 0.0000	time 0.1320 (0.2344)	loss 0.8071 (0.8678)	grad_norm 0.2520 (0.2564)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:42:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1200/2502]	eta 0:04:57 lr 0.000092	 wd 0.0000	time 0.2220 (0.2281)	loss 0.8926 (0.8685)	grad_norm 0.2563 (0.2565)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:42:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1300/2502]	eta 0:04:27 lr 0.000092	 wd 0.0000	time 0.1747 (0.2225)	loss 0.9429 (0.8678)	grad_norm 0.2624 (0.2564)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:43:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1400/2502]	eta 0:04:02 lr 0.000092	 wd 0.0000	time 0.2234 (0.2197)	loss 0.8350 (0.8670)	grad_norm 0.2620 (0.2564)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:43:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1500/2502]	eta 0:03:41 lr 0.000092	 wd 0.0000	time 0.2579 (0.2214)	loss 0.8516 (0.8678)	grad_norm 0.2519 (0.2565)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:43:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1600/2502]	eta 0:03:16 lr 0.000092	 wd 0.0000	time 0.1804 (0.2175)	loss 0.7915 (0.8683)	grad_norm 0.2616 (0.2565)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:43:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1700/2502]	eta 0:02:51 lr 0.000092	 wd 0.0000	time 0.1684 (0.2141)	loss 0.8618 (0.8688)	grad_norm 0.2462 (0.2565)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:44:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1800/2502]	eta 0:02:28 lr 0.000091	 wd 0.0000	time 0.1610 (0.2112)	loss 0.8550 (0.8681)	grad_norm 0.2600 (0.2566)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:44:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][1900/2502]	eta 0:02:06 lr 0.000091	 wd 0.0000	time 0.2616 (0.2097)	loss 0.8364 (0.8679)	grad_norm 0.2586 (0.2566)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:44:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2000/2502]	eta 0:01:45 lr 0.000091	 wd 0.0000	time 0.0947 (0.2109)	loss 0.9434 (0.8684)	grad_norm 0.2639 (0.2567)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:45:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2100/2502]	eta 0:01:24 lr 0.000091	 wd 0.0000	time 0.1770 (0.2093)	loss 0.9702 (0.8679)	grad_norm 0.2601 (0.2567)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:45:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2200/2502]	eta 0:01:02 lr 0.000091	 wd 0.0000	time 0.1542 (0.2074)	loss 0.9702 (0.8680)	grad_norm 0.2602 (0.2568)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:45:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2300/2502]	eta 0:00:41 lr 0.000091	 wd 0.0000	time 0.1462 (0.2056)	loss 0.7378 (0.8677)	grad_norm 0.2694 (0.2568)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:46:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2400/2502]	eta 0:00:20 lr 0.000091	 wd 0.0000	time 0.2578 (0.2042)	loss 0.7764 (0.8674)	grad_norm 0.2655 (0.2568)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:46:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [5/30][2500/2502]	eta 0:00:00 lr 0.000091	 wd 0.0000	time 0.0813 (0.2022)	loss 0.7549 (0.8670)	grad_norm 0.2524 (0.2569)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:46:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 5 training takes 0:08:33
[2024-07-30 19:46:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 27.847 (27.847)	Loss 0.3562 (0.3562)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 3061MB
[2024-07-30 19:47:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.244 Acc@5 97.616
[2024-07-30 19:47:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 19:47:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 19:47:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][0/2502]	eta 11:36:15 lr 0.000091	 wd 0.0000	time 16.6970 (16.6970)	loss 0.9204 (0.9204)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:47:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][100/2502]	eta 0:12:59 lr 0.000090	 wd 0.0000	time 0.2160 (0.3244)	loss 0.8691 (0.8781)	grad_norm 0.2706 (0.2570)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:48:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][200/2502]	eta 0:13:34 lr 0.000090	 wd 0.0000	time 0.1289 (0.3540)	loss 0.7896 (0.8715)	grad_norm 0.2567 (0.2566)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:48:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][300/2502]	eta 0:10:32 lr 0.000090	 wd 0.0000	time 0.1389 (0.2870)	loss 0.8667 (0.8711)	grad_norm 0.2561 (0.2570)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:48:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][400/2502]	eta 0:08:54 lr 0.000090	 wd 0.0000	time 0.1542 (0.2543)	loss 0.8457 (0.8697)	grad_norm 0.2520 (0.2571)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:49:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][500/2502]	eta 0:07:47 lr 0.000090	 wd 0.0000	time 0.1802 (0.2337)	loss 0.8940 (0.8692)	grad_norm 0.2472 (0.2571)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:49:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][600/2502]	eta 0:07:05 lr 0.000090	 wd 0.0000	time 0.1770 (0.2237)	loss 0.8975 (0.8687)	grad_norm 0.2668 (0.2573)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:49:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][700/2502]	eta 0:07:26 lr 0.000090	 wd 0.0000	time 0.1903 (0.2476)	loss 0.9849 (0.8686)	grad_norm 0.2594 (0.2575)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:50:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][800/2502]	eta 0:06:41 lr 0.000090	 wd 0.0000	time 0.1078 (0.2357)	loss 0.7153 (0.8689)	grad_norm 0.2555 (0.2574)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:50:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][900/2502]	eta 0:06:03 lr 0.000089	 wd 0.0000	time 0.1883 (0.2269)	loss 0.8652 (0.8684)	grad_norm 0.2456 (0.2574)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:50:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1000/2502]	eta 0:05:29 lr 0.000089	 wd 0.0000	time 0.1385 (0.2195)	loss 0.8242 (0.8694)	grad_norm 0.2518 (nan)	loss_scale 32768.0000 (32833.4705)	mem 3061MB
[2024-07-30 19:51:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1100/2502]	eta 0:05:03 lr 0.000089	 wd 0.0000	time 0.1690 (0.2165)	loss 0.7988 (0.8682)	grad_norm 0.2582 (nan)	loss_scale 32768.0000 (32827.5241)	mem 3061MB
[2024-07-30 19:51:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1200/2502]	eta 0:04:39 lr 0.000089	 wd 0.0000	time 0.2015 (0.2144)	loss 0.8389 (0.8683)	grad_norm 0.2516 (nan)	loss_scale 32768.0000 (32822.5679)	mem 3061MB
[2024-07-30 19:51:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1300/2502]	eta 0:04:12 lr 0.000089	 wd 0.0000	time 0.1703 (0.2101)	loss 0.7705 (0.8676)	grad_norm 0.2555 (nan)	loss_scale 32768.0000 (32818.3736)	mem 3061MB
[2024-07-30 19:51:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1400/2502]	eta 0:03:47 lr 0.000089	 wd 0.0000	time 0.1244 (0.2063)	loss 0.8818 (0.8672)	grad_norm 0.2571 (nan)	loss_scale 32768.0000 (32814.7780)	mem 3061MB
[2024-07-30 19:52:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1500/2502]	eta 0:03:23 lr 0.000089	 wd 0.0000	time 0.1281 (0.2031)	loss 0.7739 (0.8671)	grad_norm 0.2568 (nan)	loss_scale 32768.0000 (32811.6616)	mem 3061MB
[2024-07-30 19:52:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1600/2502]	eta 0:03:01 lr 0.000089	 wd 0.0000	time 0.1938 (0.2007)	loss 0.7734 (0.8667)	grad_norm 0.2473 (nan)	loss_scale 32768.0000 (32808.9344)	mem 3061MB
[2024-07-30 19:52:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1700/2502]	eta 0:02:46 lr 0.000088	 wd 0.0000	time 0.1671 (0.2078)	loss 0.8369 (0.8655)	grad_norm 0.2424 (nan)	loss_scale 32768.0000 (32806.5279)	mem 3061MB
[2024-07-30 19:53:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1800/2502]	eta 0:02:24 lr 0.000088	 wd 0.0000	time 0.1921 (0.2054)	loss 0.8066 (0.8653)	grad_norm 0.2598 (nan)	loss_scale 32768.0000 (32804.3887)	mem 3061MB
[2024-07-30 19:53:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][1900/2502]	eta 0:02:02 lr 0.000088	 wd 0.0000	time 0.1588 (0.2031)	loss 0.8857 (0.8658)	grad_norm 0.2581 (nan)	loss_scale 32768.0000 (32802.4745)	mem 3061MB
[2024-07-30 19:53:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2000/2502]	eta 0:01:40 lr 0.000088	 wd 0.0000	time 0.1080 (0.2012)	loss 0.9170 (0.8664)	grad_norm 0.2637 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 19:54:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2100/2502]	eta 0:01:20 lr 0.000088	 wd 0.0000	time 0.1573 (0.1997)	loss 0.7852 (0.8664)	grad_norm 0.2577 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 19:54:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2200/2502]	eta 0:01:00 lr 0.000088	 wd 0.0000	time 0.2080 (0.1994)	loss 0.8657 (0.8658)	grad_norm 0.2635 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 19:54:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2300/2502]	eta 0:00:40 lr 0.000088	 wd 0.0000	time 0.1796 (0.1995)	loss 0.8213 (0.8658)	grad_norm 0.2626 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 19:55:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2400/2502]	eta 0:00:20 lr 0.000087	 wd 0.0000	time 0.1269 (0.1980)	loss 0.8623 (0.8665)	grad_norm 0.2506 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 19:55:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [6/30][2500/2502]	eta 0:00:00 lr 0.000087	 wd 0.0000	time 0.0813 (0.1948)	loss 0.7617 (0.8670)	grad_norm 0.2629 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 19:55:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 6 training takes 0:08:11
[2024-07-30 19:55:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 18.379 (18.379)	Loss 0.3601 (0.3601)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 19:55:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.246 Acc@5 97.608
[2024-07-30 19:55:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 19:55:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 19:56:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][0/2502]	eta 1 day, 2:08:01 lr 0.000087	 wd 0.0000	time 37.6026 (37.6026)	loss 0.8271 (0.8271)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:56:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][100/2502]	eta 0:21:14 lr 0.000087	 wd 0.0000	time 0.1753 (0.5305)	loss 0.9565 (0.8651)	grad_norm 0.2570 (0.2589)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:56:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][200/2502]	eta 0:13:08 lr 0.000087	 wd 0.0000	time 0.1651 (0.3427)	loss 0.8569 (0.8632)	grad_norm 0.2500 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:57:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][300/2502]	eta 0:10:11 lr 0.000087	 wd 0.0000	time 0.1316 (0.2779)	loss 0.8174 (0.8608)	grad_norm 0.2611 (0.2585)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:57:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][400/2502]	eta 0:10:37 lr 0.000087	 wd 0.0000	time 0.1313 (0.3033)	loss 0.8750 (0.8653)	grad_norm 0.2796 (0.2585)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:58:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][500/2502]	eta 0:09:16 lr 0.000087	 wd 0.0000	time 0.1500 (0.2780)	loss 0.7622 (0.8630)	grad_norm 0.2386 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:58:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][600/2502]	eta 0:08:09 lr 0.000086	 wd 0.0000	time 0.1966 (0.2575)	loss 0.9810 (0.8651)	grad_norm 0.2436 (0.2583)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:58:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][700/2502]	eta 0:07:17 lr 0.000086	 wd 0.0000	time 0.1519 (0.2425)	loss 0.7891 (0.8649)	grad_norm 0.2403 (0.2584)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:58:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][800/2502]	eta 0:06:34 lr 0.000086	 wd 0.0000	time 0.2393 (0.2318)	loss 0.8149 (0.8640)	grad_norm 0.2518 (0.2585)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:59:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][900/2502]	eta 0:06:29 lr 0.000086	 wd 0.0000	time 0.3104 (0.2431)	loss 0.8335 (0.8649)	grad_norm 0.2573 (0.2586)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 19:59:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1000/2502]	eta 0:05:55 lr 0.000086	 wd 0.0000	time 0.1212 (0.2369)	loss 0.7593 (0.8648)	grad_norm 0.2728 (0.2585)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:00:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1100/2502]	eta 0:05:21 lr 0.000086	 wd 0.0000	time 0.1475 (0.2294)	loss 0.7734 (0.8643)	grad_norm 0.2576 (0.2586)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:00:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1200/2502]	eta 0:04:50 lr 0.000086	 wd 0.0000	time 0.1737 (0.2231)	loss 0.9009 (0.8637)	grad_norm 0.2625 (0.2585)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:00:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1300/2502]	eta 0:04:22 lr 0.000085	 wd 0.0000	time 0.2031 (0.2184)	loss 0.9053 (0.8633)	grad_norm 0.2480 (0.2585)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:01:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1400/2502]	eta 0:04:08 lr 0.000085	 wd 0.0000	time 0.4812 (0.2251)	loss 0.7700 (0.8636)	grad_norm 0.2563 (0.2586)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:01:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1500/2502]	eta 0:03:42 lr 0.000085	 wd 0.0000	time 0.1845 (0.2217)	loss 0.8320 (0.8634)	grad_norm 0.2618 (0.2586)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:01:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1600/2502]	eta 0:03:16 lr 0.000085	 wd 0.0000	time 0.1455 (0.2177)	loss 0.8779 (0.8632)	grad_norm 0.2575 (0.2585)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:01:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1700/2502]	eta 0:02:51 lr 0.000085	 wd 0.0000	time 0.1515 (0.2143)	loss 0.9883 (0.8629)	grad_norm 0.2551 (0.2585)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:02:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1800/2502]	eta 0:02:28 lr 0.000085	 wd 0.0000	time 0.1695 (0.2115)	loss 0.8325 (0.8630)	grad_norm 0.2585 (0.2586)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:02:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][1900/2502]	eta 0:02:06 lr 0.000085	 wd 0.0000	time 0.1775 (0.2107)	loss 0.9092 (0.8630)	grad_norm 0.2589 (0.2587)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:02:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2000/2502]	eta 0:01:45 lr 0.000084	 wd 0.0000	time 0.2763 (0.2106)	loss 0.8208 (0.8626)	grad_norm 0.2648 (0.2587)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:03:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2100/2502]	eta 0:01:23 lr 0.000084	 wd 0.0000	time 0.2507 (0.2085)	loss 1.0049 (0.8636)	grad_norm 0.2731 (0.2588)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:03:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2200/2502]	eta 0:01:02 lr 0.000084	 wd 0.0000	time 0.0984 (0.2065)	loss 0.6899 (0.8629)	grad_norm 0.2737 (0.2589)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:03:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2300/2502]	eta 0:00:41 lr 0.000084	 wd 0.0000	time 0.1772 (0.2048)	loss 0.9453 (0.8630)	grad_norm 0.2607 (0.2589)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:03:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2400/2502]	eta 0:00:20 lr 0.000084	 wd 0.0000	time 0.1855 (0.2043)	loss 0.9409 (0.8633)	grad_norm 0.2668 (0.2589)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:04:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [7/30][2500/2502]	eta 0:00:00 lr 0.000084	 wd 0.0000	time 0.0816 (0.2037)	loss 0.8662 (0.8638)	grad_norm 0.2713 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 20:04:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 7 training takes 0:08:34
[2024-07-30 20:04:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.690 (19.690)	Loss 0.3550 (0.3550)	Acc@1 92.383 (92.383)	Acc@5 98.633 (98.633)	Mem 3061MB
[2024-07-30 20:04:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.234 Acc@5 97.656
[2024-07-30 20:04:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 20:04:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 20:05:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][0/2502]	eta 12:04:56 lr 0.000084	 wd 0.0000	time 17.3845 (17.3845)	loss 0.7896 (0.7896)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:05:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][100/2502]	eta 0:13:52 lr 0.000083	 wd 0.0000	time 0.3066 (0.3467)	loss 0.8521 (0.8682)	grad_norm 0.2569 (0.2600)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:06:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][200/2502]	eta 0:13:25 lr 0.000083	 wd 0.0000	time 0.1498 (0.3498)	loss 0.8555 (0.8665)	grad_norm 0.2601 (0.2598)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:06:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][300/2502]	eta 0:10:24 lr 0.000083	 wd 0.0000	time 0.1442 (0.2836)	loss 0.8442 (0.8628)	grad_norm 0.2661 (0.2595)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:06:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][400/2502]	eta 0:08:48 lr 0.000083	 wd 0.0000	time 0.1336 (0.2514)	loss 0.9541 (0.8641)	grad_norm 0.2603 (0.2592)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:06:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][500/2502]	eta 0:07:42 lr 0.000083	 wd 0.0000	time 0.1323 (0.2312)	loss 0.8091 (0.8651)	grad_norm 0.2656 (0.2595)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:07:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][600/2502]	eta 0:07:02 lr 0.000083	 wd 0.0000	time 0.2929 (0.2223)	loss 0.8540 (0.8647)	grad_norm 0.2718 (0.2593)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:07:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][700/2502]	eta 0:07:21 lr 0.000083	 wd 0.0000	time 0.0974 (0.2453)	loss 0.8789 (0.8641)	grad_norm 0.2665 (0.2594)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:08:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][800/2502]	eta 0:06:37 lr 0.000082	 wd 0.0000	time 0.1162 (0.2337)	loss 0.7388 (0.8635)	grad_norm 0.2547 (0.2593)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:08:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][900/2502]	eta 0:06:00 lr 0.000082	 wd 0.0000	time 0.1662 (0.2250)	loss 0.9810 (0.8645)	grad_norm 0.2537 (0.2594)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:08:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1000/2502]	eta 0:05:26 lr 0.000082	 wd 0.0000	time 0.2081 (0.2177)	loss 0.9990 (0.8653)	grad_norm 0.2564 (0.2595)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:08:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1100/2502]	eta 0:05:04 lr 0.000082	 wd 0.0000	time 0.2786 (0.2172)	loss 0.9639 (0.8650)	grad_norm 0.2625 (0.2596)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:09:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1200/2502]	eta 0:04:49 lr 0.000082	 wd 0.0000	time 0.1024 (0.2223)	loss 0.8184 (0.8648)	grad_norm 0.2576 (0.2595)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:09:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1300/2502]	eta 0:04:20 lr 0.000082	 wd 0.0000	time 0.1641 (0.2170)	loss 0.8154 (0.8650)	grad_norm 0.2631 (0.2596)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:09:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1400/2502]	eta 0:03:54 lr 0.000081	 wd 0.0000	time 0.1361 (0.2125)	loss 0.8145 (0.8649)	grad_norm 0.2609 (0.2596)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:10:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1500/2502]	eta 0:03:29 lr 0.000081	 wd 0.0000	time 0.1621 (0.2089)	loss 0.8521 (0.8648)	grad_norm 0.2683 (0.2597)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:10:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1600/2502]	eta 0:03:07 lr 0.000081	 wd 0.0000	time 0.1848 (0.2077)	loss 0.9658 (0.8643)	grad_norm 0.2538 (0.2597)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:10:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1700/2502]	eta 0:02:47 lr 0.000081	 wd 0.0000	time 0.1553 (0.2084)	loss 0.8457 (0.8650)	grad_norm 0.2529 (0.2598)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:11:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1800/2502]	eta 0:02:24 lr 0.000081	 wd 0.0000	time 0.0990 (0.2059)	loss 0.8535 (0.8656)	grad_norm 0.2648 (0.2599)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:11:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][1900/2502]	eta 0:02:02 lr 0.000081	 wd 0.0000	time 0.1489 (0.2039)	loss 0.7749 (0.8651)	grad_norm 0.2467 (0.2599)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:11:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2000/2502]	eta 0:01:41 lr 0.000080	 wd 0.0000	time 0.1289 (0.2019)	loss 0.7910 (0.8651)	grad_norm 0.2761 (0.2599)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:11:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2100/2502]	eta 0:01:20 lr 0.000080	 wd 0.0000	time 0.1801 (0.2007)	loss 0.8657 (0.8654)	grad_norm 0.2567 (0.2600)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:12:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2200/2502]	eta 0:01:00 lr 0.000080	 wd 0.0000	time 0.1282 (0.2019)	loss 0.8091 (0.8649)	grad_norm 0.2620 (0.2601)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:12:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2300/2502]	eta 0:00:40 lr 0.000080	 wd 0.0000	time 0.1469 (0.2004)	loss 0.9609 (0.8648)	grad_norm 0.2561 (0.2601)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:12:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2400/2502]	eta 0:00:20 lr 0.000080	 wd 0.0000	time 0.1559 (0.1988)	loss 0.9668 (0.8647)	grad_norm 0.2668 (0.2602)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:13:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [8/30][2500/2502]	eta 0:00:00 lr 0.000080	 wd 0.0000	time 0.0830 (0.1956)	loss 0.8896 (0.8648)	grad_norm 0.2582 (0.2603)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:13:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 8 training takes 0:08:13
[2024-07-30 20:13:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 20.009 (20.009)	Loss 0.3594 (0.3594)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 20:13:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.232 Acc@5 97.626
[2024-07-30 20:13:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 20:13:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 20:14:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][0/2502]	eta 23:18:17 lr 0.000080	 wd 0.0000	time 33.5320 (33.5320)	loss 0.8379 (0.8379)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:14:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][100/2502]	eta 0:19:15 lr 0.000079	 wd 0.0000	time 0.1509 (0.4811)	loss 0.9463 (0.8606)	grad_norm 0.2660 (0.2608)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:14:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][200/2502]	eta 0:12:14 lr 0.000079	 wd 0.0000	time 0.1668 (0.3192)	loss 0.7290 (0.8586)	grad_norm 0.2529 (0.2606)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:15:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][300/2502]	eta 0:09:41 lr 0.000079	 wd 0.0000	time 0.2130 (0.2641)	loss 0.9204 (0.8601)	grad_norm 0.2572 (0.2609)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:15:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][400/2502]	eta 0:10:44 lr 0.000079	 wd 0.0000	time 0.1536 (0.3067)	loss 0.8477 (0.8598)	grad_norm 0.2501 (0.2608)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:16:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][500/2502]	eta 0:09:13 lr 0.000079	 wd 0.0000	time 0.1565 (0.2764)	loss 0.6660 (0.8647)	grad_norm 0.2692 (0.2610)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:16:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][600/2502]	eta 0:08:07 lr 0.000079	 wd 0.0000	time 0.1016 (0.2564)	loss 0.7080 (0.8622)	grad_norm 0.2607 (0.2609)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:16:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][700/2502]	eta 0:07:14 lr 0.000078	 wd 0.0000	time 0.1416 (0.2410)	loss 0.9424 (0.8630)	grad_norm 0.2661 (0.2610)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:16:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][800/2502]	eta 0:06:36 lr 0.000078	 wd 0.0000	time 0.1958 (0.2330)	loss 0.8989 (0.8640)	grad_norm 0.2484 (0.2610)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:17:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][900/2502]	eta 0:06:33 lr 0.000078	 wd 0.0000	time 0.1349 (0.2456)	loss 1.0137 (0.8645)	grad_norm 0.2608 (0.2610)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:17:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1000/2502]	eta 0:05:55 lr 0.000078	 wd 0.0000	time 0.1342 (0.2364)	loss 0.9541 (0.8649)	grad_norm 0.2593 (0.2610)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:17:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1100/2502]	eta 0:05:21 lr 0.000078	 wd 0.0000	time 0.0918 (0.2290)	loss 0.7842 (0.8648)	grad_norm 0.2664 (0.2610)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:18:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1200/2502]	eta 0:04:49 lr 0.000078	 wd 0.0000	time 0.1877 (0.2226)	loss 0.9346 (0.8647)	grad_norm 0.2685 (0.2611)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:18:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1300/2502]	eta 0:04:22 lr 0.000077	 wd 0.0000	time 0.1853 (0.2186)	loss 0.9365 (0.8651)	grad_norm 0.2556 (0.2610)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:18:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1400/2502]	eta 0:03:59 lr 0.000077	 wd 0.0000	time 0.1779 (0.2175)	loss 0.8481 (0.8653)	grad_norm 0.2521 (0.2610)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:19:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1500/2502]	eta 0:03:34 lr 0.000077	 wd 0.0000	time 0.1319 (0.2139)	loss 0.9106 (0.8655)	grad_norm 0.2613 (nan)	loss_scale 32768.0000 (32811.6616)	mem 3061MB
[2024-07-30 20:19:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1600/2502]	eta 0:03:09 lr 0.000077	 wd 0.0000	time 0.1567 (0.2104)	loss 0.8706 (0.8650)	grad_norm 0.2547 (nan)	loss_scale 32768.0000 (32808.9344)	mem 3061MB
[2024-07-30 20:19:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1700/2502]	eta 0:02:46 lr 0.000077	 wd 0.0000	time 0.1351 (0.2073)	loss 0.7969 (0.8658)	grad_norm 0.2515 (nan)	loss_scale 32768.0000 (32806.5279)	mem 3061MB
[2024-07-30 20:19:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1800/2502]	eta 0:02:23 lr 0.000077	 wd 0.0000	time 0.1887 (0.2047)	loss 0.7017 (0.8657)	grad_norm 0.2685 (nan)	loss_scale 32768.0000 (32804.3887)	mem 3061MB
[2024-07-30 20:20:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][1900/2502]	eta 0:02:02 lr 0.000076	 wd 0.0000	time 0.2819 (0.2040)	loss 0.8955 (0.8659)	grad_norm 0.2557 (nan)	loss_scale 32768.0000 (32802.4745)	mem 3061MB
[2024-07-30 20:20:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2000/2502]	eta 0:01:42 lr 0.000076	 wd 0.0000	time 0.1643 (0.2048)	loss 0.9067 (0.8668)	grad_norm 0.2529 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 20:20:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2100/2502]	eta 0:01:21 lr 0.000076	 wd 0.0000	time 0.1860 (0.2030)	loss 1.0039 (0.8672)	grad_norm 0.2543 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 20:21:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2200/2502]	eta 0:01:00 lr 0.000076	 wd 0.0000	time 0.0986 (0.2014)	loss 0.8989 (0.8675)	grad_norm 0.2624 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 20:21:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2300/2502]	eta 0:00:40 lr 0.000076	 wd 0.0000	time 0.1124 (0.1997)	loss 0.8462 (0.8671)	grad_norm 0.2769 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 20:21:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2400/2502]	eta 0:00:20 lr 0.000075	 wd 0.0000	time 0.3448 (0.1991)	loss 0.8223 (0.8671)	grad_norm 0.2650 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 20:21:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [9/30][2500/2502]	eta 0:00:00 lr 0.000075	 wd 0.0000	time 0.0814 (0.1964)	loss 0.8535 (0.8672)	grad_norm 0.2534 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 20:22:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 9 training takes 0:08:19
[2024-07-30 20:22:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 22.751 (22.751)	Loss 0.3562 (0.3562)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 20:22:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.226 Acc@5 97.628
[2024-07-30 20:22:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.2%
[2024-07-30 20:22:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 20:22:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][0/2502]	eta 12:48:53 lr 0.000075	 wd 0.0000	time 18.4388 (18.4388)	loss 1.0117 (1.0117)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:23:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][100/2502]	eta 0:13:40 lr 0.000075	 wd 0.0000	time 0.2123 (0.3418)	loss 0.7104 (0.8786)	grad_norm 0.2712 (0.2626)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:23:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][200/2502]	eta 0:14:22 lr 0.000075	 wd 0.0000	time 0.1400 (0.3745)	loss 0.9463 (0.8708)	grad_norm 0.2723 (0.2621)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:24:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][300/2502]	eta 0:11:03 lr 0.000075	 wd 0.0000	time 0.1805 (0.3012)	loss 0.8477 (0.8670)	grad_norm 0.2524 (0.2622)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:24:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][400/2502]	eta 0:09:14 lr 0.000075	 wd 0.0000	time 0.1000 (0.2638)	loss 0.9028 (0.8658)	grad_norm 0.2619 (0.2620)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:24:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][500/2502]	eta 0:08:01 lr 0.000074	 wd 0.0000	time 0.1195 (0.2407)	loss 0.7573 (0.8671)	grad_norm 0.2687 (0.2622)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:24:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][600/2502]	eta 0:07:18 lr 0.000074	 wd 0.0000	time 0.1926 (0.2304)	loss 0.9258 (0.8661)	grad_norm 0.2598 (0.2620)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:25:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][700/2502]	eta 0:07:23 lr 0.000074	 wd 0.0000	time 0.1064 (0.2460)	loss 0.7920 (0.8647)	grad_norm 0.2557 (0.2621)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:25:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][800/2502]	eta 0:06:39 lr 0.000074	 wd 0.0000	time 0.1167 (0.2344)	loss 0.8608 (0.8652)	grad_norm 0.2581 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:25:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][900/2502]	eta 0:06:01 lr 0.000074	 wd 0.0000	time 0.2135 (0.2258)	loss 0.8203 (0.8659)	grad_norm 0.2608 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:26:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1000/2502]	eta 0:05:27 lr 0.000073	 wd 0.0000	time 0.1471 (0.2179)	loss 0.8135 (0.8659)	grad_norm 0.2594 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:26:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1100/2502]	eta 0:04:59 lr 0.000073	 wd 0.0000	time 0.2717 (0.2138)	loss 0.7856 (0.8658)	grad_norm 0.2602 (0.2622)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:27:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1200/2502]	eta 0:04:47 lr 0.000073	 wd 0.0000	time 0.1906 (0.2208)	loss 0.9810 (0.8655)	grad_norm 0.2604 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:27:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1300/2502]	eta 0:04:19 lr 0.000073	 wd 0.0000	time 0.1214 (0.2157)	loss 0.8867 (0.8656)	grad_norm 0.2619 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:27:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1400/2502]	eta 0:03:52 lr 0.000073	 wd 0.0000	time 0.1515 (0.2113)	loss 0.7764 (0.8654)	grad_norm 0.2808 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:27:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1500/2502]	eta 0:03:27 lr 0.000073	 wd 0.0000	time 0.1680 (0.2074)	loss 0.8521 (0.8652)	grad_norm 0.2580 (0.2622)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:28:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1600/2502]	eta 0:03:04 lr 0.000072	 wd 0.0000	time 0.1771 (0.2050)	loss 0.7666 (0.8655)	grad_norm 0.2556 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:28:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1700/2502]	eta 0:02:45 lr 0.000072	 wd 0.0000	time 0.3256 (0.2064)	loss 0.8945 (0.8658)	grad_norm 0.2599 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:28:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1800/2502]	eta 0:02:23 lr 0.000072	 wd 0.0000	time 0.1575 (0.2044)	loss 0.9351 (0.8656)	grad_norm 0.2772 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:29:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][1900/2502]	eta 0:02:01 lr 0.000072	 wd 0.0000	time 0.1492 (0.2022)	loss 0.9360 (0.8655)	grad_norm 0.2696 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:29:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2000/2502]	eta 0:01:40 lr 0.000072	 wd 0.0000	time 0.1316 (0.2004)	loss 0.8735 (0.8660)	grad_norm 0.2649 (0.2625)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:29:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2100/2502]	eta 0:01:19 lr 0.000071	 wd 0.0000	time 0.1422 (0.1986)	loss 0.8623 (0.8659)	grad_norm 0.2710 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:29:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2200/2502]	eta 0:00:59 lr 0.000071	 wd 0.0000	time 0.1820 (0.1980)	loss 0.8740 (0.8664)	grad_norm 0.2590 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:30:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2300/2502]	eta 0:00:39 lr 0.000071	 wd 0.0000	time 0.1840 (0.1980)	loss 0.9087 (0.8660)	grad_norm 0.2596 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:30:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2400/2502]	eta 0:00:20 lr 0.000071	 wd 0.0000	time 0.1615 (0.1967)	loss 0.8652 (0.8664)	grad_norm 0.2537 (0.2624)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:30:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [10/30][2500/2502]	eta 0:00:00 lr 0.000071	 wd 0.0000	time 0.0813 (0.1935)	loss 0.9873 (0.8659)	grad_norm 0.2650 (0.2625)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:30:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 10 training takes 0:08:10
[2024-07-30 20:31:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.788 (19.788)	Loss 0.3608 (0.3608)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 20:31:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.264 Acc@5 97.634
[2024-07-30 20:31:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 20:31:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 20:31:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][0/2502]	eta 1 day, 0:40:50 lr 0.000071	 wd 0.0000	time 35.5116 (35.5116)	loss 0.7822 (0.7822)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:32:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][100/2502]	eta 0:20:24 lr 0.000070	 wd 0.0000	time 0.1605 (0.5099)	loss 0.8643 (0.8605)	grad_norm 0.2589 (0.2630)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:32:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][200/2502]	eta 0:12:42 lr 0.000070	 wd 0.0000	time 0.1119 (0.3311)	loss 0.8882 (0.8630)	grad_norm 0.2603 (0.2623)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:32:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][300/2502]	eta 0:09:56 lr 0.000070	 wd 0.0000	time 0.1323 (0.2710)	loss 0.9727 (0.8641)	grad_norm 0.2646 (0.2627)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:33:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][400/2502]	eta 0:09:02 lr 0.000070	 wd 0.0000	time 0.4774 (0.2582)	loss 0.9253 (0.8622)	grad_norm 0.2711 (0.2629)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:33:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][500/2502]	eta 0:08:54 lr 0.000070	 wd 0.0000	time 0.2024 (0.2667)	loss 0.7769 (0.8619)	grad_norm 0.2561 (nan)	loss_scale 32768.0000 (32898.8104)	mem 3061MB
[2024-07-30 20:33:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][600/2502]	eta 0:07:50 lr 0.000069	 wd 0.0000	time 0.1259 (0.2476)	loss 1.0498 (0.8603)	grad_norm 0.2613 (nan)	loss_scale 32768.0000 (32877.0449)	mem 3061MB
[2024-07-30 20:34:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][700/2502]	eta 0:07:02 lr 0.000069	 wd 0.0000	time 0.1460 (0.2342)	loss 0.8540 (0.8627)	grad_norm 0.2679 (nan)	loss_scale 32768.0000 (32861.4893)	mem 3061MB
[2024-07-30 20:34:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][800/2502]	eta 0:06:20 lr 0.000069	 wd 0.0000	time 0.0912 (0.2237)	loss 0.8906 (0.8636)	grad_norm 0.2640 (nan)	loss_scale 32768.0000 (32849.8177)	mem 3061MB
[2024-07-30 20:34:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][900/2502]	eta 0:05:56 lr 0.000069	 wd 0.0000	time 0.4231 (0.2226)	loss 0.9717 (0.8638)	grad_norm 0.2678 (nan)	loss_scale 32768.0000 (32840.7370)	mem 3061MB
[2024-07-30 20:35:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1000/2502]	eta 0:05:51 lr 0.000069	 wd 0.0000	time 0.1289 (0.2338)	loss 0.8086 (0.8650)	grad_norm 0.2671 (nan)	loss_scale 32768.0000 (32833.4705)	mem 3061MB
[2024-07-30 20:35:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1100/2502]	eta 0:05:17 lr 0.000069	 wd 0.0000	time 0.1822 (0.2264)	loss 0.7935 (0.8654)	grad_norm 0.2614 (nan)	loss_scale 32768.0000 (32827.5241)	mem 3061MB
[2024-07-30 20:35:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1200/2502]	eta 0:04:46 lr 0.000068	 wd 0.0000	time 0.1225 (0.2204)	loss 0.9351 (0.8658)	grad_norm 0.2660 (nan)	loss_scale 32768.0000 (32822.5679)	mem 3061MB
[2024-07-30 20:36:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1300/2502]	eta 0:04:18 lr 0.000068	 wd 0.0000	time 0.1570 (0.2153)	loss 0.7358 (0.8659)	grad_norm 0.2606 (nan)	loss_scale 32768.0000 (32818.3736)	mem 3061MB
[2024-07-30 20:36:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1400/2502]	eta 0:03:56 lr 0.000068	 wd 0.0000	time 0.3288 (0.2145)	loss 0.8306 (0.8665)	grad_norm 0.2699 (nan)	loss_scale 32768.0000 (32814.7780)	mem 3061MB
[2024-07-30 20:36:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1500/2502]	eta 0:03:38 lr 0.000068	 wd 0.0000	time 0.1431 (0.2179)	loss 0.9395 (0.8663)	grad_norm 0.2593 (nan)	loss_scale 32768.0000 (32811.6616)	mem 3061MB
[2024-07-30 20:37:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1600/2502]	eta 0:03:13 lr 0.000068	 wd 0.0000	time 0.1471 (0.2141)	loss 0.9204 (0.8664)	grad_norm 0.2821 (nan)	loss_scale 32768.0000 (32808.9344)	mem 3061MB
[2024-07-30 20:37:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1700/2502]	eta 0:02:48 lr 0.000067	 wd 0.0000	time 0.1376 (0.2107)	loss 0.7861 (0.8667)	grad_norm 0.2653 (nan)	loss_scale 32768.0000 (32806.5279)	mem 3061MB
[2024-07-30 20:37:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1800/2502]	eta 0:02:25 lr 0.000067	 wd 0.0000	time 0.1135 (0.2079)	loss 1.0977 (0.8675)	grad_norm 0.2635 (nan)	loss_scale 32768.0000 (32804.3887)	mem 3061MB
[2024-07-30 20:37:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][1900/2502]	eta 0:02:04 lr 0.000067	 wd 0.0000	time 0.1482 (0.2070)	loss 0.7544 (0.8679)	grad_norm 0.2564 (nan)	loss_scale 32768.0000 (32802.4745)	mem 3061MB
[2024-07-30 20:38:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2000/2502]	eta 0:01:44 lr 0.000067	 wd 0.0000	time 0.1243 (0.2076)	loss 0.9023 (0.8675)	grad_norm 0.2616 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 20:38:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2100/2502]	eta 0:01:22 lr 0.000067	 wd 0.0000	time 0.1553 (0.2057)	loss 0.8545 (0.8673)	grad_norm 0.2749 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 20:38:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2200/2502]	eta 0:01:01 lr 0.000066	 wd 0.0000	time 0.1731 (0.2038)	loss 0.8833 (0.8673)	grad_norm 0.2648 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 20:39:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2300/2502]	eta 0:00:40 lr 0.000066	 wd 0.0000	time 0.1306 (0.2021)	loss 0.8374 (0.8673)	grad_norm 0.2624 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 20:39:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2400/2502]	eta 0:00:20 lr 0.000066	 wd 0.0000	time 0.1744 (0.2009)	loss 0.8745 (0.8677)	grad_norm 0.2626 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 20:39:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [11/30][2500/2502]	eta 0:00:00 lr 0.000066	 wd 0.0000	time 0.0820 (0.1981)	loss 1.0381 (0.8670)	grad_norm 0.2627 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 20:39:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 11 training takes 0:08:20
[2024-07-30 20:40:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 23.355 (23.355)	Loss 0.3579 (0.3579)	Acc@1 91.797 (91.797)	Acc@5 98.633 (98.633)	Mem 3061MB
[2024-07-30 20:40:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.276 Acc@5 97.636
[2024-07-30 20:40:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 20:40:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 20:40:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][0/2502]	eta 11:00:38 lr 0.000066	 wd 0.0000	time 15.8427 (15.8427)	loss 0.8872 (0.8872)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:40:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][100/2502]	eta 0:12:46 lr 0.000066	 wd 0.0000	time 0.1253 (0.3190)	loss 0.8145 (0.8555)	grad_norm 0.2705 (0.2647)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:41:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][200/2502]	eta 0:13:03 lr 0.000065	 wd 0.0000	time 0.2141 (0.3403)	loss 0.8413 (0.8614)	grad_norm 0.2602 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:41:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][300/2502]	eta 0:10:21 lr 0.000065	 wd 0.0000	time 0.1806 (0.2822)	loss 0.8970 (0.8708)	grad_norm 0.2731 (0.2641)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:42:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][400/2502]	eta 0:08:44 lr 0.000065	 wd 0.0000	time 0.1464 (0.2496)	loss 0.8262 (0.8724)	grad_norm 0.2595 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:42:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][500/2502]	eta 0:07:39 lr 0.000065	 wd 0.0000	time 0.1390 (0.2298)	loss 0.7485 (0.8711)	grad_norm 0.2634 (0.2639)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:42:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][600/2502]	eta 0:06:53 lr 0.000065	 wd 0.0000	time 0.1567 (0.2173)	loss 0.7729 (0.8712)	grad_norm 0.2644 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:43:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][700/2502]	eta 0:07:05 lr 0.000064	 wd 0.0000	time 0.1023 (0.2361)	loss 0.8018 (0.8709)	grad_norm 0.2613 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:43:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][800/2502]	eta 0:06:25 lr 0.000064	 wd 0.0000	time 0.1226 (0.2264)	loss 0.8901 (0.8695)	grad_norm 0.2539 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:43:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][900/2502]	eta 0:05:49 lr 0.000064	 wd 0.0000	time 0.1278 (0.2183)	loss 0.7930 (0.8690)	grad_norm 0.2682 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:43:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1000/2502]	eta 0:05:17 lr 0.000064	 wd 0.0000	time 0.1266 (0.2115)	loss 0.9043 (0.8690)	grad_norm 0.2618 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:44:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1100/2502]	eta 0:04:49 lr 0.000064	 wd 0.0000	time 0.1480 (0.2063)	loss 0.7437 (0.8691)	grad_norm 0.2527 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:44:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1200/2502]	eta 0:04:41 lr 0.000063	 wd 0.0000	time 0.2956 (0.2164)	loss 0.8804 (0.8684)	grad_norm 0.2696 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:45:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1300/2502]	eta 0:04:15 lr 0.000063	 wd 0.0000	time 0.1596 (0.2124)	loss 0.7871 (0.8686)	grad_norm 0.2736 (0.2641)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:45:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1400/2502]	eta 0:03:49 lr 0.000063	 wd 0.0000	time 0.2139 (0.2084)	loss 0.9253 (0.8689)	grad_norm 0.2694 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:45:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1500/2502]	eta 0:03:25 lr 0.000063	 wd 0.0000	time 0.0981 (0.2046)	loss 0.8447 (0.8697)	grad_norm 0.2592 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:45:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1600/2502]	eta 0:03:02 lr 0.000063	 wd 0.0000	time 0.1864 (0.2020)	loss 0.8579 (0.8690)	grad_norm 0.2534 (0.2643)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:46:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1700/2502]	eta 0:02:41 lr 0.000062	 wd 0.0000	time 0.1838 (0.2014)	loss 0.8413 (0.8690)	grad_norm 0.2649 (0.2644)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:46:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1800/2502]	eta 0:02:21 lr 0.000062	 wd 0.0000	time 0.1904 (0.2019)	loss 0.7847 (0.8691)	grad_norm 0.2635 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:46:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][1900/2502]	eta 0:02:00 lr 0.000062	 wd 0.0000	time 0.1678 (0.2001)	loss 0.8369 (0.8687)	grad_norm 0.2596 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:47:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2000/2502]	eta 0:01:39 lr 0.000062	 wd 0.0000	time 0.1799 (0.1985)	loss 0.8315 (0.8690)	grad_norm 0.2598 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 20:47:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2100/2502]	eta 0:01:19 lr 0.000062	 wd 0.0000	time 0.1568 (0.1967)	loss 0.8398 (0.8693)	grad_norm 0.2602 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 20:47:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2200/2502]	eta 0:00:59 lr 0.000061	 wd 0.0000	time 0.2161 (0.1963)	loss 0.8896 (0.8695)	grad_norm 0.2753 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 20:47:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2300/2502]	eta 0:00:39 lr 0.000061	 wd 0.0000	time 0.1562 (0.1968)	loss 0.8677 (0.8692)	grad_norm 0.2488 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 20:48:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2400/2502]	eta 0:00:19 lr 0.000061	 wd 0.0000	time 0.2424 (0.1955)	loss 0.8535 (0.8684)	grad_norm 0.2644 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 20:48:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [12/30][2500/2502]	eta 0:00:00 lr 0.000061	 wd 0.0000	time 0.0821 (0.1923)	loss 0.8726 (0.8682)	grad_norm 0.2687 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 20:48:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 12 training takes 0:08:09
[2024-07-30 20:48:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 18.600 (18.600)	Loss 0.3555 (0.3555)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 20:49:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.318 Acc@5 97.638
[2024-07-30 20:49:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 20:49:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 20:49:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][0/2502]	eta 1 day, 3:48:23 lr 0.000061	 wd 0.0000	time 40.0095 (40.0095)	loss 0.8398 (0.8398)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:50:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][100/2502]	eta 0:21:50 lr 0.000061	 wd 0.0000	time 0.1709 (0.5458)	loss 0.7954 (0.8591)	grad_norm 0.2586 (0.2633)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:50:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][200/2502]	eta 0:13:25 lr 0.000060	 wd 0.0000	time 0.1266 (0.3500)	loss 0.7793 (0.8674)	grad_norm 0.2636 (0.2640)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:50:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][300/2502]	eta 0:10:28 lr 0.000060	 wd 0.0000	time 0.1333 (0.2855)	loss 0.7773 (0.8619)	grad_norm 0.2655 (0.2642)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:51:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][400/2502]	eta 0:09:40 lr 0.000060	 wd 0.0000	time 0.4866 (0.2764)	loss 0.7441 (0.8628)	grad_norm 0.2642 (0.2645)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:51:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][500/2502]	eta 0:09:17 lr 0.000060	 wd 0.0000	time 0.1754 (0.2782)	loss 0.8403 (0.8629)	grad_norm 0.2703 (0.2648)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:51:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][600/2502]	eta 0:08:09 lr 0.000060	 wd 0.0000	time 0.1040 (0.2574)	loss 0.7935 (0.8641)	grad_norm 0.2692 (0.2652)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:51:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][700/2502]	eta 0:07:16 lr 0.000059	 wd 0.0000	time 0.1183 (0.2424)	loss 0.9878 (0.8646)	grad_norm 0.2866 (0.2652)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:52:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][800/2502]	eta 0:06:33 lr 0.000059	 wd 0.0000	time 0.1830 (0.2310)	loss 0.8970 (0.8646)	grad_norm 0.2627 (0.2652)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:52:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][900/2502]	eta 0:06:32 lr 0.000059	 wd 0.0000	time 3.6388 (0.2452)	loss 0.9028 (0.8654)	grad_norm 0.2686 (0.2654)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:53:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1000/2502]	eta 0:05:56 lr 0.000059	 wd 0.0000	time 0.1278 (0.2373)	loss 0.9590 (0.8666)	grad_norm 0.2730 (0.2655)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:53:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1100/2502]	eta 0:05:22 lr 0.000059	 wd 0.0000	time 0.2386 (0.2297)	loss 0.8389 (0.8660)	grad_norm 0.2690 (0.2654)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:53:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1200/2502]	eta 0:04:50 lr 0.000058	 wd 0.0000	time 0.2082 (0.2232)	loss 0.9517 (0.8663)	grad_norm 0.2717 (0.2654)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:53:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1300/2502]	eta 0:04:21 lr 0.000058	 wd 0.0000	time 0.1830 (0.2179)	loss 0.8691 (0.8669)	grad_norm 0.2704 (0.2656)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:54:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1400/2502]	eta 0:04:07 lr 0.000058	 wd 0.0000	time 0.1971 (0.2243)	loss 1.0400 (0.8667)	grad_norm 0.2589 (0.2657)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:54:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1500/2502]	eta 0:03:40 lr 0.000058	 wd 0.0000	time 0.1287 (0.2206)	loss 0.8936 (0.8668)	grad_norm 0.2737 (0.2657)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:54:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1600/2502]	eta 0:03:15 lr 0.000058	 wd 0.0000	time 0.1157 (0.2165)	loss 0.8096 (0.8671)	grad_norm 0.2611 (0.2657)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:55:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1700/2502]	eta 0:02:50 lr 0.000057	 wd 0.0000	time 0.1565 (0.2131)	loss 0.8149 (0.8671)	grad_norm 0.2624 (0.2657)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:55:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1800/2502]	eta 0:02:27 lr 0.000057	 wd 0.0000	time 0.2090 (0.2104)	loss 0.8267 (0.8672)	grad_norm 0.2745 (0.2658)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:55:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][1900/2502]	eta 0:02:06 lr 0.000057	 wd 0.0000	time 0.1769 (0.2098)	loss 0.7891 (0.8661)	grad_norm 0.2710 (0.2658)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:56:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2000/2502]	eta 0:01:45 lr 0.000057	 wd 0.0000	time 0.1404 (0.2101)	loss 0.8594 (0.8668)	grad_norm 0.2618 (0.2659)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:56:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2100/2502]	eta 0:01:23 lr 0.000057	 wd 0.0000	time 0.1471 (0.2079)	loss 0.8613 (0.8673)	grad_norm 0.2503 (0.2659)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:56:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2200/2502]	eta 0:01:02 lr 0.000056	 wd 0.0000	time 0.1895 (0.2060)	loss 0.9409 (0.8674)	grad_norm 0.2729 (0.2659)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:56:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2300/2502]	eta 0:00:41 lr 0.000056	 wd 0.0000	time 0.1832 (0.2042)	loss 0.7910 (0.8669)	grad_norm 0.2674 (0.2659)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:57:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2400/2502]	eta 0:00:20 lr 0.000056	 wd 0.0000	time 0.1576 (0.2034)	loss 0.8774 (0.8672)	grad_norm 0.2579 (0.2659)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:57:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [13/30][2500/2502]	eta 0:00:00 lr 0.000056	 wd 0.0000	time 0.0819 (0.2004)	loss 0.8159 (0.8673)	grad_norm 0.2641 (0.2659)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:57:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 13 training takes 0:08:35
[2024-07-30 20:58:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 20.546 (20.546)	Loss 0.3569 (0.3569)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 20:58:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.284 Acc@5 97.650
[2024-07-30 20:58:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 20:58:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 20:58:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][0/2502]	eta 10:46:02 lr 0.000056	 wd 0.0000	time 15.4925 (15.4925)	loss 0.9600 (0.9600)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:59:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][100/2502]	eta 0:21:20 lr 0.000055	 wd 0.0000	time 0.1325 (0.5330)	loss 0.8384 (0.8629)	grad_norm 0.2612 (0.2658)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:59:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][200/2502]	eta 0:13:21 lr 0.000055	 wd 0.0000	time 0.1862 (0.3480)	loss 0.8262 (0.8644)	grad_norm 0.2584 (0.2656)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 20:59:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][300/2502]	eta 0:10:22 lr 0.000055	 wd 0.0000	time 0.1535 (0.2825)	loss 1.1025 (0.8675)	grad_norm 0.2639 (0.2654)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:00:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][400/2502]	eta 0:08:44 lr 0.000055	 wd 0.0000	time 0.1216 (0.2496)	loss 1.0576 (0.8663)	grad_norm 0.2647 (0.2659)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:00:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][500/2502]	eta 0:07:42 lr 0.000055	 wd 0.0000	time 0.1650 (0.2310)	loss 0.9004 (0.8663)	grad_norm 0.2552 (0.2661)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:01:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][600/2502]	eta 0:08:14 lr 0.000054	 wd 0.0000	time 0.1510 (0.2598)	loss 0.8413 (0.8669)	grad_norm 0.2772 (0.2664)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:01:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][700/2502]	eta 0:07:21 lr 0.000054	 wd 0.0000	time 0.1465 (0.2448)	loss 0.7871 (0.8659)	grad_norm 0.2697 (0.2666)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:01:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][800/2502]	eta 0:06:37 lr 0.000054	 wd 0.0000	time 0.1397 (0.2336)	loss 0.7891 (0.8662)	grad_norm 0.2686 (0.2666)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:01:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][900/2502]	eta 0:05:59 lr 0.000054	 wd 0.0000	time 0.1474 (0.2245)	loss 0.8555 (0.8659)	grad_norm 0.2812 (0.2667)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:02:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1000/2502]	eta 0:05:28 lr 0.000054	 wd 0.0000	time 0.2238 (0.2189)	loss 0.9097 (0.8652)	grad_norm 0.2835 (nan)	loss_scale 32768.0000 (32833.4705)	mem 3061MB
[2024-07-30 21:02:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1100/2502]	eta 0:05:30 lr 0.000053	 wd 0.0000	time 0.1431 (0.2360)	loss 0.8262 (0.8650)	grad_norm 0.2578 (nan)	loss_scale 32768.0000 (32827.5241)	mem 3061MB
[2024-07-30 21:02:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1200/2502]	eta 0:04:58 lr 0.000053	 wd 0.0000	time 0.1860 (0.2294)	loss 0.8613 (0.8650)	grad_norm 0.2733 (nan)	loss_scale 32768.0000 (32822.5679)	mem 3061MB
[2024-07-30 21:03:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1300/2502]	eta 0:04:29 lr 0.000053	 wd 0.0000	time 0.1296 (0.2238)	loss 1.0547 (0.8647)	grad_norm 0.2687 (nan)	loss_scale 32768.0000 (32818.3736)	mem 3061MB
[2024-07-30 21:03:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1400/2502]	eta 0:04:01 lr 0.000053	 wd 0.0000	time 0.1290 (0.2189)	loss 0.8999 (0.8650)	grad_norm 0.2561 (nan)	loss_scale 32768.0000 (32814.7780)	mem 3061MB
[2024-07-30 21:03:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1500/2502]	eta 0:03:37 lr 0.000053	 wd 0.0000	time 0.1406 (0.2166)	loss 0.8423 (0.8654)	grad_norm 0.2706 (nan)	loss_scale 32768.0000 (32811.6616)	mem 3061MB
[2024-07-30 21:04:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1600/2502]	eta 0:03:15 lr 0.000052	 wd 0.0000	time 0.6829 (0.2163)	loss 0.8584 (0.8651)	grad_norm 0.2761 (nan)	loss_scale 32768.0000 (32808.9344)	mem 3061MB
[2024-07-30 21:04:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1700/2502]	eta 0:02:50 lr 0.000052	 wd 0.0000	time 0.1698 (0.2131)	loss 1.0244 (0.8656)	grad_norm 0.2833 (nan)	loss_scale 32768.0000 (32806.5279)	mem 3061MB
[2024-07-30 21:04:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1800/2502]	eta 0:02:27 lr 0.000052	 wd 0.0000	time 0.1804 (0.2104)	loss 0.6826 (0.8658)	grad_norm 0.2641 (nan)	loss_scale 32768.0000 (32804.3887)	mem 3061MB
[2024-07-30 21:04:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][1900/2502]	eta 0:02:05 lr 0.000052	 wd 0.0000	time 0.1316 (0.2079)	loss 0.8169 (0.8656)	grad_norm 0.2699 (nan)	loss_scale 32768.0000 (32802.4745)	mem 3061MB
[2024-07-30 21:05:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2000/2502]	eta 0:01:43 lr 0.000052	 wd 0.0000	time 0.1917 (0.2063)	loss 0.7964 (0.8654)	grad_norm 0.2752 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 21:05:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2100/2502]	eta 0:01:23 lr 0.000051	 wd 0.0000	time 0.1540 (0.2074)	loss 0.9277 (0.8655)	grad_norm 0.2696 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 21:05:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2200/2502]	eta 0:01:02 lr 0.000051	 wd 0.0000	time 0.1165 (0.2057)	loss 0.8647 (0.8662)	grad_norm 0.2536 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 21:06:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2300/2502]	eta 0:00:41 lr 0.000051	 wd 0.0000	time 0.1805 (0.2039)	loss 0.8252 (0.8660)	grad_norm 0.2706 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 21:06:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2400/2502]	eta 0:00:20 lr 0.000051	 wd 0.0000	time 0.2114 (0.2023)	loss 0.9502 (0.8665)	grad_norm 0.2676 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 21:06:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [14/30][2500/2502]	eta 0:00:00 lr 0.000051	 wd 0.0000	time 0.0816 (0.1988)	loss 0.8921 (0.8667)	grad_norm 0.2758 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 21:06:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 14 training takes 0:08:26
[2024-07-30 21:07:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 37.786 (37.786)	Loss 0.3545 (0.3545)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 21:07:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.286 Acc@5 97.634
[2024-07-30 21:07:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 21:07:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.32%
[2024-07-30 21:08:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][0/2502]	eta 10:58:02 lr 0.000051	 wd 0.0000	time 15.7805 (15.7805)	loss 0.7852 (0.7852)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:08:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][100/2502]	eta 0:12:34 lr 0.000050	 wd 0.0000	time 0.2234 (0.3141)	loss 0.9692 (0.8725)	grad_norm 0.2559 (0.2665)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:08:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][200/2502]	eta 0:11:01 lr 0.000050	 wd 0.0000	time 0.3028 (0.2873)	loss 1.0000 (0.8690)	grad_norm 0.2677 (0.2671)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:09:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][300/2502]	eta 0:10:45 lr 0.000050	 wd 0.0000	time 0.1744 (0.2933)	loss 0.9194 (0.8675)	grad_norm 0.2613 (0.2673)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:09:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][400/2502]	eta 0:09:01 lr 0.000050	 wd 0.0000	time 0.1571 (0.2577)	loss 1.0068 (0.8684)	grad_norm 0.2791 (0.2675)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:09:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][500/2502]	eta 0:07:52 lr 0.000049	 wd 0.0000	time 0.1258 (0.2362)	loss 0.7754 (0.8702)	grad_norm 0.2715 (0.2679)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:09:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][600/2502]	eta 0:07:02 lr 0.000049	 wd 0.0000	time 0.1997 (0.2222)	loss 0.8325 (0.8700)	grad_norm 0.2699 (0.2678)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:10:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][700/2502]	eta 0:07:01 lr 0.000049	 wd 0.0000	time 0.2913 (0.2338)	loss 0.8145 (0.8674)	grad_norm 0.2790 (0.2679)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:10:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][800/2502]	eta 0:06:40 lr 0.000049	 wd 0.0000	time 0.1921 (0.2355)	loss 1.0107 (0.8678)	grad_norm 0.2735 (0.2680)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:11:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][900/2502]	eta 0:06:02 lr 0.000049	 wd 0.0000	time 0.1258 (0.2264)	loss 0.7896 (0.8679)	grad_norm 0.2775 (0.2681)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:11:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1000/2502]	eta 0:05:29 lr 0.000048	 wd 0.0000	time 0.1100 (0.2191)	loss 0.9336 (0.8675)	grad_norm 0.2689 (0.2682)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:11:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1100/2502]	eta 0:04:59 lr 0.000048	 wd 0.0000	time 0.1938 (0.2137)	loss 0.9048 (0.8654)	grad_norm 0.2834 (0.2681)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:12:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1200/2502]	eta 0:04:45 lr 0.000048	 wd 0.0000	time 0.2263 (0.2193)	loss 0.7949 (0.8663)	grad_norm 0.2648 (0.2680)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:12:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1300/2502]	eta 0:04:17 lr 0.000048	 wd 0.0000	time 0.1545 (0.2146)	loss 0.8970 (0.8658)	grad_norm 0.2643 (0.2682)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:12:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1400/2502]	eta 0:03:51 lr 0.000048	 wd 0.0000	time 0.1488 (0.2101)	loss 0.7881 (0.8663)	grad_norm 0.2716 (0.2683)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:12:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1500/2502]	eta 0:03:27 lr 0.000047	 wd 0.0000	time 0.1322 (0.2068)	loss 0.9170 (0.8658)	grad_norm 0.2611 (0.2685)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:13:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1600/2502]	eta 0:03:03 lr 0.000047	 wd 0.0000	time 0.1428 (0.2038)	loss 0.9331 (0.8659)	grad_norm 0.2657 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:13:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1700/2502]	eta 0:02:43 lr 0.000047	 wd 0.0000	time 0.1920 (0.2033)	loss 0.7842 (0.8662)	grad_norm 0.2689 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:13:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1800/2502]	eta 0:02:23 lr 0.000047	 wd 0.0000	time 0.1050 (0.2040)	loss 1.0039 (0.8667)	grad_norm 0.2861 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:14:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][1900/2502]	eta 0:02:01 lr 0.000047	 wd 0.0000	time 0.1311 (0.2019)	loss 0.9404 (0.8662)	grad_norm 0.2825 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:14:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2000/2502]	eta 0:01:40 lr 0.000046	 wd 0.0000	time 0.1546 (0.2000)	loss 0.9980 (0.8671)	grad_norm 0.2801 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:14:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2100/2502]	eta 0:01:19 lr 0.000046	 wd 0.0000	time 0.1255 (0.1984)	loss 0.8330 (0.8670)	grad_norm 0.2634 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:15:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2200/2502]	eta 0:00:59 lr 0.000046	 wd 0.0000	time 0.2339 (0.1975)	loss 0.8872 (0.8673)	grad_norm 0.2630 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:15:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2300/2502]	eta 0:00:40 lr 0.000046	 wd 0.0000	time 0.1691 (0.2008)	loss 0.8711 (0.8673)	grad_norm 0.2881 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:15:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2400/2502]	eta 0:00:20 lr 0.000046	 wd 0.0000	time 0.1219 (0.1991)	loss 0.9146 (0.8673)	grad_norm 0.2613 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:15:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [15/30][2500/2502]	eta 0:00:00 lr 0.000045	 wd 0.0000	time 0.0812 (0.1958)	loss 1.0615 (0.8676)	grad_norm 0.2675 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 21:16:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 15 training takes 0:08:17
[2024-07-30 21:16:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_15.pth saving......
[2024-07-30 21:16:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_15.pth saved !!!
[2024-07-30 21:16:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 18.647 (18.647)	Loss 0.3591 (0.3591)	Acc@1 91.992 (91.992)	Acc@5 98.633 (98.633)	Mem 3061MB
[2024-07-30 21:16:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.348 Acc@5 97.648
[2024-07-30 21:16:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 21:16:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 21:16:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 160): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_best.pth saving......
[2024-07-30 21:16:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 162): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_best.pth saved !!!
[2024-07-30 21:17:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][0/2502]	eta 1 day, 0:51:19 lr 0.000045	 wd 0.0000	time 35.7631 (35.7631)	loss 0.7412 (0.7412)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:17:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][100/2502]	eta 0:20:09 lr 0.000045	 wd 0.0000	time 0.2158 (0.5036)	loss 0.9604 (0.8792)	grad_norm 0.2681 (0.2690)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:17:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][200/2502]	eta 0:12:39 lr 0.000045	 wd 0.0000	time 0.1303 (0.3297)	loss 0.8638 (0.8678)	grad_norm 0.2756 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:18:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][300/2502]	eta 0:10:00 lr 0.000045	 wd 0.0000	time 0.2046 (0.2729)	loss 0.9072 (0.8689)	grad_norm 0.2659 (0.2683)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:18:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][400/2502]	eta 0:10:27 lr 0.000045	 wd 0.0000	time 0.1889 (0.2985)	loss 0.8936 (0.8683)	grad_norm 0.2682 (0.2688)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:18:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][500/2502]	eta 0:09:01 lr 0.000044	 wd 0.0000	time 0.1587 (0.2706)	loss 0.9585 (0.8675)	grad_norm 0.2714 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:19:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][600/2502]	eta 0:07:57 lr 0.000044	 wd 0.0000	time 0.1717 (0.2510)	loss 0.9199 (0.8680)	grad_norm 0.2624 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:19:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][700/2502]	eta 0:07:06 lr 0.000044	 wd 0.0000	time 0.1835 (0.2369)	loss 0.8726 (0.8684)	grad_norm 0.2684 (0.2686)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:19:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][800/2502]	eta 0:06:26 lr 0.000044	 wd 0.0000	time 0.1325 (0.2272)	loss 0.8638 (0.8677)	grad_norm 0.2650 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:20:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][900/2502]	eta 0:06:23 lr 0.000043	 wd 0.0000	time 0.1546 (0.2393)	loss 0.8062 (0.8691)	grad_norm 0.2752 (0.2689)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:20:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1000/2502]	eta 0:05:46 lr 0.000043	 wd 0.0000	time 0.1686 (0.2309)	loss 0.8438 (0.8692)	grad_norm 0.2706 (0.2691)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:20:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1100/2502]	eta 0:05:13 lr 0.000043	 wd 0.0000	time 0.1238 (0.2238)	loss 0.9448 (0.8695)	grad_norm 0.2802 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:21:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1200/2502]	eta 0:04:43 lr 0.000043	 wd 0.0000	time 0.1389 (0.2178)	loss 0.8916 (0.8692)	grad_norm 0.2743 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:21:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1300/2502]	eta 0:04:16 lr 0.000043	 wd 0.0000	time 0.1276 (0.2134)	loss 0.9580 (0.8687)	grad_norm 0.2714 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:22:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1400/2502]	eta 0:04:08 lr 0.000042	 wd 0.0000	time 0.1357 (0.2253)	loss 0.7959 (0.8681)	grad_norm 0.2622 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:22:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1500/2502]	eta 0:03:41 lr 0.000042	 wd 0.0000	time 0.1417 (0.2208)	loss 0.8120 (0.8677)	grad_norm 0.2542 (0.2694)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:22:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1600/2502]	eta 0:03:15 lr 0.000042	 wd 0.0000	time 0.1366 (0.2169)	loss 0.7969 (0.8676)	grad_norm 0.2673 (0.2693)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:22:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1700/2502]	eta 0:02:51 lr 0.000042	 wd 0.0000	time 0.1672 (0.2133)	loss 0.8540 (0.8674)	grad_norm 0.2703 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:23:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1800/2502]	eta 0:02:28 lr 0.000042	 wd 0.0000	time 0.1715 (0.2113)	loss 1.0068 (0.8676)	grad_norm 0.2569 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:23:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][1900/2502]	eta 0:02:07 lr 0.000041	 wd 0.0000	time 0.1309 (0.2120)	loss 0.9800 (0.8666)	grad_norm 0.2634 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:23:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2000/2502]	eta 0:01:45 lr 0.000041	 wd 0.0000	time 0.1435 (0.2098)	loss 0.8418 (0.8664)	grad_norm 0.2665 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:24:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2100/2502]	eta 0:01:23 lr 0.000041	 wd 0.0000	time 0.1649 (0.2075)	loss 0.6880 (0.8661)	grad_norm 0.2665 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:24:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2200/2502]	eta 0:01:02 lr 0.000041	 wd 0.0000	time 0.1923 (0.2056)	loss 0.7905 (0.8661)	grad_norm 0.2733 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:24:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2300/2502]	eta 0:00:41 lr 0.000041	 wd 0.0000	time 0.1548 (0.2039)	loss 0.6787 (0.8656)	grad_norm 0.2848 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:24:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2400/2502]	eta 0:00:20 lr 0.000040	 wd 0.0000	time 0.2567 (0.2045)	loss 0.7793 (0.8655)	grad_norm 0.2722 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:25:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [16/30][2500/2502]	eta 0:00:00 lr 0.000040	 wd 0.0000	time 0.0811 (0.2031)	loss 0.8413 (0.8652)	grad_norm 0.2827 (0.2696)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:25:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 16 training takes 0:08:34
[2024-07-30 21:25:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 18.329 (18.329)	Loss 0.3569 (0.3569)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 21:25:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.282 Acc@5 97.636
[2024-07-30 21:25:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 21:25:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 21:26:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][0/2502]	eta 18:20:52 lr 0.000040	 wd 0.0000	time 26.3997 (26.3997)	loss 0.7617 (0.7617)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:26:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][100/2502]	eta 0:20:46 lr 0.000040	 wd 0.0000	time 0.1577 (0.5189)	loss 0.9644 (0.8670)	grad_norm 0.2617 (0.2687)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:27:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][200/2502]	eta 0:12:53 lr 0.000040	 wd 0.0000	time 0.1450 (0.3362)	loss 0.8345 (0.8697)	grad_norm 0.2603 (0.2695)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:27:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][300/2502]	eta 0:10:07 lr 0.000040	 wd 0.0000	time 0.1900 (0.2761)	loss 0.8687 (0.8664)	grad_norm 0.2842 (0.2699)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:27:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][400/2502]	eta 0:08:37 lr 0.000039	 wd 0.0000	time 0.1019 (0.2461)	loss 0.9199 (0.8649)	grad_norm 0.2659 (0.2702)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:27:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][500/2502]	eta 0:07:38 lr 0.000039	 wd 0.0000	time 0.1458 (0.2289)	loss 0.7495 (0.8630)	grad_norm 0.2844 (0.2704)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:28:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][600/2502]	eta 0:08:08 lr 0.000039	 wd 0.0000	time 0.1412 (0.2570)	loss 0.8013 (0.8644)	grad_norm 0.2828 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:28:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][700/2502]	eta 0:07:16 lr 0.000039	 wd 0.0000	time 0.1572 (0.2423)	loss 0.8862 (0.8636)	grad_norm 0.2772 (0.2708)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:29:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][800/2502]	eta 0:06:33 lr 0.000039	 wd 0.0000	time 0.1707 (0.2314)	loss 0.7861 (0.8639)	grad_norm 0.2624 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:29:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][900/2502]	eta 0:05:56 lr 0.000038	 wd 0.0000	time 0.1340 (0.2222)	loss 0.9683 (0.8646)	grad_norm 0.2642 (0.2705)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:29:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1000/2502]	eta 0:05:25 lr 0.000038	 wd 0.0000	time 0.1575 (0.2169)	loss 0.9199 (0.8647)	grad_norm 0.2742 (0.2706)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:30:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1100/2502]	eta 0:05:14 lr 0.000038	 wd 0.0000	time 0.2001 (0.2244)	loss 0.7349 (0.8660)	grad_norm 0.2698 (0.2707)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:30:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1200/2502]	eta 0:04:44 lr 0.000038	 wd 0.0000	time 0.1396 (0.2185)	loss 0.7676 (0.8675)	grad_norm 0.2745 (0.2709)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:30:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1300/2502]	eta 0:04:16 lr 0.000038	 wd 0.0000	time 0.1461 (0.2135)	loss 0.9175 (0.8668)	grad_norm 0.2700 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:30:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1400/2502]	eta 0:03:50 lr 0.000037	 wd 0.0000	time 0.1811 (0.2093)	loss 0.8945 (0.8677)	grad_norm 0.2578 (0.2710)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:31:06 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1500/2502]	eta 0:03:26 lr 0.000037	 wd 0.0000	time 0.1622 (0.2066)	loss 0.8579 (0.8674)	grad_norm 0.2748 (nan)	loss_scale 32768.0000 (32811.6616)	mem 3061MB
[2024-07-30 21:31:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1600/2502]	eta 0:03:08 lr 0.000037	 wd 0.0000	time 0.0944 (0.2086)	loss 1.0381 (0.8673)	grad_norm 0.2764 (nan)	loss_scale 32768.0000 (32808.9344)	mem 3061MB
[2024-07-30 21:31:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1700/2502]	eta 0:02:44 lr 0.000037	 wd 0.0000	time 0.1945 (0.2057)	loss 0.9907 (0.8674)	grad_norm 0.2747 (nan)	loss_scale 32768.0000 (32806.5279)	mem 3061MB
[2024-07-30 21:32:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1800/2502]	eta 0:02:22 lr 0.000037	 wd 0.0000	time 0.1309 (0.2033)	loss 0.7734 (0.8688)	grad_norm 0.2686 (nan)	loss_scale 32768.0000 (32804.3887)	mem 3061MB
[2024-07-30 21:32:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][1900/2502]	eta 0:02:01 lr 0.000036	 wd 0.0000	time 0.1791 (0.2013)	loss 0.7534 (0.8692)	grad_norm 0.2704 (nan)	loss_scale 32768.0000 (32802.4745)	mem 3061MB
[2024-07-30 21:32:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2000/2502]	eta 0:01:40 lr 0.000036	 wd 0.0000	time 0.1704 (0.1993)	loss 0.7949 (0.8687)	grad_norm 0.2690 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 21:32:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2100/2502]	eta 0:01:20 lr 0.000036	 wd 0.0000	time 0.2221 (0.1992)	loss 0.7778 (0.8682)	grad_norm 0.2670 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 21:33:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2200/2502]	eta 0:01:00 lr 0.000036	 wd 0.0000	time 0.1808 (0.1999)	loss 0.9219 (0.8680)	grad_norm 0.2696 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 21:33:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2300/2502]	eta 0:00:40 lr 0.000036	 wd 0.0000	time 0.1335 (0.1984)	loss 0.9087 (0.8676)	grad_norm 0.2735 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 21:33:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2400/2502]	eta 0:00:20 lr 0.000035	 wd 0.0000	time 0.1448 (0.1970)	loss 0.8276 (0.8679)	grad_norm 0.2732 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 21:34:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [17/30][2500/2502]	eta 0:00:00 lr 0.000035	 wd 0.0000	time 0.0814 (0.1938)	loss 0.9160 (0.8683)	grad_norm 0.2673 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 21:34:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 17 training takes 0:08:12
[2024-07-30 21:34:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 34.869 (34.869)	Loss 0.3555 (0.3555)	Acc@1 91.797 (91.797)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 21:35:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.292 Acc@5 97.644
[2024-07-30 21:35:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 21:35:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 21:35:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][0/2502]	eta 12:09:39 lr 0.000035	 wd 0.0000	time 17.4977 (17.4977)	loss 0.9077 (0.9077)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:35:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][100/2502]	eta 0:13:08 lr 0.000035	 wd 0.0000	time 0.1911 (0.3284)	loss 0.9780 (0.8712)	grad_norm 0.2811 (0.2718)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:35:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][200/2502]	eta 0:09:19 lr 0.000035	 wd 0.0000	time 0.2420 (0.2431)	loss 0.8350 (0.8670)	grad_norm 0.2688 (0.2721)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:36:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][300/2502]	eta 0:10:21 lr 0.000035	 wd 0.0000	time 0.1791 (0.2823)	loss 0.9087 (0.8710)	grad_norm 0.2695 (0.2726)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:36:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][400/2502]	eta 0:08:54 lr 0.000034	 wd 0.0000	time 0.1057 (0.2542)	loss 0.7964 (0.8724)	grad_norm 0.2776 (0.2724)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:37:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][500/2502]	eta 0:07:47 lr 0.000034	 wd 0.0000	time 0.1641 (0.2337)	loss 0.7041 (0.8722)	grad_norm 0.2742 (0.2720)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:37:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][600/2502]	eta 0:06:57 lr 0.000034	 wd 0.0000	time 0.1859 (0.2197)	loss 0.9346 (0.8688)	grad_norm 0.2737 (0.2722)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:37:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][700/2502]	eta 0:06:19 lr 0.000034	 wd 0.0000	time 0.2218 (0.2105)	loss 0.9097 (0.8657)	grad_norm 0.2586 (0.2719)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:38:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][800/2502]	eta 0:06:29 lr 0.000034	 wd 0.0000	time 0.2274 (0.2289)	loss 1.0547 (0.8640)	grad_norm 0.2640 (0.2718)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:38:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][900/2502]	eta 0:05:55 lr 0.000033	 wd 0.0000	time 0.1829 (0.2216)	loss 0.9355 (0.8645)	grad_norm 0.2909 (0.2717)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:38:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1000/2502]	eta 0:05:22 lr 0.000033	 wd 0.0000	time 0.1162 (0.2148)	loss 0.8423 (0.8653)	grad_norm 0.2703 (0.2718)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:38:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1100/2502]	eta 0:04:53 lr 0.000033	 wd 0.0000	time 0.1297 (0.2092)	loss 0.7798 (0.8664)	grad_norm 0.2668 (0.2718)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:39:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1200/2502]	eta 0:04:26 lr 0.000033	 wd 0.0000	time 0.1570 (0.2050)	loss 0.8804 (0.8659)	grad_norm 0.2703 (0.2719)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:39:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1300/2502]	eta 0:04:20 lr 0.000033	 wd 0.0000	time 0.1981 (0.2164)	loss 0.8613 (0.8671)	grad_norm 0.2761 (0.2720)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:40:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1400/2502]	eta 0:03:53 lr 0.000032	 wd 0.0000	time 0.1334 (0.2123)	loss 0.9888 (0.8666)	grad_norm 0.2812 (0.2721)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:40:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1500/2502]	eta 0:03:28 lr 0.000032	 wd 0.0000	time 0.1080 (0.2084)	loss 0.8433 (0.8675)	grad_norm 0.2650 (0.2720)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:40:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1600/2502]	eta 0:03:04 lr 0.000032	 wd 0.0000	time 0.1538 (0.2051)	loss 0.8599 (0.8669)	grad_norm 0.2673 (0.2722)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:40:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1700/2502]	eta 0:02:42 lr 0.000032	 wd 0.0000	time 0.1641 (0.2028)	loss 0.9688 (0.8670)	grad_norm 0.2755 (0.2722)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:41:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1800/2502]	eta 0:02:23 lr 0.000032	 wd 0.0000	time 0.0943 (0.2050)	loss 0.8286 (0.8669)	grad_norm 0.2874 (0.2723)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:41:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][1900/2502]	eta 0:02:02 lr 0.000032	 wd 0.0000	time 0.2365 (0.2028)	loss 0.8237 (0.8666)	grad_norm 0.2792 (0.2724)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:41:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2000/2502]	eta 0:01:40 lr 0.000031	 wd 0.0000	time 0.1436 (0.2008)	loss 0.8784 (0.8671)	grad_norm 0.2669 (0.2724)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:42:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2100/2502]	eta 0:01:20 lr 0.000031	 wd 0.0000	time 0.1486 (0.1992)	loss 0.7251 (0.8673)	grad_norm 0.2754 (0.2724)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:42:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2200/2502]	eta 0:00:59 lr 0.000031	 wd 0.0000	time 0.2025 (0.1975)	loss 0.8838 (0.8671)	grad_norm 0.2658 (0.2725)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:42:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2300/2502]	eta 0:00:39 lr 0.000031	 wd 0.0000	time 0.1718 (0.1974)	loss 0.7617 (0.8675)	grad_norm 0.2666 (0.2725)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:42:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2400/2502]	eta 0:00:20 lr 0.000031	 wd 0.0000	time 0.2230 (0.1977)	loss 0.8779 (0.8676)	grad_norm 0.2779 (0.2726)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:43:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [18/30][2500/2502]	eta 0:00:00 lr 0.000030	 wd 0.0000	time 0.0812 (0.1947)	loss 0.8579 (0.8677)	grad_norm 0.2756 (0.2726)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:43:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 18 training takes 0:08:15
[2024-07-30 21:43:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.304 (19.304)	Loss 0.3550 (0.3550)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 21:43:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.324 Acc@5 97.644
[2024-07-30 21:43:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 21:43:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 21:44:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][0/2502]	eta 1 day, 0:16:54 lr 0.000030	 wd 0.0000	time 34.9378 (34.9378)	loss 0.8525 (0.8525)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:44:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][100/2502]	eta 0:20:34 lr 0.000030	 wd 0.0000	time 0.1168 (0.5139)	loss 0.9990 (0.8591)	grad_norm 0.2678 (0.2728)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:45:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][200/2502]	eta 0:12:45 lr 0.000030	 wd 0.0000	time 0.1521 (0.3325)	loss 0.6865 (0.8576)	grad_norm 0.2798 (0.2731)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:45:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][300/2502]	eta 0:10:02 lr 0.000030	 wd 0.0000	time 0.1269 (0.2737)	loss 0.9658 (0.8626)	grad_norm 0.2689 (0.2729)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:45:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][400/2502]	eta 0:08:33 lr 0.000030	 wd 0.0000	time 0.1433 (0.2442)	loss 0.8120 (0.8649)	grad_norm 0.2564 (0.2726)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:46:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][500/2502]	eta 0:09:32 lr 0.000029	 wd 0.0000	time 0.1604 (0.2859)	loss 0.9199 (0.8646)	grad_norm 0.2697 (nan)	loss_scale 32768.0000 (32898.8104)	mem 3061MB
[2024-07-30 21:46:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][600/2502]	eta 0:08:25 lr 0.000029	 wd 0.0000	time 0.1890 (0.2658)	loss 0.7334 (0.8664)	grad_norm 0.2681 (nan)	loss_scale 32768.0000 (32877.0449)	mem 3061MB
[2024-07-30 21:46:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][700/2502]	eta 0:07:30 lr 0.000029	 wd 0.0000	time 0.1179 (0.2499)	loss 0.9707 (0.8675)	grad_norm 0.2683 (nan)	loss_scale 32768.0000 (32861.4893)	mem 3061MB
[2024-07-30 21:47:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][800/2502]	eta 0:06:43 lr 0.000029	 wd 0.0000	time 0.1712 (0.2374)	loss 0.8501 (0.8686)	grad_norm 0.2754 (nan)	loss_scale 32768.0000 (32849.8177)	mem 3061MB
[2024-07-30 21:47:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][900/2502]	eta 0:06:11 lr 0.000029	 wd 0.0000	time 0.2616 (0.2318)	loss 0.8408 (0.8685)	grad_norm 0.2762 (nan)	loss_scale 32768.0000 (32840.7370)	mem 3061MB
[2024-07-30 21:47:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1000/2502]	eta 0:05:59 lr 0.000028	 wd 0.0000	time 0.1625 (0.2395)	loss 0.9468 (0.8693)	grad_norm 0.2701 (nan)	loss_scale 32768.0000 (32833.4705)	mem 3061MB
[2024-07-30 21:48:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1100/2502]	eta 0:05:25 lr 0.000028	 wd 0.0000	time 0.1539 (0.2318)	loss 0.8286 (0.8686)	grad_norm 0.2768 (nan)	loss_scale 32768.0000 (32827.5241)	mem 3061MB
[2024-07-30 21:48:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1200/2502]	eta 0:04:53 lr 0.000028	 wd 0.0000	time 0.1436 (0.2253)	loss 0.8647 (0.8685)	grad_norm 0.2758 (nan)	loss_scale 32768.0000 (32822.5679)	mem 3061MB
[2024-07-30 21:48:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1300/2502]	eta 0:04:24 lr 0.000028	 wd 0.0000	time 0.1441 (0.2197)	loss 0.8252 (0.8691)	grad_norm 0.2659 (nan)	loss_scale 32768.0000 (32818.3736)	mem 3061MB
[2024-07-30 21:49:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1400/2502]	eta 0:03:58 lr 0.000028	 wd 0.0000	time 0.2821 (0.2168)	loss 0.8223 (0.8686)	grad_norm 0.2717 (nan)	loss_scale 32768.0000 (32814.7780)	mem 3061MB
[2024-07-30 21:49:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1500/2502]	eta 0:03:43 lr 0.000028	 wd 0.0000	time 0.1266 (0.2226)	loss 0.8755 (0.8690)	grad_norm 0.2535 (nan)	loss_scale 32768.0000 (32811.6616)	mem 3061MB
[2024-07-30 21:49:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1600/2502]	eta 0:03:17 lr 0.000027	 wd 0.0000	time 0.1111 (0.2185)	loss 0.8735 (0.8693)	grad_norm 0.2820 (nan)	loss_scale 32768.0000 (32808.9344)	mem 3061MB
[2024-07-30 21:50:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1700/2502]	eta 0:02:52 lr 0.000027	 wd 0.0000	time 0.2210 (0.2149)	loss 0.9712 (0.8693)	grad_norm 0.2751 (nan)	loss_scale 32768.0000 (32806.5279)	mem 3061MB
[2024-07-30 21:50:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1800/2502]	eta 0:02:28 lr 0.000027	 wd 0.0000	time 0.1201 (0.2120)	loss 0.8022 (0.8696)	grad_norm 0.2683 (nan)	loss_scale 32768.0000 (32804.3887)	mem 3061MB
[2024-07-30 21:50:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][1900/2502]	eta 0:02:06 lr 0.000027	 wd 0.0000	time 0.1809 (0.2104)	loss 0.8354 (0.8696)	grad_norm 0.2681 (nan)	loss_scale 32768.0000 (32802.4745)	mem 3061MB
[2024-07-30 21:51:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2000/2502]	eta 0:01:47 lr 0.000027	 wd 0.0000	time 0.1249 (0.2133)	loss 0.9126 (0.8694)	grad_norm 0.2678 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 21:51:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2100/2502]	eta 0:01:24 lr 0.000026	 wd 0.0000	time 0.1643 (0.2108)	loss 0.9502 (0.8691)	grad_norm 0.2728 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 21:51:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2200/2502]	eta 0:01:03 lr 0.000026	 wd 0.0000	time 0.1141 (0.2087)	loss 0.8618 (0.8686)	grad_norm 0.3037 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 21:51:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2300/2502]	eta 0:00:41 lr 0.000026	 wd 0.0000	time 0.1320 (0.2066)	loss 0.8872 (0.8683)	grad_norm 0.2744 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 21:52:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2400/2502]	eta 0:00:20 lr 0.000026	 wd 0.0000	time 0.1945 (0.2053)	loss 0.9331 (0.8682)	grad_norm 0.2849 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 21:52:23 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [19/30][2500/2502]	eta 0:00:00 lr 0.000026	 wd 0.0000	time 0.0822 (0.2024)	loss 0.7007 (0.8682)	grad_norm 0.2692 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 21:52:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 19 training takes 0:08:38
[2024-07-30 21:53:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 27.514 (27.514)	Loss 0.3574 (0.3574)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 21:53:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.296 Acc@5 97.670
[2024-07-30 21:53:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 21:53:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 21:53:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][0/2502]	eta 10:05:52 lr 0.000026	 wd 0.0000	time 14.5295 (14.5295)	loss 0.8164 (0.8164)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:54:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][100/2502]	eta 0:16:03 lr 0.000026	 wd 0.0000	time 0.4492 (0.4010)	loss 0.9937 (0.8715)	grad_norm 0.2735 (0.2752)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:54:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][200/2502]	eta 0:13:01 lr 0.000025	 wd 0.0000	time 0.1486 (0.3396)	loss 0.9272 (0.8634)	grad_norm 0.2745 (0.2745)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:54:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][300/2502]	eta 0:10:08 lr 0.000025	 wd 0.0000	time 0.1038 (0.2763)	loss 0.7451 (0.8594)	grad_norm 0.2829 (0.2746)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:54:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][400/2502]	eta 0:08:35 lr 0.000025	 wd 0.0000	time 0.1170 (0.2450)	loss 0.8638 (0.8602)	grad_norm 0.2709 (0.2743)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:55:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][500/2502]	eta 0:07:31 lr 0.000025	 wd 0.0000	time 0.1639 (0.2255)	loss 0.8540 (0.8595)	grad_norm 0.2667 (0.2748)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:55:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][600/2502]	eta 0:08:02 lr 0.000025	 wd 0.0000	time 3.1418 (0.2538)	loss 0.7891 (0.8602)	grad_norm 0.2779 (0.2746)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:56:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][700/2502]	eta 0:07:15 lr 0.000025	 wd 0.0000	time 0.1075 (0.2418)	loss 0.7803 (0.8604)	grad_norm 0.2676 (0.2747)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:56:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][800/2502]	eta 0:06:33 lr 0.000024	 wd 0.0000	time 0.1580 (0.2310)	loss 0.9849 (0.8610)	grad_norm 0.2689 (0.2746)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:56:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][900/2502]	eta 0:05:56 lr 0.000024	 wd 0.0000	time 0.1482 (0.2224)	loss 0.7524 (0.8611)	grad_norm 0.2587 (0.2747)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:56:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1000/2502]	eta 0:05:24 lr 0.000024	 wd 0.0000	time 0.1803 (0.2164)	loss 0.7954 (0.8607)	grad_norm 0.2679 (0.2744)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:57:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1100/2502]	eta 0:05:16 lr 0.000024	 wd 0.0000	time 0.1362 (0.2254)	loss 0.7847 (0.8610)	grad_norm 0.2748 (0.2744)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:57:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1200/2502]	eta 0:04:45 lr 0.000024	 wd 0.0000	time 0.1202 (0.2196)	loss 0.7251 (0.8609)	grad_norm 0.2683 (0.2744)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:58:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1300/2502]	eta 0:04:17 lr 0.000023	 wd 0.0000	time 0.2117 (0.2146)	loss 0.8774 (0.8610)	grad_norm 0.2783 (0.2743)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:58:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1400/2502]	eta 0:03:51 lr 0.000023	 wd 0.0000	time 0.1451 (0.2102)	loss 0.9077 (0.8615)	grad_norm 0.2733 (0.2744)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:58:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1500/2502]	eta 0:03:27 lr 0.000023	 wd 0.0000	time 0.1804 (0.2067)	loss 0.9707 (0.8611)	grad_norm 0.2760 (0.2744)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:58:51 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1600/2502]	eta 0:03:05 lr 0.000023	 wd 0.0000	time 0.2193 (0.2058)	loss 0.9111 (0.8604)	grad_norm 0.2856 (0.2745)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:59:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1700/2502]	eta 0:02:45 lr 0.000023	 wd 0.0000	time 0.1556 (0.2058)	loss 0.9468 (0.8605)	grad_norm 0.2684 (0.2744)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:59:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1800/2502]	eta 0:02:22 lr 0.000023	 wd 0.0000	time 0.1737 (0.2035)	loss 0.7920 (0.8612)	grad_norm 0.2784 (0.2745)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 21:59:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][1900/2502]	eta 0:02:01 lr 0.000022	 wd 0.0000	time 0.1411 (0.2015)	loss 0.9927 (0.8619)	grad_norm 0.2798 (0.2745)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:00:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2000/2502]	eta 0:01:40 lr 0.000022	 wd 0.0000	time 0.1572 (0.1995)	loss 0.8965 (0.8618)	grad_norm 0.2715 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 22:00:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2100/2502]	eta 0:01:19 lr 0.000022	 wd 0.0000	time 0.1671 (0.1988)	loss 0.9155 (0.8623)	grad_norm 0.2699 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 22:00:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2200/2502]	eta 0:01:00 lr 0.000022	 wd 0.0000	time 0.1349 (0.1995)	loss 0.8765 (0.8629)	grad_norm 0.2803 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 22:00:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2300/2502]	eta 0:00:40 lr 0.000022	 wd 0.0000	time 0.1940 (0.1985)	loss 0.8091 (0.8637)	grad_norm 0.2841 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 22:01:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2400/2502]	eta 0:00:20 lr 0.000022	 wd 0.0000	time 0.1977 (0.1971)	loss 0.8242 (0.8639)	grad_norm 0.2766 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 22:01:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [20/30][2500/2502]	eta 0:00:00 lr 0.000021	 wd 0.0000	time 0.0822 (0.1939)	loss 0.7754 (0.8636)	grad_norm 0.2698 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 22:01:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 20 training takes 0:08:11
[2024-07-30 22:02:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 39.360 (39.360)	Loss 0.3569 (0.3569)	Acc@1 91.992 (91.992)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 22:02:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.312 Acc@5 97.662
[2024-07-30 22:02:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 22:02:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 22:02:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][0/2502]	eta 10:51:20 lr 0.000021	 wd 0.0000	time 15.6199 (15.6199)	loss 0.8970 (0.8970)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:03:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][100/2502]	eta 0:12:52 lr 0.000021	 wd 0.0000	time 0.1250 (0.3216)	loss 0.8750 (0.8764)	grad_norm 0.2780 (0.2747)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:03:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][200/2502]	eta 0:09:11 lr 0.000021	 wd 0.0000	time 0.1633 (0.2394)	loss 0.9199 (0.8693)	grad_norm 0.2648 (0.2741)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:03:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][300/2502]	eta 0:10:07 lr 0.000021	 wd 0.0000	time 2.5084 (0.2760)	loss 0.8896 (0.8667)	grad_norm 0.2742 (0.2747)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:04:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][400/2502]	eta 0:09:01 lr 0.000021	 wd 0.0000	time 0.1035 (0.2577)	loss 0.9810 (0.8667)	grad_norm 0.2761 (0.2745)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:04:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][500/2502]	eta 0:07:53 lr 0.000021	 wd 0.0000	time 0.1807 (0.2368)	loss 0.8203 (0.8670)	grad_norm 0.2747 (0.2746)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:04:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][600/2502]	eta 0:07:02 lr 0.000020	 wd 0.0000	time 0.1505 (0.2222)	loss 0.8550 (0.8666)	grad_norm 0.2766 (0.2748)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:05:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][700/2502]	eta 0:06:22 lr 0.000020	 wd 0.0000	time 0.1545 (0.2125)	loss 0.9971 (0.8668)	grad_norm 0.2798 (0.2748)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:05:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][800/2502]	eta 0:06:39 lr 0.000020	 wd 0.0000	time 0.1850 (0.2345)	loss 0.8887 (0.8670)	grad_norm 0.2851 (0.2749)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:05:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][900/2502]	eta 0:06:01 lr 0.000020	 wd 0.0000	time 0.1483 (0.2260)	loss 0.8247 (0.8680)	grad_norm 0.2722 (0.2748)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:06:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1000/2502]	eta 0:05:28 lr 0.000020	 wd 0.0000	time 0.1151 (0.2187)	loss 0.8262 (0.8673)	grad_norm 0.2574 (0.2749)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:06:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1100/2502]	eta 0:04:58 lr 0.000020	 wd 0.0000	time 0.1600 (0.2127)	loss 0.8784 (0.8679)	grad_norm 0.2694 (0.2749)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:06:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1200/2502]	eta 0:04:32 lr 0.000019	 wd 0.0000	time 0.1688 (0.2089)	loss 0.8267 (0.8691)	grad_norm 0.2742 (0.2750)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:07:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1300/2502]	eta 0:04:20 lr 0.000019	 wd 0.0000	time 0.1546 (0.2164)	loss 0.9341 (0.8686)	grad_norm 0.2671 (0.2749)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:07:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1400/2502]	eta 0:03:53 lr 0.000019	 wd 0.0000	time 0.1652 (0.2121)	loss 0.8857 (0.8686)	grad_norm 0.2692 (0.2749)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:07:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1500/2502]	eta 0:03:28 lr 0.000019	 wd 0.0000	time 0.1890 (0.2082)	loss 0.9277 (0.8684)	grad_norm 0.2724 (0.2748)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:07:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1600/2502]	eta 0:03:04 lr 0.000019	 wd 0.0000	time 0.1665 (0.2050)	loss 0.8999 (0.8679)	grad_norm 0.2846 (0.2750)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:08:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1700/2502]	eta 0:02:42 lr 0.000019	 wd 0.0000	time 0.2164 (0.2029)	loss 0.8789 (0.8684)	grad_norm 0.2709 (0.2750)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:08:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1800/2502]	eta 0:02:27 lr 0.000018	 wd 0.0000	time 0.1270 (0.2095)	loss 0.8755 (0.8685)	grad_norm 0.2716 (0.2751)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:09:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][1900/2502]	eta 0:02:04 lr 0.000018	 wd 0.0000	time 0.2101 (0.2070)	loss 0.8931 (0.8686)	grad_norm 0.2737 (0.2751)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:09:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2000/2502]	eta 0:01:42 lr 0.000018	 wd 0.0000	time 0.2342 (0.2047)	loss 0.7500 (0.8684)	grad_norm 0.2836 (0.2752)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:09:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2100/2502]	eta 0:01:21 lr 0.000018	 wd 0.0000	time 0.1280 (0.2028)	loss 0.7783 (0.8679)	grad_norm 0.2622 (0.2753)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:09:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2200/2502]	eta 0:01:00 lr 0.000018	 wd 0.0000	time 0.2347 (0.2017)	loss 0.7842 (0.8673)	grad_norm 0.2760 (0.2753)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:10:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2300/2502]	eta 0:00:40 lr 0.000018	 wd 0.0000	time 0.1310 (0.2020)	loss 0.9258 (0.8673)	grad_norm 0.2754 (0.2754)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:10:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2400/2502]	eta 0:00:20 lr 0.000018	 wd 0.0000	time 0.1155 (0.2010)	loss 0.8589 (0.8673)	grad_norm 0.2733 (0.2755)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:10:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [21/30][2500/2502]	eta 0:00:00 lr 0.000017	 wd 0.0000	time 0.0819 (0.1977)	loss 0.8901 (0.8675)	grad_norm 0.2569 (0.2755)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:10:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 21 training takes 0:08:22
[2024-07-30 22:11:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.420 (19.420)	Loss 0.3540 (0.3540)	Acc@1 92.383 (92.383)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 22:11:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.328 Acc@5 97.664
[2024-07-30 22:11:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 22:11:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 22:12:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][0/2502]	eta 1 day, 1:47:31 lr 0.000017	 wd 0.0000	time 37.1108 (37.1108)	loss 0.8232 (0.8232)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:12:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][100/2502]	eta 0:21:13 lr 0.000017	 wd 0.0000	time 0.1867 (0.5304)	loss 0.9062 (0.8718)	grad_norm 0.2828 (0.2761)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:12:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][200/2502]	eta 0:13:08 lr 0.000017	 wd 0.0000	time 0.1491 (0.3424)	loss 0.8003 (0.8674)	grad_norm 0.2706 (0.2757)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:12:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][300/2502]	eta 0:10:14 lr 0.000017	 wd 0.0000	time 0.1663 (0.2788)	loss 0.8525 (0.8667)	grad_norm 0.2760 (0.2761)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:13:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][400/2502]	eta 0:09:16 lr 0.000017	 wd 0.0000	time 0.4117 (0.2646)	loss 0.8047 (0.8715)	grad_norm 0.2686 (0.2762)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:13:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][500/2502]	eta 0:09:20 lr 0.000017	 wd 0.0000	time 0.1722 (0.2802)	loss 0.7036 (0.8697)	grad_norm 0.2649 (0.2758)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:14:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][600/2502]	eta 0:08:11 lr 0.000016	 wd 0.0000	time 0.1695 (0.2587)	loss 0.9180 (0.8713)	grad_norm 0.2648 (0.2758)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:14:22 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][700/2502]	eta 0:07:18 lr 0.000016	 wd 0.0000	time 0.1281 (0.2436)	loss 0.9766 (0.8699)	grad_norm 0.2651 (0.2760)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:14:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][800/2502]	eta 0:06:35 lr 0.000016	 wd 0.0000	time 0.1313 (0.2324)	loss 0.8813 (0.8699)	grad_norm 0.2702 (0.2759)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:15:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][900/2502]	eta 0:06:23 lr 0.000016	 wd 0.0000	time 0.3626 (0.2392)	loss 0.8262 (0.8698)	grad_norm 0.2706 (0.2761)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:15:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1000/2502]	eta 0:05:59 lr 0.000016	 wd 0.0000	time 0.1544 (0.2393)	loss 0.8975 (0.8694)	grad_norm 0.2696 (nan)	loss_scale 32768.0000 (32833.4705)	mem 3061MB
[2024-07-30 22:15:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1100/2502]	eta 0:05:24 lr 0.000016	 wd 0.0000	time 0.1367 (0.2314)	loss 0.7632 (0.8679)	grad_norm 0.2672 (nan)	loss_scale 32768.0000 (32827.5241)	mem 3061MB
[2024-07-30 22:16:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1200/2502]	eta 0:04:53 lr 0.000016	 wd 0.0000	time 0.1228 (0.2251)	loss 0.8364 (0.8683)	grad_norm 0.2684 (nan)	loss_scale 32768.0000 (32822.5679)	mem 3061MB
[2024-07-30 22:16:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1300/2502]	eta 0:04:24 lr 0.000015	 wd 0.0000	time 0.1672 (0.2199)	loss 0.8608 (0.8670)	grad_norm 0.2729 (nan)	loss_scale 32768.0000 (32818.3736)	mem 3061MB
[2024-07-30 22:16:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1400/2502]	eta 0:04:11 lr 0.000015	 wd 0.0000	time 0.1801 (0.2284)	loss 0.8486 (0.8667)	grad_norm 0.2728 (nan)	loss_scale 32768.0000 (32814.7780)	mem 3061MB
[2024-07-30 22:17:08 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1500/2502]	eta 0:03:44 lr 0.000015	 wd 0.0000	time 0.1378 (0.2240)	loss 0.6846 (0.8666)	grad_norm 0.2723 (nan)	loss_scale 32768.0000 (32811.6616)	mem 3061MB
[2024-07-30 22:17:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1600/2502]	eta 0:03:18 lr 0.000015	 wd 0.0000	time 0.1491 (0.2200)	loss 0.8154 (0.8669)	grad_norm 0.2775 (nan)	loss_scale 32768.0000 (32808.9344)	mem 3061MB
[2024-07-30 22:17:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1700/2502]	eta 0:02:53 lr 0.000015	 wd 0.0000	time 0.2034 (0.2162)	loss 0.8809 (0.8664)	grad_norm 0.2730 (nan)	loss_scale 32768.0000 (32806.5279)	mem 3061MB
[2024-07-30 22:17:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1800/2502]	eta 0:02:29 lr 0.000015	 wd 0.0000	time 0.1702 (0.2136)	loss 0.9185 (0.8664)	grad_norm 0.2714 (nan)	loss_scale 32768.0000 (32804.3887)	mem 3061MB
[2024-07-30 22:18:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][1900/2502]	eta 0:02:12 lr 0.000015	 wd 0.0000	time 0.1827 (0.2198)	loss 0.8765 (0.8669)	grad_norm 0.2713 (nan)	loss_scale 32768.0000 (32802.4745)	mem 3061MB
[2024-07-30 22:18:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2000/2502]	eta 0:01:48 lr 0.000014	 wd 0.0000	time 0.1718 (0.2168)	loss 0.9492 (0.8666)	grad_norm 0.2590 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 22:19:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2100/2502]	eta 0:01:26 lr 0.000014	 wd 0.0000	time 0.1453 (0.2143)	loss 0.8022 (0.8670)	grad_norm 0.2734 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 22:19:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2200/2502]	eta 0:01:04 lr 0.000014	 wd 0.0000	time 0.1478 (0.2120)	loss 0.6885 (0.8669)	grad_norm 0.2840 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 22:19:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2300/2502]	eta 0:00:42 lr 0.000014	 wd 0.0000	time 0.2269 (0.2103)	loss 0.9360 (0.8669)	grad_norm 0.2771 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 22:19:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2400/2502]	eta 0:00:21 lr 0.000014	 wd 0.0000	time 0.1184 (0.2107)	loss 0.7612 (0.8670)	grad_norm 0.2785 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 22:20:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [22/30][2500/2502]	eta 0:00:00 lr 0.000014	 wd 0.0000	time 0.0815 (0.2074)	loss 0.8276 (0.8666)	grad_norm 0.2747 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 22:20:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 22 training takes 0:08:48
[2024-07-30 22:20:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.830 (19.830)	Loss 0.3540 (0.3540)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 22:20:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.324 Acc@5 97.656
[2024-07-30 22:20:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 22:20:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 22:21:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][0/2502]	eta 20:54:39 lr 0.000014	 wd 0.0000	time 30.0877 (30.0877)	loss 0.7666 (0.7666)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:21:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][100/2502]	eta 0:19:53 lr 0.000014	 wd 0.0000	time 0.1331 (0.4969)	loss 0.8682 (0.8682)	grad_norm 0.2761 (0.2783)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:22:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][200/2502]	eta 0:12:29 lr 0.000013	 wd 0.0000	time 0.1598 (0.3255)	loss 0.9351 (0.8652)	grad_norm 0.2912 (0.2776)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:22:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][300/2502]	eta 0:09:52 lr 0.000013	 wd 0.0000	time 0.1624 (0.2689)	loss 0.7642 (0.8638)	grad_norm 0.2747 (0.2777)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:22:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][400/2502]	eta 0:08:24 lr 0.000013	 wd 0.0000	time 0.1600 (0.2400)	loss 0.9800 (0.8652)	grad_norm 0.2724 (0.2779)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:22:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][500/2502]	eta 0:07:39 lr 0.000013	 wd 0.0000	time 0.2924 (0.2298)	loss 0.8789 (0.8691)	grad_norm 0.2685 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:23:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][600/2502]	eta 0:07:58 lr 0.000013	 wd 0.0000	time 0.1534 (0.2516)	loss 0.8931 (0.8697)	grad_norm 0.2786 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:23:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][700/2502]	eta 0:07:07 lr 0.000013	 wd 0.0000	time 0.1669 (0.2373)	loss 0.9609 (0.8705)	grad_norm 0.2638 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:23:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][800/2502]	eta 0:06:25 lr 0.000013	 wd 0.0000	time 0.1971 (0.2268)	loss 0.9688 (0.8701)	grad_norm 0.2772 (0.2777)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:24:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][900/2502]	eta 0:05:49 lr 0.000012	 wd 0.0000	time 0.1440 (0.2180)	loss 1.1025 (0.8685)	grad_norm 0.2829 (0.2776)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:24:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1000/2502]	eta 0:05:22 lr 0.000012	 wd 0.0000	time 0.2077 (0.2148)	loss 0.7393 (0.8690)	grad_norm 0.2729 (0.2777)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:25:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1100/2502]	eta 0:05:10 lr 0.000012	 wd 0.0000	time 0.1498 (0.2216)	loss 0.7148 (0.8681)	grad_norm 0.2840 (0.2776)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:25:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1200/2502]	eta 0:04:40 lr 0.000012	 wd 0.0000	time 0.1439 (0.2158)	loss 0.9272 (0.8684)	grad_norm 0.2647 (0.2776)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:25:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1300/2502]	eta 0:04:13 lr 0.000012	 wd 0.0000	time 0.1652 (0.2112)	loss 0.9302 (0.8686)	grad_norm 0.2774 (0.2777)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:25:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1400/2502]	eta 0:03:48 lr 0.000012	 wd 0.0000	time 0.1419 (0.2071)	loss 0.9326 (0.8691)	grad_norm 0.2815 (0.2777)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:26:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1500/2502]	eta 0:03:25 lr 0.000012	 wd 0.0000	time 0.2078 (0.2049)	loss 0.7520 (0.8699)	grad_norm 0.2846 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:26:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1600/2502]	eta 0:03:05 lr 0.000012	 wd 0.0000	time 0.1504 (0.2055)	loss 0.8779 (0.8700)	grad_norm 0.2737 (0.2779)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:26:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1700/2502]	eta 0:02:42 lr 0.000011	 wd 0.0000	time 0.2165 (0.2029)	loss 0.7798 (0.8697)	grad_norm 0.2779 (0.2779)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:26:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1800/2502]	eta 0:02:20 lr 0.000011	 wd 0.0000	time 0.1348 (0.2006)	loss 0.8872 (0.8700)	grad_norm 0.2798 (0.2780)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:27:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][1900/2502]	eta 0:01:59 lr 0.000011	 wd 0.0000	time 0.1139 (0.1987)	loss 0.7944 (0.8696)	grad_norm 0.2766 (0.2779)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:27:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2000/2502]	eta 0:01:38 lr 0.000011	 wd 0.0000	time 0.1877 (0.1971)	loss 0.9712 (0.8693)	grad_norm 0.2777 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:27:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2100/2502]	eta 0:01:19 lr 0.000011	 wd 0.0000	time 0.1822 (0.1976)	loss 1.0371 (0.8693)	grad_norm 0.2574 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:28:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2200/2502]	eta 0:00:59 lr 0.000011	 wd 0.0000	time 0.2142 (0.1983)	loss 0.9395 (0.8687)	grad_norm 0.2833 (0.2777)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:28:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2300/2502]	eta 0:00:39 lr 0.000011	 wd 0.0000	time 0.1236 (0.1968)	loss 0.8638 (0.8689)	grad_norm 0.2729 (0.2777)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:28:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2400/2502]	eta 0:00:19 lr 0.000011	 wd 0.0000	time 0.2164 (0.1955)	loss 0.8599 (0.8690)	grad_norm 0.2809 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:28:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [23/30][2500/2502]	eta 0:00:00 lr 0.000010	 wd 0.0000	time 0.0806 (0.1924)	loss 0.7993 (0.8688)	grad_norm 0.2836 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 22:29:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 23 training takes 0:08:08
[2024-07-30 22:29:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 39.592 (39.592)	Loss 0.3547 (0.3547)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 22:30:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.328 Acc@5 97.666
[2024-07-30 22:30:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 22:30:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 22:30:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][0/2502]	eta 11:57:06 lr 0.000010	 wd 0.0000	time 17.1968 (17.1968)	loss 0.8716 (0.8716)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:30:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][100/2502]	eta 0:12:37 lr 0.000010	 wd 0.0000	time 0.1447 (0.3153)	loss 0.9790 (0.8639)	grad_norm 0.2651 (0.2779)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:30:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][200/2502]	eta 0:09:18 lr 0.000010	 wd 0.0000	time 0.2140 (0.2425)	loss 0.8867 (0.8663)	grad_norm 0.2799 (0.2774)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:31:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][300/2502]	eta 0:10:52 lr 0.000010	 wd 0.0000	time 0.1278 (0.2962)	loss 0.7949 (0.8696)	grad_norm 0.2906 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:31:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][400/2502]	eta 0:09:06 lr 0.000010	 wd 0.0000	time 0.1154 (0.2602)	loss 0.7329 (0.8705)	grad_norm 0.2753 (0.2780)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:32:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][500/2502]	eta 0:07:58 lr 0.000010	 wd 0.0000	time 0.1042 (0.2389)	loss 0.8813 (0.8724)	grad_norm 0.2929 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:32:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][600/2502]	eta 0:07:06 lr 0.000010	 wd 0.0000	time 0.1589 (0.2241)	loss 0.8989 (0.8701)	grad_norm 0.2681 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:32:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][700/2502]	eta 0:06:38 lr 0.000010	 wd 0.0000	time 0.2699 (0.2209)	loss 0.8301 (0.8695)	grad_norm 0.2769 (0.2780)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:33:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][800/2502]	eta 0:06:39 lr 0.000010	 wd 0.0000	time 0.1170 (0.2345)	loss 0.8037 (0.8687)	grad_norm 0.2875 (0.2779)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:33:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][900/2502]	eta 0:06:00 lr 0.000009	 wd 0.0000	time 0.1315 (0.2251)	loss 0.9307 (0.8695)	grad_norm 0.2788 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:33:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1000/2502]	eta 0:05:27 lr 0.000009	 wd 0.0000	time 0.1103 (0.2182)	loss 0.8125 (0.8703)	grad_norm 0.2745 (0.2778)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:33:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1100/2502]	eta 0:04:57 lr 0.000009	 wd 0.0000	time 0.1513 (0.2119)	loss 0.8115 (0.8702)	grad_norm 0.2803 (0.2780)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:34:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1200/2502]	eta 0:04:34 lr 0.000009	 wd 0.0000	time 0.2130 (0.2106)	loss 0.8271 (0.8699)	grad_norm 0.2632 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:34:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1300/2502]	eta 0:04:16 lr 0.000009	 wd 0.0000	time 0.1315 (0.2137)	loss 0.7319 (0.8685)	grad_norm 0.2815 (0.2780)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:34:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1400/2502]	eta 0:03:50 lr 0.000009	 wd 0.0000	time 0.1597 (0.2093)	loss 0.7656 (0.8688)	grad_norm 0.2723 (0.2780)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:35:13 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1500/2502]	eta 0:03:26 lr 0.000009	 wd 0.0000	time 0.1399 (0.2059)	loss 0.8208 (0.8688)	grad_norm 0.2796 (0.2780)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:35:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1600/2502]	eta 0:03:02 lr 0.000009	 wd 0.0000	time 0.1654 (0.2029)	loss 0.9019 (0.8688)	grad_norm 0.2742 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:35:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1700/2502]	eta 0:02:41 lr 0.000008	 wd 0.0000	time 0.1485 (0.2011)	loss 0.9478 (0.8691)	grad_norm 0.2815 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:36:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1800/2502]	eta 0:02:22 lr 0.000008	 wd 0.0000	time 0.1844 (0.2027)	loss 0.7715 (0.8694)	grad_norm 0.2659 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:36:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][1900/2502]	eta 0:02:00 lr 0.000008	 wd 0.0000	time 0.1794 (0.2009)	loss 0.7476 (0.8691)	grad_norm 0.2681 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:36:42 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2000/2502]	eta 0:01:39 lr 0.000008	 wd 0.0000	time 0.2159 (0.1990)	loss 0.7070 (0.8689)	grad_norm 0.2729 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:36:59 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2100/2502]	eta 0:01:19 lr 0.000008	 wd 0.0000	time 0.2825 (0.1975)	loss 0.9731 (0.8687)	grad_norm 0.2772 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:37:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2200/2502]	eta 0:00:59 lr 0.000008	 wd 0.0000	time 0.2379 (0.1960)	loss 0.8652 (0.8686)	grad_norm 0.2733 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:37:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2300/2502]	eta 0:00:39 lr 0.000008	 wd 0.0000	time 0.1835 (0.1958)	loss 0.9014 (0.8687)	grad_norm 0.2777 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:37:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2400/2502]	eta 0:00:20 lr 0.000008	 wd 0.0000	time 0.1846 (0.1962)	loss 1.0391 (0.8686)	grad_norm 0.2765 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:38:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [24/30][2500/2502]	eta 0:00:00 lr 0.000008	 wd 0.0000	time 0.0813 (0.1932)	loss 0.9780 (0.8685)	grad_norm 0.2715 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:38:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 24 training takes 0:08:10
[2024-07-30 22:38:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 19.489 (19.489)	Loss 0.3555 (0.3555)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 22:38:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.338 Acc@5 97.660
[2024-07-30 22:38:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 22:38:53 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 22:39:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][0/2502]	eta 1 day, 0:12:58 lr 0.000008	 wd 0.0000	time 34.8436 (34.8436)	loss 0.8657 (0.8657)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:39:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][100/2502]	eta 0:20:02 lr 0.000008	 wd 0.0000	time 0.1148 (0.5004)	loss 0.8281 (0.8841)	grad_norm 0.2689 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:39:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][200/2502]	eta 0:12:31 lr 0.000007	 wd 0.0000	time 0.1320 (0.3264)	loss 0.8257 (0.8798)	grad_norm 0.2841 (0.2783)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:40:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][300/2502]	eta 0:09:54 lr 0.000007	 wd 0.0000	time 0.1086 (0.2700)	loss 0.8984 (0.8724)	grad_norm 0.2814 (0.2786)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:40:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][400/2502]	eta 0:08:27 lr 0.000007	 wd 0.0000	time 0.1691 (0.2415)	loss 0.7437 (0.8732)	grad_norm 0.2808 (0.2785)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:41:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][500/2502]	eta 0:09:02 lr 0.000007	 wd 0.0000	time 0.1700 (0.2710)	loss 0.8486 (0.8726)	grad_norm 0.2645 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:41:25 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][600/2502]	eta 0:08:00 lr 0.000007	 wd 0.0000	time 0.1307 (0.2526)	loss 0.7349 (0.8723)	grad_norm 0.2859 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:41:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][700/2502]	eta 0:07:10 lr 0.000007	 wd 0.0000	time 0.1758 (0.2387)	loss 0.8281 (0.8712)	grad_norm 0.2794 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:41:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][800/2502]	eta 0:06:27 lr 0.000007	 wd 0.0000	time 0.1276 (0.2277)	loss 0.9731 (0.8709)	grad_norm 0.2688 (0.2782)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:42:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][900/2502]	eta 0:05:53 lr 0.000007	 wd 0.0000	time 0.1939 (0.2205)	loss 0.7246 (0.8705)	grad_norm 0.2816 (0.2783)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:42:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1000/2502]	eta 0:05:53 lr 0.000007	 wd 0.0000	time 0.1568 (0.2353)	loss 0.9292 (0.8710)	grad_norm 0.2856 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:43:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1100/2502]	eta 0:05:20 lr 0.000007	 wd 0.0000	time 0.1979 (0.2283)	loss 0.9932 (0.8705)	grad_norm 0.2783 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:43:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1200/2502]	eta 0:04:49 lr 0.000006	 wd 0.0000	time 0.1265 (0.2221)	loss 1.0039 (0.8714)	grad_norm 0.2793 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:43:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1300/2502]	eta 0:04:20 lr 0.000006	 wd 0.0000	time 0.2024 (0.2166)	loss 0.8730 (0.8703)	grad_norm 0.2711 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:43:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1400/2502]	eta 0:03:55 lr 0.000006	 wd 0.0000	time 0.2584 (0.2133)	loss 0.9219 (0.8700)	grad_norm 0.2643 (0.2783)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:44:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1500/2502]	eta 0:03:45 lr 0.000006	 wd 0.0000	time 0.1570 (0.2250)	loss 0.9526 (0.8708)	grad_norm 0.2768 (nan)	loss_scale 32768.0000 (32811.6616)	mem 3061MB
[2024-07-30 22:44:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1600/2502]	eta 0:03:19 lr 0.000006	 wd 0.0000	time 0.1805 (0.2207)	loss 0.7368 (0.8704)	grad_norm 0.2681 (nan)	loss_scale 32768.0000 (32808.9344)	mem 3061MB
[2024-07-30 22:45:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1700/2502]	eta 0:02:54 lr 0.000006	 wd 0.0000	time 0.1356 (0.2171)	loss 0.8105 (0.8712)	grad_norm 0.2681 (nan)	loss_scale 32768.0000 (32806.5279)	mem 3061MB
[2024-07-30 22:45:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1800/2502]	eta 0:02:30 lr 0.000006	 wd 0.0000	time 0.2566 (0.2139)	loss 0.8989 (0.8707)	grad_norm 0.2705 (nan)	loss_scale 32768.0000 (32804.3887)	mem 3061MB
[2024-07-30 22:45:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][1900/2502]	eta 0:02:08 lr 0.000006	 wd 0.0000	time 0.2633 (0.2131)	loss 0.9985 (0.8706)	grad_norm 0.2756 (nan)	loss_scale 32768.0000 (32802.4745)	mem 3061MB
[2024-07-30 22:46:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2000/2502]	eta 0:01:47 lr 0.000006	 wd 0.0000	time 0.1438 (0.2132)	loss 0.9839 (0.8706)	grad_norm 0.2791 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 22:46:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2100/2502]	eta 0:01:24 lr 0.000006	 wd 0.0000	time 0.1603 (0.2110)	loss 0.8999 (0.8701)	grad_norm 0.2774 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 22:46:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2200/2502]	eta 0:01:03 lr 0.000006	 wd 0.0000	time 0.1913 (0.2090)	loss 0.8276 (0.8698)	grad_norm 0.2599 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 22:46:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2300/2502]	eta 0:00:41 lr 0.000005	 wd 0.0000	time 0.1535 (0.2070)	loss 0.7759 (0.8696)	grad_norm 0.2693 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 22:47:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2400/2502]	eta 0:00:21 lr 0.000005	 wd 0.0000	time 0.1810 (0.2060)	loss 0.8257 (0.8695)	grad_norm 0.2665 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 22:47:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [25/30][2500/2502]	eta 0:00:00 lr 0.000005	 wd 0.0000	time 0.0817 (0.2030)	loss 0.8545 (0.8699)	grad_norm 0.2864 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 22:47:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 25 training takes 0:08:43
[2024-07-30 22:47:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 22.188 (22.188)	Loss 0.3552 (0.3552)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 22:48:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.320 Acc@5 97.660
[2024-07-30 22:48:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 22:48:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 22:48:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][0/2502]	eta 13:47:37 lr 0.000005	 wd 0.0000	time 19.8473 (19.8473)	loss 1.0166 (1.0166)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:49:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][100/2502]	eta 0:21:11 lr 0.000005	 wd 0.0000	time 0.1119 (0.5295)	loss 0.7725 (0.8777)	grad_norm 0.2749 (0.2819)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:49:26 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][200/2502]	eta 0:13:09 lr 0.000005	 wd 0.0000	time 0.1183 (0.3431)	loss 0.8472 (0.8738)	grad_norm 0.2845 (0.2806)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:49:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][300/2502]	eta 0:10:13 lr 0.000005	 wd 0.0000	time 0.1403 (0.2786)	loss 0.8545 (0.8752)	grad_norm 0.2942 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:49:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][400/2502]	eta 0:08:39 lr 0.000005	 wd 0.0000	time 0.1658 (0.2470)	loss 0.8984 (0.8730)	grad_norm 0.2841 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:50:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][500/2502]	eta 0:07:38 lr 0.000005	 wd 0.0000	time 0.1464 (0.2289)	loss 0.8232 (0.8712)	grad_norm 0.2680 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:50:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][600/2502]	eta 0:08:01 lr 0.000005	 wd 0.0000	time 0.1717 (0.2530)	loss 0.8569 (0.8720)	grad_norm 0.2767 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:51:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][700/2502]	eta 0:07:12 lr 0.000005	 wd 0.0000	time 0.1991 (0.2399)	loss 0.8130 (0.8702)	grad_norm 0.2743 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:51:20 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][800/2502]	eta 0:06:30 lr 0.000005	 wd 0.0000	time 0.1722 (0.2292)	loss 0.8477 (0.8713)	grad_norm 0.2887 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:51:35 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][900/2502]	eta 0:05:53 lr 0.000005	 wd 0.0000	time 0.1146 (0.2204)	loss 0.7842 (0.8698)	grad_norm 0.2816 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:51:52 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1000/2502]	eta 0:05:22 lr 0.000004	 wd 0.0000	time 0.1887 (0.2147)	loss 0.9668 (0.8701)	grad_norm 0.2721 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:52:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1100/2502]	eta 0:05:18 lr 0.000004	 wd 0.0000	time 0.1577 (0.2273)	loss 0.9673 (0.8708)	grad_norm 0.2709 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:52:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1200/2502]	eta 0:04:48 lr 0.000004	 wd 0.0000	time 0.1200 (0.2215)	loss 0.9038 (0.8705)	grad_norm 0.2738 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:52:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1300/2502]	eta 0:04:20 lr 0.000004	 wd 0.0000	time 0.1425 (0.2163)	loss 0.7500 (0.8708)	grad_norm 0.2808 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:53:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1400/2502]	eta 0:03:53 lr 0.000004	 wd 0.0000	time 0.1913 (0.2119)	loss 0.9619 (0.8706)	grad_norm 0.2736 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:53:31 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1500/2502]	eta 0:03:29 lr 0.000004	 wd 0.0000	time 0.1520 (0.2090)	loss 0.8457 (0.8709)	grad_norm 0.2679 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:54:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1600/2502]	eta 0:03:18 lr 0.000004	 wd 0.0000	time 0.2425 (0.2196)	loss 0.7344 (0.8699)	grad_norm 0.2648 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:54:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1700/2502]	eta 0:02:53 lr 0.000004	 wd 0.0000	time 0.1303 (0.2161)	loss 0.8467 (0.8706)	grad_norm 0.2729 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:54:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1800/2502]	eta 0:02:29 lr 0.000004	 wd 0.0000	time 0.2030 (0.2130)	loss 0.9199 (0.8711)	grad_norm 0.2748 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:54:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][1900/2502]	eta 0:02:06 lr 0.000004	 wd 0.0000	time 0.1359 (0.2102)	loss 0.8691 (0.8704)	grad_norm 0.2783 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:55:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2000/2502]	eta 0:01:45 lr 0.000004	 wd 0.0000	time 0.1850 (0.2093)	loss 0.9087 (0.8703)	grad_norm 0.2820 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:55:38 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2100/2502]	eta 0:01:24 lr 0.000004	 wd 0.0000	time 0.2696 (0.2098)	loss 0.9077 (0.8705)	grad_norm 0.2930 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:55:55 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2200/2502]	eta 0:01:02 lr 0.000004	 wd 0.0000	time 0.2289 (0.2080)	loss 0.9380 (0.8704)	grad_norm 0.2765 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:56:11 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2300/2502]	eta 0:00:41 lr 0.000004	 wd 0.0000	time 0.1315 (0.2061)	loss 0.8369 (0.8701)	grad_norm 0.2831 (0.2789)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:56:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2400/2502]	eta 0:00:20 lr 0.000003	 wd 0.0000	time 0.1822 (0.2043)	loss 0.8652 (0.8705)	grad_norm 0.2884 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:56:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [26/30][2500/2502]	eta 0:00:00 lr 0.000003	 wd 0.0000	time 0.0818 (0.2008)	loss 0.9272 (0.8705)	grad_norm 0.2775 (0.2790)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:56:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 26 training takes 0:08:31
[2024-07-30 22:57:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 40.626 (40.626)	Loss 0.3550 (0.3550)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 22:57:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.334 Acc@5 97.662
[2024-07-30 22:57:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 22:57:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 22:58:03 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][0/2502]	eta 11:03:18 lr 0.000003	 wd 0.0000	time 15.9066 (15.9066)	loss 0.9097 (0.9097)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:58:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][100/2502]	eta 0:13:40 lr 0.000003	 wd 0.0000	time 0.1918 (0.3415)	loss 0.8779 (0.8746)	grad_norm 0.2736 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:58:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][200/2502]	eta 0:13:29 lr 0.000003	 wd 0.0000	time 0.1845 (0.3517)	loss 0.7065 (0.8697)	grad_norm 0.2845 (0.2781)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:59:12 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][300/2502]	eta 0:10:27 lr 0.000003	 wd 0.0000	time 0.1392 (0.2849)	loss 0.8750 (0.8703)	grad_norm 0.2816 (0.2784)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:59:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][400/2502]	eta 0:08:51 lr 0.000003	 wd 0.0000	time 0.2163 (0.2527)	loss 0.8169 (0.8690)	grad_norm 0.2787 (0.2787)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 22:59:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][500/2502]	eta 0:07:44 lr 0.000003	 wd 0.0000	time 0.1873 (0.2321)	loss 0.7500 (0.8682)	grad_norm 0.2924 (nan)	loss_scale 32768.0000 (32898.8104)	mem 3061MB
[2024-07-30 23:00:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][600/2502]	eta 0:07:03 lr 0.000003	 wd 0.0000	time 0.1744 (0.2227)	loss 0.8037 (0.8706)	grad_norm 0.2899 (nan)	loss_scale 32768.0000 (32877.0449)	mem 3061MB
[2024-07-30 23:00:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][700/2502]	eta 0:07:08 lr 0.000003	 wd 0.0000	time 0.1268 (0.2378)	loss 0.8291 (0.8701)	grad_norm 0.2907 (nan)	loss_scale 32768.0000 (32861.4893)	mem 3061MB
[2024-07-30 23:00:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][800/2502]	eta 0:06:26 lr 0.000003	 wd 0.0000	time 0.1517 (0.2271)	loss 0.8789 (0.8696)	grad_norm 0.2703 (nan)	loss_scale 32768.0000 (32849.8177)	mem 3061MB
[2024-07-30 23:01:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][900/2502]	eta 0:05:50 lr 0.000003	 wd 0.0000	time 0.1467 (0.2190)	loss 0.7275 (0.8692)	grad_norm 0.2677 (nan)	loss_scale 32768.0000 (32840.7370)	mem 3061MB
[2024-07-30 23:01:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1000/2502]	eta 0:05:18 lr 0.000003	 wd 0.0000	time 0.1762 (0.2121)	loss 0.8745 (0.8688)	grad_norm 0.2734 (nan)	loss_scale 32768.0000 (32833.4705)	mem 3061MB
[2024-07-30 23:01:36 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1100/2502]	eta 0:04:52 lr 0.000003	 wd 0.0000	time 0.2320 (0.2085)	loss 0.7661 (0.8688)	grad_norm 0.2844 (nan)	loss_scale 32768.0000 (32827.5241)	mem 3061MB
[2024-07-30 23:02:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1200/2502]	eta 0:04:50 lr 0.000003	 wd 0.0000	time 0.1980 (0.2230)	loss 0.8950 (0.8681)	grad_norm 0.2766 (nan)	loss_scale 32768.0000 (32822.5679)	mem 3061MB
[2024-07-30 23:02:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1300/2502]	eta 0:04:21 lr 0.000003	 wd 0.0000	time 0.1380 (0.2178)	loss 0.8418 (0.8681)	grad_norm 0.2715 (nan)	loss_scale 32768.0000 (32818.3736)	mem 3061MB
[2024-07-30 23:02:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1400/2502]	eta 0:03:55 lr 0.000003	 wd 0.0000	time 0.1804 (0.2133)	loss 0.8154 (0.8680)	grad_norm 0.2813 (nan)	loss_scale 32768.0000 (32814.7780)	mem 3061MB
[2024-07-30 23:03:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1500/2502]	eta 0:03:29 lr 0.000003	 wd 0.0000	time 0.1520 (0.2093)	loss 0.9565 (0.8681)	grad_norm 0.2755 (nan)	loss_scale 32768.0000 (32811.6616)	mem 3061MB
[2024-07-30 23:03:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1600/2502]	eta 0:03:07 lr 0.000003	 wd 0.0000	time 0.2083 (0.2076)	loss 0.8755 (0.8681)	grad_norm 0.2746 (nan)	loss_scale 32768.0000 (32808.9344)	mem 3061MB
[2024-07-30 23:03:41 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1700/2502]	eta 0:02:46 lr 0.000002	 wd 0.0000	time 0.1596 (0.2082)	loss 0.8711 (0.8683)	grad_norm 0.2844 (nan)	loss_scale 32768.0000 (32806.5279)	mem 3061MB
[2024-07-30 23:03:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1800/2502]	eta 0:02:24 lr 0.000002	 wd 0.0000	time 0.1733 (0.2057)	loss 0.7637 (0.8686)	grad_norm 0.2787 (nan)	loss_scale 32768.0000 (32804.3887)	mem 3061MB
[2024-07-30 23:04:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][1900/2502]	eta 0:02:02 lr 0.000002	 wd 0.0000	time 0.1874 (0.2036)	loss 0.8091 (0.8688)	grad_norm 0.2808 (nan)	loss_scale 32768.0000 (32802.4745)	mem 3061MB
[2024-07-30 23:04:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2000/2502]	eta 0:01:41 lr 0.000002	 wd 0.0000	time 0.1704 (0.2016)	loss 0.7607 (0.8685)	grad_norm 0.2691 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 23:04:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2100/2502]	eta 0:01:20 lr 0.000002	 wd 0.0000	time 0.2142 (0.2002)	loss 1.0049 (0.8693)	grad_norm 0.2940 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 23:05:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2200/2502]	eta 0:01:00 lr 0.000002	 wd 0.0000	time 0.1642 (0.2015)	loss 0.7349 (0.8688)	grad_norm 0.2728 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 23:05:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2300/2502]	eta 0:00:40 lr 0.000002	 wd 0.0000	time 0.1162 (0.2001)	loss 0.8203 (0.8691)	grad_norm 0.2776 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 23:05:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2400/2502]	eta 0:00:20 lr 0.000002	 wd 0.0000	time 0.1284 (0.1986)	loss 0.8857 (0.8687)	grad_norm 0.2841 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 23:05:56 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [27/30][2500/2502]	eta 0:00:00 lr 0.000002	 wd 0.0000	time 0.0817 (0.1955)	loss 0.8555 (0.8689)	grad_norm 0.2737 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 23:06:04 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 27 training takes 0:08:17
[2024-07-30 23:06:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 30.546 (30.546)	Loss 0.3547 (0.3547)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 23:07:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.322 Acc@5 97.656
[2024-07-30 23:07:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 23:07:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 23:07:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][0/2502]	eta 11:22:35 lr 0.000002	 wd 0.0000	time 16.3692 (16.3692)	loss 0.8403 (0.8403)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:07:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][100/2502]	eta 0:13:11 lr 0.000002	 wd 0.0000	time 0.1513 (0.3294)	loss 0.8887 (0.8656)	grad_norm 0.2797 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:07:49 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][200/2502]	eta 0:09:16 lr 0.000002	 wd 0.0000	time 0.1820 (0.2417)	loss 0.8345 (0.8709)	grad_norm 0.2811 (0.2797)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:08:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][300/2502]	eta 0:08:30 lr 0.000002	 wd 0.0000	time 0.3538 (0.2318)	loss 0.9956 (0.8726)	grad_norm 0.2776 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:08:43 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][400/2502]	eta 0:08:58 lr 0.000002	 wd 0.0000	time 0.1815 (0.2560)	loss 0.7642 (0.8677)	grad_norm 0.2744 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:08:58 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][500/2502]	eta 0:07:50 lr 0.000002	 wd 0.0000	time 0.1068 (0.2349)	loss 0.8730 (0.8702)	grad_norm 0.2719 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:09:14 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][600/2502]	eta 0:07:00 lr 0.000002	 wd 0.0000	time 0.1771 (0.2213)	loss 0.9204 (0.8712)	grad_norm 0.2751 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:09:28 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][700/2502]	eta 0:06:20 lr 0.000002	 wd 0.0000	time 0.1050 (0.2109)	loss 0.8545 (0.8702)	grad_norm 0.2762 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:09:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][800/2502]	eta 0:05:55 lr 0.000002	 wd 0.0000	time 0.1873 (0.2091)	loss 0.8394 (0.8708)	grad_norm 0.2758 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:10:15 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][900/2502]	eta 0:05:46 lr 0.000002	 wd 0.0000	time 0.2021 (0.2162)	loss 0.8115 (0.8707)	grad_norm 0.2833 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:10:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1000/2502]	eta 0:05:14 lr 0.000002	 wd 0.0000	time 0.1563 (0.2097)	loss 0.8389 (0.8704)	grad_norm 0.2649 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:10:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1100/2502]	eta 0:04:46 lr 0.000002	 wd 0.0000	time 0.1161 (0.2046)	loss 0.8101 (0.8686)	grad_norm 0.2850 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:11:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1200/2502]	eta 0:04:20 lr 0.000002	 wd 0.0000	time 0.1459 (0.2003)	loss 0.8516 (0.8687)	grad_norm 0.2860 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:11:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1300/2502]	eta 0:03:58 lr 0.000002	 wd 0.0000	time 0.2268 (0.1987)	loss 0.9590 (0.8691)	grad_norm 0.2804 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:11:44 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1400/2502]	eta 0:03:43 lr 0.000002	 wd 0.0000	time 0.1601 (0.2026)	loss 0.7808 (0.8683)	grad_norm 0.2761 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:12:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1500/2502]	eta 0:03:19 lr 0.000002	 wd 0.0000	time 0.1380 (0.1994)	loss 0.7769 (0.8685)	grad_norm 0.2933 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:12:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1600/2502]	eta 0:02:57 lr 0.000002	 wd 0.0000	time 0.1088 (0.1968)	loss 1.0049 (0.8688)	grad_norm 0.2844 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:12:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1700/2502]	eta 0:02:36 lr 0.000001	 wd 0.0000	time 0.2722 (0.1948)	loss 0.9258 (0.8689)	grad_norm 0.2909 (0.2791)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:12:48 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1800/2502]	eta 0:02:15 lr 0.000001	 wd 0.0000	time 0.1525 (0.1930)	loss 0.7612 (0.8685)	grad_norm 0.2858 (0.2792)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:13:07 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][1900/2502]	eta 0:01:56 lr 0.000001	 wd 0.0000	time 0.1510 (0.1929)	loss 0.8525 (0.8695)	grad_norm 0.2684 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:13:29 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2000/2502]	eta 0:01:37 lr 0.000001	 wd 0.0000	time 0.1613 (0.1939)	loss 0.7959 (0.8687)	grad_norm 0.2752 (nan)	loss_scale 32768.0000 (32800.7516)	mem 3061MB
[2024-07-30 23:13:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2100/2502]	eta 0:01:17 lr 0.000001	 wd 0.0000	time 0.1581 (0.1924)	loss 0.8320 (0.8685)	grad_norm 0.2848 (nan)	loss_scale 32768.0000 (32799.1928)	mem 3061MB
[2024-07-30 23:14:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2200/2502]	eta 0:00:57 lr 0.000001	 wd 0.0000	time 0.1345 (0.1912)	loss 0.8799 (0.8680)	grad_norm 0.2826 (nan)	loss_scale 32768.0000 (32797.7756)	mem 3061MB
[2024-07-30 23:14:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2300/2502]	eta 0:00:38 lr 0.000001	 wd 0.0000	time 0.1368 (0.1901)	loss 0.8018 (0.8678)	grad_norm 0.2784 (nan)	loss_scale 32768.0000 (32796.4815)	mem 3061MB
[2024-07-30 23:14:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2400/2502]	eta 0:00:19 lr 0.000001	 wd 0.0000	time 0.3215 (0.1901)	loss 0.9688 (0.8674)	grad_norm 0.2768 (nan)	loss_scale 32768.0000 (32795.2953)	mem 3061MB
[2024-07-30 23:14:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [28/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.0818 (0.1876)	loss 0.8330 (0.8675)	grad_norm 0.2676 (nan)	loss_scale 32768.0000 (32794.2039)	mem 3061MB
[2024-07-30 23:15:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 28 training takes 0:08:04
[2024-07-30 23:15:27 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 21.503 (21.503)	Loss 0.3555 (0.3555)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 23:15:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.326 Acc@5 97.658
[2024-07-30 23:15:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 23:15:45 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 23:16:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][0/2502]	eta 16:22:38 lr 0.000001	 wd 0.0000	time 23.5646 (23.5646)	loss 0.9434 (0.9434)	grad_norm 0.0000 (0.0000)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:16:39 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][100/2502]	eta 0:21:14 lr 0.000001	 wd 0.0000	time 0.2103 (0.5307)	loss 0.8350 (0.8763)	grad_norm 0.2833 (0.2802)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:16:54 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][200/2502]	eta 0:13:11 lr 0.000001	 wd 0.0000	time 0.1110 (0.3440)	loss 0.8887 (0.8759)	grad_norm 0.2880 (0.2800)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:17:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][300/2502]	eta 0:10:15 lr 0.000001	 wd 0.0000	time 0.1475 (0.2794)	loss 0.8428 (0.8760)	grad_norm 0.2789 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:17:24 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][400/2502]	eta 0:08:40 lr 0.000001	 wd 0.0000	time 0.1953 (0.2479)	loss 0.8618 (0.8756)	grad_norm 0.2729 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:17:40 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][500/2502]	eta 0:07:40 lr 0.000001	 wd 0.0000	time 0.1466 (0.2299)	loss 0.8345 (0.8753)	grad_norm 0.2834 (0.2798)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:18:19 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][600/2502]	eta 0:08:07 lr 0.000001	 wd 0.0000	time 1.5320 (0.2565)	loss 0.7422 (0.8743)	grad_norm 0.2845 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:18:34 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][700/2502]	eta 0:07:15 lr 0.000001	 wd 0.0000	time 0.1560 (0.2417)	loss 0.8345 (0.8735)	grad_norm 0.2742 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:18:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][800/2502]	eta 0:06:32 lr 0.000001	 wd 0.0000	time 0.1719 (0.2305)	loss 0.8154 (0.8739)	grad_norm 0.2673 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:19:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][900/2502]	eta 0:05:55 lr 0.000001	 wd 0.0000	time 0.1375 (0.2218)	loss 0.8647 (0.8741)	grad_norm 0.2860 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:19:21 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1000/2502]	eta 0:05:24 lr 0.000001	 wd 0.0000	time 0.1385 (0.2159)	loss 0.8174 (0.8744)	grad_norm 0.2858 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:20:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1100/2502]	eta 0:05:25 lr 0.000001	 wd 0.0000	time 0.1422 (0.2323)	loss 0.9819 (0.8738)	grad_norm 0.2726 (0.2793)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:20:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1200/2502]	eta 0:04:54 lr 0.000001	 wd 0.0000	time 0.1719 (0.2258)	loss 0.7490 (0.8726)	grad_norm 0.2825 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:20:32 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1300/2502]	eta 0:04:24 lr 0.000001	 wd 0.0000	time 0.1385 (0.2205)	loss 0.8706 (0.8725)	grad_norm 0.2870 (0.2796)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:20:47 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1400/2502]	eta 0:03:57 lr 0.000001	 wd 0.0000	time 0.1627 (0.2156)	loss 0.9585 (0.8723)	grad_norm 0.2902 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:21:05 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1500/2502]	eta 0:03:33 lr 0.000001	 wd 0.0000	time 0.1875 (0.2132)	loss 0.8003 (0.8710)	grad_norm 0.2893 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:21:30 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1600/2502]	eta 0:03:14 lr 0.000001	 wd 0.0000	time 0.1429 (0.2157)	loss 0.9014 (0.8704)	grad_norm 0.2734 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:21:46 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1700/2502]	eta 0:02:50 lr 0.000001	 wd 0.0000	time 0.1465 (0.2123)	loss 0.9043 (0.8693)	grad_norm 0.2857 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:22:02 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1800/2502]	eta 0:02:27 lr 0.000001	 wd 0.0000	time 0.1819 (0.2095)	loss 0.7598 (0.8688)	grad_norm 0.2683 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:22:18 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][1900/2502]	eta 0:02:04 lr 0.000001	 wd 0.0000	time 0.1320 (0.2069)	loss 0.7056 (0.8688)	grad_norm 0.2801 (0.2795)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:22:37 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2000/2502]	eta 0:01:43 lr 0.000001	 wd 0.0000	time 0.2455 (0.2057)	loss 0.8306 (0.8692)	grad_norm 0.2836 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:23:00 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2100/2502]	eta 0:01:23 lr 0.000001	 wd 0.0000	time 0.1543 (0.2069)	loss 0.7954 (0.8693)	grad_norm 0.2682 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:23:17 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2200/2502]	eta 0:01:01 lr 0.000001	 wd 0.0000	time 0.2497 (0.2053)	loss 0.7515 (0.8688)	grad_norm 0.2785 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:23:33 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2300/2502]	eta 0:00:41 lr 0.000001	 wd 0.0000	time 0.1312 (0.2035)	loss 0.7173 (0.8691)	grad_norm 0.2894 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:23:50 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2400/2502]	eta 0:00:20 lr 0.000001	 wd 0.0000	time 0.1561 (0.2019)	loss 0.7725 (0.8690)	grad_norm 0.2829 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:24:01 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 240): INFO Train: [29/30][2500/2502]	eta 0:00:00 lr 0.000001	 wd 0.0000	time 0.0820 (0.1985)	loss 0.9551 (0.8688)	grad_norm 0.2859 (0.2794)	loss_scale 32768.0000 (32768.0000)	mem 3061MB
[2024-07-30 23:24:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 249): INFO EPOCH 29 training takes 0:08:24
[2024-07-30 23:24:09 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 145): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_29.pth saving......
[2024-07-30 23:24:10 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (utils.py 147): INFO pretrain/diffusion-ft/adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3/diffusion_ft_adapter_conv_b_sequence_stage3/ckpt_epoch_29.pth saved !!!
[2024-07-30 23:24:57 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 289): INFO Test: [0/98]	Time 46.202 (46.202)	Loss 0.3557 (0.3557)	Acc@1 92.188 (92.188)	Acc@5 98.828 (98.828)	Mem 3061MB
[2024-07-30 23:25:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 296): INFO  * Acc@1 85.334 Acc@5 97.656
[2024-07-30 23:25:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 180): INFO Accuracy of the network on the 50000 test images: 85.3%
[2024-07-30 23:25:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 182): INFO Max accuracy: 85.35%
[2024-07-30 23:25:16 adapter_convnext_diffusion_finetune_base_224_22kto1k_finetune_step_stage_process3] (main.py 189): INFO Training time 4:34:51
