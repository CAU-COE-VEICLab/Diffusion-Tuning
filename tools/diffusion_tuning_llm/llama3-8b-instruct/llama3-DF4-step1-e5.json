{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 14.98846331333641,
  "eval_steps": 5000,
  "global_step": 12180,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0012305799107829565,
      "grad_norm": 1.0078125,
      "learning_rate": 2.7322404371584703e-08,
      "loss": 0.31,
      "step": 1
    },
    {
      "epoch": 0.012305799107829564,
      "grad_norm": 0.91015625,
      "learning_rate": 2.73224043715847e-07,
      "loss": 0.2943,
      "step": 10
    },
    {
      "epoch": 0.024611598215659128,
      "grad_norm": 0.95703125,
      "learning_rate": 5.46448087431694e-07,
      "loss": 0.2973,
      "step": 20
    },
    {
      "epoch": 0.03691739732348869,
      "grad_norm": 0.90234375,
      "learning_rate": 8.196721311475409e-07,
      "loss": 0.261,
      "step": 30
    },
    {
      "epoch": 0.049223196431318256,
      "grad_norm": 1.015625,
      "learning_rate": 1.092896174863388e-06,
      "loss": 0.2832,
      "step": 40
    },
    {
      "epoch": 0.06152899553914783,
      "grad_norm": 0.83203125,
      "learning_rate": 1.3661202185792352e-06,
      "loss": 0.3101,
      "step": 50
    },
    {
      "epoch": 0.07383479464697738,
      "grad_norm": 0.95703125,
      "learning_rate": 1.6393442622950819e-06,
      "loss": 0.288,
      "step": 60
    },
    {
      "epoch": 0.08614059375480695,
      "grad_norm": 0.9609375,
      "learning_rate": 1.912568306010929e-06,
      "loss": 0.2963,
      "step": 70
    },
    {
      "epoch": 0.09844639286263651,
      "grad_norm": 0.97265625,
      "learning_rate": 2.185792349726776e-06,
      "loss": 0.3013,
      "step": 80
    },
    {
      "epoch": 0.11075219197046608,
      "grad_norm": 0.93359375,
      "learning_rate": 2.459016393442623e-06,
      "loss": 0.2864,
      "step": 90
    },
    {
      "epoch": 0.12305799107829565,
      "grad_norm": 1.28125,
      "learning_rate": 2.7322404371584705e-06,
      "loss": 0.2434,
      "step": 100
    },
    {
      "epoch": 0.1353637901861252,
      "grad_norm": 0.94140625,
      "learning_rate": 3.0054644808743173e-06,
      "loss": 0.2672,
      "step": 110
    },
    {
      "epoch": 0.14766958929395477,
      "grad_norm": 0.9765625,
      "learning_rate": 3.2786885245901638e-06,
      "loss": 0.2836,
      "step": 120
    },
    {
      "epoch": 0.15997538840178435,
      "grad_norm": 0.9921875,
      "learning_rate": 3.551912568306011e-06,
      "loss": 0.2975,
      "step": 130
    },
    {
      "epoch": 0.1722811875096139,
      "grad_norm": 0.9921875,
      "learning_rate": 3.825136612021858e-06,
      "loss": 0.2812,
      "step": 140
    },
    {
      "epoch": 0.18458698661744347,
      "grad_norm": 0.93359375,
      "learning_rate": 4.098360655737705e-06,
      "loss": 0.3171,
      "step": 150
    },
    {
      "epoch": 0.19689278572527302,
      "grad_norm": 0.87109375,
      "learning_rate": 4.371584699453552e-06,
      "loss": 0.2979,
      "step": 160
    },
    {
      "epoch": 0.2091985848331026,
      "grad_norm": 0.9375,
      "learning_rate": 4.6448087431694e-06,
      "loss": 0.288,
      "step": 170
    },
    {
      "epoch": 0.22150438394093216,
      "grad_norm": 1.03125,
      "learning_rate": 4.918032786885246e-06,
      "loss": 0.2798,
      "step": 180
    },
    {
      "epoch": 0.23381018304876172,
      "grad_norm": 0.94921875,
      "learning_rate": 5.191256830601094e-06,
      "loss": 0.2605,
      "step": 190
    },
    {
      "epoch": 0.2461159821565913,
      "grad_norm": 0.875,
      "learning_rate": 5.464480874316941e-06,
      "loss": 0.2515,
      "step": 200
    },
    {
      "epoch": 0.25842178126442084,
      "grad_norm": 0.81640625,
      "learning_rate": 5.737704918032787e-06,
      "loss": 0.2792,
      "step": 210
    },
    {
      "epoch": 0.2707275803722504,
      "grad_norm": 0.97265625,
      "learning_rate": 6.010928961748635e-06,
      "loss": 0.2822,
      "step": 220
    },
    {
      "epoch": 0.28303337948008,
      "grad_norm": 1.03125,
      "learning_rate": 6.284153005464482e-06,
      "loss": 0.2955,
      "step": 230
    },
    {
      "epoch": 0.29533917858790953,
      "grad_norm": 0.875,
      "learning_rate": 6.5573770491803276e-06,
      "loss": 0.2904,
      "step": 240
    },
    {
      "epoch": 0.3076449776957391,
      "grad_norm": 1.0546875,
      "learning_rate": 6.830601092896175e-06,
      "loss": 0.2856,
      "step": 250
    },
    {
      "epoch": 0.3199507768035687,
      "grad_norm": 0.91015625,
      "learning_rate": 7.103825136612022e-06,
      "loss": 0.27,
      "step": 260
    },
    {
      "epoch": 0.33225657591139823,
      "grad_norm": 0.890625,
      "learning_rate": 7.3770491803278695e-06,
      "loss": 0.3003,
      "step": 270
    },
    {
      "epoch": 0.3445623750192278,
      "grad_norm": 0.9375,
      "learning_rate": 7.650273224043716e-06,
      "loss": 0.2889,
      "step": 280
    },
    {
      "epoch": 0.3568681741270574,
      "grad_norm": 1.015625,
      "learning_rate": 7.923497267759564e-06,
      "loss": 0.3041,
      "step": 290
    },
    {
      "epoch": 0.36917397323488693,
      "grad_norm": 0.97265625,
      "learning_rate": 8.19672131147541e-06,
      "loss": 0.2922,
      "step": 300
    },
    {
      "epoch": 0.3814797723427165,
      "grad_norm": 0.9453125,
      "learning_rate": 8.469945355191259e-06,
      "loss": 0.2793,
      "step": 310
    },
    {
      "epoch": 0.39378557145054605,
      "grad_norm": 1.046875,
      "learning_rate": 8.743169398907103e-06,
      "loss": 0.2735,
      "step": 320
    },
    {
      "epoch": 0.40609137055837563,
      "grad_norm": 0.921875,
      "learning_rate": 9.016393442622952e-06,
      "loss": 0.2836,
      "step": 330
    },
    {
      "epoch": 0.4183971696662052,
      "grad_norm": 0.9375,
      "learning_rate": 9.2896174863388e-06,
      "loss": 0.2811,
      "step": 340
    },
    {
      "epoch": 0.43070296877403474,
      "grad_norm": 0.79296875,
      "learning_rate": 9.562841530054644e-06,
      "loss": 0.3022,
      "step": 350
    },
    {
      "epoch": 0.44300876788186433,
      "grad_norm": 1.03125,
      "learning_rate": 9.836065573770493e-06,
      "loss": 0.2834,
      "step": 360
    },
    {
      "epoch": 0.4553145669896939,
      "grad_norm": 0.8203125,
      "learning_rate": 9.99999717143761e-06,
      "loss": 0.2715,
      "step": 370
    },
    {
      "epoch": 0.46762036609752344,
      "grad_norm": 0.96875,
      "learning_rate": 9.999965350147457e-06,
      "loss": 0.2716,
      "step": 380
    },
    {
      "epoch": 0.47992616520535303,
      "grad_norm": 0.9609375,
      "learning_rate": 9.999898172089934e-06,
      "loss": 0.2871,
      "step": 390
    },
    {
      "epoch": 0.4922319643131826,
      "grad_norm": 0.8984375,
      "learning_rate": 9.999795637740085e-06,
      "loss": 0.2956,
      "step": 400
    },
    {
      "epoch": 0.5045377634210122,
      "grad_norm": 0.7734375,
      "learning_rate": 9.999657747822969e-06,
      "loss": 0.2739,
      "step": 410
    },
    {
      "epoch": 0.5168435625288417,
      "grad_norm": 0.98828125,
      "learning_rate": 9.999484503313661e-06,
      "loss": 0.2682,
      "step": 420
    },
    {
      "epoch": 0.5291493616366713,
      "grad_norm": 0.9921875,
      "learning_rate": 9.999275905437247e-06,
      "loss": 0.3099,
      "step": 430
    },
    {
      "epoch": 0.5414551607445008,
      "grad_norm": 0.875,
      "learning_rate": 9.9990319556688e-06,
      "loss": 0.3043,
      "step": 440
    },
    {
      "epoch": 0.5537609598523304,
      "grad_norm": 0.8828125,
      "learning_rate": 9.998752655733394e-06,
      "loss": 0.2969,
      "step": 450
    },
    {
      "epoch": 0.56606675896016,
      "grad_norm": 1.0625,
      "learning_rate": 9.998438007606066e-06,
      "loss": 0.2805,
      "step": 460
    },
    {
      "epoch": 0.5783725580679896,
      "grad_norm": 0.8515625,
      "learning_rate": 9.998088013511823e-06,
      "loss": 0.3036,
      "step": 470
    },
    {
      "epoch": 0.5906783571758191,
      "grad_norm": 0.9921875,
      "learning_rate": 9.997702675925612e-06,
      "loss": 0.3181,
      "step": 480
    },
    {
      "epoch": 0.6029841562836487,
      "grad_norm": 0.984375,
      "learning_rate": 9.997281997572308e-06,
      "loss": 0.2855,
      "step": 490
    },
    {
      "epoch": 0.6152899553914782,
      "grad_norm": 0.80078125,
      "learning_rate": 9.9968259814267e-06,
      "loss": 0.2672,
      "step": 500
    },
    {
      "epoch": 0.6275957544993078,
      "grad_norm": 1.015625,
      "learning_rate": 9.996334630713464e-06,
      "loss": 0.2815,
      "step": 510
    },
    {
      "epoch": 0.6399015536071374,
      "grad_norm": 0.890625,
      "learning_rate": 9.995807948907134e-06,
      "loss": 0.2823,
      "step": 520
    },
    {
      "epoch": 0.6522073527149669,
      "grad_norm": 0.98046875,
      "learning_rate": 9.995245939732093e-06,
      "loss": 0.2779,
      "step": 530
    },
    {
      "epoch": 0.6645131518227965,
      "grad_norm": 0.9921875,
      "learning_rate": 9.99464860716253e-06,
      "loss": 0.2943,
      "step": 540
    },
    {
      "epoch": 0.676818950930626,
      "grad_norm": 0.91796875,
      "learning_rate": 9.994015955422426e-06,
      "loss": 0.2791,
      "step": 550
    },
    {
      "epoch": 0.6891247500384556,
      "grad_norm": 1.1328125,
      "learning_rate": 9.993347988985518e-06,
      "loss": 0.2721,
      "step": 560
    },
    {
      "epoch": 0.7014305491462852,
      "grad_norm": 1.359375,
      "learning_rate": 9.992644712575261e-06,
      "loss": 0.3225,
      "step": 570
    },
    {
      "epoch": 0.7137363482541148,
      "grad_norm": 1.0,
      "learning_rate": 9.99190613116481e-06,
      "loss": 0.2827,
      "step": 580
    },
    {
      "epoch": 0.7260421473619443,
      "grad_norm": 0.9453125,
      "learning_rate": 9.991132249976969e-06,
      "loss": 0.2894,
      "step": 590
    },
    {
      "epoch": 0.7383479464697739,
      "grad_norm": 0.796875,
      "learning_rate": 9.990323074484164e-06,
      "loss": 0.2577,
      "step": 600
    },
    {
      "epoch": 0.7506537455776034,
      "grad_norm": 0.78125,
      "learning_rate": 9.989478610408401e-06,
      "loss": 0.2939,
      "step": 610
    },
    {
      "epoch": 0.762959544685433,
      "grad_norm": 0.96875,
      "learning_rate": 9.988598863721223e-06,
      "loss": 0.2564,
      "step": 620
    },
    {
      "epoch": 0.7752653437932626,
      "grad_norm": 0.97265625,
      "learning_rate": 9.987683840643679e-06,
      "loss": 0.2971,
      "step": 630
    },
    {
      "epoch": 0.7875711429010921,
      "grad_norm": 0.8984375,
      "learning_rate": 9.986733547646258e-06,
      "loss": 0.2575,
      "step": 640
    },
    {
      "epoch": 0.7998769420089217,
      "grad_norm": 1.4765625,
      "learning_rate": 9.985747991448867e-06,
      "loss": 0.2967,
      "step": 650
    },
    {
      "epoch": 0.8121827411167513,
      "grad_norm": 0.8125,
      "learning_rate": 9.984727179020773e-06,
      "loss": 0.2721,
      "step": 660
    },
    {
      "epoch": 0.8244885402245808,
      "grad_norm": 0.89453125,
      "learning_rate": 9.983671117580548e-06,
      "loss": 0.2858,
      "step": 670
    },
    {
      "epoch": 0.8367943393324104,
      "grad_norm": 0.9453125,
      "learning_rate": 9.98257981459603e-06,
      "loss": 0.2622,
      "step": 680
    },
    {
      "epoch": 0.84910013844024,
      "grad_norm": 0.83203125,
      "learning_rate": 9.981453277784261e-06,
      "loss": 0.276,
      "step": 690
    },
    {
      "epoch": 0.8614059375480695,
      "grad_norm": 1.0234375,
      "learning_rate": 9.980291515111435e-06,
      "loss": 0.3005,
      "step": 700
    },
    {
      "epoch": 0.8737117366558991,
      "grad_norm": 0.890625,
      "learning_rate": 9.979094534792843e-06,
      "loss": 0.2994,
      "step": 710
    },
    {
      "epoch": 0.8860175357637287,
      "grad_norm": 0.828125,
      "learning_rate": 9.97786234529282e-06,
      "loss": 0.2732,
      "step": 720
    },
    {
      "epoch": 0.8983233348715582,
      "grad_norm": 1.0078125,
      "learning_rate": 9.976594955324667e-06,
      "loss": 0.3107,
      "step": 730
    },
    {
      "epoch": 0.9106291339793878,
      "grad_norm": 0.875,
      "learning_rate": 9.975292373850611e-06,
      "loss": 0.2959,
      "step": 740
    },
    {
      "epoch": 0.9229349330872173,
      "grad_norm": 0.9453125,
      "learning_rate": 9.973954610081732e-06,
      "loss": 0.2905,
      "step": 750
    },
    {
      "epoch": 0.9352407321950469,
      "grad_norm": 0.72265625,
      "learning_rate": 9.972581673477892e-06,
      "loss": 0.2996,
      "step": 760
    },
    {
      "epoch": 0.9475465313028765,
      "grad_norm": 0.84765625,
      "learning_rate": 9.971173573747684e-06,
      "loss": 0.2857,
      "step": 770
    },
    {
      "epoch": 0.9598523304107061,
      "grad_norm": 1.0703125,
      "learning_rate": 9.969730320848341e-06,
      "loss": 0.2666,
      "step": 780
    },
    {
      "epoch": 0.9721581295185356,
      "grad_norm": 0.9609375,
      "learning_rate": 9.968251924985691e-06,
      "loss": 0.2472,
      "step": 790
    },
    {
      "epoch": 0.9844639286263652,
      "grad_norm": 1.1875,
      "learning_rate": 9.966738396614063e-06,
      "loss": 0.2758,
      "step": 800
    },
    {
      "epoch": 0.9967697277341947,
      "grad_norm": 0.8515625,
      "learning_rate": 9.965189746436225e-06,
      "loss": 0.2715,
      "step": 810
    },
    {
      "epoch": 1.0090755268420244,
      "grad_norm": 1.0625,
      "learning_rate": 9.963605985403309e-06,
      "loss": 0.3009,
      "step": 820
    },
    {
      "epoch": 1.0213813259498539,
      "grad_norm": 0.9609375,
      "learning_rate": 9.961987124714722e-06,
      "loss": 0.2823,
      "step": 830
    },
    {
      "epoch": 1.0336871250576833,
      "grad_norm": 0.96875,
      "learning_rate": 9.960333175818084e-06,
      "loss": 0.2819,
      "step": 840
    },
    {
      "epoch": 1.045992924165513,
      "grad_norm": 1.7421875,
      "learning_rate": 9.958644150409131e-06,
      "loss": 0.262,
      "step": 850
    },
    {
      "epoch": 1.0582987232733425,
      "grad_norm": 0.86328125,
      "learning_rate": 9.956920060431641e-06,
      "loss": 0.2798,
      "step": 860
    },
    {
      "epoch": 1.0706045223811722,
      "grad_norm": 0.90625,
      "learning_rate": 9.95516091807735e-06,
      "loss": 0.2992,
      "step": 870
    },
    {
      "epoch": 1.0829103214890017,
      "grad_norm": 0.8046875,
      "learning_rate": 9.95336673578586e-06,
      "loss": 0.2724,
      "step": 880
    },
    {
      "epoch": 1.0952161205968312,
      "grad_norm": 1.140625,
      "learning_rate": 9.951537526244557e-06,
      "loss": 0.2635,
      "step": 890
    },
    {
      "epoch": 1.1075219197046609,
      "grad_norm": 1.03125,
      "learning_rate": 9.949673302388516e-06,
      "loss": 0.2975,
      "step": 900
    },
    {
      "epoch": 1.1198277188124903,
      "grad_norm": 0.88671875,
      "learning_rate": 9.947774077400416e-06,
      "loss": 0.2723,
      "step": 910
    },
    {
      "epoch": 1.13213351792032,
      "grad_norm": 1.2890625,
      "learning_rate": 9.945839864710442e-06,
      "loss": 0.2943,
      "step": 920
    },
    {
      "epoch": 1.1444393170281495,
      "grad_norm": 1.046875,
      "learning_rate": 9.943870677996189e-06,
      "loss": 0.3049,
      "step": 930
    },
    {
      "epoch": 1.156745116135979,
      "grad_norm": 5.59375,
      "learning_rate": 9.94186653118257e-06,
      "loss": 0.2667,
      "step": 940
    },
    {
      "epoch": 1.1690509152438087,
      "grad_norm": 0.921875,
      "learning_rate": 9.939827438441712e-06,
      "loss": 0.2617,
      "step": 950
    },
    {
      "epoch": 1.1813567143516381,
      "grad_norm": 1.1953125,
      "learning_rate": 9.937753414192862e-06,
      "loss": 0.2734,
      "step": 960
    },
    {
      "epoch": 1.1936625134594678,
      "grad_norm": 1.0,
      "learning_rate": 9.935644473102278e-06,
      "loss": 0.2595,
      "step": 970
    },
    {
      "epoch": 1.2059683125672973,
      "grad_norm": 0.92578125,
      "learning_rate": 9.933500630083134e-06,
      "loss": 0.2795,
      "step": 980
    },
    {
      "epoch": 1.218274111675127,
      "grad_norm": 1.078125,
      "learning_rate": 9.931321900295406e-06,
      "loss": 0.2515,
      "step": 990
    },
    {
      "epoch": 1.2305799107829565,
      "grad_norm": 0.828125,
      "learning_rate": 9.929108299145769e-06,
      "loss": 0.2519,
      "step": 1000
    },
    {
      "epoch": 1.242885709890786,
      "grad_norm": 1.640625,
      "learning_rate": 9.926859842287487e-06,
      "loss": 0.275,
      "step": 1010
    },
    {
      "epoch": 1.2551915089986156,
      "grad_norm": 1.1640625,
      "learning_rate": 9.924576545620304e-06,
      "loss": 0.269,
      "step": 1020
    },
    {
      "epoch": 1.2674973081064451,
      "grad_norm": 0.98046875,
      "learning_rate": 9.922258425290332e-06,
      "loss": 0.2918,
      "step": 1030
    },
    {
      "epoch": 1.2798031072142746,
      "grad_norm": 1.0859375,
      "learning_rate": 9.919905497689927e-06,
      "loss": 0.2794,
      "step": 1040
    },
    {
      "epoch": 1.2921089063221043,
      "grad_norm": 0.95703125,
      "learning_rate": 9.917517779457593e-06,
      "loss": 0.2783,
      "step": 1050
    },
    {
      "epoch": 1.304414705429934,
      "grad_norm": 1.1953125,
      "learning_rate": 9.915095287477843e-06,
      "loss": 0.2824,
      "step": 1060
    },
    {
      "epoch": 1.3167205045377635,
      "grad_norm": 0.98046875,
      "learning_rate": 9.912638038881095e-06,
      "loss": 0.2764,
      "step": 1070
    },
    {
      "epoch": 1.329026303645593,
      "grad_norm": 0.99609375,
      "learning_rate": 9.910146051043541e-06,
      "loss": 0.2721,
      "step": 1080
    },
    {
      "epoch": 1.3413321027534226,
      "grad_norm": 1.1171875,
      "learning_rate": 9.90761934158703e-06,
      "loss": 0.2888,
      "step": 1090
    },
    {
      "epoch": 1.353637901861252,
      "grad_norm": 1.0078125,
      "learning_rate": 9.905057928378946e-06,
      "loss": 0.2779,
      "step": 1100
    },
    {
      "epoch": 1.3659437009690816,
      "grad_norm": 1.0703125,
      "learning_rate": 9.902461829532066e-06,
      "loss": 0.2605,
      "step": 1110
    },
    {
      "epoch": 1.3782495000769113,
      "grad_norm": 1.0234375,
      "learning_rate": 9.899831063404453e-06,
      "loss": 0.2819,
      "step": 1120
    },
    {
      "epoch": 1.3905552991847407,
      "grad_norm": 0.75390625,
      "learning_rate": 9.897165648599315e-06,
      "loss": 0.2761,
      "step": 1130
    },
    {
      "epoch": 1.4028610982925704,
      "grad_norm": 0.9765625,
      "learning_rate": 9.894465603964869e-06,
      "loss": 0.2739,
      "step": 1140
    },
    {
      "epoch": 1.4151668974004,
      "grad_norm": 0.8984375,
      "learning_rate": 9.891730948594218e-06,
      "loss": 0.2686,
      "step": 1150
    },
    {
      "epoch": 1.4274726965082296,
      "grad_norm": 0.87109375,
      "learning_rate": 9.888961701825213e-06,
      "loss": 0.2619,
      "step": 1160
    },
    {
      "epoch": 1.439778495616059,
      "grad_norm": 0.89453125,
      "learning_rate": 9.886157883240312e-06,
      "loss": 0.2829,
      "step": 1170
    },
    {
      "epoch": 1.4520842947238886,
      "grad_norm": 0.93359375,
      "learning_rate": 9.883319512666445e-06,
      "loss": 0.2869,
      "step": 1180
    },
    {
      "epoch": 1.4643900938317183,
      "grad_norm": 1.1796875,
      "learning_rate": 9.88044661017487e-06,
      "loss": 0.2713,
      "step": 1190
    },
    {
      "epoch": 1.4766958929395477,
      "grad_norm": 0.99609375,
      "learning_rate": 9.87753919608104e-06,
      "loss": 0.2679,
      "step": 1200
    },
    {
      "epoch": 1.4890016920473772,
      "grad_norm": 0.92578125,
      "learning_rate": 9.874597290944447e-06,
      "loss": 0.2659,
      "step": 1210
    },
    {
      "epoch": 1.501307491155207,
      "grad_norm": 1.078125,
      "learning_rate": 9.871620915568489e-06,
      "loss": 0.2752,
      "step": 1220
    },
    {
      "epoch": 1.5136132902630366,
      "grad_norm": 1.359375,
      "learning_rate": 9.868610091000315e-06,
      "loss": 0.2769,
      "step": 1230
    },
    {
      "epoch": 1.525919089370866,
      "grad_norm": 1.046875,
      "learning_rate": 9.865564838530675e-06,
      "loss": 0.2735,
      "step": 1240
    },
    {
      "epoch": 1.5382248884786955,
      "grad_norm": 1.0234375,
      "learning_rate": 9.862485179693774e-06,
      "loss": 0.2777,
      "step": 1250
    },
    {
      "epoch": 1.5505306875865252,
      "grad_norm": 0.8203125,
      "learning_rate": 9.859371136267121e-06,
      "loss": 0.2724,
      "step": 1260
    },
    {
      "epoch": 1.5628364866943547,
      "grad_norm": 0.9140625,
      "learning_rate": 9.85622273027137e-06,
      "loss": 0.2503,
      "step": 1270
    },
    {
      "epoch": 1.5751422858021842,
      "grad_norm": 0.99609375,
      "learning_rate": 9.853039983970167e-06,
      "loss": 0.2881,
      "step": 1280
    },
    {
      "epoch": 1.5874480849100139,
      "grad_norm": 0.8828125,
      "learning_rate": 9.849822919869993e-06,
      "loss": 0.2784,
      "step": 1290
    },
    {
      "epoch": 1.5997538840178436,
      "grad_norm": 0.87109375,
      "learning_rate": 9.846571560720003e-06,
      "loss": 0.278,
      "step": 1300
    },
    {
      "epoch": 1.6120596831256728,
      "grad_norm": 0.85546875,
      "learning_rate": 9.843285929511864e-06,
      "loss": 0.254,
      "step": 1310
    },
    {
      "epoch": 1.6243654822335025,
      "grad_norm": 1.1953125,
      "learning_rate": 9.839966049479597e-06,
      "loss": 0.2802,
      "step": 1320
    },
    {
      "epoch": 1.6366712813413322,
      "grad_norm": 1.03125,
      "learning_rate": 9.836611944099413e-06,
      "loss": 0.2629,
      "step": 1330
    },
    {
      "epoch": 1.6489770804491617,
      "grad_norm": 0.99609375,
      "learning_rate": 9.833223637089537e-06,
      "loss": 0.2733,
      "step": 1340
    },
    {
      "epoch": 1.6612828795569912,
      "grad_norm": 1.0078125,
      "learning_rate": 9.829801152410053e-06,
      "loss": 0.2813,
      "step": 1350
    },
    {
      "epoch": 1.6735886786648209,
      "grad_norm": 1.0625,
      "learning_rate": 9.82634451426273e-06,
      "loss": 0.2649,
      "step": 1360
    },
    {
      "epoch": 1.6858944777726503,
      "grad_norm": 1.2734375,
      "learning_rate": 9.822853747090846e-06,
      "loss": 0.2344,
      "step": 1370
    },
    {
      "epoch": 1.6982002768804798,
      "grad_norm": 1.015625,
      "learning_rate": 9.819328875579019e-06,
      "loss": 0.301,
      "step": 1380
    },
    {
      "epoch": 1.7105060759883095,
      "grad_norm": 1.0390625,
      "learning_rate": 9.815769924653036e-06,
      "loss": 0.2886,
      "step": 1390
    },
    {
      "epoch": 1.7228118750961392,
      "grad_norm": 0.8984375,
      "learning_rate": 9.81217691947967e-06,
      "loss": 0.272,
      "step": 1400
    },
    {
      "epoch": 1.7351176742039687,
      "grad_norm": 0.8671875,
      "learning_rate": 9.80854988546651e-06,
      "loss": 0.2617,
      "step": 1410
    },
    {
      "epoch": 1.7474234733117981,
      "grad_norm": 1.1640625,
      "learning_rate": 9.804888848261769e-06,
      "loss": 0.3146,
      "step": 1420
    },
    {
      "epoch": 1.7597292724196278,
      "grad_norm": 0.7734375,
      "learning_rate": 9.801193833754116e-06,
      "loss": 0.2947,
      "step": 1430
    },
    {
      "epoch": 1.7720350715274573,
      "grad_norm": 1.1015625,
      "learning_rate": 9.797464868072489e-06,
      "loss": 0.2851,
      "step": 1440
    },
    {
      "epoch": 1.7843408706352868,
      "grad_norm": 1.046875,
      "learning_rate": 9.793701977585898e-06,
      "loss": 0.2531,
      "step": 1450
    },
    {
      "epoch": 1.7966466697431165,
      "grad_norm": 0.9453125,
      "learning_rate": 9.789905188903263e-06,
      "loss": 0.2666,
      "step": 1460
    },
    {
      "epoch": 1.808952468850946,
      "grad_norm": 1.328125,
      "learning_rate": 9.786074528873205e-06,
      "loss": 0.2866,
      "step": 1470
    },
    {
      "epoch": 1.8212582679587754,
      "grad_norm": 0.7734375,
      "learning_rate": 9.782210024583857e-06,
      "loss": 0.2656,
      "step": 1480
    },
    {
      "epoch": 1.8335640670666051,
      "grad_norm": 1.3046875,
      "learning_rate": 9.77831170336269e-06,
      "loss": 0.2693,
      "step": 1490
    },
    {
      "epoch": 1.8458698661744348,
      "grad_norm": 0.890625,
      "learning_rate": 9.774379592776296e-06,
      "loss": 0.3005,
      "step": 1500
    },
    {
      "epoch": 1.8581756652822643,
      "grad_norm": 0.84765625,
      "learning_rate": 9.770413720630218e-06,
      "loss": 0.2738,
      "step": 1510
    },
    {
      "epoch": 1.8704814643900938,
      "grad_norm": 1.03125,
      "learning_rate": 9.766414114968729e-06,
      "loss": 0.2825,
      "step": 1520
    },
    {
      "epoch": 1.8827872634979235,
      "grad_norm": 0.953125,
      "learning_rate": 9.762380804074655e-06,
      "loss": 0.289,
      "step": 1530
    },
    {
      "epoch": 1.895093062605753,
      "grad_norm": 0.91015625,
      "learning_rate": 9.758313816469158e-06,
      "loss": 0.294,
      "step": 1540
    },
    {
      "epoch": 1.9073988617135824,
      "grad_norm": 1.0625,
      "learning_rate": 9.754213180911546e-06,
      "loss": 0.3048,
      "step": 1550
    },
    {
      "epoch": 1.9197046608214121,
      "grad_norm": 0.875,
      "learning_rate": 9.75007892639906e-06,
      "loss": 0.2776,
      "step": 1560
    },
    {
      "epoch": 1.9320104599292418,
      "grad_norm": 1.0546875,
      "learning_rate": 9.745911082166681e-06,
      "loss": 0.283,
      "step": 1570
    },
    {
      "epoch": 1.944316259037071,
      "grad_norm": 1.078125,
      "learning_rate": 9.741709677686912e-06,
      "loss": 0.2775,
      "step": 1580
    },
    {
      "epoch": 1.9566220581449008,
      "grad_norm": 0.9140625,
      "learning_rate": 9.737474742669574e-06,
      "loss": 0.2823,
      "step": 1590
    },
    {
      "epoch": 1.9689278572527305,
      "grad_norm": 0.98828125,
      "learning_rate": 9.7332063070616e-06,
      "loss": 0.2846,
      "step": 1600
    },
    {
      "epoch": 1.98123365636056,
      "grad_norm": 1.171875,
      "learning_rate": 9.728904401046812e-06,
      "loss": 0.2638,
      "step": 1610
    },
    {
      "epoch": 1.9935394554683894,
      "grad_norm": 0.96875,
      "learning_rate": 9.724569055045722e-06,
      "loss": 0.2933,
      "step": 1620
    },
    {
      "epoch": 2.005845254576219,
      "grad_norm": 0.9921875,
      "learning_rate": 9.720200299715306e-06,
      "loss": 0.2808,
      "step": 1630
    },
    {
      "epoch": 2.018151053684049,
      "grad_norm": 1.0390625,
      "learning_rate": 9.715798165948788e-06,
      "loss": 0.258,
      "step": 1640
    },
    {
      "epoch": 2.030456852791878,
      "grad_norm": 0.91796875,
      "learning_rate": 9.711362684875431e-06,
      "loss": 0.2683,
      "step": 1650
    },
    {
      "epoch": 2.0427626518997077,
      "grad_norm": 0.84375,
      "learning_rate": 9.706893887860307e-06,
      "loss": 0.246,
      "step": 1660
    },
    {
      "epoch": 2.0550684510075374,
      "grad_norm": 1.015625,
      "learning_rate": 9.702391806504077e-06,
      "loss": 0.2594,
      "step": 1670
    },
    {
      "epoch": 2.0673742501153667,
      "grad_norm": 1.125,
      "learning_rate": 9.69785647264277e-06,
      "loss": 0.2802,
      "step": 1680
    },
    {
      "epoch": 2.0796800492231964,
      "grad_norm": 0.9765625,
      "learning_rate": 9.693287918347558e-06,
      "loss": 0.2499,
      "step": 1690
    },
    {
      "epoch": 2.091985848331026,
      "grad_norm": 0.96484375,
      "learning_rate": 9.68868617592453e-06,
      "loss": 0.2675,
      "step": 1700
    },
    {
      "epoch": 2.1042916474388558,
      "grad_norm": 1.0234375,
      "learning_rate": 9.684051277914451e-06,
      "loss": 0.2542,
      "step": 1710
    },
    {
      "epoch": 2.116597446546685,
      "grad_norm": 0.90234375,
      "learning_rate": 9.679383257092558e-06,
      "loss": 0.2642,
      "step": 1720
    },
    {
      "epoch": 2.1289032456545147,
      "grad_norm": 1.328125,
      "learning_rate": 9.6746821464683e-06,
      "loss": 0.2893,
      "step": 1730
    },
    {
      "epoch": 2.1412090447623444,
      "grad_norm": 0.9921875,
      "learning_rate": 9.669947979285127e-06,
      "loss": 0.2487,
      "step": 1740
    },
    {
      "epoch": 2.1535148438701737,
      "grad_norm": 1.015625,
      "learning_rate": 9.665180789020234e-06,
      "loss": 0.2791,
      "step": 1750
    },
    {
      "epoch": 2.1658206429780034,
      "grad_norm": 1.1484375,
      "learning_rate": 9.660380609384347e-06,
      "loss": 0.2708,
      "step": 1760
    },
    {
      "epoch": 2.178126442085833,
      "grad_norm": 1.125,
      "learning_rate": 9.655547474321469e-06,
      "loss": 0.2506,
      "step": 1770
    },
    {
      "epoch": 2.1904322411936623,
      "grad_norm": 0.921875,
      "learning_rate": 9.65068141800864e-06,
      "loss": 0.2554,
      "step": 1780
    },
    {
      "epoch": 2.202738040301492,
      "grad_norm": 1.1015625,
      "learning_rate": 9.645782474855705e-06,
      "loss": 0.2916,
      "step": 1790
    },
    {
      "epoch": 2.2150438394093217,
      "grad_norm": 0.84375,
      "learning_rate": 9.640850679505061e-06,
      "loss": 0.2611,
      "step": 1800
    },
    {
      "epoch": 2.2273496385171514,
      "grad_norm": 1.03125,
      "learning_rate": 9.635886066831418e-06,
      "loss": 0.2548,
      "step": 1810
    },
    {
      "epoch": 2.2396554376249806,
      "grad_norm": 1.21875,
      "learning_rate": 9.630888671941552e-06,
      "loss": 0.2783,
      "step": 1820
    },
    {
      "epoch": 2.2519612367328103,
      "grad_norm": 1.046875,
      "learning_rate": 9.625858530174053e-06,
      "loss": 0.2576,
      "step": 1830
    },
    {
      "epoch": 2.26426703584064,
      "grad_norm": 0.8984375,
      "learning_rate": 9.620795677099077e-06,
      "loss": 0.2903,
      "step": 1840
    },
    {
      "epoch": 2.2765728349484693,
      "grad_norm": 0.82421875,
      "learning_rate": 9.615700148518096e-06,
      "loss": 0.2675,
      "step": 1850
    },
    {
      "epoch": 2.288878634056299,
      "grad_norm": 0.8984375,
      "learning_rate": 9.610571980463645e-06,
      "loss": 0.2627,
      "step": 1860
    },
    {
      "epoch": 2.3011844331641287,
      "grad_norm": 1.234375,
      "learning_rate": 9.605411209199062e-06,
      "loss": 0.2502,
      "step": 1870
    },
    {
      "epoch": 2.313490232271958,
      "grad_norm": 1.3203125,
      "learning_rate": 9.600217871218238e-06,
      "loss": 0.2676,
      "step": 1880
    },
    {
      "epoch": 2.3257960313797876,
      "grad_norm": 0.82421875,
      "learning_rate": 9.594992003245358e-06,
      "loss": 0.2549,
      "step": 1890
    },
    {
      "epoch": 2.3381018304876173,
      "grad_norm": 1.1640625,
      "learning_rate": 9.589733642234637e-06,
      "loss": 0.2445,
      "step": 1900
    },
    {
      "epoch": 2.350407629595447,
      "grad_norm": 1.0390625,
      "learning_rate": 9.584442825370062e-06,
      "loss": 0.2395,
      "step": 1910
    },
    {
      "epoch": 2.3627134287032763,
      "grad_norm": 0.75,
      "learning_rate": 9.579119590065126e-06,
      "loss": 0.274,
      "step": 1920
    },
    {
      "epoch": 2.375019227811106,
      "grad_norm": 0.95703125,
      "learning_rate": 9.573763973962573e-06,
      "loss": 0.2564,
      "step": 1930
    },
    {
      "epoch": 2.3873250269189357,
      "grad_norm": 0.86328125,
      "learning_rate": 9.568376014934115e-06,
      "loss": 0.2683,
      "step": 1940
    },
    {
      "epoch": 2.3996308260267654,
      "grad_norm": 0.9765625,
      "learning_rate": 9.562955751080183e-06,
      "loss": 0.2693,
      "step": 1950
    },
    {
      "epoch": 2.4119366251345946,
      "grad_norm": 1.3125,
      "learning_rate": 9.557503220729643e-06,
      "loss": 0.2476,
      "step": 1960
    },
    {
      "epoch": 2.4242424242424243,
      "grad_norm": 1.078125,
      "learning_rate": 9.55201846243953e-06,
      "loss": 0.2638,
      "step": 1970
    },
    {
      "epoch": 2.436548223350254,
      "grad_norm": 0.8203125,
      "learning_rate": 9.546501514994779e-06,
      "loss": 0.2684,
      "step": 1980
    },
    {
      "epoch": 2.4488540224580833,
      "grad_norm": 0.9453125,
      "learning_rate": 9.540952417407944e-06,
      "loss": 0.2597,
      "step": 1990
    },
    {
      "epoch": 2.461159821565913,
      "grad_norm": 1.09375,
      "learning_rate": 9.53537120891893e-06,
      "loss": 0.2562,
      "step": 2000
    },
    {
      "epoch": 2.4734656206737426,
      "grad_norm": 0.9765625,
      "learning_rate": 9.52975792899471e-06,
      "loss": 0.309,
      "step": 2010
    },
    {
      "epoch": 2.485771419781572,
      "grad_norm": 1.171875,
      "learning_rate": 9.52411261732904e-06,
      "loss": 0.28,
      "step": 2020
    },
    {
      "epoch": 2.4980772188894016,
      "grad_norm": 1.1796875,
      "learning_rate": 9.518435313842193e-06,
      "loss": 0.2862,
      "step": 2030
    },
    {
      "epoch": 2.5103830179972313,
      "grad_norm": 1.03125,
      "learning_rate": 9.51272605868067e-06,
      "loss": 0.278,
      "step": 2040
    },
    {
      "epoch": 2.5226888171050605,
      "grad_norm": 0.94921875,
      "learning_rate": 9.506984892216909e-06,
      "loss": 0.2637,
      "step": 2050
    },
    {
      "epoch": 2.5349946162128902,
      "grad_norm": 1.109375,
      "learning_rate": 9.501211855049011e-06,
      "loss": 0.2506,
      "step": 2060
    },
    {
      "epoch": 2.54730041532072,
      "grad_norm": 1.0703125,
      "learning_rate": 9.495406988000441e-06,
      "loss": 0.2677,
      "step": 2070
    },
    {
      "epoch": 2.559606214428549,
      "grad_norm": 1.109375,
      "learning_rate": 9.489570332119756e-06,
      "loss": 0.2481,
      "step": 2080
    },
    {
      "epoch": 2.571912013536379,
      "grad_norm": 1.0234375,
      "learning_rate": 9.483701928680296e-06,
      "loss": 0.2416,
      "step": 2090
    },
    {
      "epoch": 2.5842178126442086,
      "grad_norm": 1.03125,
      "learning_rate": 9.477801819179902e-06,
      "loss": 0.2725,
      "step": 2100
    },
    {
      "epoch": 2.5965236117520383,
      "grad_norm": 1.0546875,
      "learning_rate": 9.471870045340626e-06,
      "loss": 0.2598,
      "step": 2110
    },
    {
      "epoch": 2.608829410859868,
      "grad_norm": 0.80078125,
      "learning_rate": 9.465906649108427e-06,
      "loss": 0.2544,
      "step": 2120
    },
    {
      "epoch": 2.621135209967697,
      "grad_norm": 0.82421875,
      "learning_rate": 9.45991167265288e-06,
      "loss": 0.2489,
      "step": 2130
    },
    {
      "epoch": 2.633441009075527,
      "grad_norm": 1.1015625,
      "learning_rate": 9.453885158366875e-06,
      "loss": 0.2849,
      "step": 2140
    },
    {
      "epoch": 2.6457468081833566,
      "grad_norm": 0.94140625,
      "learning_rate": 9.447827148866322e-06,
      "loss": 0.2719,
      "step": 2150
    },
    {
      "epoch": 2.658052607291186,
      "grad_norm": 0.8828125,
      "learning_rate": 9.441737686989844e-06,
      "loss": 0.2532,
      "step": 2160
    },
    {
      "epoch": 2.6703584063990156,
      "grad_norm": 1.1953125,
      "learning_rate": 9.435616815798476e-06,
      "loss": 0.2589,
      "step": 2170
    },
    {
      "epoch": 2.6826642055068453,
      "grad_norm": 0.95703125,
      "learning_rate": 9.429464578575362e-06,
      "loss": 0.2754,
      "step": 2180
    },
    {
      "epoch": 2.6949700046146745,
      "grad_norm": 0.91015625,
      "learning_rate": 9.423281018825448e-06,
      "loss": 0.2631,
      "step": 2190
    },
    {
      "epoch": 2.707275803722504,
      "grad_norm": 1.0078125,
      "learning_rate": 9.417066180275173e-06,
      "loss": 0.2775,
      "step": 2200
    },
    {
      "epoch": 2.719581602830334,
      "grad_norm": 0.9921875,
      "learning_rate": 9.410820106872162e-06,
      "loss": 0.2652,
      "step": 2210
    },
    {
      "epoch": 2.731887401938163,
      "grad_norm": 1.1796875,
      "learning_rate": 9.404542842784914e-06,
      "loss": 0.2867,
      "step": 2220
    },
    {
      "epoch": 2.744193201045993,
      "grad_norm": 0.98046875,
      "learning_rate": 9.39823443240249e-06,
      "loss": 0.2808,
      "step": 2230
    },
    {
      "epoch": 2.7564990001538225,
      "grad_norm": 1.078125,
      "learning_rate": 9.3918949203342e-06,
      "loss": 0.2929,
      "step": 2240
    },
    {
      "epoch": 2.768804799261652,
      "grad_norm": 0.8984375,
      "learning_rate": 9.385524351409283e-06,
      "loss": 0.2585,
      "step": 2250
    },
    {
      "epoch": 2.7811105983694815,
      "grad_norm": 1.4921875,
      "learning_rate": 9.379122770676598e-06,
      "loss": 0.2814,
      "step": 2260
    },
    {
      "epoch": 2.793416397477311,
      "grad_norm": 1.109375,
      "learning_rate": 9.372690223404296e-06,
      "loss": 0.2591,
      "step": 2270
    },
    {
      "epoch": 2.805722196585141,
      "grad_norm": 0.96875,
      "learning_rate": 9.366226755079513e-06,
      "loss": 0.2781,
      "step": 2280
    },
    {
      "epoch": 2.8180279956929706,
      "grad_norm": 1.015625,
      "learning_rate": 9.35973241140803e-06,
      "loss": 0.2538,
      "step": 2290
    },
    {
      "epoch": 2.8303337948008,
      "grad_norm": 0.98828125,
      "learning_rate": 9.353207238313964e-06,
      "loss": 0.261,
      "step": 2300
    },
    {
      "epoch": 2.8426395939086295,
      "grad_norm": 0.81640625,
      "learning_rate": 9.346651281939446e-06,
      "loss": 0.268,
      "step": 2310
    },
    {
      "epoch": 2.854945393016459,
      "grad_norm": 0.8828125,
      "learning_rate": 9.340064588644278e-06,
      "loss": 0.2603,
      "step": 2320
    },
    {
      "epoch": 2.8672511921242885,
      "grad_norm": 0.98828125,
      "learning_rate": 9.333447205005619e-06,
      "loss": 0.2469,
      "step": 2330
    },
    {
      "epoch": 2.879556991232118,
      "grad_norm": 0.94140625,
      "learning_rate": 9.326799177817653e-06,
      "loss": 0.2601,
      "step": 2340
    },
    {
      "epoch": 2.891862790339948,
      "grad_norm": 1.0390625,
      "learning_rate": 9.320120554091257e-06,
      "loss": 0.2777,
      "step": 2350
    },
    {
      "epoch": 2.904168589447777,
      "grad_norm": 0.921875,
      "learning_rate": 9.313411381053665e-06,
      "loss": 0.2752,
      "step": 2360
    },
    {
      "epoch": 2.916474388555607,
      "grad_norm": 0.8046875,
      "learning_rate": 9.306671706148143e-06,
      "loss": 0.2612,
      "step": 2370
    },
    {
      "epoch": 2.9287801876634365,
      "grad_norm": 0.86328125,
      "learning_rate": 9.299901577033643e-06,
      "loss": 0.261,
      "step": 2380
    },
    {
      "epoch": 2.9410859867712658,
      "grad_norm": 0.76171875,
      "learning_rate": 9.293101041584473e-06,
      "loss": 0.2549,
      "step": 2390
    },
    {
      "epoch": 2.9533917858790955,
      "grad_norm": 1.09375,
      "learning_rate": 9.286270147889956e-06,
      "loss": 0.2678,
      "step": 2400
    },
    {
      "epoch": 2.965697584986925,
      "grad_norm": 1.1015625,
      "learning_rate": 9.279408944254091e-06,
      "loss": 0.2626,
      "step": 2410
    },
    {
      "epoch": 2.9780033840947544,
      "grad_norm": 0.9609375,
      "learning_rate": 9.272517479195208e-06,
      "loss": 0.2635,
      "step": 2420
    },
    {
      "epoch": 2.990309183202584,
      "grad_norm": 1.8359375,
      "learning_rate": 9.265595801445635e-06,
      "loss": 0.2796,
      "step": 2430
    },
    {
      "epoch": 3.002614982310414,
      "grad_norm": 0.9296875,
      "learning_rate": 9.258643959951339e-06,
      "loss": 0.2753,
      "step": 2440
    },
    {
      "epoch": 3.0149207814182435,
      "grad_norm": 1.6875,
      "learning_rate": 9.251662003871587e-06,
      "loss": 0.2776,
      "step": 2450
    },
    {
      "epoch": 3.0272265805260727,
      "grad_norm": 1.046875,
      "learning_rate": 9.244649982578602e-06,
      "loss": 0.2805,
      "step": 2460
    },
    {
      "epoch": 3.0395323796339024,
      "grad_norm": 0.87890625,
      "learning_rate": 9.23760794565721e-06,
      "loss": 0.2104,
      "step": 2470
    },
    {
      "epoch": 3.051838178741732,
      "grad_norm": 0.984375,
      "learning_rate": 9.230535942904486e-06,
      "loss": 0.2505,
      "step": 2480
    },
    {
      "epoch": 3.064143977849562,
      "grad_norm": 0.89453125,
      "learning_rate": 9.223434024329409e-06,
      "loss": 0.266,
      "step": 2490
    },
    {
      "epoch": 3.076449776957391,
      "grad_norm": 1.1015625,
      "learning_rate": 9.216302240152506e-06,
      "loss": 0.2405,
      "step": 2500
    },
    {
      "epoch": 3.0887555760652208,
      "grad_norm": 1.28125,
      "learning_rate": 9.209140640805489e-06,
      "loss": 0.256,
      "step": 2510
    },
    {
      "epoch": 3.1010613751730505,
      "grad_norm": 0.8984375,
      "learning_rate": 9.201949276930913e-06,
      "loss": 0.2699,
      "step": 2520
    },
    {
      "epoch": 3.1133671742808797,
      "grad_norm": 3.015625,
      "learning_rate": 9.194728199381803e-06,
      "loss": 0.2928,
      "step": 2530
    },
    {
      "epoch": 3.1256729733887094,
      "grad_norm": 2.078125,
      "learning_rate": 9.187477459221306e-06,
      "loss": 0.2485,
      "step": 2540
    },
    {
      "epoch": 3.137978772496539,
      "grad_norm": 0.828125,
      "learning_rate": 9.180197107722326e-06,
      "loss": 0.2479,
      "step": 2550
    },
    {
      "epoch": 3.1502845716043684,
      "grad_norm": 1.03125,
      "learning_rate": 9.172887196367156e-06,
      "loss": 0.2394,
      "step": 2560
    },
    {
      "epoch": 3.162590370712198,
      "grad_norm": 0.921875,
      "learning_rate": 9.165547776847122e-06,
      "loss": 0.246,
      "step": 2570
    },
    {
      "epoch": 3.1748961698200278,
      "grad_norm": 0.94140625,
      "learning_rate": 9.158178901062214e-06,
      "loss": 0.2266,
      "step": 2580
    },
    {
      "epoch": 3.1872019689278575,
      "grad_norm": 1.046875,
      "learning_rate": 9.150780621120718e-06,
      "loss": 0.2415,
      "step": 2590
    },
    {
      "epoch": 3.1995077680356867,
      "grad_norm": 1.0546875,
      "learning_rate": 9.143352989338851e-06,
      "loss": 0.2559,
      "step": 2600
    },
    {
      "epoch": 3.2118135671435164,
      "grad_norm": 0.9921875,
      "learning_rate": 9.135896058240384e-06,
      "loss": 0.2503,
      "step": 2610
    },
    {
      "epoch": 3.224119366251346,
      "grad_norm": 0.890625,
      "learning_rate": 9.128409880556277e-06,
      "loss": 0.264,
      "step": 2620
    },
    {
      "epoch": 3.2364251653591753,
      "grad_norm": 1.03125,
      "learning_rate": 9.12089450922431e-06,
      "loss": 0.2728,
      "step": 2630
    },
    {
      "epoch": 3.248730964467005,
      "grad_norm": 0.9296875,
      "learning_rate": 9.113349997388694e-06,
      "loss": 0.2459,
      "step": 2640
    },
    {
      "epoch": 3.2610367635748347,
      "grad_norm": 1.09375,
      "learning_rate": 9.105776398399713e-06,
      "loss": 0.2729,
      "step": 2650
    },
    {
      "epoch": 3.2733425626826644,
      "grad_norm": 0.87890625,
      "learning_rate": 9.09817376581333e-06,
      "loss": 0.2406,
      "step": 2660
    },
    {
      "epoch": 3.2856483617904937,
      "grad_norm": 1.0625,
      "learning_rate": 9.09054215339082e-06,
      "loss": 0.2533,
      "step": 2670
    },
    {
      "epoch": 3.2979541608983234,
      "grad_norm": 0.96484375,
      "learning_rate": 9.08288161509839e-06,
      "loss": 0.235,
      "step": 2680
    },
    {
      "epoch": 3.310259960006153,
      "grad_norm": 1.03125,
      "learning_rate": 9.075192205106784e-06,
      "loss": 0.2482,
      "step": 2690
    },
    {
      "epoch": 3.3225657591139823,
      "grad_norm": 1.140625,
      "learning_rate": 9.06747397779092e-06,
      "loss": 0.2374,
      "step": 2700
    },
    {
      "epoch": 3.334871558221812,
      "grad_norm": 1.1171875,
      "learning_rate": 9.059726987729487e-06,
      "loss": 0.2904,
      "step": 2710
    },
    {
      "epoch": 3.3471773573296417,
      "grad_norm": 0.94140625,
      "learning_rate": 9.051951289704568e-06,
      "loss": 0.2516,
      "step": 2720
    },
    {
      "epoch": 3.359483156437471,
      "grad_norm": 0.78515625,
      "learning_rate": 9.044146938701256e-06,
      "loss": 0.2524,
      "step": 2730
    },
    {
      "epoch": 3.3717889555453007,
      "grad_norm": 1.25,
      "learning_rate": 9.036313989907259e-06,
      "loss": 0.2674,
      "step": 2740
    },
    {
      "epoch": 3.3840947546531304,
      "grad_norm": 0.98828125,
      "learning_rate": 9.028452498712508e-06,
      "loss": 0.2695,
      "step": 2750
    },
    {
      "epoch": 3.3964005537609596,
      "grad_norm": 1.1171875,
      "learning_rate": 9.020562520708774e-06,
      "loss": 0.2559,
      "step": 2760
    },
    {
      "epoch": 3.4087063528687893,
      "grad_norm": 0.95703125,
      "learning_rate": 9.012644111689262e-06,
      "loss": 0.2455,
      "step": 2770
    },
    {
      "epoch": 3.421012151976619,
      "grad_norm": 0.98828125,
      "learning_rate": 9.004697327648235e-06,
      "loss": 0.2738,
      "step": 2780
    },
    {
      "epoch": 3.4333179510844487,
      "grad_norm": 0.85546875,
      "learning_rate": 8.996722224780598e-06,
      "loss": 0.2634,
      "step": 2790
    },
    {
      "epoch": 3.445623750192278,
      "grad_norm": 1.0625,
      "learning_rate": 8.988718859481513e-06,
      "loss": 0.2807,
      "step": 2800
    },
    {
      "epoch": 3.4579295493001077,
      "grad_norm": 0.92578125,
      "learning_rate": 8.980687288346e-06,
      "loss": 0.2461,
      "step": 2810
    },
    {
      "epoch": 3.4702353484079373,
      "grad_norm": 1.3359375,
      "learning_rate": 8.972627568168527e-06,
      "loss": 0.261,
      "step": 2820
    },
    {
      "epoch": 3.482541147515767,
      "grad_norm": 0.87890625,
      "learning_rate": 8.964539755942623e-06,
      "loss": 0.2579,
      "step": 2830
    },
    {
      "epoch": 3.4948469466235963,
      "grad_norm": 0.9453125,
      "learning_rate": 8.956423908860461e-06,
      "loss": 0.2504,
      "step": 2840
    },
    {
      "epoch": 3.507152745731426,
      "grad_norm": 1.0078125,
      "learning_rate": 8.948280084312464e-06,
      "loss": 0.2751,
      "step": 2850
    },
    {
      "epoch": 3.5194585448392557,
      "grad_norm": 0.9296875,
      "learning_rate": 8.940108339886891e-06,
      "loss": 0.2685,
      "step": 2860
    },
    {
      "epoch": 3.531764343947085,
      "grad_norm": 0.96484375,
      "learning_rate": 8.931908733369439e-06,
      "loss": 0.2514,
      "step": 2870
    },
    {
      "epoch": 3.5440701430549146,
      "grad_norm": 0.953125,
      "learning_rate": 8.923681322742821e-06,
      "loss": 0.2674,
      "step": 2880
    },
    {
      "epoch": 3.5563759421627443,
      "grad_norm": 0.94140625,
      "learning_rate": 8.915426166186374e-06,
      "loss": 0.2457,
      "step": 2890
    },
    {
      "epoch": 3.5686817412705736,
      "grad_norm": 0.9140625,
      "learning_rate": 8.907143322075629e-06,
      "loss": 0.2481,
      "step": 2900
    },
    {
      "epoch": 3.5809875403784033,
      "grad_norm": 0.93359375,
      "learning_rate": 8.898832848981914e-06,
      "loss": 0.2621,
      "step": 2910
    },
    {
      "epoch": 3.593293339486233,
      "grad_norm": 0.8125,
      "learning_rate": 8.890494805671923e-06,
      "loss": 0.247,
      "step": 2920
    },
    {
      "epoch": 3.6055991385940622,
      "grad_norm": 0.953125,
      "learning_rate": 8.882129251107322e-06,
      "loss": 0.276,
      "step": 2930
    },
    {
      "epoch": 3.617904937701892,
      "grad_norm": 1.4765625,
      "learning_rate": 8.873736244444311e-06,
      "loss": 0.2445,
      "step": 2940
    },
    {
      "epoch": 3.6302107368097216,
      "grad_norm": 0.953125,
      "learning_rate": 8.86531584503322e-06,
      "loss": 0.2598,
      "step": 2950
    },
    {
      "epoch": 3.6425165359175513,
      "grad_norm": 1.171875,
      "learning_rate": 8.856868112418081e-06,
      "loss": 0.2519,
      "step": 2960
    },
    {
      "epoch": 3.6548223350253806,
      "grad_norm": 0.84375,
      "learning_rate": 8.848393106336212e-06,
      "loss": 0.2602,
      "step": 2970
    },
    {
      "epoch": 3.6671281341332103,
      "grad_norm": 1.03125,
      "learning_rate": 8.839890886717792e-06,
      "loss": 0.2537,
      "step": 2980
    },
    {
      "epoch": 3.67943393324104,
      "grad_norm": 0.953125,
      "learning_rate": 8.831361513685436e-06,
      "loss": 0.2709,
      "step": 2990
    },
    {
      "epoch": 3.6917397323488697,
      "grad_norm": 1.125,
      "learning_rate": 8.822805047553778e-06,
      "loss": 0.257,
      "step": 3000
    },
    {
      "epoch": 3.704045531456699,
      "grad_norm": 1.015625,
      "learning_rate": 8.81422154882903e-06,
      "loss": 0.2508,
      "step": 3010
    },
    {
      "epoch": 3.7163513305645286,
      "grad_norm": 0.96484375,
      "learning_rate": 8.805611078208567e-06,
      "loss": 0.2647,
      "step": 3020
    },
    {
      "epoch": 3.7286571296723583,
      "grad_norm": 0.96875,
      "learning_rate": 8.796973696580494e-06,
      "loss": 0.2316,
      "step": 3030
    },
    {
      "epoch": 3.7409629287801875,
      "grad_norm": 1.171875,
      "learning_rate": 8.788309465023209e-06,
      "loss": 0.2453,
      "step": 3040
    },
    {
      "epoch": 3.7532687278880172,
      "grad_norm": 1.0859375,
      "learning_rate": 8.779618444804982e-06,
      "loss": 0.2396,
      "step": 3050
    },
    {
      "epoch": 3.765574526995847,
      "grad_norm": 1.0234375,
      "learning_rate": 8.77090069738352e-06,
      "loss": 0.284,
      "step": 3060
    },
    {
      "epoch": 3.777880326103676,
      "grad_norm": 1.3203125,
      "learning_rate": 8.762156284405517e-06,
      "loss": 0.2565,
      "step": 3070
    },
    {
      "epoch": 3.790186125211506,
      "grad_norm": 1.03125,
      "learning_rate": 8.753385267706239e-06,
      "loss": 0.2667,
      "step": 3080
    },
    {
      "epoch": 3.8024919243193356,
      "grad_norm": 1.03125,
      "learning_rate": 8.744587709309077e-06,
      "loss": 0.25,
      "step": 3090
    },
    {
      "epoch": 3.814797723427165,
      "grad_norm": 0.94921875,
      "learning_rate": 8.735763671425103e-06,
      "loss": 0.2685,
      "step": 3100
    },
    {
      "epoch": 3.8271035225349945,
      "grad_norm": 1.2421875,
      "learning_rate": 8.726913216452646e-06,
      "loss": 0.2608,
      "step": 3110
    },
    {
      "epoch": 3.8394093216428242,
      "grad_norm": 1.0,
      "learning_rate": 8.718036406976831e-06,
      "loss": 0.2537,
      "step": 3120
    },
    {
      "epoch": 3.8517151207506535,
      "grad_norm": 0.97265625,
      "learning_rate": 8.709133305769151e-06,
      "loss": 0.2394,
      "step": 3130
    },
    {
      "epoch": 3.864020919858483,
      "grad_norm": 0.98046875,
      "learning_rate": 8.700203975787019e-06,
      "loss": 0.2875,
      "step": 3140
    },
    {
      "epoch": 3.876326718966313,
      "grad_norm": 1.21875,
      "learning_rate": 8.691248480173322e-06,
      "loss": 0.2696,
      "step": 3150
    },
    {
      "epoch": 3.8886325180741426,
      "grad_norm": 1.03125,
      "learning_rate": 8.682266882255972e-06,
      "loss": 0.2523,
      "step": 3160
    },
    {
      "epoch": 3.9009383171819723,
      "grad_norm": 1.0,
      "learning_rate": 8.673259245547464e-06,
      "loss": 0.2607,
      "step": 3170
    },
    {
      "epoch": 3.9132441162898015,
      "grad_norm": 1.84375,
      "learning_rate": 8.664225633744421e-06,
      "loss": 0.2706,
      "step": 3180
    },
    {
      "epoch": 3.925549915397631,
      "grad_norm": 1.125,
      "learning_rate": 8.655166110727149e-06,
      "loss": 0.2295,
      "step": 3190
    },
    {
      "epoch": 3.937855714505461,
      "grad_norm": 1.0625,
      "learning_rate": 8.646080740559183e-06,
      "loss": 0.2753,
      "step": 3200
    },
    {
      "epoch": 3.95016151361329,
      "grad_norm": 1.203125,
      "learning_rate": 8.63696958748683e-06,
      "loss": 0.2256,
      "step": 3210
    },
    {
      "epoch": 3.96246731272112,
      "grad_norm": 1.03125,
      "learning_rate": 8.627832715938722e-06,
      "loss": 0.2461,
      "step": 3220
    },
    {
      "epoch": 3.9747731118289495,
      "grad_norm": 1.03125,
      "learning_rate": 8.61867019052535e-06,
      "loss": 0.2844,
      "step": 3230
    },
    {
      "epoch": 3.987078910936779,
      "grad_norm": 1.0703125,
      "learning_rate": 8.609482076038627e-06,
      "loss": 0.2559,
      "step": 3240
    },
    {
      "epoch": 3.9993847100446085,
      "grad_norm": 1.2421875,
      "learning_rate": 8.600268437451404e-06,
      "loss": 0.2661,
      "step": 3250
    },
    {
      "epoch": 4.011690509152438,
      "grad_norm": 1.2890625,
      "learning_rate": 8.59102933991703e-06,
      "loss": 0.2436,
      "step": 3260
    },
    {
      "epoch": 4.023996308260267,
      "grad_norm": 1.078125,
      "learning_rate": 8.581764848768878e-06,
      "loss": 0.2886,
      "step": 3270
    },
    {
      "epoch": 4.036302107368098,
      "grad_norm": 0.84375,
      "learning_rate": 8.572475029519897e-06,
      "loss": 0.236,
      "step": 3280
    },
    {
      "epoch": 4.048607906475927,
      "grad_norm": 1.0078125,
      "learning_rate": 8.563159947862136e-06,
      "loss": 0.2357,
      "step": 3290
    },
    {
      "epoch": 4.060913705583756,
      "grad_norm": 1.21875,
      "learning_rate": 8.55381966966629e-06,
      "loss": 0.2674,
      "step": 3300
    },
    {
      "epoch": 4.073219504691586,
      "grad_norm": 1.1484375,
      "learning_rate": 8.54445426098122e-06,
      "loss": 0.2648,
      "step": 3310
    },
    {
      "epoch": 4.0855253037994155,
      "grad_norm": 0.84375,
      "learning_rate": 8.535063788033507e-06,
      "loss": 0.2275,
      "step": 3320
    },
    {
      "epoch": 4.097831102907245,
      "grad_norm": 0.94921875,
      "learning_rate": 8.525648317226959e-06,
      "loss": 0.2261,
      "step": 3330
    },
    {
      "epoch": 4.110136902015075,
      "grad_norm": 1.140625,
      "learning_rate": 8.51620791514216e-06,
      "loss": 0.2305,
      "step": 3340
    },
    {
      "epoch": 4.122442701122904,
      "grad_norm": 0.96875,
      "learning_rate": 8.506742648535996e-06,
      "loss": 0.2313,
      "step": 3350
    },
    {
      "epoch": 4.134748500230733,
      "grad_norm": 1.1328125,
      "learning_rate": 8.497252584341175e-06,
      "loss": 0.278,
      "step": 3360
    },
    {
      "epoch": 4.1470542993385635,
      "grad_norm": 1.125,
      "learning_rate": 8.48773778966576e-06,
      "loss": 0.2473,
      "step": 3370
    },
    {
      "epoch": 4.159360098446393,
      "grad_norm": 0.97265625,
      "learning_rate": 8.478198331792694e-06,
      "loss": 0.2686,
      "step": 3380
    },
    {
      "epoch": 4.171665897554222,
      "grad_norm": 1.0859375,
      "learning_rate": 8.468634278179323e-06,
      "loss": 0.2667,
      "step": 3390
    },
    {
      "epoch": 4.183971696662052,
      "grad_norm": 0.97265625,
      "learning_rate": 8.459045696456921e-06,
      "loss": 0.2863,
      "step": 3400
    },
    {
      "epoch": 4.196277495769881,
      "grad_norm": 1.8984375,
      "learning_rate": 8.449432654430206e-06,
      "loss": 0.286,
      "step": 3410
    },
    {
      "epoch": 4.2085832948777115,
      "grad_norm": 1.0234375,
      "learning_rate": 8.439795220076867e-06,
      "loss": 0.28,
      "step": 3420
    },
    {
      "epoch": 4.220889093985541,
      "grad_norm": 0.94140625,
      "learning_rate": 8.430133461547085e-06,
      "loss": 0.2583,
      "step": 3430
    },
    {
      "epoch": 4.23319489309337,
      "grad_norm": 1.078125,
      "learning_rate": 8.42044744716304e-06,
      "loss": 0.2454,
      "step": 3440
    },
    {
      "epoch": 4.2455006922012,
      "grad_norm": 1.21875,
      "learning_rate": 8.410737245418437e-06,
      "loss": 0.2486,
      "step": 3450
    },
    {
      "epoch": 4.257806491309029,
      "grad_norm": 1.1484375,
      "learning_rate": 8.401002924978025e-06,
      "loss": 0.2771,
      "step": 3460
    },
    {
      "epoch": 4.270112290416859,
      "grad_norm": 0.6953125,
      "learning_rate": 8.391244554677099e-06,
      "loss": 0.2483,
      "step": 3470
    },
    {
      "epoch": 4.282418089524689,
      "grad_norm": 0.9140625,
      "learning_rate": 8.38146220352102e-06,
      "loss": 0.2544,
      "step": 3480
    },
    {
      "epoch": 4.294723888632518,
      "grad_norm": 0.9453125,
      "learning_rate": 8.371655940684737e-06,
      "loss": 0.2286,
      "step": 3490
    },
    {
      "epoch": 4.307029687740347,
      "grad_norm": 1.0078125,
      "learning_rate": 8.361825835512276e-06,
      "loss": 0.2559,
      "step": 3500
    },
    {
      "epoch": 4.3193354868481775,
      "grad_norm": 0.91015625,
      "learning_rate": 8.351971957516269e-06,
      "loss": 0.2409,
      "step": 3510
    },
    {
      "epoch": 4.331641285956007,
      "grad_norm": 0.71484375,
      "learning_rate": 8.342094376377453e-06,
      "loss": 0.2234,
      "step": 3520
    },
    {
      "epoch": 4.343947085063836,
      "grad_norm": 0.921875,
      "learning_rate": 8.33219316194418e-06,
      "loss": 0.2401,
      "step": 3530
    },
    {
      "epoch": 4.356252884171666,
      "grad_norm": 0.9609375,
      "learning_rate": 8.322268384231921e-06,
      "loss": 0.2601,
      "step": 3540
    },
    {
      "epoch": 4.368558683279495,
      "grad_norm": 0.98046875,
      "learning_rate": 8.312320113422777e-06,
      "loss": 0.2518,
      "step": 3550
    },
    {
      "epoch": 4.380864482387325,
      "grad_norm": 1.0703125,
      "learning_rate": 8.302348419864972e-06,
      "loss": 0.2676,
      "step": 3560
    },
    {
      "epoch": 4.393170281495155,
      "grad_norm": 0.859375,
      "learning_rate": 8.292353374072364e-06,
      "loss": 0.2393,
      "step": 3570
    },
    {
      "epoch": 4.405476080602984,
      "grad_norm": 1.171875,
      "learning_rate": 8.282335046723946e-06,
      "loss": 0.2421,
      "step": 3580
    },
    {
      "epoch": 4.417781879710814,
      "grad_norm": 1.03125,
      "learning_rate": 8.272293508663344e-06,
      "loss": 0.2488,
      "step": 3590
    },
    {
      "epoch": 4.430087678818643,
      "grad_norm": 0.96875,
      "learning_rate": 8.262228830898313e-06,
      "loss": 0.2486,
      "step": 3600
    },
    {
      "epoch": 4.442393477926473,
      "grad_norm": 1.5390625,
      "learning_rate": 8.25214108460024e-06,
      "loss": 0.2492,
      "step": 3610
    },
    {
      "epoch": 4.454699277034303,
      "grad_norm": 1.0859375,
      "learning_rate": 8.242030341103641e-06,
      "loss": 0.2321,
      "step": 3620
    },
    {
      "epoch": 4.467005076142132,
      "grad_norm": 1.1171875,
      "learning_rate": 8.231896671905652e-06,
      "loss": 0.2438,
      "step": 3630
    },
    {
      "epoch": 4.479310875249961,
      "grad_norm": 0.84375,
      "learning_rate": 8.221740148665526e-06,
      "loss": 0.2632,
      "step": 3640
    },
    {
      "epoch": 4.491616674357791,
      "grad_norm": 0.83203125,
      "learning_rate": 8.21156084320413e-06,
      "loss": 0.2638,
      "step": 3650
    },
    {
      "epoch": 4.503922473465621,
      "grad_norm": 2.078125,
      "learning_rate": 8.201358827503423e-06,
      "loss": 0.2453,
      "step": 3660
    },
    {
      "epoch": 4.51622827257345,
      "grad_norm": 1.078125,
      "learning_rate": 8.19113417370597e-06,
      "loss": 0.2618,
      "step": 3670
    },
    {
      "epoch": 4.52853407168128,
      "grad_norm": 1.03125,
      "learning_rate": 8.18088695411441e-06,
      "loss": 0.2661,
      "step": 3680
    },
    {
      "epoch": 4.540839870789109,
      "grad_norm": 0.9765625,
      "learning_rate": 8.170617241190959e-06,
      "loss": 0.2657,
      "step": 3690
    },
    {
      "epoch": 4.553145669896939,
      "grad_norm": 0.88671875,
      "learning_rate": 8.16032510755689e-06,
      "loss": 0.2573,
      "step": 3700
    },
    {
      "epoch": 4.565451469004769,
      "grad_norm": 1.1484375,
      "learning_rate": 8.15001062599202e-06,
      "loss": 0.247,
      "step": 3710
    },
    {
      "epoch": 4.577757268112598,
      "grad_norm": 1.8046875,
      "learning_rate": 8.139673869434201e-06,
      "loss": 0.2377,
      "step": 3720
    },
    {
      "epoch": 4.590063067220427,
      "grad_norm": 0.828125,
      "learning_rate": 8.129314910978802e-06,
      "loss": 0.2218,
      "step": 3730
    },
    {
      "epoch": 4.602368866328257,
      "grad_norm": 1.1015625,
      "learning_rate": 8.118933823878183e-06,
      "loss": 0.2544,
      "step": 3740
    },
    {
      "epoch": 4.614674665436087,
      "grad_norm": 1.0078125,
      "learning_rate": 8.108530681541192e-06,
      "loss": 0.2477,
      "step": 3750
    },
    {
      "epoch": 4.626980464543916,
      "grad_norm": 1.0625,
      "learning_rate": 8.098105557532634e-06,
      "loss": 0.2618,
      "step": 3760
    },
    {
      "epoch": 4.639286263651746,
      "grad_norm": 0.8828125,
      "learning_rate": 8.087658525572757e-06,
      "loss": 0.2389,
      "step": 3770
    },
    {
      "epoch": 4.651592062759575,
      "grad_norm": 0.8828125,
      "learning_rate": 8.077189659536729e-06,
      "loss": 0.2505,
      "step": 3780
    },
    {
      "epoch": 4.6638978618674045,
      "grad_norm": 3.859375,
      "learning_rate": 8.066699033454114e-06,
      "loss": 0.2671,
      "step": 3790
    },
    {
      "epoch": 4.676203660975235,
      "grad_norm": 1.25,
      "learning_rate": 8.056186721508356e-06,
      "loss": 0.2345,
      "step": 3800
    },
    {
      "epoch": 4.688509460083064,
      "grad_norm": 0.953125,
      "learning_rate": 8.045652798036237e-06,
      "loss": 0.2056,
      "step": 3810
    },
    {
      "epoch": 4.700815259190894,
      "grad_norm": 1.1796875,
      "learning_rate": 8.035097337527373e-06,
      "loss": 0.2324,
      "step": 3820
    },
    {
      "epoch": 4.713121058298723,
      "grad_norm": 1.046875,
      "learning_rate": 8.024520414623673e-06,
      "loss": 0.2566,
      "step": 3830
    },
    {
      "epoch": 4.7254268574065525,
      "grad_norm": 1.3046875,
      "learning_rate": 8.013922104118816e-06,
      "loss": 0.2395,
      "step": 3840
    },
    {
      "epoch": 4.737732656514383,
      "grad_norm": 1.1328125,
      "learning_rate": 8.003302480957724e-06,
      "loss": 0.2559,
      "step": 3850
    },
    {
      "epoch": 4.750038455622212,
      "grad_norm": 1.2578125,
      "learning_rate": 7.992661620236022e-06,
      "loss": 0.2643,
      "step": 3860
    },
    {
      "epoch": 4.762344254730041,
      "grad_norm": 0.99609375,
      "learning_rate": 7.981999597199519e-06,
      "loss": 0.2509,
      "step": 3870
    },
    {
      "epoch": 4.774650053837871,
      "grad_norm": 1.0390625,
      "learning_rate": 7.971316487243675e-06,
      "loss": 0.235,
      "step": 3880
    },
    {
      "epoch": 4.786955852945701,
      "grad_norm": 1.171875,
      "learning_rate": 7.960612365913059e-06,
      "loss": 0.2553,
      "step": 3890
    },
    {
      "epoch": 4.799261652053531,
      "grad_norm": 0.90234375,
      "learning_rate": 7.949887308900818e-06,
      "loss": 0.2558,
      "step": 3900
    },
    {
      "epoch": 4.81156745116136,
      "grad_norm": 1.21875,
      "learning_rate": 7.93914139204815e-06,
      "loss": 0.2129,
      "step": 3910
    },
    {
      "epoch": 4.823873250269189,
      "grad_norm": 0.80078125,
      "learning_rate": 7.928374691343757e-06,
      "loss": 0.2623,
      "step": 3920
    },
    {
      "epoch": 4.836179049377019,
      "grad_norm": 1.1015625,
      "learning_rate": 7.917587282923312e-06,
      "loss": 0.2494,
      "step": 3930
    },
    {
      "epoch": 4.848484848484849,
      "grad_norm": 1.046875,
      "learning_rate": 7.906779243068923e-06,
      "loss": 0.2346,
      "step": 3940
    },
    {
      "epoch": 4.860790647592678,
      "grad_norm": 0.90625,
      "learning_rate": 7.89595064820859e-06,
      "loss": 0.2469,
      "step": 3950
    },
    {
      "epoch": 4.873096446700508,
      "grad_norm": 1.0859375,
      "learning_rate": 7.885101574915666e-06,
      "loss": 0.2495,
      "step": 3960
    },
    {
      "epoch": 4.885402245808337,
      "grad_norm": 1.15625,
      "learning_rate": 7.874232099908311e-06,
      "loss": 0.2467,
      "step": 3970
    },
    {
      "epoch": 4.8977080449161665,
      "grad_norm": 1.03125,
      "learning_rate": 7.863342300048963e-06,
      "loss": 0.2733,
      "step": 3980
    },
    {
      "epoch": 4.910013844023997,
      "grad_norm": 1.0703125,
      "learning_rate": 7.852432252343775e-06,
      "loss": 0.2626,
      "step": 3990
    },
    {
      "epoch": 4.922319643131826,
      "grad_norm": 1.0859375,
      "learning_rate": 7.84150203394209e-06,
      "loss": 0.2634,
      "step": 4000
    },
    {
      "epoch": 4.934625442239655,
      "grad_norm": 1.140625,
      "learning_rate": 7.830551722135878e-06,
      "loss": 0.2511,
      "step": 4010
    },
    {
      "epoch": 4.946931241347485,
      "grad_norm": 1.2421875,
      "learning_rate": 7.819581394359201e-06,
      "loss": 0.2355,
      "step": 4020
    },
    {
      "epoch": 4.9592370404553145,
      "grad_norm": 1.09375,
      "learning_rate": 7.808591128187664e-06,
      "loss": 0.2497,
      "step": 4030
    },
    {
      "epoch": 4.971542839563144,
      "grad_norm": 1.1015625,
      "learning_rate": 7.797581001337859e-06,
      "loss": 0.2369,
      "step": 4040
    },
    {
      "epoch": 4.983848638670974,
      "grad_norm": 1.1015625,
      "learning_rate": 7.786551091666829e-06,
      "loss": 0.2462,
      "step": 4050
    },
    {
      "epoch": 4.996154437778803,
      "grad_norm": 0.9296875,
      "learning_rate": 7.775501477171503e-06,
      "loss": 0.2718,
      "step": 4060
    },
    {
      "epoch": 5.008460236886632,
      "grad_norm": 0.8046875,
      "learning_rate": 7.76443223598815e-06,
      "loss": 0.2269,
      "step": 4070
    },
    {
      "epoch": 5.020766035994463,
      "grad_norm": 1.484375,
      "learning_rate": 7.753343446391832e-06,
      "loss": 0.2453,
      "step": 4080
    },
    {
      "epoch": 5.033071835102292,
      "grad_norm": 1.1328125,
      "learning_rate": 7.742235186795843e-06,
      "loss": 0.2739,
      "step": 4090
    },
    {
      "epoch": 5.045377634210121,
      "grad_norm": 1.1015625,
      "learning_rate": 7.731107535751157e-06,
      "loss": 0.2331,
      "step": 4100
    },
    {
      "epoch": 5.057683433317951,
      "grad_norm": 1.203125,
      "learning_rate": 7.719960571945872e-06,
      "loss": 0.2344,
      "step": 4110
    },
    {
      "epoch": 5.0699892324257805,
      "grad_norm": 0.9609375,
      "learning_rate": 7.708794374204655e-06,
      "loss": 0.236,
      "step": 4120
    },
    {
      "epoch": 5.082295031533611,
      "grad_norm": 1.203125,
      "learning_rate": 7.697609021488188e-06,
      "loss": 0.2421,
      "step": 4130
    },
    {
      "epoch": 5.09460083064144,
      "grad_norm": 1.0078125,
      "learning_rate": 7.6864045928926e-06,
      "loss": 0.2436,
      "step": 4140
    },
    {
      "epoch": 5.106906629749269,
      "grad_norm": 0.96484375,
      "learning_rate": 7.675181167648915e-06,
      "loss": 0.2353,
      "step": 4150
    },
    {
      "epoch": 5.119212428857099,
      "grad_norm": 1.4453125,
      "learning_rate": 7.66393882512249e-06,
      "loss": 0.2417,
      "step": 4160
    },
    {
      "epoch": 5.1315182279649285,
      "grad_norm": 1.609375,
      "learning_rate": 7.652677644812455e-06,
      "loss": 0.2688,
      "step": 4170
    },
    {
      "epoch": 5.143824027072758,
      "grad_norm": 1.0078125,
      "learning_rate": 7.641397706351144e-06,
      "loss": 0.2293,
      "step": 4180
    },
    {
      "epoch": 5.156129826180588,
      "grad_norm": 0.76171875,
      "learning_rate": 7.630099089503546e-06,
      "loss": 0.2549,
      "step": 4190
    },
    {
      "epoch": 5.168435625288417,
      "grad_norm": 1.078125,
      "learning_rate": 7.61878187416673e-06,
      "loss": 0.2677,
      "step": 4200
    },
    {
      "epoch": 5.180741424396246,
      "grad_norm": 0.875,
      "learning_rate": 7.607446140369275e-06,
      "loss": 0.2484,
      "step": 4210
    },
    {
      "epoch": 5.1930472235040765,
      "grad_norm": 0.81640625,
      "learning_rate": 7.596091968270722e-06,
      "loss": 0.2799,
      "step": 4220
    },
    {
      "epoch": 5.205353022611906,
      "grad_norm": 1.0625,
      "learning_rate": 7.584719438160988e-06,
      "loss": 0.2614,
      "step": 4230
    },
    {
      "epoch": 5.217658821719735,
      "grad_norm": 1.0078125,
      "learning_rate": 7.573328630459813e-06,
      "loss": 0.2654,
      "step": 4240
    },
    {
      "epoch": 5.229964620827565,
      "grad_norm": 0.984375,
      "learning_rate": 7.561919625716181e-06,
      "loss": 0.2425,
      "step": 4250
    },
    {
      "epoch": 5.242270419935394,
      "grad_norm": 0.984375,
      "learning_rate": 7.5504925046077596e-06,
      "loss": 0.2283,
      "step": 4260
    },
    {
      "epoch": 5.254576219043225,
      "grad_norm": 2.03125,
      "learning_rate": 7.5390473479403184e-06,
      "loss": 0.2446,
      "step": 4270
    },
    {
      "epoch": 5.266882018151054,
      "grad_norm": 0.85546875,
      "learning_rate": 7.527584236647165e-06,
      "loss": 0.2394,
      "step": 4280
    },
    {
      "epoch": 5.279187817258883,
      "grad_norm": 0.8125,
      "learning_rate": 7.516103251788578e-06,
      "loss": 0.2623,
      "step": 4290
    },
    {
      "epoch": 5.291493616366713,
      "grad_norm": 0.984375,
      "learning_rate": 7.504604474551218e-06,
      "loss": 0.2191,
      "step": 4300
    },
    {
      "epoch": 5.3037994154745425,
      "grad_norm": 1.046875,
      "learning_rate": 7.4930879862475705e-06,
      "loss": 0.2433,
      "step": 4310
    },
    {
      "epoch": 5.316105214582372,
      "grad_norm": 0.93359375,
      "learning_rate": 7.481553868315357e-06,
      "loss": 0.2692,
      "step": 4320
    },
    {
      "epoch": 5.328411013690202,
      "grad_norm": 1.015625,
      "learning_rate": 7.470002202316966e-06,
      "loss": 0.2342,
      "step": 4330
    },
    {
      "epoch": 5.340716812798031,
      "grad_norm": 0.9296875,
      "learning_rate": 7.458433069938881e-06,
      "loss": 0.2565,
      "step": 4340
    },
    {
      "epoch": 5.35302261190586,
      "grad_norm": 0.96875,
      "learning_rate": 7.446846552991092e-06,
      "loss": 0.253,
      "step": 4350
    },
    {
      "epoch": 5.3653284110136905,
      "grad_norm": 1.09375,
      "learning_rate": 7.435242733406521e-06,
      "loss": 0.2359,
      "step": 4360
    },
    {
      "epoch": 5.37763421012152,
      "grad_norm": 0.8984375,
      "learning_rate": 7.423621693240449e-06,
      "loss": 0.2368,
      "step": 4370
    },
    {
      "epoch": 5.389940009229349,
      "grad_norm": 0.93359375,
      "learning_rate": 7.411983514669929e-06,
      "loss": 0.2643,
      "step": 4380
    },
    {
      "epoch": 5.402245808337179,
      "grad_norm": 0.8515625,
      "learning_rate": 7.400328279993205e-06,
      "loss": 0.2423,
      "step": 4390
    },
    {
      "epoch": 5.414551607445008,
      "grad_norm": 1.0625,
      "learning_rate": 7.3886560716291325e-06,
      "loss": 0.2377,
      "step": 4400
    },
    {
      "epoch": 5.426857406552838,
      "grad_norm": 1.0546875,
      "learning_rate": 7.376966972116592e-06,
      "loss": 0.2601,
      "step": 4410
    },
    {
      "epoch": 5.439163205660668,
      "grad_norm": 0.921875,
      "learning_rate": 7.365261064113916e-06,
      "loss": 0.2495,
      "step": 4420
    },
    {
      "epoch": 5.451469004768497,
      "grad_norm": 1.015625,
      "learning_rate": 7.353538430398286e-06,
      "loss": 0.208,
      "step": 4430
    },
    {
      "epoch": 5.463774803876326,
      "grad_norm": 1.4765625,
      "learning_rate": 7.3417991538651674e-06,
      "loss": 0.2273,
      "step": 4440
    },
    {
      "epoch": 5.476080602984156,
      "grad_norm": 0.99609375,
      "learning_rate": 7.330043317527706e-06,
      "loss": 0.2523,
      "step": 4450
    },
    {
      "epoch": 5.488386402091986,
      "grad_norm": 1.03125,
      "learning_rate": 7.318271004516156e-06,
      "loss": 0.2276,
      "step": 4460
    },
    {
      "epoch": 5.500692201199815,
      "grad_norm": 0.984375,
      "learning_rate": 7.306482298077275e-06,
      "loss": 0.2657,
      "step": 4470
    },
    {
      "epoch": 5.512998000307645,
      "grad_norm": 1.3984375,
      "learning_rate": 7.294677281573756e-06,
      "loss": 0.2298,
      "step": 4480
    },
    {
      "epoch": 5.525303799415474,
      "grad_norm": 1.0859375,
      "learning_rate": 7.28285603848362e-06,
      "loss": 0.245,
      "step": 4490
    },
    {
      "epoch": 5.5376095985233045,
      "grad_norm": 1.0625,
      "learning_rate": 7.271018652399635e-06,
      "loss": 0.2442,
      "step": 4500
    },
    {
      "epoch": 5.549915397631134,
      "grad_norm": 0.859375,
      "learning_rate": 7.2591652070287225e-06,
      "loss": 0.264,
      "step": 4510
    },
    {
      "epoch": 5.562221196738963,
      "grad_norm": 1.2578125,
      "learning_rate": 7.247295786191365e-06,
      "loss": 0.2077,
      "step": 4520
    },
    {
      "epoch": 5.574526995846793,
      "grad_norm": 0.89453125,
      "learning_rate": 7.235410473821014e-06,
      "loss": 0.2363,
      "step": 4530
    },
    {
      "epoch": 5.586832794954622,
      "grad_norm": 0.94921875,
      "learning_rate": 7.223509353963498e-06,
      "loss": 0.2501,
      "step": 4540
    },
    {
      "epoch": 5.599138594062452,
      "grad_norm": 1.0703125,
      "learning_rate": 7.211592510776426e-06,
      "loss": 0.273,
      "step": 4550
    },
    {
      "epoch": 5.611444393170282,
      "grad_norm": 1.359375,
      "learning_rate": 7.19966002852859e-06,
      "loss": 0.234,
      "step": 4560
    },
    {
      "epoch": 5.623750192278111,
      "grad_norm": 0.87890625,
      "learning_rate": 7.187711991599376e-06,
      "loss": 0.24,
      "step": 4570
    },
    {
      "epoch": 5.63605599138594,
      "grad_norm": 1.203125,
      "learning_rate": 7.175748484478162e-06,
      "loss": 0.2323,
      "step": 4580
    },
    {
      "epoch": 5.64836179049377,
      "grad_norm": 0.96484375,
      "learning_rate": 7.163769591763723e-06,
      "loss": 0.224,
      "step": 4590
    },
    {
      "epoch": 5.6606675896016,
      "grad_norm": 0.90625,
      "learning_rate": 7.151775398163629e-06,
      "loss": 0.2307,
      "step": 4600
    },
    {
      "epoch": 5.67297338870943,
      "grad_norm": 0.953125,
      "learning_rate": 7.13976598849365e-06,
      "loss": 0.2394,
      "step": 4610
    },
    {
      "epoch": 5.685279187817259,
      "grad_norm": 1.375,
      "learning_rate": 7.127741447677157e-06,
      "loss": 0.2317,
      "step": 4620
    },
    {
      "epoch": 5.697584986925088,
      "grad_norm": 1.0546875,
      "learning_rate": 7.115701860744515e-06,
      "loss": 0.2563,
      "step": 4630
    },
    {
      "epoch": 5.709890786032918,
      "grad_norm": 0.94921875,
      "learning_rate": 7.103647312832493e-06,
      "loss": 0.2478,
      "step": 4640
    },
    {
      "epoch": 5.722196585140748,
      "grad_norm": 0.796875,
      "learning_rate": 7.0915778891836475e-06,
      "loss": 0.2413,
      "step": 4650
    },
    {
      "epoch": 5.734502384248577,
      "grad_norm": 0.95703125,
      "learning_rate": 7.0794936751457335e-06,
      "loss": 0.2626,
      "step": 4660
    },
    {
      "epoch": 5.746808183356407,
      "grad_norm": 1.1171875,
      "learning_rate": 7.067394756171089e-06,
      "loss": 0.2566,
      "step": 4670
    },
    {
      "epoch": 5.759113982464236,
      "grad_norm": 1.109375,
      "learning_rate": 7.055281217816041e-06,
      "loss": 0.2296,
      "step": 4680
    },
    {
      "epoch": 5.771419781572066,
      "grad_norm": 1.1640625,
      "learning_rate": 7.043153145740296e-06,
      "loss": 0.2476,
      "step": 4690
    },
    {
      "epoch": 5.783725580679896,
      "grad_norm": 1.078125,
      "learning_rate": 7.031010625706331e-06,
      "loss": 0.2371,
      "step": 4700
    },
    {
      "epoch": 5.796031379787725,
      "grad_norm": 1.046875,
      "learning_rate": 7.018853743578793e-06,
      "loss": 0.2601,
      "step": 4710
    },
    {
      "epoch": 5.808337178895554,
      "grad_norm": 0.95703125,
      "learning_rate": 7.006682585323889e-06,
      "loss": 0.2629,
      "step": 4720
    },
    {
      "epoch": 5.820642978003384,
      "grad_norm": 1.0390625,
      "learning_rate": 6.9944972370087775e-06,
      "loss": 0.2478,
      "step": 4730
    },
    {
      "epoch": 5.832948777111214,
      "grad_norm": 0.97265625,
      "learning_rate": 6.98229778480096e-06,
      "loss": 0.2393,
      "step": 4740
    },
    {
      "epoch": 5.845254576219043,
      "grad_norm": 0.91796875,
      "learning_rate": 6.970084314967673e-06,
      "loss": 0.2805,
      "step": 4750
    },
    {
      "epoch": 5.857560375326873,
      "grad_norm": 0.9765625,
      "learning_rate": 6.957856913875278e-06,
      "loss": 0.2148,
      "step": 4760
    },
    {
      "epoch": 5.869866174434702,
      "grad_norm": 0.94921875,
      "learning_rate": 6.94561566798865e-06,
      "loss": 0.2496,
      "step": 4770
    },
    {
      "epoch": 5.8821719735425315,
      "grad_norm": 0.9453125,
      "learning_rate": 6.933360663870564e-06,
      "loss": 0.2345,
      "step": 4780
    },
    {
      "epoch": 5.894477772650362,
      "grad_norm": 1.1171875,
      "learning_rate": 6.921091988181089e-06,
      "loss": 0.2451,
      "step": 4790
    },
    {
      "epoch": 5.906783571758191,
      "grad_norm": 1.1015625,
      "learning_rate": 6.908809727676966e-06,
      "loss": 0.2891,
      "step": 4800
    },
    {
      "epoch": 5.91908937086602,
      "grad_norm": 1.0,
      "learning_rate": 6.896513969211003e-06,
      "loss": 0.2749,
      "step": 4810
    },
    {
      "epoch": 5.93139516997385,
      "grad_norm": 0.98046875,
      "learning_rate": 6.884204799731457e-06,
      "loss": 0.2456,
      "step": 4820
    },
    {
      "epoch": 5.9437009690816796,
      "grad_norm": 1.21875,
      "learning_rate": 6.8718823062814184e-06,
      "loss": 0.258,
      "step": 4830
    },
    {
      "epoch": 5.95600676818951,
      "grad_norm": 1.234375,
      "learning_rate": 6.859546575998203e-06,
      "loss": 0.2549,
      "step": 4840
    },
    {
      "epoch": 5.968312567297339,
      "grad_norm": 0.95703125,
      "learning_rate": 6.847197696112718e-06,
      "loss": 0.2315,
      "step": 4850
    },
    {
      "epoch": 5.980618366405168,
      "grad_norm": 1.25,
      "learning_rate": 6.834835753948867e-06,
      "loss": 0.2667,
      "step": 4860
    },
    {
      "epoch": 5.992924165512998,
      "grad_norm": 0.88671875,
      "learning_rate": 6.822460836922917e-06,
      "loss": 0.245,
      "step": 4870
    },
    {
      "epoch": 6.005229964620828,
      "grad_norm": 0.9453125,
      "learning_rate": 6.810073032542888e-06,
      "loss": 0.2247,
      "step": 4880
    },
    {
      "epoch": 6.017535763728657,
      "grad_norm": 1.125,
      "learning_rate": 6.79767242840793e-06,
      "loss": 0.2394,
      "step": 4890
    },
    {
      "epoch": 6.029841562836487,
      "grad_norm": 0.98046875,
      "learning_rate": 6.785259112207705e-06,
      "loss": 0.2433,
      "step": 4900
    },
    {
      "epoch": 6.042147361944316,
      "grad_norm": 1.0703125,
      "learning_rate": 6.77283317172177e-06,
      "loss": 0.2196,
      "step": 4910
    },
    {
      "epoch": 6.0544531610521455,
      "grad_norm": 1.1328125,
      "learning_rate": 6.760394694818949e-06,
      "loss": 0.2278,
      "step": 4920
    },
    {
      "epoch": 6.066758960159976,
      "grad_norm": 1.109375,
      "learning_rate": 6.747943769456719e-06,
      "loss": 0.2108,
      "step": 4930
    },
    {
      "epoch": 6.079064759267805,
      "grad_norm": 1.1015625,
      "learning_rate": 6.735480483680587e-06,
      "loss": 0.2637,
      "step": 4940
    },
    {
      "epoch": 6.091370558375634,
      "grad_norm": 0.9921875,
      "learning_rate": 6.723004925623461e-06,
      "loss": 0.2592,
      "step": 4950
    },
    {
      "epoch": 6.103676357483464,
      "grad_norm": 1.296875,
      "learning_rate": 6.710517183505032e-06,
      "loss": 0.235,
      "step": 4960
    },
    {
      "epoch": 6.1159821565912935,
      "grad_norm": 1.0546875,
      "learning_rate": 6.698017345631153e-06,
      "loss": 0.2621,
      "step": 4970
    },
    {
      "epoch": 6.128287955699124,
      "grad_norm": 1.0546875,
      "learning_rate": 6.685505500393204e-06,
      "loss": 0.2535,
      "step": 4980
    },
    {
      "epoch": 6.140593754806953,
      "grad_norm": 1.0,
      "learning_rate": 6.6729817362674855e-06,
      "loss": 0.2495,
      "step": 4990
    },
    {
      "epoch": 6.152899553914782,
      "grad_norm": 0.94140625,
      "learning_rate": 6.660446141814568e-06,
      "loss": 0.2528,
      "step": 5000
    },
    {
      "epoch": 6.152899553914782,
      "eval_loss": NaN,
      "eval_runtime": 441.995,
      "eval_samples_per_second": 117.653,
      "eval_steps_per_second": 14.708,
      "step": 5000
    },
    {
      "epoch": 6.165205353022612,
      "grad_norm": 1.1171875,
      "learning_rate": 6.647898805678688e-06,
      "loss": 0.2119,
      "step": 5010
    },
    {
      "epoch": 6.1775111521304416,
      "grad_norm": 1.1796875,
      "learning_rate": 6.635339816587109e-06,
      "loss": 0.2477,
      "step": 5020
    },
    {
      "epoch": 6.189816951238271,
      "grad_norm": 1.2421875,
      "learning_rate": 6.622769263349496e-06,
      "loss": 0.2541,
      "step": 5030
    },
    {
      "epoch": 6.202122750346101,
      "grad_norm": 1.03125,
      "learning_rate": 6.610187234857295e-06,
      "loss": 0.235,
      "step": 5040
    },
    {
      "epoch": 6.21442854945393,
      "grad_norm": 1.640625,
      "learning_rate": 6.597593820083088e-06,
      "loss": 0.2211,
      "step": 5050
    },
    {
      "epoch": 6.2267343485617594,
      "grad_norm": 0.9765625,
      "learning_rate": 6.584989108079982e-06,
      "loss": 0.2322,
      "step": 5060
    },
    {
      "epoch": 6.23904014766959,
      "grad_norm": 1.1640625,
      "learning_rate": 6.572373187980969e-06,
      "loss": 0.2565,
      "step": 5070
    },
    {
      "epoch": 6.251345946777419,
      "grad_norm": 1.1875,
      "learning_rate": 6.559746148998296e-06,
      "loss": 0.2322,
      "step": 5080
    },
    {
      "epoch": 6.263651745885248,
      "grad_norm": 0.89453125,
      "learning_rate": 6.547108080422839e-06,
      "loss": 0.2477,
      "step": 5090
    },
    {
      "epoch": 6.275957544993078,
      "grad_norm": 0.84765625,
      "learning_rate": 6.534459071623468e-06,
      "loss": 0.2348,
      "step": 5100
    },
    {
      "epoch": 6.2882633441009075,
      "grad_norm": 1.0,
      "learning_rate": 6.521799212046415e-06,
      "loss": 0.2663,
      "step": 5110
    },
    {
      "epoch": 6.300569143208737,
      "grad_norm": 0.90234375,
      "learning_rate": 6.509128591214641e-06,
      "loss": 0.2545,
      "step": 5120
    },
    {
      "epoch": 6.312874942316567,
      "grad_norm": 0.8359375,
      "learning_rate": 6.496447298727206e-06,
      "loss": 0.2362,
      "step": 5130
    },
    {
      "epoch": 6.325180741424396,
      "grad_norm": 0.90234375,
      "learning_rate": 6.483755424258633e-06,
      "loss": 0.2738,
      "step": 5140
    },
    {
      "epoch": 6.337486540532225,
      "grad_norm": 0.98828125,
      "learning_rate": 6.471053057558276e-06,
      "loss": 0.2582,
      "step": 5150
    },
    {
      "epoch": 6.3497923396400555,
      "grad_norm": 1.0234375,
      "learning_rate": 6.458340288449682e-06,
      "loss": 0.2412,
      "step": 5160
    },
    {
      "epoch": 6.362098138747885,
      "grad_norm": 1.03125,
      "learning_rate": 6.445617206829957e-06,
      "loss": 0.228,
      "step": 5170
    },
    {
      "epoch": 6.374403937855715,
      "grad_norm": 1.1484375,
      "learning_rate": 6.4328839026691324e-06,
      "loss": 0.2642,
      "step": 5180
    },
    {
      "epoch": 6.386709736963544,
      "grad_norm": 1.1171875,
      "learning_rate": 6.420140466009527e-06,
      "loss": 0.2483,
      "step": 5190
    },
    {
      "epoch": 6.399015536071373,
      "grad_norm": 0.86328125,
      "learning_rate": 6.407386986965109e-06,
      "loss": 0.2399,
      "step": 5200
    },
    {
      "epoch": 6.4113213351792036,
      "grad_norm": 0.91796875,
      "learning_rate": 6.394623555720864e-06,
      "loss": 0.2507,
      "step": 5210
    },
    {
      "epoch": 6.423627134287033,
      "grad_norm": 1.171875,
      "learning_rate": 6.38185026253215e-06,
      "loss": 0.2432,
      "step": 5220
    },
    {
      "epoch": 6.435932933394862,
      "grad_norm": 1.0859375,
      "learning_rate": 6.369067197724063e-06,
      "loss": 0.2808,
      "step": 5230
    },
    {
      "epoch": 6.448238732502692,
      "grad_norm": 1.1484375,
      "learning_rate": 6.356274451690803e-06,
      "loss": 0.25,
      "step": 5240
    },
    {
      "epoch": 6.4605445316105214,
      "grad_norm": 1.0703125,
      "learning_rate": 6.343472114895022e-06,
      "loss": 0.2498,
      "step": 5250
    },
    {
      "epoch": 6.472850330718351,
      "grad_norm": 1.328125,
      "learning_rate": 6.3306602778671974e-06,
      "loss": 0.2293,
      "step": 5260
    },
    {
      "epoch": 6.485156129826181,
      "grad_norm": 1.0703125,
      "learning_rate": 6.317839031204987e-06,
      "loss": 0.2581,
      "step": 5270
    },
    {
      "epoch": 6.49746192893401,
      "grad_norm": 1.21875,
      "learning_rate": 6.305008465572583e-06,
      "loss": 0.2367,
      "step": 5280
    },
    {
      "epoch": 6.509767728041839,
      "grad_norm": 0.9921875,
      "learning_rate": 6.292168671700082e-06,
      "loss": 0.2464,
      "step": 5290
    },
    {
      "epoch": 6.5220735271496695,
      "grad_norm": 1.1640625,
      "learning_rate": 6.279319740382832e-06,
      "loss": 0.2493,
      "step": 5300
    },
    {
      "epoch": 6.534379326257499,
      "grad_norm": 1.09375,
      "learning_rate": 6.2664617624808e-06,
      "loss": 0.2265,
      "step": 5310
    },
    {
      "epoch": 6.546685125365329,
      "grad_norm": 1.015625,
      "learning_rate": 6.253594828917922e-06,
      "loss": 0.2189,
      "step": 5320
    },
    {
      "epoch": 6.558990924473158,
      "grad_norm": 0.99609375,
      "learning_rate": 6.240719030681463e-06,
      "loss": 0.2416,
      "step": 5330
    },
    {
      "epoch": 6.571296723580987,
      "grad_norm": 1.25,
      "learning_rate": 6.227834458821372e-06,
      "loss": 0.2259,
      "step": 5340
    },
    {
      "epoch": 6.5836025226888175,
      "grad_norm": 1.0390625,
      "learning_rate": 6.2149412044496495e-06,
      "loss": 0.2384,
      "step": 5350
    },
    {
      "epoch": 6.595908321796647,
      "grad_norm": 1.109375,
      "learning_rate": 6.202039358739681e-06,
      "loss": 0.2425,
      "step": 5360
    },
    {
      "epoch": 6.608214120904476,
      "grad_norm": 0.7578125,
      "learning_rate": 6.189129012925612e-06,
      "loss": 0.2399,
      "step": 5370
    },
    {
      "epoch": 6.620519920012306,
      "grad_norm": 0.92578125,
      "learning_rate": 6.176210258301693e-06,
      "loss": 0.2587,
      "step": 5380
    },
    {
      "epoch": 6.632825719120135,
      "grad_norm": 0.82421875,
      "learning_rate": 6.163283186221638e-06,
      "loss": 0.2406,
      "step": 5390
    },
    {
      "epoch": 6.645131518227965,
      "grad_norm": 0.9375,
      "learning_rate": 6.150347888097976e-06,
      "loss": 0.2454,
      "step": 5400
    },
    {
      "epoch": 6.657437317335795,
      "grad_norm": 1.09375,
      "learning_rate": 6.137404455401407e-06,
      "loss": 0.2309,
      "step": 5410
    },
    {
      "epoch": 6.669743116443624,
      "grad_norm": 1.296875,
      "learning_rate": 6.124452979660154e-06,
      "loss": 0.2474,
      "step": 5420
    },
    {
      "epoch": 6.682048915551453,
      "grad_norm": 1.1171875,
      "learning_rate": 6.111493552459312e-06,
      "loss": 0.2524,
      "step": 5430
    },
    {
      "epoch": 6.6943547146592834,
      "grad_norm": 1.2734375,
      "learning_rate": 6.098526265440208e-06,
      "loss": 0.2741,
      "step": 5440
    },
    {
      "epoch": 6.706660513767113,
      "grad_norm": 1.375,
      "learning_rate": 6.0855512102997485e-06,
      "loss": 0.2642,
      "step": 5450
    },
    {
      "epoch": 6.718966312874942,
      "grad_norm": 0.91796875,
      "learning_rate": 6.07256847878977e-06,
      "loss": 0.2225,
      "step": 5460
    },
    {
      "epoch": 6.731272111982772,
      "grad_norm": 1.3125,
      "learning_rate": 6.0595781627163906e-06,
      "loss": 0.257,
      "step": 5470
    },
    {
      "epoch": 6.743577911090601,
      "grad_norm": 1.234375,
      "learning_rate": 6.0465803539393655e-06,
      "loss": 0.2334,
      "step": 5480
    },
    {
      "epoch": 6.755883710198431,
      "grad_norm": 1.21875,
      "learning_rate": 6.033575144371432e-06,
      "loss": 0.2568,
      "step": 5490
    },
    {
      "epoch": 6.768189509306261,
      "grad_norm": 0.9375,
      "learning_rate": 6.02056262597766e-06,
      "loss": 0.2635,
      "step": 5500
    },
    {
      "epoch": 6.78049530841409,
      "grad_norm": 1.03125,
      "learning_rate": 6.007542890774806e-06,
      "loss": 0.2571,
      "step": 5510
    },
    {
      "epoch": 6.792801107521919,
      "grad_norm": 2.0,
      "learning_rate": 5.994516030830655e-06,
      "loss": 0.2258,
      "step": 5520
    },
    {
      "epoch": 6.805106906629749,
      "grad_norm": 1.1171875,
      "learning_rate": 5.981482138263381e-06,
      "loss": 0.2219,
      "step": 5530
    },
    {
      "epoch": 6.817412705737579,
      "grad_norm": 1.1015625,
      "learning_rate": 5.968441305240878e-06,
      "loss": 0.2535,
      "step": 5540
    },
    {
      "epoch": 6.829718504845409,
      "grad_norm": 1.125,
      "learning_rate": 5.955393623980132e-06,
      "loss": 0.2468,
      "step": 5550
    },
    {
      "epoch": 6.842024303953238,
      "grad_norm": 1.046875,
      "learning_rate": 5.942339186746544e-06,
      "loss": 0.2273,
      "step": 5560
    },
    {
      "epoch": 6.854330103061067,
      "grad_norm": 0.94921875,
      "learning_rate": 5.929278085853296e-06,
      "loss": 0.2248,
      "step": 5570
    },
    {
      "epoch": 6.866635902168897,
      "grad_norm": 0.96484375,
      "learning_rate": 5.916210413660687e-06,
      "loss": 0.2532,
      "step": 5580
    },
    {
      "epoch": 6.878941701276727,
      "grad_norm": 0.828125,
      "learning_rate": 5.9031362625754885e-06,
      "loss": 0.2536,
      "step": 5590
    },
    {
      "epoch": 6.891247500384556,
      "grad_norm": 1.046875,
      "learning_rate": 5.890055725050283e-06,
      "loss": 0.207,
      "step": 5600
    },
    {
      "epoch": 6.903553299492386,
      "grad_norm": 0.93359375,
      "learning_rate": 5.876968893582818e-06,
      "loss": 0.2399,
      "step": 5610
    },
    {
      "epoch": 6.915859098600215,
      "grad_norm": 0.98828125,
      "learning_rate": 5.863875860715346e-06,
      "loss": 0.2512,
      "step": 5620
    },
    {
      "epoch": 6.928164897708045,
      "grad_norm": 1.0234375,
      "learning_rate": 5.85077671903397e-06,
      "loss": 0.2543,
      "step": 5630
    },
    {
      "epoch": 6.940470696815875,
      "grad_norm": 1.0625,
      "learning_rate": 5.837671561167996e-06,
      "loss": 0.2516,
      "step": 5640
    },
    {
      "epoch": 6.952776495923704,
      "grad_norm": 1.2109375,
      "learning_rate": 5.8245604797892666e-06,
      "loss": 0.219,
      "step": 5650
    },
    {
      "epoch": 6.965082295031534,
      "grad_norm": 1.1015625,
      "learning_rate": 5.811443567611516e-06,
      "loss": 0.26,
      "step": 5660
    },
    {
      "epoch": 6.977388094139363,
      "grad_norm": 1.015625,
      "learning_rate": 5.798320917389712e-06,
      "loss": 0.2358,
      "step": 5670
    },
    {
      "epoch": 6.989693893247193,
      "grad_norm": 0.984375,
      "learning_rate": 5.785192621919392e-06,
      "loss": 0.2331,
      "step": 5680
    },
    {
      "epoch": 7.001999692355023,
      "grad_norm": 0.90234375,
      "learning_rate": 5.77205877403602e-06,
      "loss": 0.2455,
      "step": 5690
    },
    {
      "epoch": 7.014305491462852,
      "grad_norm": 0.9921875,
      "learning_rate": 5.758919466614319e-06,
      "loss": 0.2521,
      "step": 5700
    },
    {
      "epoch": 7.026611290570681,
      "grad_norm": 1.0703125,
      "learning_rate": 5.745774792567622e-06,
      "loss": 0.2422,
      "step": 5710
    },
    {
      "epoch": 7.038917089678511,
      "grad_norm": 1.3125,
      "learning_rate": 5.7326248448472065e-06,
      "loss": 0.2623,
      "step": 5720
    },
    {
      "epoch": 7.051222888786341,
      "grad_norm": 0.921875,
      "learning_rate": 5.719469716441649e-06,
      "loss": 0.2294,
      "step": 5730
    },
    {
      "epoch": 7.06352868789417,
      "grad_norm": 1.296875,
      "learning_rate": 5.706309500376153e-06,
      "loss": 0.2268,
      "step": 5740
    },
    {
      "epoch": 7.075834487002,
      "grad_norm": 1.4453125,
      "learning_rate": 5.693144289711907e-06,
      "loss": 0.2315,
      "step": 5750
    },
    {
      "epoch": 7.088140286109829,
      "grad_norm": 0.81640625,
      "learning_rate": 5.6799741775454135e-06,
      "loss": 0.2066,
      "step": 5760
    },
    {
      "epoch": 7.1004460852176585,
      "grad_norm": 1.0546875,
      "learning_rate": 5.666799257007835e-06,
      "loss": 0.226,
      "step": 5770
    },
    {
      "epoch": 7.112751884325489,
      "grad_norm": 1.125,
      "learning_rate": 5.6536196212643356e-06,
      "loss": 0.2209,
      "step": 5780
    },
    {
      "epoch": 7.125057683433318,
      "grad_norm": 0.96484375,
      "learning_rate": 5.640435363513428e-06,
      "loss": 0.2531,
      "step": 5790
    },
    {
      "epoch": 7.137363482541147,
      "grad_norm": 0.9453125,
      "learning_rate": 5.627246576986303e-06,
      "loss": 0.2299,
      "step": 5800
    },
    {
      "epoch": 7.149669281648977,
      "grad_norm": 0.953125,
      "learning_rate": 5.6140533549461775e-06,
      "loss": 0.2405,
      "step": 5810
    },
    {
      "epoch": 7.1619750807568066,
      "grad_norm": 0.87109375,
      "learning_rate": 5.600855790687638e-06,
      "loss": 0.2288,
      "step": 5820
    },
    {
      "epoch": 7.174280879864636,
      "grad_norm": 1.0,
      "learning_rate": 5.5876539775359695e-06,
      "loss": 0.2751,
      "step": 5830
    },
    {
      "epoch": 7.186586678972466,
      "grad_norm": 0.91015625,
      "learning_rate": 5.574448008846508e-06,
      "loss": 0.2547,
      "step": 5840
    },
    {
      "epoch": 7.198892478080295,
      "grad_norm": 1.046875,
      "learning_rate": 5.561237978003972e-06,
      "loss": 0.2472,
      "step": 5850
    },
    {
      "epoch": 7.2111982771881245,
      "grad_norm": 0.97265625,
      "learning_rate": 5.548023978421809e-06,
      "loss": 0.2647,
      "step": 5860
    },
    {
      "epoch": 7.223504076295955,
      "grad_norm": 0.99609375,
      "learning_rate": 5.534806103541526e-06,
      "loss": 0.231,
      "step": 5870
    },
    {
      "epoch": 7.235809875403784,
      "grad_norm": 0.87890625,
      "learning_rate": 5.521584446832036e-06,
      "loss": 0.2177,
      "step": 5880
    },
    {
      "epoch": 7.248115674511614,
      "grad_norm": 1.21875,
      "learning_rate": 5.508359101788996e-06,
      "loss": 0.2674,
      "step": 5890
    },
    {
      "epoch": 7.260421473619443,
      "grad_norm": 1.140625,
      "learning_rate": 5.495130161934143e-06,
      "loss": 0.2669,
      "step": 5900
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 0.91015625,
      "learning_rate": 5.4818977208146375e-06,
      "loss": 0.2064,
      "step": 5910
    },
    {
      "epoch": 7.285033071835103,
      "grad_norm": 0.95703125,
      "learning_rate": 5.468661872002393e-06,
      "loss": 0.2218,
      "step": 5920
    },
    {
      "epoch": 7.297338870942932,
      "grad_norm": 1.140625,
      "learning_rate": 5.455422709093427e-06,
      "loss": 0.2432,
      "step": 5930
    },
    {
      "epoch": 7.309644670050761,
      "grad_norm": 1.03125,
      "learning_rate": 5.442180325707185e-06,
      "loss": 0.2591,
      "step": 5940
    },
    {
      "epoch": 7.321950469158591,
      "grad_norm": 1.09375,
      "learning_rate": 5.428934815485892e-06,
      "loss": 0.2349,
      "step": 5950
    },
    {
      "epoch": 7.3342562682664205,
      "grad_norm": 1.15625,
      "learning_rate": 5.415686272093882e-06,
      "loss": 0.2089,
      "step": 5960
    },
    {
      "epoch": 7.34656206737425,
      "grad_norm": 0.9140625,
      "learning_rate": 5.402434789216938e-06,
      "loss": 0.2351,
      "step": 5970
    },
    {
      "epoch": 7.35886786648208,
      "grad_norm": 0.8984375,
      "learning_rate": 5.389180460561627e-06,
      "loss": 0.2699,
      "step": 5980
    },
    {
      "epoch": 7.371173665589909,
      "grad_norm": 0.9296875,
      "learning_rate": 5.3759233798546425e-06,
      "loss": 0.2311,
      "step": 5990
    },
    {
      "epoch": 7.383479464697738,
      "grad_norm": 1.484375,
      "learning_rate": 5.362663640842138e-06,
      "loss": 0.2457,
      "step": 6000
    },
    {
      "epoch": 7.3957852638055686,
      "grad_norm": 1.0703125,
      "learning_rate": 5.3494013372890645e-06,
      "loss": 0.2733,
      "step": 6010
    },
    {
      "epoch": 7.408091062913398,
      "grad_norm": 1.2421875,
      "learning_rate": 5.336136562978509e-06,
      "loss": 0.2698,
      "step": 6020
    },
    {
      "epoch": 7.420396862021228,
      "grad_norm": 1.1796875,
      "learning_rate": 5.3228694117110295e-06,
      "loss": 0.2376,
      "step": 6030
    },
    {
      "epoch": 7.432702661129057,
      "grad_norm": 0.8828125,
      "learning_rate": 5.309599977303991e-06,
      "loss": 0.2368,
      "step": 6040
    },
    {
      "epoch": 7.4450084602368864,
      "grad_norm": 1.375,
      "learning_rate": 5.296328353590904e-06,
      "loss": 0.2338,
      "step": 6050
    },
    {
      "epoch": 7.457314259344717,
      "grad_norm": 1.3046875,
      "learning_rate": 5.283054634420764e-06,
      "loss": 0.2335,
      "step": 6060
    },
    {
      "epoch": 7.469620058452546,
      "grad_norm": 1.09375,
      "learning_rate": 5.269778913657381e-06,
      "loss": 0.2356,
      "step": 6070
    },
    {
      "epoch": 7.481925857560375,
      "grad_norm": 0.9375,
      "learning_rate": 5.256501285178719e-06,
      "loss": 0.2305,
      "step": 6080
    },
    {
      "epoch": 7.494231656668205,
      "grad_norm": 1.0703125,
      "learning_rate": 5.243221842876235e-06,
      "loss": 0.2492,
      "step": 6090
    },
    {
      "epoch": 7.5065374557760345,
      "grad_norm": 1.5,
      "learning_rate": 5.229940680654205e-06,
      "loss": 0.2736,
      "step": 6100
    },
    {
      "epoch": 7.518843254883864,
      "grad_norm": 1.109375,
      "learning_rate": 5.216657892429078e-06,
      "loss": 0.2598,
      "step": 6110
    },
    {
      "epoch": 7.531149053991694,
      "grad_norm": 1.0859375,
      "learning_rate": 5.2033735721287925e-06,
      "loss": 0.2369,
      "step": 6120
    },
    {
      "epoch": 7.543454853099523,
      "grad_norm": 2.09375,
      "learning_rate": 5.190087813692127e-06,
      "loss": 0.2626,
      "step": 6130
    },
    {
      "epoch": 7.555760652207352,
      "grad_norm": 1.1328125,
      "learning_rate": 5.1768007110680225e-06,
      "loss": 0.2269,
      "step": 6140
    },
    {
      "epoch": 7.5680664513151825,
      "grad_norm": 1.15625,
      "learning_rate": 5.163512358214932e-06,
      "loss": 0.222,
      "step": 6150
    },
    {
      "epoch": 7.580372250423012,
      "grad_norm": 0.96875,
      "learning_rate": 5.150222849100146e-06,
      "loss": 0.2242,
      "step": 6160
    },
    {
      "epoch": 7.592678049530841,
      "grad_norm": 0.98046875,
      "learning_rate": 5.136932277699133e-06,
      "loss": 0.2435,
      "step": 6170
    },
    {
      "epoch": 7.604983848638671,
      "grad_norm": 1.4921875,
      "learning_rate": 5.123640737994873e-06,
      "loss": 0.2396,
      "step": 6180
    },
    {
      "epoch": 7.6172896477465,
      "grad_norm": 1.171875,
      "learning_rate": 5.11034832397719e-06,
      "loss": 0.2345,
      "step": 6190
    },
    {
      "epoch": 7.62959544685433,
      "grad_norm": 0.921875,
      "learning_rate": 5.097055129642096e-06,
      "loss": 0.2492,
      "step": 6200
    },
    {
      "epoch": 7.64190124596216,
      "grad_norm": 0.9140625,
      "learning_rate": 5.083761248991117e-06,
      "loss": 0.2602,
      "step": 6210
    },
    {
      "epoch": 7.654207045069989,
      "grad_norm": 0.7734375,
      "learning_rate": 5.070466776030636e-06,
      "loss": 0.227,
      "step": 6220
    },
    {
      "epoch": 7.666512844177818,
      "grad_norm": 0.95703125,
      "learning_rate": 5.0571718047712195e-06,
      "loss": 0.2515,
      "step": 6230
    },
    {
      "epoch": 7.6788186432856484,
      "grad_norm": 1.0703125,
      "learning_rate": 5.043876429226962e-06,
      "loss": 0.2086,
      "step": 6240
    },
    {
      "epoch": 7.691124442393478,
      "grad_norm": 1.1640625,
      "learning_rate": 5.030580743414811e-06,
      "loss": 0.2541,
      "step": 6250
    },
    {
      "epoch": 7.703430241501308,
      "grad_norm": 1.0390625,
      "learning_rate": 5.017284841353919e-06,
      "loss": 0.245,
      "step": 6260
    },
    {
      "epoch": 7.715736040609137,
      "grad_norm": 0.90625,
      "learning_rate": 5.003988817064954e-06,
      "loss": 0.2545,
      "step": 6270
    },
    {
      "epoch": 7.728041839716966,
      "grad_norm": 0.86328125,
      "learning_rate": 4.990692764569459e-06,
      "loss": 0.2545,
      "step": 6280
    },
    {
      "epoch": 7.7403476388247965,
      "grad_norm": 1.015625,
      "learning_rate": 4.977396777889173e-06,
      "loss": 0.2408,
      "step": 6290
    },
    {
      "epoch": 7.752653437932626,
      "grad_norm": 0.92578125,
      "learning_rate": 4.964100951045366e-06,
      "loss": 0.2415,
      "step": 6300
    },
    {
      "epoch": 7.764959237040455,
      "grad_norm": 1.1953125,
      "learning_rate": 4.950805378058185e-06,
      "loss": 0.2475,
      "step": 6310
    },
    {
      "epoch": 7.777265036148285,
      "grad_norm": 1.09375,
      "learning_rate": 4.937510152945973e-06,
      "loss": 0.2178,
      "step": 6320
    },
    {
      "epoch": 7.789570835256114,
      "grad_norm": 1.0859375,
      "learning_rate": 4.924215369724622e-06,
      "loss": 0.2356,
      "step": 6330
    },
    {
      "epoch": 7.801876634363944,
      "grad_norm": 0.9140625,
      "learning_rate": 4.9109211224068935e-06,
      "loss": 0.2529,
      "step": 6340
    },
    {
      "epoch": 7.814182433471774,
      "grad_norm": 0.9609375,
      "learning_rate": 4.897627505001761e-06,
      "loss": 0.2386,
      "step": 6350
    },
    {
      "epoch": 7.826488232579603,
      "grad_norm": 0.8984375,
      "learning_rate": 4.884334611513743e-06,
      "loss": 0.2669,
      "step": 6360
    },
    {
      "epoch": 7.838794031687433,
      "grad_norm": 1.03125,
      "learning_rate": 4.871042535942239e-06,
      "loss": 0.2251,
      "step": 6370
    },
    {
      "epoch": 7.851099830795262,
      "grad_norm": 0.9765625,
      "learning_rate": 4.857751372280865e-06,
      "loss": 0.2069,
      "step": 6380
    },
    {
      "epoch": 7.863405629903092,
      "grad_norm": 1.0546875,
      "learning_rate": 4.844461214516792e-06,
      "loss": 0.2249,
      "step": 6390
    },
    {
      "epoch": 7.875711429010922,
      "grad_norm": 1.6875,
      "learning_rate": 4.831172156630071e-06,
      "loss": 0.2308,
      "step": 6400
    },
    {
      "epoch": 7.888017228118751,
      "grad_norm": 0.875,
      "learning_rate": 4.817884292592982e-06,
      "loss": 0.2591,
      "step": 6410
    },
    {
      "epoch": 7.90032302722658,
      "grad_norm": 1.3046875,
      "learning_rate": 4.804597716369355e-06,
      "loss": 0.2252,
      "step": 6420
    },
    {
      "epoch": 7.9126288263344104,
      "grad_norm": 1.4296875,
      "learning_rate": 4.791312521913921e-06,
      "loss": 0.2576,
      "step": 6430
    },
    {
      "epoch": 7.92493462544224,
      "grad_norm": 1.015625,
      "learning_rate": 4.77802880317164e-06,
      "loss": 0.2577,
      "step": 6440
    },
    {
      "epoch": 7.937240424550069,
      "grad_norm": 0.88671875,
      "learning_rate": 4.764746654077026e-06,
      "loss": 0.2568,
      "step": 6450
    },
    {
      "epoch": 7.949546223657899,
      "grad_norm": 0.77734375,
      "learning_rate": 4.751466168553509e-06,
      "loss": 0.2389,
      "step": 6460
    },
    {
      "epoch": 7.961852022765728,
      "grad_norm": 0.80859375,
      "learning_rate": 4.738187440512742e-06,
      "loss": 0.2341,
      "step": 6470
    },
    {
      "epoch": 7.974157821873558,
      "grad_norm": 1.0234375,
      "learning_rate": 4.724910563853958e-06,
      "loss": 0.2646,
      "step": 6480
    },
    {
      "epoch": 7.986463620981388,
      "grad_norm": 1.1015625,
      "learning_rate": 4.711635632463294e-06,
      "loss": 0.2479,
      "step": 6490
    },
    {
      "epoch": 7.998769420089217,
      "grad_norm": 1.2890625,
      "learning_rate": 4.6983627402131335e-06,
      "loss": 0.2367,
      "step": 6500
    },
    {
      "epoch": 8.011075219197046,
      "grad_norm": 0.9765625,
      "learning_rate": 4.685091980961441e-06,
      "loss": 0.2437,
      "step": 6510
    },
    {
      "epoch": 8.023381018304876,
      "grad_norm": 1.0546875,
      "learning_rate": 4.671823448551092e-06,
      "loss": 0.2515,
      "step": 6520
    },
    {
      "epoch": 8.035686817412707,
      "grad_norm": 1.1015625,
      "learning_rate": 4.658557236809223e-06,
      "loss": 0.2562,
      "step": 6530
    },
    {
      "epoch": 8.047992616520535,
      "grad_norm": 1.015625,
      "learning_rate": 4.645293439546558e-06,
      "loss": 0.2283,
      "step": 6540
    },
    {
      "epoch": 8.060298415628365,
      "grad_norm": 1.0390625,
      "learning_rate": 4.632032150556743e-06,
      "loss": 0.2429,
      "step": 6550
    },
    {
      "epoch": 8.072604214736195,
      "grad_norm": 0.921875,
      "learning_rate": 4.61877346361569e-06,
      "loss": 0.2406,
      "step": 6560
    },
    {
      "epoch": 8.084910013844024,
      "grad_norm": 0.94921875,
      "learning_rate": 4.605517472480912e-06,
      "loss": 0.2379,
      "step": 6570
    },
    {
      "epoch": 8.097215812951854,
      "grad_norm": 1.0625,
      "learning_rate": 4.592264270890855e-06,
      "loss": 0.2321,
      "step": 6580
    },
    {
      "epoch": 8.109521612059684,
      "grad_norm": 1.2890625,
      "learning_rate": 4.579013952564246e-06,
      "loss": 0.2284,
      "step": 6590
    },
    {
      "epoch": 8.121827411167512,
      "grad_norm": 0.96484375,
      "learning_rate": 4.565766611199415e-06,
      "loss": 0.2474,
      "step": 6600
    },
    {
      "epoch": 8.134133210275342,
      "grad_norm": 1.203125,
      "learning_rate": 4.5525223404736475e-06,
      "loss": 0.2374,
      "step": 6610
    },
    {
      "epoch": 8.146439009383172,
      "grad_norm": 1.140625,
      "learning_rate": 4.539281234042509e-06,
      "loss": 0.2456,
      "step": 6620
    },
    {
      "epoch": 8.158744808491,
      "grad_norm": 1.0625,
      "learning_rate": 4.526043385539193e-06,
      "loss": 0.2235,
      "step": 6630
    },
    {
      "epoch": 8.171050607598831,
      "grad_norm": 1.125,
      "learning_rate": 4.512808888573859e-06,
      "loss": 0.226,
      "step": 6640
    },
    {
      "epoch": 8.183356406706661,
      "grad_norm": 1.25,
      "learning_rate": 4.499577836732954e-06,
      "loss": 0.2359,
      "step": 6650
    },
    {
      "epoch": 8.19566220581449,
      "grad_norm": 0.94921875,
      "learning_rate": 4.486350323578578e-06,
      "loss": 0.2201,
      "step": 6660
    },
    {
      "epoch": 8.20796800492232,
      "grad_norm": 0.87890625,
      "learning_rate": 4.473126442647795e-06,
      "loss": 0.2422,
      "step": 6670
    },
    {
      "epoch": 8.22027380403015,
      "grad_norm": 1.078125,
      "learning_rate": 4.459906287451992e-06,
      "loss": 0.2471,
      "step": 6680
    },
    {
      "epoch": 8.232579603137978,
      "grad_norm": 1.109375,
      "learning_rate": 4.446689951476208e-06,
      "loss": 0.2417,
      "step": 6690
    },
    {
      "epoch": 8.244885402245808,
      "grad_norm": 0.8984375,
      "learning_rate": 4.4334775281784705e-06,
      "loss": 0.2158,
      "step": 6700
    },
    {
      "epoch": 8.257191201353638,
      "grad_norm": 0.97265625,
      "learning_rate": 4.420269110989146e-06,
      "loss": 0.248,
      "step": 6710
    },
    {
      "epoch": 8.269497000461467,
      "grad_norm": 0.92578125,
      "learning_rate": 4.407064793310265e-06,
      "loss": 0.2372,
      "step": 6720
    },
    {
      "epoch": 8.281802799569297,
      "grad_norm": 0.8046875,
      "learning_rate": 4.393864668514875e-06,
      "loss": 0.2627,
      "step": 6730
    },
    {
      "epoch": 8.294108598677127,
      "grad_norm": 0.94140625,
      "learning_rate": 4.380668829946373e-06,
      "loss": 0.2457,
      "step": 6740
    },
    {
      "epoch": 8.306414397784955,
      "grad_norm": 1.1328125,
      "learning_rate": 4.367477370917839e-06,
      "loss": 0.2394,
      "step": 6750
    },
    {
      "epoch": 8.318720196892786,
      "grad_norm": 1.234375,
      "learning_rate": 4.354290384711394e-06,
      "loss": 0.2396,
      "step": 6760
    },
    {
      "epoch": 8.331025996000616,
      "grad_norm": 0.9609375,
      "learning_rate": 4.341107964577523e-06,
      "loss": 0.2208,
      "step": 6770
    },
    {
      "epoch": 8.343331795108444,
      "grad_norm": 1.2890625,
      "learning_rate": 4.327930203734422e-06,
      "loss": 0.2308,
      "step": 6780
    },
    {
      "epoch": 8.355637594216274,
      "grad_norm": 1.0859375,
      "learning_rate": 4.314757195367347e-06,
      "loss": 0.2766,
      "step": 6790
    },
    {
      "epoch": 8.367943393324104,
      "grad_norm": 0.8984375,
      "learning_rate": 4.301589032627937e-06,
      "loss": 0.2359,
      "step": 6800
    },
    {
      "epoch": 8.380249192431933,
      "grad_norm": 0.9921875,
      "learning_rate": 4.2884258086335755e-06,
      "loss": 0.2422,
      "step": 6810
    },
    {
      "epoch": 8.392554991539763,
      "grad_norm": 0.96875,
      "learning_rate": 4.275267616466713e-06,
      "loss": 0.2441,
      "step": 6820
    },
    {
      "epoch": 8.404860790647593,
      "grad_norm": 1.1796875,
      "learning_rate": 4.262114549174222e-06,
      "loss": 0.251,
      "step": 6830
    },
    {
      "epoch": 8.417166589755423,
      "grad_norm": 0.94140625,
      "learning_rate": 4.248966699766741e-06,
      "loss": 0.2232,
      "step": 6840
    },
    {
      "epoch": 8.429472388863251,
      "grad_norm": 0.890625,
      "learning_rate": 4.2358241612179975e-06,
      "loss": 0.2148,
      "step": 6850
    },
    {
      "epoch": 8.441778187971082,
      "grad_norm": 0.97265625,
      "learning_rate": 4.222687026464177e-06,
      "loss": 0.2541,
      "step": 6860
    },
    {
      "epoch": 8.454083987078912,
      "grad_norm": 1.03125,
      "learning_rate": 4.209555388403243e-06,
      "loss": 0.2264,
      "step": 6870
    },
    {
      "epoch": 8.46638978618674,
      "grad_norm": 1.1640625,
      "learning_rate": 4.196429339894295e-06,
      "loss": 0.2224,
      "step": 6880
    },
    {
      "epoch": 8.47869558529457,
      "grad_norm": 1.015625,
      "learning_rate": 4.183308973756905e-06,
      "loss": 0.239,
      "step": 6890
    },
    {
      "epoch": 8.4910013844024,
      "grad_norm": 1.0625,
      "learning_rate": 4.170194382770462e-06,
      "loss": 0.2239,
      "step": 6900
    },
    {
      "epoch": 8.503307183510229,
      "grad_norm": 1.0390625,
      "learning_rate": 4.1570856596735176e-06,
      "loss": 0.2297,
      "step": 6910
    },
    {
      "epoch": 8.515612982618059,
      "grad_norm": 1.296875,
      "learning_rate": 4.143982897163127e-06,
      "loss": 0.249,
      "step": 6920
    },
    {
      "epoch": 8.527918781725889,
      "grad_norm": 0.77734375,
      "learning_rate": 4.1308861878942005e-06,
      "loss": 0.2279,
      "step": 6930
    },
    {
      "epoch": 8.540224580833717,
      "grad_norm": 1.3125,
      "learning_rate": 4.1177956244788404e-06,
      "loss": 0.2931,
      "step": 6940
    },
    {
      "epoch": 8.552530379941548,
      "grad_norm": 0.984375,
      "learning_rate": 4.104711299485687e-06,
      "loss": 0.223,
      "step": 6950
    },
    {
      "epoch": 8.564836179049378,
      "grad_norm": 0.98046875,
      "learning_rate": 4.09163330543927e-06,
      "loss": 0.213,
      "step": 6960
    },
    {
      "epoch": 8.577141978157206,
      "grad_norm": 0.9296875,
      "learning_rate": 4.078561734819348e-06,
      "loss": 0.251,
      "step": 6970
    },
    {
      "epoch": 8.589447777265036,
      "grad_norm": 1.0234375,
      "learning_rate": 4.065496680060257e-06,
      "loss": 0.2422,
      "step": 6980
    },
    {
      "epoch": 8.601753576372866,
      "grad_norm": 2.59375,
      "learning_rate": 4.052438233550262e-06,
      "loss": 0.2812,
      "step": 6990
    },
    {
      "epoch": 8.614059375480695,
      "grad_norm": 0.890625,
      "learning_rate": 4.039386487630889e-06,
      "loss": 0.2429,
      "step": 7000
    },
    {
      "epoch": 8.626365174588525,
      "grad_norm": 1.046875,
      "learning_rate": 4.02634153459629e-06,
      "loss": 0.2422,
      "step": 7010
    },
    {
      "epoch": 8.638670973696355,
      "grad_norm": 1.1328125,
      "learning_rate": 4.0133034666925755e-06,
      "loss": 0.2737,
      "step": 7020
    },
    {
      "epoch": 8.650976772804183,
      "grad_norm": 1.2734375,
      "learning_rate": 4.000272376117171e-06,
      "loss": 0.2296,
      "step": 7030
    },
    {
      "epoch": 8.663282571912013,
      "grad_norm": 1.0390625,
      "learning_rate": 3.987248355018167e-06,
      "loss": 0.2279,
      "step": 7040
    },
    {
      "epoch": 8.675588371019844,
      "grad_norm": 1.0859375,
      "learning_rate": 3.974231495493654e-06,
      "loss": 0.2367,
      "step": 7050
    },
    {
      "epoch": 8.687894170127672,
      "grad_norm": 1.015625,
      "learning_rate": 3.961221889591087e-06,
      "loss": 0.2338,
      "step": 7060
    },
    {
      "epoch": 8.700199969235502,
      "grad_norm": 1.1484375,
      "learning_rate": 3.948219629306624e-06,
      "loss": 0.2251,
      "step": 7070
    },
    {
      "epoch": 8.712505768343332,
      "grad_norm": 1.0625,
      "learning_rate": 3.935224806584481e-06,
      "loss": 0.2331,
      "step": 7080
    },
    {
      "epoch": 8.72481156745116,
      "grad_norm": 1.015625,
      "learning_rate": 3.9222375133162825e-06,
      "loss": 0.2215,
      "step": 7090
    },
    {
      "epoch": 8.73711736655899,
      "grad_norm": 0.98828125,
      "learning_rate": 3.909257841340401e-06,
      "loss": 0.2451,
      "step": 7100
    },
    {
      "epoch": 8.74942316566682,
      "grad_norm": 0.96484375,
      "learning_rate": 3.896285882441326e-06,
      "loss": 0.2396,
      "step": 7110
    },
    {
      "epoch": 8.76172896477465,
      "grad_norm": 1.0546875,
      "learning_rate": 3.883321728348995e-06,
      "loss": 0.2413,
      "step": 7120
    },
    {
      "epoch": 8.77403476388248,
      "grad_norm": 0.98828125,
      "learning_rate": 3.8703654707381635e-06,
      "loss": 0.2795,
      "step": 7130
    },
    {
      "epoch": 8.78634056299031,
      "grad_norm": 1.546875,
      "learning_rate": 3.857417201227743e-06,
      "loss": 0.2638,
      "step": 7140
    },
    {
      "epoch": 8.79864636209814,
      "grad_norm": 0.96875,
      "learning_rate": 3.844477011380157e-06,
      "loss": 0.2309,
      "step": 7150
    },
    {
      "epoch": 8.810952161205968,
      "grad_norm": 0.98828125,
      "learning_rate": 3.831544992700698e-06,
      "loss": 0.2357,
      "step": 7160
    },
    {
      "epoch": 8.823257960313798,
      "grad_norm": 1.046875,
      "learning_rate": 3.818621236636873e-06,
      "loss": 0.2451,
      "step": 7170
    },
    {
      "epoch": 8.835563759421628,
      "grad_norm": 0.9296875,
      "learning_rate": 3.8057058345777625e-06,
      "loss": 0.2321,
      "step": 7180
    },
    {
      "epoch": 8.847869558529457,
      "grad_norm": 0.9765625,
      "learning_rate": 3.7927988778533755e-06,
      "loss": 0.237,
      "step": 7190
    },
    {
      "epoch": 8.860175357637287,
      "grad_norm": 1.2109375,
      "learning_rate": 3.779900457733995e-06,
      "loss": 0.2268,
      "step": 7200
    },
    {
      "epoch": 8.872481156745117,
      "grad_norm": 0.94921875,
      "learning_rate": 3.767010665429543e-06,
      "loss": 0.2513,
      "step": 7210
    },
    {
      "epoch": 8.884786955852945,
      "grad_norm": 0.953125,
      "learning_rate": 3.7541295920889266e-06,
      "loss": 0.266,
      "step": 7220
    },
    {
      "epoch": 8.897092754960775,
      "grad_norm": 1.984375,
      "learning_rate": 3.7412573287994e-06,
      "loss": 0.2343,
      "step": 7230
    },
    {
      "epoch": 8.909398554068606,
      "grad_norm": 1.0,
      "learning_rate": 3.7283939665859216e-06,
      "loss": 0.2388,
      "step": 7240
    },
    {
      "epoch": 8.921704353176434,
      "grad_norm": 1.0078125,
      "learning_rate": 3.7155395964104966e-06,
      "loss": 0.2351,
      "step": 7250
    },
    {
      "epoch": 8.934010152284264,
      "grad_norm": 0.9609375,
      "learning_rate": 3.7026943091715552e-06,
      "loss": 0.2374,
      "step": 7260
    },
    {
      "epoch": 8.946315951392094,
      "grad_norm": 0.92578125,
      "learning_rate": 3.6898581957032907e-06,
      "loss": 0.2589,
      "step": 7270
    },
    {
      "epoch": 8.958621750499923,
      "grad_norm": 1.125,
      "learning_rate": 3.677031346775029e-06,
      "loss": 0.2578,
      "step": 7280
    },
    {
      "epoch": 8.970927549607753,
      "grad_norm": 0.84375,
      "learning_rate": 3.6642138530905815e-06,
      "loss": 0.2465,
      "step": 7290
    },
    {
      "epoch": 8.983233348715583,
      "grad_norm": 1.1171875,
      "learning_rate": 3.6514058052876033e-06,
      "loss": 0.2284,
      "step": 7300
    },
    {
      "epoch": 8.995539147823411,
      "grad_norm": 0.94140625,
      "learning_rate": 3.6386072939369576e-06,
      "loss": 0.239,
      "step": 7310
    },
    {
      "epoch": 9.007844946931241,
      "grad_norm": 0.890625,
      "learning_rate": 3.6258184095420658e-06,
      "loss": 0.2239,
      "step": 7320
    },
    {
      "epoch": 9.020150746039072,
      "grad_norm": 1.0546875,
      "learning_rate": 3.6130392425382803e-06,
      "loss": 0.2468,
      "step": 7330
    },
    {
      "epoch": 9.0324565451469,
      "grad_norm": 0.94140625,
      "learning_rate": 3.6002698832922338e-06,
      "loss": 0.2361,
      "step": 7340
    },
    {
      "epoch": 9.04476234425473,
      "grad_norm": 1.09375,
      "learning_rate": 3.587510422101203e-06,
      "loss": 0.2609,
      "step": 7350
    },
    {
      "epoch": 9.05706814336256,
      "grad_norm": 1.6484375,
      "learning_rate": 3.574760949192476e-06,
      "loss": 0.2138,
      "step": 7360
    },
    {
      "epoch": 9.069373942470389,
      "grad_norm": 0.98046875,
      "learning_rate": 3.5620215547227046e-06,
      "loss": 0.2414,
      "step": 7370
    },
    {
      "epoch": 9.081679741578219,
      "grad_norm": 1.3515625,
      "learning_rate": 3.5492923287772736e-06,
      "loss": 0.2701,
      "step": 7380
    },
    {
      "epoch": 9.093985540686049,
      "grad_norm": 1.0390625,
      "learning_rate": 3.536573361369667e-06,
      "loss": 0.2362,
      "step": 7390
    },
    {
      "epoch": 9.106291339793877,
      "grad_norm": 1.1875,
      "learning_rate": 3.5238647424408197e-06,
      "loss": 0.2718,
      "step": 7400
    },
    {
      "epoch": 9.118597138901707,
      "grad_norm": 1.109375,
      "learning_rate": 3.511166561858492e-06,
      "loss": 0.2485,
      "step": 7410
    },
    {
      "epoch": 9.130902938009537,
      "grad_norm": 1.1171875,
      "learning_rate": 3.498478909416629e-06,
      "loss": 0.2266,
      "step": 7420
    },
    {
      "epoch": 9.143208737117366,
      "grad_norm": 0.88671875,
      "learning_rate": 3.4858018748347285e-06,
      "loss": 0.2445,
      "step": 7430
    },
    {
      "epoch": 9.155514536225196,
      "grad_norm": 1.953125,
      "learning_rate": 3.4731355477572023e-06,
      "loss": 0.2317,
      "step": 7440
    },
    {
      "epoch": 9.167820335333026,
      "grad_norm": 1.2734375,
      "learning_rate": 3.4604800177527476e-06,
      "loss": 0.245,
      "step": 7450
    },
    {
      "epoch": 9.180126134440854,
      "grad_norm": 1.09375,
      "learning_rate": 3.4478353743137127e-06,
      "loss": 0.2223,
      "step": 7460
    },
    {
      "epoch": 9.192431933548685,
      "grad_norm": 1.0625,
      "learning_rate": 3.435201706855459e-06,
      "loss": 0.2742,
      "step": 7470
    },
    {
      "epoch": 9.204737732656515,
      "grad_norm": 0.91796875,
      "learning_rate": 3.422579104715735e-06,
      "loss": 0.2362,
      "step": 7480
    },
    {
      "epoch": 9.217043531764343,
      "grad_norm": 0.91015625,
      "learning_rate": 3.4099676571540387e-06,
      "loss": 0.2453,
      "step": 7490
    },
    {
      "epoch": 9.229349330872173,
      "grad_norm": 0.80078125,
      "learning_rate": 3.3973674533509925e-06,
      "loss": 0.231,
      "step": 7500
    },
    {
      "epoch": 9.241655129980003,
      "grad_norm": 1.5625,
      "learning_rate": 3.3847785824077106e-06,
      "loss": 0.2576,
      "step": 7510
    },
    {
      "epoch": 9.253960929087832,
      "grad_norm": 0.953125,
      "learning_rate": 3.372201133345163e-06,
      "loss": 0.2321,
      "step": 7520
    },
    {
      "epoch": 9.266266728195662,
      "grad_norm": 1.1171875,
      "learning_rate": 3.359635195103558e-06,
      "loss": 0.2453,
      "step": 7530
    },
    {
      "epoch": 9.278572527303492,
      "grad_norm": 1.484375,
      "learning_rate": 3.347080856541698e-06,
      "loss": 0.2369,
      "step": 7540
    },
    {
      "epoch": 9.290878326411322,
      "grad_norm": 0.9375,
      "learning_rate": 3.3345382064363676e-06,
      "loss": 0.2313,
      "step": 7550
    },
    {
      "epoch": 9.30318412551915,
      "grad_norm": 1.4609375,
      "learning_rate": 3.3220073334816928e-06,
      "loss": 0.2186,
      "step": 7560
    },
    {
      "epoch": 9.31548992462698,
      "grad_norm": 1.28125,
      "learning_rate": 3.309488326288518e-06,
      "loss": 0.2718,
      "step": 7570
    },
    {
      "epoch": 9.32779572373481,
      "grad_norm": 1.1875,
      "learning_rate": 3.296981273383784e-06,
      "loss": 0.2656,
      "step": 7580
    },
    {
      "epoch": 9.34010152284264,
      "grad_norm": 1.09375,
      "learning_rate": 3.284486263209893e-06,
      "loss": 0.204,
      "step": 7590
    },
    {
      "epoch": 9.35240732195047,
      "grad_norm": 0.7265625,
      "learning_rate": 3.272003384124094e-06,
      "loss": 0.2397,
      "step": 7600
    },
    {
      "epoch": 9.3647131210583,
      "grad_norm": 1.015625,
      "learning_rate": 3.259532724397848e-06,
      "loss": 0.2469,
      "step": 7610
    },
    {
      "epoch": 9.377018920166128,
      "grad_norm": 1.1015625,
      "learning_rate": 3.247074372216208e-06,
      "loss": 0.2571,
      "step": 7620
    },
    {
      "epoch": 9.389324719273958,
      "grad_norm": 1.2734375,
      "learning_rate": 3.2346284156771984e-06,
      "loss": 0.2227,
      "step": 7630
    },
    {
      "epoch": 9.401630518381788,
      "grad_norm": 1.0703125,
      "learning_rate": 3.2221949427911846e-06,
      "loss": 0.244,
      "step": 7640
    },
    {
      "epoch": 9.413936317489616,
      "grad_norm": 0.91015625,
      "learning_rate": 3.2097740414802587e-06,
      "loss": 0.2313,
      "step": 7650
    },
    {
      "epoch": 9.426242116597447,
      "grad_norm": 1.0234375,
      "learning_rate": 3.1973657995776153e-06,
      "loss": 0.238,
      "step": 7660
    },
    {
      "epoch": 9.438547915705277,
      "grad_norm": 1.546875,
      "learning_rate": 3.184970304826923e-06,
      "loss": 0.2426,
      "step": 7670
    },
    {
      "epoch": 9.450853714813105,
      "grad_norm": 0.89453125,
      "learning_rate": 3.1725876448817185e-06,
      "loss": 0.2224,
      "step": 7680
    },
    {
      "epoch": 9.463159513920935,
      "grad_norm": 1.4375,
      "learning_rate": 3.1602179073047693e-06,
      "loss": 0.2566,
      "step": 7690
    },
    {
      "epoch": 9.475465313028765,
      "grad_norm": 0.99609375,
      "learning_rate": 3.1478611795674713e-06,
      "loss": 0.2525,
      "step": 7700
    },
    {
      "epoch": 9.487771112136594,
      "grad_norm": 1.0859375,
      "learning_rate": 3.13551754904922e-06,
      "loss": 0.2425,
      "step": 7710
    },
    {
      "epoch": 9.500076911244424,
      "grad_norm": 0.8515625,
      "learning_rate": 3.123187103036792e-06,
      "loss": 0.226,
      "step": 7720
    },
    {
      "epoch": 9.512382710352254,
      "grad_norm": 1.1484375,
      "learning_rate": 3.1108699287237383e-06,
      "loss": 0.2387,
      "step": 7730
    },
    {
      "epoch": 9.524688509460082,
      "grad_norm": 1.046875,
      "learning_rate": 3.09856611320975e-06,
      "loss": 0.2317,
      "step": 7740
    },
    {
      "epoch": 9.536994308567913,
      "grad_norm": 0.984375,
      "learning_rate": 3.0862757435000635e-06,
      "loss": 0.2395,
      "step": 7750
    },
    {
      "epoch": 9.549300107675743,
      "grad_norm": 1.1875,
      "learning_rate": 3.073998906504829e-06,
      "loss": 0.2192,
      "step": 7760
    },
    {
      "epoch": 9.561605906783571,
      "grad_norm": 1.0703125,
      "learning_rate": 3.0617356890385e-06,
      "loss": 0.238,
      "step": 7770
    },
    {
      "epoch": 9.573911705891401,
      "grad_norm": 0.8125,
      "learning_rate": 3.0494861778192244e-06,
      "loss": 0.2434,
      "step": 7780
    },
    {
      "epoch": 9.586217504999231,
      "grad_norm": 0.82421875,
      "learning_rate": 3.037250459468224e-06,
      "loss": 0.2262,
      "step": 7790
    },
    {
      "epoch": 9.59852330410706,
      "grad_norm": 1.015625,
      "learning_rate": 3.0250286205091904e-06,
      "loss": 0.2534,
      "step": 7800
    },
    {
      "epoch": 9.61082910321489,
      "grad_norm": 0.97265625,
      "learning_rate": 3.0128207473676663e-06,
      "loss": 0.2524,
      "step": 7810
    },
    {
      "epoch": 9.62313490232272,
      "grad_norm": 1.0703125,
      "learning_rate": 3.0006269263704335e-06,
      "loss": 0.2385,
      "step": 7820
    },
    {
      "epoch": 9.635440701430548,
      "grad_norm": 1.2109375,
      "learning_rate": 2.9884472437449113e-06,
      "loss": 0.2283,
      "step": 7830
    },
    {
      "epoch": 9.647746500538378,
      "grad_norm": 1.0859375,
      "learning_rate": 2.9762817856185345e-06,
      "loss": 0.2352,
      "step": 7840
    },
    {
      "epoch": 9.660052299646209,
      "grad_norm": 1.0625,
      "learning_rate": 2.9641306380181533e-06,
      "loss": 0.2306,
      "step": 7850
    },
    {
      "epoch": 9.672358098754039,
      "grad_norm": 1.21875,
      "learning_rate": 2.951993886869429e-06,
      "loss": 0.2501,
      "step": 7860
    },
    {
      "epoch": 9.684663897861867,
      "grad_norm": 1.15625,
      "learning_rate": 2.939871617996205e-06,
      "loss": 0.2262,
      "step": 7870
    },
    {
      "epoch": 9.696969696969697,
      "grad_norm": 1.171875,
      "learning_rate": 2.9277639171199314e-06,
      "loss": 0.2337,
      "step": 7880
    },
    {
      "epoch": 9.709275496077527,
      "grad_norm": 0.953125,
      "learning_rate": 2.9156708698590273e-06,
      "loss": 0.2653,
      "step": 7890
    },
    {
      "epoch": 9.721581295185356,
      "grad_norm": 1.0390625,
      "learning_rate": 2.903592561728304e-06,
      "loss": 0.24,
      "step": 7900
    },
    {
      "epoch": 9.733887094293186,
      "grad_norm": 0.8515625,
      "learning_rate": 2.8915290781383353e-06,
      "loss": 0.2499,
      "step": 7910
    },
    {
      "epoch": 9.746192893401016,
      "grad_norm": 1.078125,
      "learning_rate": 2.8794805043948683e-06,
      "loss": 0.2341,
      "step": 7920
    },
    {
      "epoch": 9.758498692508844,
      "grad_norm": 1.0078125,
      "learning_rate": 2.8674469256982196e-06,
      "loss": 0.2241,
      "step": 7930
    },
    {
      "epoch": 9.770804491616675,
      "grad_norm": 1.140625,
      "learning_rate": 2.8554284271426667e-06,
      "loss": 0.2376,
      "step": 7940
    },
    {
      "epoch": 9.783110290724505,
      "grad_norm": 0.875,
      "learning_rate": 2.843425093715849e-06,
      "loss": 0.22,
      "step": 7950
    },
    {
      "epoch": 9.795416089832333,
      "grad_norm": 1.015625,
      "learning_rate": 2.8314370102981703e-06,
      "loss": 0.2192,
      "step": 7960
    },
    {
      "epoch": 9.807721888940163,
      "grad_norm": 0.8828125,
      "learning_rate": 2.81946426166219e-06,
      "loss": 0.2496,
      "step": 7970
    },
    {
      "epoch": 9.820027688047993,
      "grad_norm": 1.171875,
      "learning_rate": 2.807506932472037e-06,
      "loss": 0.2416,
      "step": 7980
    },
    {
      "epoch": 9.832333487155822,
      "grad_norm": 0.91796875,
      "learning_rate": 2.795565107282796e-06,
      "loss": 0.2441,
      "step": 7990
    },
    {
      "epoch": 9.844639286263652,
      "grad_norm": 1.078125,
      "learning_rate": 2.783638870539918e-06,
      "loss": 0.2567,
      "step": 8000
    },
    {
      "epoch": 9.856945085371482,
      "grad_norm": 0.90234375,
      "learning_rate": 2.7717283065786265e-06,
      "loss": 0.2456,
      "step": 8010
    },
    {
      "epoch": 9.86925088447931,
      "grad_norm": 1.140625,
      "learning_rate": 2.759833499623309e-06,
      "loss": 0.2275,
      "step": 8020
    },
    {
      "epoch": 9.88155668358714,
      "grad_norm": 1.0,
      "learning_rate": 2.747954533786939e-06,
      "loss": 0.2345,
      "step": 8030
    },
    {
      "epoch": 9.89386248269497,
      "grad_norm": 1.078125,
      "learning_rate": 2.736091493070457e-06,
      "loss": 0.2393,
      "step": 8040
    },
    {
      "epoch": 9.906168281802799,
      "grad_norm": 0.86328125,
      "learning_rate": 2.7242444613622022e-06,
      "loss": 0.2373,
      "step": 8050
    },
    {
      "epoch": 9.918474080910629,
      "grad_norm": 0.8984375,
      "learning_rate": 2.712413522437306e-06,
      "loss": 0.2285,
      "step": 8060
    },
    {
      "epoch": 9.93077988001846,
      "grad_norm": 1.15625,
      "learning_rate": 2.7005987599570984e-06,
      "loss": 0.2404,
      "step": 8070
    },
    {
      "epoch": 9.943085679126288,
      "grad_norm": 1.203125,
      "learning_rate": 2.6888002574685185e-06,
      "loss": 0.2698,
      "step": 8080
    },
    {
      "epoch": 9.955391478234118,
      "grad_norm": 0.87109375,
      "learning_rate": 2.677018098403525e-06,
      "loss": 0.2401,
      "step": 8090
    },
    {
      "epoch": 9.967697277341948,
      "grad_norm": 1.1015625,
      "learning_rate": 2.6652523660785084e-06,
      "loss": 0.2569,
      "step": 8100
    },
    {
      "epoch": 9.980003076449776,
      "grad_norm": 0.90234375,
      "learning_rate": 2.6535031436937e-06,
      "loss": 0.2391,
      "step": 8110
    },
    {
      "epoch": 9.992308875557606,
      "grad_norm": 0.94140625,
      "learning_rate": 2.6417705143325767e-06,
      "loss": 0.2181,
      "step": 8120
    },
    {
      "epoch": 10.004614674665437,
      "grad_norm": 1.03125,
      "learning_rate": 2.6300545609612837e-06,
      "loss": 0.2101,
      "step": 8130
    },
    {
      "epoch": 10.016920473773265,
      "grad_norm": 0.81640625,
      "learning_rate": 2.6183553664280408e-06,
      "loss": 0.2326,
      "step": 8140
    },
    {
      "epoch": 10.029226272881095,
      "grad_norm": 0.93359375,
      "learning_rate": 2.606673013462564e-06,
      "loss": 0.25,
      "step": 8150
    },
    {
      "epoch": 10.041532071988925,
      "grad_norm": 1.1328125,
      "learning_rate": 2.595007584675475e-06,
      "loss": 0.2418,
      "step": 8160
    },
    {
      "epoch": 10.053837871096754,
      "grad_norm": 1.015625,
      "learning_rate": 2.5833591625577094e-06,
      "loss": 0.2225,
      "step": 8170
    },
    {
      "epoch": 10.066143670204584,
      "grad_norm": 0.84765625,
      "learning_rate": 2.571727829479954e-06,
      "loss": 0.2479,
      "step": 8180
    },
    {
      "epoch": 10.078449469312414,
      "grad_norm": 0.89453125,
      "learning_rate": 2.5601136676920424e-06,
      "loss": 0.2227,
      "step": 8190
    },
    {
      "epoch": 10.090755268420242,
      "grad_norm": 1.1484375,
      "learning_rate": 2.5485167593223902e-06,
      "loss": 0.2536,
      "step": 8200
    },
    {
      "epoch": 10.103061067528072,
      "grad_norm": 1.1484375,
      "learning_rate": 2.5369371863774034e-06,
      "loss": 0.2349,
      "step": 8210
    },
    {
      "epoch": 10.115366866635902,
      "grad_norm": 0.9453125,
      "learning_rate": 2.5253750307408996e-06,
      "loss": 0.2601,
      "step": 8220
    },
    {
      "epoch": 10.127672665743733,
      "grad_norm": 1.0234375,
      "learning_rate": 2.513830374173539e-06,
      "loss": 0.2565,
      "step": 8230
    },
    {
      "epoch": 10.139978464851561,
      "grad_norm": 1.1796875,
      "learning_rate": 2.502303298312232e-06,
      "loss": 0.2339,
      "step": 8240
    },
    {
      "epoch": 10.152284263959391,
      "grad_norm": 1.125,
      "learning_rate": 2.4907938846695734e-06,
      "loss": 0.2394,
      "step": 8250
    },
    {
      "epoch": 10.164590063067221,
      "grad_norm": 0.99609375,
      "learning_rate": 2.479302214633259e-06,
      "loss": 0.2419,
      "step": 8260
    },
    {
      "epoch": 10.17689586217505,
      "grad_norm": 1.296875,
      "learning_rate": 2.4678283694655096e-06,
      "loss": 0.2198,
      "step": 8270
    },
    {
      "epoch": 10.18920166128288,
      "grad_norm": 1.1015625,
      "learning_rate": 2.4563724303025073e-06,
      "loss": 0.2479,
      "step": 8280
    },
    {
      "epoch": 10.20150746039071,
      "grad_norm": 0.98828125,
      "learning_rate": 2.4449344781538043e-06,
      "loss": 0.2143,
      "step": 8290
    },
    {
      "epoch": 10.213813259498538,
      "grad_norm": 0.9296875,
      "learning_rate": 2.4335145939017673e-06,
      "loss": 0.2239,
      "step": 8300
    },
    {
      "epoch": 10.226119058606368,
      "grad_norm": 0.98828125,
      "learning_rate": 2.4221128583009922e-06,
      "loss": 0.224,
      "step": 8310
    },
    {
      "epoch": 10.238424857714199,
      "grad_norm": 0.87109375,
      "learning_rate": 2.4107293519777398e-06,
      "loss": 0.2379,
      "step": 8320
    },
    {
      "epoch": 10.250730656822027,
      "grad_norm": 0.90234375,
      "learning_rate": 2.3993641554293673e-06,
      "loss": 0.2462,
      "step": 8330
    },
    {
      "epoch": 10.263036455929857,
      "grad_norm": 1.09375,
      "learning_rate": 2.3880173490237525e-06,
      "loss": 0.2537,
      "step": 8340
    },
    {
      "epoch": 10.275342255037687,
      "grad_norm": 1.0703125,
      "learning_rate": 2.376689012998728e-06,
      "loss": 0.2694,
      "step": 8350
    },
    {
      "epoch": 10.287648054145516,
      "grad_norm": 0.9375,
      "learning_rate": 2.365379227461521e-06,
      "loss": 0.2623,
      "step": 8360
    },
    {
      "epoch": 10.299953853253346,
      "grad_norm": 0.828125,
      "learning_rate": 2.3540880723881744e-06,
      "loss": 0.254,
      "step": 8370
    },
    {
      "epoch": 10.312259652361176,
      "grad_norm": 1.1171875,
      "learning_rate": 2.3428156276229926e-06,
      "loss": 0.2606,
      "step": 8380
    },
    {
      "epoch": 10.324565451469004,
      "grad_norm": 0.828125,
      "learning_rate": 2.3315619728779674e-06,
      "loss": 0.2278,
      "step": 8390
    },
    {
      "epoch": 10.336871250576834,
      "grad_norm": 1.1953125,
      "learning_rate": 2.3203271877322203e-06,
      "loss": 0.2758,
      "step": 8400
    },
    {
      "epoch": 10.349177049684664,
      "grad_norm": 1.1328125,
      "learning_rate": 2.3091113516314417e-06,
      "loss": 0.2072,
      "step": 8410
    },
    {
      "epoch": 10.361482848792493,
      "grad_norm": 0.99609375,
      "learning_rate": 2.297914543887319e-06,
      "loss": 0.2424,
      "step": 8420
    },
    {
      "epoch": 10.373788647900323,
      "grad_norm": 0.97265625,
      "learning_rate": 2.2867368436769928e-06,
      "loss": 0.2683,
      "step": 8430
    },
    {
      "epoch": 10.386094447008153,
      "grad_norm": 1.078125,
      "learning_rate": 2.275578330042471e-06,
      "loss": 0.2317,
      "step": 8440
    },
    {
      "epoch": 10.398400246115981,
      "grad_norm": 0.84375,
      "learning_rate": 2.2644390818900996e-06,
      "loss": 0.2558,
      "step": 8450
    },
    {
      "epoch": 10.410706045223812,
      "grad_norm": 1.0078125,
      "learning_rate": 2.2533191779899872e-06,
      "loss": 0.2188,
      "step": 8460
    },
    {
      "epoch": 10.423011844331642,
      "grad_norm": 1.1484375,
      "learning_rate": 2.2422186969754473e-06,
      "loss": 0.2612,
      "step": 8470
    },
    {
      "epoch": 10.43531764343947,
      "grad_norm": 0.8125,
      "learning_rate": 2.23113771734245e-06,
      "loss": 0.2384,
      "step": 8480
    },
    {
      "epoch": 10.4476234425473,
      "grad_norm": 0.93359375,
      "learning_rate": 2.2200763174490593e-06,
      "loss": 0.2418,
      "step": 8490
    },
    {
      "epoch": 10.45992924165513,
      "grad_norm": 1.0703125,
      "learning_rate": 2.2090345755148877e-06,
      "loss": 0.2346,
      "step": 8500
    },
    {
      "epoch": 10.472235040762959,
      "grad_norm": 1.1875,
      "learning_rate": 2.198012569620539e-06,
      "loss": 0.2599,
      "step": 8510
    },
    {
      "epoch": 10.484540839870789,
      "grad_norm": 0.90625,
      "learning_rate": 2.1870103777070504e-06,
      "loss": 0.2372,
      "step": 8520
    },
    {
      "epoch": 10.496846638978619,
      "grad_norm": 1.1796875,
      "learning_rate": 2.17602807757535e-06,
      "loss": 0.241,
      "step": 8530
    },
    {
      "epoch": 10.50915243808645,
      "grad_norm": 1.0625,
      "learning_rate": 2.1650657468856994e-06,
      "loss": 0.2398,
      "step": 8540
    },
    {
      "epoch": 10.521458237194278,
      "grad_norm": 0.92578125,
      "learning_rate": 2.1541234631571533e-06,
      "loss": 0.2297,
      "step": 8550
    },
    {
      "epoch": 10.533764036302108,
      "grad_norm": 0.9453125,
      "learning_rate": 2.143201303767008e-06,
      "loss": 0.2507,
      "step": 8560
    },
    {
      "epoch": 10.546069835409938,
      "grad_norm": 0.953125,
      "learning_rate": 2.1322993459502405e-06,
      "loss": 0.2599,
      "step": 8570
    },
    {
      "epoch": 10.558375634517766,
      "grad_norm": 1.046875,
      "learning_rate": 2.1214176667989876e-06,
      "loss": 0.2238,
      "step": 8580
    },
    {
      "epoch": 10.570681433625596,
      "grad_norm": 1.0390625,
      "learning_rate": 2.1105563432619796e-06,
      "loss": 0.2355,
      "step": 8590
    },
    {
      "epoch": 10.582987232733426,
      "grad_norm": 1.1953125,
      "learning_rate": 2.09971545214401e-06,
      "loss": 0.2274,
      "step": 8600
    },
    {
      "epoch": 10.595293031841255,
      "grad_norm": 1.078125,
      "learning_rate": 2.0888950701053808e-06,
      "loss": 0.2021,
      "step": 8610
    },
    {
      "epoch": 10.607598830949085,
      "grad_norm": 1.1328125,
      "learning_rate": 2.0780952736613665e-06,
      "loss": 0.245,
      "step": 8620
    },
    {
      "epoch": 10.619904630056915,
      "grad_norm": 1.078125,
      "learning_rate": 2.0673161391816787e-06,
      "loss": 0.249,
      "step": 8630
    },
    {
      "epoch": 10.632210429164743,
      "grad_norm": 0.79296875,
      "learning_rate": 2.056557742889911e-06,
      "loss": 0.2401,
      "step": 8640
    },
    {
      "epoch": 10.644516228272574,
      "grad_norm": 1.03125,
      "learning_rate": 2.0458201608630192e-06,
      "loss": 0.2194,
      "step": 8650
    },
    {
      "epoch": 10.656822027380404,
      "grad_norm": 1.0234375,
      "learning_rate": 2.035103469030764e-06,
      "loss": 0.2334,
      "step": 8660
    },
    {
      "epoch": 10.669127826488232,
      "grad_norm": 0.88671875,
      "learning_rate": 2.0244077431751853e-06,
      "loss": 0.2366,
      "step": 8670
    },
    {
      "epoch": 10.681433625596062,
      "grad_norm": 0.85546875,
      "learning_rate": 2.0137330589300686e-06,
      "loss": 0.2509,
      "step": 8680
    },
    {
      "epoch": 10.693739424703892,
      "grad_norm": 1.0546875,
      "learning_rate": 2.003079491780399e-06,
      "loss": 0.2631,
      "step": 8690
    },
    {
      "epoch": 10.70604522381172,
      "grad_norm": 1.03125,
      "learning_rate": 1.992447117061842e-06,
      "loss": 0.2398,
      "step": 8700
    },
    {
      "epoch": 10.71835102291955,
      "grad_norm": 1.0234375,
      "learning_rate": 1.9818360099601964e-06,
      "loss": 0.2487,
      "step": 8710
    },
    {
      "epoch": 10.730656822027381,
      "grad_norm": 1.0625,
      "learning_rate": 1.9712462455108687e-06,
      "loss": 0.2266,
      "step": 8720
    },
    {
      "epoch": 10.74296262113521,
      "grad_norm": 1.0546875,
      "learning_rate": 1.96067789859835e-06,
      "loss": 0.2369,
      "step": 8730
    },
    {
      "epoch": 10.75526842024304,
      "grad_norm": 0.9921875,
      "learning_rate": 1.9501310439556732e-06,
      "loss": 0.2322,
      "step": 8740
    },
    {
      "epoch": 10.76757421935087,
      "grad_norm": 1.140625,
      "learning_rate": 1.939605756163889e-06,
      "loss": 0.2217,
      "step": 8750
    },
    {
      "epoch": 10.779880018458698,
      "grad_norm": 0.953125,
      "learning_rate": 1.9291021096515494e-06,
      "loss": 0.2252,
      "step": 8760
    },
    {
      "epoch": 10.792185817566528,
      "grad_norm": 1.046875,
      "learning_rate": 1.918620178694161e-06,
      "loss": 0.237,
      "step": 8770
    },
    {
      "epoch": 10.804491616674358,
      "grad_norm": 1.078125,
      "learning_rate": 1.908160037413681e-06,
      "loss": 0.2303,
      "step": 8780
    },
    {
      "epoch": 10.816797415782187,
      "grad_norm": 1.578125,
      "learning_rate": 1.8977217597779762e-06,
      "loss": 0.223,
      "step": 8790
    },
    {
      "epoch": 10.829103214890017,
      "grad_norm": 0.84375,
      "learning_rate": 1.887305419600307e-06,
      "loss": 0.2365,
      "step": 8800
    },
    {
      "epoch": 10.841409013997847,
      "grad_norm": 0.87109375,
      "learning_rate": 1.876911090538811e-06,
      "loss": 0.249,
      "step": 8810
    },
    {
      "epoch": 10.853714813105675,
      "grad_norm": 0.921875,
      "learning_rate": 1.8665388460959688e-06,
      "loss": 0.2718,
      "step": 8820
    },
    {
      "epoch": 10.866020612213505,
      "grad_norm": 1.0859375,
      "learning_rate": 1.8561887596181006e-06,
      "loss": 0.2336,
      "step": 8830
    },
    {
      "epoch": 10.878326411321336,
      "grad_norm": 0.9375,
      "learning_rate": 1.8458609042948266e-06,
      "loss": 0.2359,
      "step": 8840
    },
    {
      "epoch": 10.890632210429164,
      "grad_norm": 1.0234375,
      "learning_rate": 1.835555353158573e-06,
      "loss": 0.2298,
      "step": 8850
    },
    {
      "epoch": 10.902938009536994,
      "grad_norm": 0.921875,
      "learning_rate": 1.8252721790840393e-06,
      "loss": 0.2361,
      "step": 8860
    },
    {
      "epoch": 10.915243808644824,
      "grad_norm": 0.96484375,
      "learning_rate": 1.8150114547876886e-06,
      "loss": 0.2362,
      "step": 8870
    },
    {
      "epoch": 10.927549607752653,
      "grad_norm": 1.1015625,
      "learning_rate": 1.804773252827231e-06,
      "loss": 0.2296,
      "step": 8880
    },
    {
      "epoch": 10.939855406860483,
      "grad_norm": 1.2421875,
      "learning_rate": 1.7945576456011115e-06,
      "loss": 0.2289,
      "step": 8890
    },
    {
      "epoch": 10.952161205968313,
      "grad_norm": 1.1796875,
      "learning_rate": 1.7843647053480024e-06,
      "loss": 0.2449,
      "step": 8900
    },
    {
      "epoch": 10.964467005076141,
      "grad_norm": 1.0703125,
      "learning_rate": 1.7741945041462877e-06,
      "loss": 0.2548,
      "step": 8910
    },
    {
      "epoch": 10.976772804183971,
      "grad_norm": 1.0625,
      "learning_rate": 1.7640471139135529e-06,
      "loss": 0.2659,
      "step": 8920
    },
    {
      "epoch": 10.989078603291802,
      "grad_norm": 1.015625,
      "learning_rate": 1.7539226064060777e-06,
      "loss": 0.2159,
      "step": 8930
    },
    {
      "epoch": 11.001384402399632,
      "grad_norm": 0.81640625,
      "learning_rate": 1.7438210532183276e-06,
      "loss": 0.2147,
      "step": 8940
    },
    {
      "epoch": 11.01369020150746,
      "grad_norm": 1.0078125,
      "learning_rate": 1.733742525782453e-06,
      "loss": 0.2487,
      "step": 8950
    },
    {
      "epoch": 11.02599600061529,
      "grad_norm": 0.92578125,
      "learning_rate": 1.7236870953677809e-06,
      "loss": 0.2253,
      "step": 8960
    },
    {
      "epoch": 11.03830179972312,
      "grad_norm": 1.1953125,
      "learning_rate": 1.7136548330803004e-06,
      "loss": 0.2478,
      "step": 8970
    },
    {
      "epoch": 11.050607598830949,
      "grad_norm": 0.984375,
      "learning_rate": 1.703645809862181e-06,
      "loss": 0.2633,
      "step": 8980
    },
    {
      "epoch": 11.062913397938779,
      "grad_norm": 1.015625,
      "learning_rate": 1.6936600964912508e-06,
      "loss": 0.2509,
      "step": 8990
    },
    {
      "epoch": 11.075219197046609,
      "grad_norm": 1.21875,
      "learning_rate": 1.6836977635805114e-06,
      "loss": 0.2438,
      "step": 9000
    },
    {
      "epoch": 11.087524996154437,
      "grad_norm": 1.09375,
      "learning_rate": 1.6737588815776263e-06,
      "loss": 0.2204,
      "step": 9010
    },
    {
      "epoch": 11.099830795262267,
      "grad_norm": 1.46875,
      "learning_rate": 1.6638435207644294e-06,
      "loss": 0.2261,
      "step": 9020
    },
    {
      "epoch": 11.112136594370098,
      "grad_norm": 1.0234375,
      "learning_rate": 1.6539517512564307e-06,
      "loss": 0.2618,
      "step": 9030
    },
    {
      "epoch": 11.124442393477926,
      "grad_norm": 1.09375,
      "learning_rate": 1.6440836430023104e-06,
      "loss": 0.2679,
      "step": 9040
    },
    {
      "epoch": 11.136748192585756,
      "grad_norm": 1.0078125,
      "learning_rate": 1.6342392657834373e-06,
      "loss": 0.2549,
      "step": 9050
    },
    {
      "epoch": 11.149053991693586,
      "grad_norm": 1.0390625,
      "learning_rate": 1.624418689213363e-06,
      "loss": 0.2452,
      "step": 9060
    },
    {
      "epoch": 11.161359790801415,
      "grad_norm": 0.94140625,
      "learning_rate": 1.6146219827373344e-06,
      "loss": 0.239,
      "step": 9070
    },
    {
      "epoch": 11.173665589909245,
      "grad_norm": 1.09375,
      "learning_rate": 1.6048492156318108e-06,
      "loss": 0.2234,
      "step": 9080
    },
    {
      "epoch": 11.185971389017075,
      "grad_norm": 0.88671875,
      "learning_rate": 1.5951004570039574e-06,
      "loss": 0.2679,
      "step": 9090
    },
    {
      "epoch": 11.198277188124903,
      "grad_norm": 0.88671875,
      "learning_rate": 1.5853757757911737e-06,
      "loss": 0.2176,
      "step": 9100
    },
    {
      "epoch": 11.210582987232733,
      "grad_norm": 0.94921875,
      "learning_rate": 1.575675240760593e-06,
      "loss": 0.2612,
      "step": 9110
    },
    {
      "epoch": 11.222888786340564,
      "grad_norm": 1.03125,
      "learning_rate": 1.5659989205086012e-06,
      "loss": 0.2506,
      "step": 9120
    },
    {
      "epoch": 11.235194585448392,
      "grad_norm": 0.90625,
      "learning_rate": 1.5563468834603562e-06,
      "loss": 0.2259,
      "step": 9130
    },
    {
      "epoch": 11.247500384556222,
      "grad_norm": 1.140625,
      "learning_rate": 1.5467191978692957e-06,
      "loss": 0.2463,
      "step": 9140
    },
    {
      "epoch": 11.259806183664052,
      "grad_norm": 1.09375,
      "learning_rate": 1.5371159318166572e-06,
      "loss": 0.2409,
      "step": 9150
    },
    {
      "epoch": 11.27211198277188,
      "grad_norm": 0.9765625,
      "learning_rate": 1.5275371532110033e-06,
      "loss": 0.2245,
      "step": 9160
    },
    {
      "epoch": 11.28441778187971,
      "grad_norm": 1.1875,
      "learning_rate": 1.5179829297877302e-06,
      "loss": 0.2204,
      "step": 9170
    },
    {
      "epoch": 11.29672358098754,
      "grad_norm": 1.0390625,
      "learning_rate": 1.5084533291085996e-06,
      "loss": 0.2358,
      "step": 9180
    },
    {
      "epoch": 11.30902938009537,
      "grad_norm": 1.2265625,
      "learning_rate": 1.4989484185612523e-06,
      "loss": 0.2301,
      "step": 9190
    },
    {
      "epoch": 11.3213351792032,
      "grad_norm": 0.89453125,
      "learning_rate": 1.4894682653587344e-06,
      "loss": 0.2554,
      "step": 9200
    },
    {
      "epoch": 11.33364097831103,
      "grad_norm": 0.875,
      "learning_rate": 1.4800129365390282e-06,
      "loss": 0.2248,
      "step": 9210
    },
    {
      "epoch": 11.345946777418858,
      "grad_norm": 2.140625,
      "learning_rate": 1.4705824989645655e-06,
      "loss": 0.2358,
      "step": 9220
    },
    {
      "epoch": 11.358252576526688,
      "grad_norm": 0.94140625,
      "learning_rate": 1.4611770193217718e-06,
      "loss": 0.2433,
      "step": 9230
    },
    {
      "epoch": 11.370558375634518,
      "grad_norm": 0.7421875,
      "learning_rate": 1.4517965641205716e-06,
      "loss": 0.2276,
      "step": 9240
    },
    {
      "epoch": 11.382864174742348,
      "grad_norm": 0.8203125,
      "learning_rate": 1.442441199693943e-06,
      "loss": 0.2121,
      "step": 9250
    },
    {
      "epoch": 11.395169973850177,
      "grad_norm": 0.95703125,
      "learning_rate": 1.433110992197435e-06,
      "loss": 0.2301,
      "step": 9260
    },
    {
      "epoch": 11.407475772958007,
      "grad_norm": 1.2109375,
      "learning_rate": 1.423806007608698e-06,
      "loss": 0.2538,
      "step": 9270
    },
    {
      "epoch": 11.419781572065837,
      "grad_norm": 0.8515625,
      "learning_rate": 1.4145263117270226e-06,
      "loss": 0.2353,
      "step": 9280
    },
    {
      "epoch": 11.432087371173665,
      "grad_norm": 0.92578125,
      "learning_rate": 1.4052719701728723e-06,
      "loss": 0.2281,
      "step": 9290
    },
    {
      "epoch": 11.444393170281495,
      "grad_norm": 1.0703125,
      "learning_rate": 1.3960430483874233e-06,
      "loss": 0.2319,
      "step": 9300
    },
    {
      "epoch": 11.456698969389326,
      "grad_norm": 1.859375,
      "learning_rate": 1.3868396116320958e-06,
      "loss": 0.2513,
      "step": 9310
    },
    {
      "epoch": 11.469004768497154,
      "grad_norm": 0.94140625,
      "learning_rate": 1.3776617249880947e-06,
      "loss": 0.24,
      "step": 9320
    },
    {
      "epoch": 11.481310567604984,
      "grad_norm": 0.9609375,
      "learning_rate": 1.3685094533559501e-06,
      "loss": 0.2637,
      "step": 9330
    },
    {
      "epoch": 11.493616366712814,
      "grad_norm": 0.9375,
      "learning_rate": 1.3593828614550575e-06,
      "loss": 0.2405,
      "step": 9340
    },
    {
      "epoch": 11.505922165820643,
      "grad_norm": 1.0703125,
      "learning_rate": 1.3502820138232232e-06,
      "loss": 0.2692,
      "step": 9350
    },
    {
      "epoch": 11.518227964928473,
      "grad_norm": 0.796875,
      "learning_rate": 1.3412069748162031e-06,
      "loss": 0.2529,
      "step": 9360
    },
    {
      "epoch": 11.530533764036303,
      "grad_norm": 1.0234375,
      "learning_rate": 1.3321578086072495e-06,
      "loss": 0.2203,
      "step": 9370
    },
    {
      "epoch": 11.542839563144131,
      "grad_norm": 0.7421875,
      "learning_rate": 1.3231345791866607e-06,
      "loss": 0.2528,
      "step": 9380
    },
    {
      "epoch": 11.555145362251961,
      "grad_norm": 0.91015625,
      "learning_rate": 1.3141373503613208e-06,
      "loss": 0.264,
      "step": 9390
    },
    {
      "epoch": 11.567451161359791,
      "grad_norm": 1.1015625,
      "learning_rate": 1.3051661857542596e-06,
      "loss": 0.2655,
      "step": 9400
    },
    {
      "epoch": 11.57975696046762,
      "grad_norm": 0.93359375,
      "learning_rate": 1.296221148804191e-06,
      "loss": 0.2589,
      "step": 9410
    },
    {
      "epoch": 11.59206275957545,
      "grad_norm": 1.0390625,
      "learning_rate": 1.2873023027650694e-06,
      "loss": 0.2485,
      "step": 9420
    },
    {
      "epoch": 11.60436855868328,
      "grad_norm": 1.515625,
      "learning_rate": 1.278409710705648e-06,
      "loss": 0.232,
      "step": 9430
    },
    {
      "epoch": 11.616674357791108,
      "grad_norm": 1.0703125,
      "learning_rate": 1.2695434355090225e-06,
      "loss": 0.2478,
      "step": 9440
    },
    {
      "epoch": 11.628980156898939,
      "grad_norm": 0.8828125,
      "learning_rate": 1.2607035398721946e-06,
      "loss": 0.2056,
      "step": 9450
    },
    {
      "epoch": 11.641285956006769,
      "grad_norm": 1.0,
      "learning_rate": 1.2518900863056237e-06,
      "loss": 0.2245,
      "step": 9460
    },
    {
      "epoch": 11.653591755114597,
      "grad_norm": 1.046875,
      "learning_rate": 1.2431031371327856e-06,
      "loss": 0.2279,
      "step": 9470
    },
    {
      "epoch": 11.665897554222427,
      "grad_norm": 1.03125,
      "learning_rate": 1.234342754489737e-06,
      "loss": 0.2172,
      "step": 9480
    },
    {
      "epoch": 11.678203353330257,
      "grad_norm": 0.96875,
      "learning_rate": 1.2256090003246684e-06,
      "loss": 0.2168,
      "step": 9490
    },
    {
      "epoch": 11.690509152438086,
      "grad_norm": 0.96875,
      "learning_rate": 1.2169019363974704e-06,
      "loss": 0.2138,
      "step": 9500
    },
    {
      "epoch": 11.702814951545916,
      "grad_norm": 1.3046875,
      "learning_rate": 1.2082216242792954e-06,
      "loss": 0.2479,
      "step": 9510
    },
    {
      "epoch": 11.715120750653746,
      "grad_norm": 1.140625,
      "learning_rate": 1.1995681253521252e-06,
      "loss": 0.2504,
      "step": 9520
    },
    {
      "epoch": 11.727426549761574,
      "grad_norm": 0.94921875,
      "learning_rate": 1.1909415008083346e-06,
      "loss": 0.2358,
      "step": 9530
    },
    {
      "epoch": 11.739732348869405,
      "grad_norm": 1.390625,
      "learning_rate": 1.1823418116502566e-06,
      "loss": 0.2148,
      "step": 9540
    },
    {
      "epoch": 11.752038147977235,
      "grad_norm": 0.98046875,
      "learning_rate": 1.1737691186897553e-06,
      "loss": 0.2449,
      "step": 9550
    },
    {
      "epoch": 11.764343947085063,
      "grad_norm": 0.9140625,
      "learning_rate": 1.1652234825477903e-06,
      "loss": 0.2476,
      "step": 9560
    },
    {
      "epoch": 11.776649746192893,
      "grad_norm": 0.97265625,
      "learning_rate": 1.1567049636539962e-06,
      "loss": 0.2644,
      "step": 9570
    },
    {
      "epoch": 11.788955545300723,
      "grad_norm": 0.9375,
      "learning_rate": 1.1482136222462498e-06,
      "loss": 0.2482,
      "step": 9580
    },
    {
      "epoch": 11.801261344408552,
      "grad_norm": 0.875,
      "learning_rate": 1.1397495183702429e-06,
      "loss": 0.2216,
      "step": 9590
    },
    {
      "epoch": 11.813567143516382,
      "grad_norm": 1.171875,
      "learning_rate": 1.1313127118790596e-06,
      "loss": 0.2562,
      "step": 9600
    },
    {
      "epoch": 11.825872942624212,
      "grad_norm": 1.125,
      "learning_rate": 1.122903262432754e-06,
      "loss": 0.23,
      "step": 9610
    },
    {
      "epoch": 11.83817874173204,
      "grad_norm": 0.9140625,
      "learning_rate": 1.1145212294979284e-06,
      "loss": 0.2203,
      "step": 9620
    },
    {
      "epoch": 11.85048454083987,
      "grad_norm": 1.0234375,
      "learning_rate": 1.1061666723473141e-06,
      "loss": 0.2556,
      "step": 9630
    },
    {
      "epoch": 11.8627903399477,
      "grad_norm": 0.95703125,
      "learning_rate": 1.0978396500593424e-06,
      "loss": 0.2454,
      "step": 9640
    },
    {
      "epoch": 11.87509613905553,
      "grad_norm": 1.15625,
      "learning_rate": 1.0895402215177425e-06,
      "loss": 0.2344,
      "step": 9650
    },
    {
      "epoch": 11.887401938163359,
      "grad_norm": 0.984375,
      "learning_rate": 1.0812684454111122e-06,
      "loss": 0.2384,
      "step": 9660
    },
    {
      "epoch": 11.89970773727119,
      "grad_norm": 1.0859375,
      "learning_rate": 1.0730243802325112e-06,
      "loss": 0.235,
      "step": 9670
    },
    {
      "epoch": 11.91201353637902,
      "grad_norm": 0.953125,
      "learning_rate": 1.064808084279042e-06,
      "loss": 0.2301,
      "step": 9680
    },
    {
      "epoch": 11.924319335486848,
      "grad_norm": 1.1328125,
      "learning_rate": 1.056619615651438e-06,
      "loss": 0.2332,
      "step": 9690
    },
    {
      "epoch": 11.936625134594678,
      "grad_norm": 0.93359375,
      "learning_rate": 1.0484590322536604e-06,
      "loss": 0.2485,
      "step": 9700
    },
    {
      "epoch": 11.948930933702508,
      "grad_norm": 1.1875,
      "learning_rate": 1.040326391792475e-06,
      "loss": 0.2245,
      "step": 9710
    },
    {
      "epoch": 11.961236732810336,
      "grad_norm": 1.03125,
      "learning_rate": 1.0322217517770588e-06,
      "loss": 0.2211,
      "step": 9720
    },
    {
      "epoch": 11.973542531918167,
      "grad_norm": 0.98828125,
      "learning_rate": 1.0241451695185827e-06,
      "loss": 0.2324,
      "step": 9730
    },
    {
      "epoch": 11.985848331025997,
      "grad_norm": 1.109375,
      "learning_rate": 1.016096702129808e-06,
      "loss": 0.2208,
      "step": 9740
    },
    {
      "epoch": 11.998154130133825,
      "grad_norm": 0.88671875,
      "learning_rate": 1.00807640652469e-06,
      "loss": 0.2458,
      "step": 9750
    },
    {
      "epoch": 12.010459929241655,
      "grad_norm": 0.8046875,
      "learning_rate": 1.000084339417966e-06,
      "loss": 0.2573,
      "step": 9760
    },
    {
      "epoch": 12.022765728349485,
      "grad_norm": 0.94140625,
      "learning_rate": 9.921205573247579e-07,
      "loss": 0.2332,
      "step": 9770
    },
    {
      "epoch": 12.035071527457314,
      "grad_norm": 1.046875,
      "learning_rate": 9.841851165601758e-07,
      "loss": 0.2334,
      "step": 9780
    },
    {
      "epoch": 12.047377326565144,
      "grad_norm": 1.140625,
      "learning_rate": 9.762780732389133e-07,
      "loss": 0.2356,
      "step": 9790
    },
    {
      "epoch": 12.059683125672974,
      "grad_norm": 1.015625,
      "learning_rate": 9.683994832748588e-07,
      "loss": 0.2569,
      "step": 9800
    },
    {
      "epoch": 12.071988924780802,
      "grad_norm": 0.9453125,
      "learning_rate": 9.605494023806911e-07,
      "loss": 0.2084,
      "step": 9810
    },
    {
      "epoch": 12.084294723888632,
      "grad_norm": 0.9296875,
      "learning_rate": 9.52727886067491e-07,
      "loss": 0.2363,
      "step": 9820
    },
    {
      "epoch": 12.096600522996463,
      "grad_norm": 1.109375,
      "learning_rate": 9.44934989644351e-07,
      "loss": 0.2308,
      "step": 9830
    },
    {
      "epoch": 12.108906322104291,
      "grad_norm": 1.265625,
      "learning_rate": 9.371707682179748e-07,
      "loss": 0.2238,
      "step": 9840
    },
    {
      "epoch": 12.121212121212121,
      "grad_norm": 1.609375,
      "learning_rate": 9.294352766922998e-07,
      "loss": 0.2149,
      "step": 9850
    },
    {
      "epoch": 12.133517920319951,
      "grad_norm": 1.1171875,
      "learning_rate": 9.217285697680994e-07,
      "loss": 0.2501,
      "step": 9860
    },
    {
      "epoch": 12.14582371942778,
      "grad_norm": 1.1015625,
      "learning_rate": 9.140507019425981e-07,
      "loss": 0.2381,
      "step": 9870
    },
    {
      "epoch": 12.15812951853561,
      "grad_norm": 1.09375,
      "learning_rate": 9.064017275090925e-07,
      "loss": 0.2412,
      "step": 9880
    },
    {
      "epoch": 12.17043531764344,
      "grad_norm": 0.80859375,
      "learning_rate": 8.98781700556558e-07,
      "loss": 0.2229,
      "step": 9890
    },
    {
      "epoch": 12.182741116751268,
      "grad_norm": 1.8515625,
      "learning_rate": 8.911906749692716e-07,
      "loss": 0.2291,
      "step": 9900
    },
    {
      "epoch": 12.195046915859098,
      "grad_norm": 1.0234375,
      "learning_rate": 8.836287044264291e-07,
      "loss": 0.2332,
      "step": 9910
    },
    {
      "epoch": 12.207352714966929,
      "grad_norm": 1.0078125,
      "learning_rate": 8.760958424017702e-07,
      "loss": 0.2275,
      "step": 9920
    },
    {
      "epoch": 12.219658514074757,
      "grad_norm": 1.0390625,
      "learning_rate": 8.685921421631937e-07,
      "loss": 0.2601,
      "step": 9930
    },
    {
      "epoch": 12.231964313182587,
      "grad_norm": 0.9765625,
      "learning_rate": 8.611176567723845e-07,
      "loss": 0.2285,
      "step": 9940
    },
    {
      "epoch": 12.244270112290417,
      "grad_norm": 1.0390625,
      "learning_rate": 8.536724390844359e-07,
      "loss": 0.2337,
      "step": 9950
    },
    {
      "epoch": 12.256575911398247,
      "grad_norm": 1.0234375,
      "learning_rate": 8.462565417474777e-07,
      "loss": 0.2522,
      "step": 9960
    },
    {
      "epoch": 12.268881710506076,
      "grad_norm": 0.91015625,
      "learning_rate": 8.388700172023062e-07,
      "loss": 0.2339,
      "step": 9970
    },
    {
      "epoch": 12.281187509613906,
      "grad_norm": 1.140625,
      "learning_rate": 8.315129176820108e-07,
      "loss": 0.2261,
      "step": 9980
    },
    {
      "epoch": 12.293493308721736,
      "grad_norm": 1.0625,
      "learning_rate": 8.241852952116014e-07,
      "loss": 0.2491,
      "step": 9990
    },
    {
      "epoch": 12.305799107829564,
      "grad_norm": 0.89453125,
      "learning_rate": 8.168872016076462e-07,
      "loss": 0.2281,
      "step": 10000
    },
    {
      "epoch": 12.305799107829564,
      "eval_loss": NaN,
      "eval_runtime": 440.4492,
      "eval_samples_per_second": 118.066,
      "eval_steps_per_second": 14.76,
      "step": 10000
    },
    {
      "epoch": 12.318104906937394,
      "grad_norm": 1.0390625,
      "learning_rate": 8.096186884779011e-07,
      "loss": 0.2576,
      "step": 10010
    },
    {
      "epoch": 12.330410706045225,
      "grad_norm": 1.0,
      "learning_rate": 8.023798072209488e-07,
      "loss": 0.253,
      "step": 10020
    },
    {
      "epoch": 12.342716505153053,
      "grad_norm": 1.4296875,
      "learning_rate": 7.951706090258354e-07,
      "loss": 0.2441,
      "step": 10030
    },
    {
      "epoch": 12.355022304260883,
      "grad_norm": 1.1328125,
      "learning_rate": 7.87991144871697e-07,
      "loss": 0.2497,
      "step": 10040
    },
    {
      "epoch": 12.367328103368713,
      "grad_norm": 0.92578125,
      "learning_rate": 7.808414655274183e-07,
      "loss": 0.243,
      "step": 10050
    },
    {
      "epoch": 12.379633902476542,
      "grad_norm": 0.953125,
      "learning_rate": 7.737216215512572e-07,
      "loss": 0.2413,
      "step": 10060
    },
    {
      "epoch": 12.391939701584372,
      "grad_norm": 0.9453125,
      "learning_rate": 7.666316632904985e-07,
      "loss": 0.225,
      "step": 10070
    },
    {
      "epoch": 12.404245500692202,
      "grad_norm": 0.9765625,
      "learning_rate": 7.595716408810888e-07,
      "loss": 0.2398,
      "step": 10080
    },
    {
      "epoch": 12.41655129980003,
      "grad_norm": 1.296875,
      "learning_rate": 7.525416042472877e-07,
      "loss": 0.2389,
      "step": 10090
    },
    {
      "epoch": 12.42885709890786,
      "grad_norm": 1.078125,
      "learning_rate": 7.455416031013158e-07,
      "loss": 0.2346,
      "step": 10100
    },
    {
      "epoch": 12.44116289801569,
      "grad_norm": 1.03125,
      "learning_rate": 7.38571686942996e-07,
      "loss": 0.2432,
      "step": 10110
    },
    {
      "epoch": 12.453468697123519,
      "grad_norm": 1.0390625,
      "learning_rate": 7.316319050594133e-07,
      "loss": 0.249,
      "step": 10120
    },
    {
      "epoch": 12.465774496231349,
      "grad_norm": 1.3359375,
      "learning_rate": 7.247223065245573e-07,
      "loss": 0.2335,
      "step": 10130
    },
    {
      "epoch": 12.47808029533918,
      "grad_norm": 1.5625,
      "learning_rate": 7.178429401989789e-07,
      "loss": 0.2114,
      "step": 10140
    },
    {
      "epoch": 12.490386094447008,
      "grad_norm": 0.90234375,
      "learning_rate": 7.109938547294481e-07,
      "loss": 0.2419,
      "step": 10150
    },
    {
      "epoch": 12.502691893554838,
      "grad_norm": 1.09375,
      "learning_rate": 7.041750985486046e-07,
      "loss": 0.2358,
      "step": 10160
    },
    {
      "epoch": 12.514997692662668,
      "grad_norm": 1.1171875,
      "learning_rate": 6.973867198746159e-07,
      "loss": 0.2437,
      "step": 10170
    },
    {
      "epoch": 12.527303491770496,
      "grad_norm": 1.03125,
      "learning_rate": 6.906287667108425e-07,
      "loss": 0.2213,
      "step": 10180
    },
    {
      "epoch": 12.539609290878326,
      "grad_norm": 0.984375,
      "learning_rate": 6.839012868454886e-07,
      "loss": 0.2526,
      "step": 10190
    },
    {
      "epoch": 12.551915089986156,
      "grad_norm": 0.9453125,
      "learning_rate": 6.772043278512747e-07,
      "loss": 0.2436,
      "step": 10200
    },
    {
      "epoch": 12.564220889093985,
      "grad_norm": 0.99609375,
      "learning_rate": 6.705379370850917e-07,
      "loss": 0.2484,
      "step": 10210
    },
    {
      "epoch": 12.576526688201815,
      "grad_norm": 0.94921875,
      "learning_rate": 6.639021616876706e-07,
      "loss": 0.2768,
      "step": 10220
    },
    {
      "epoch": 12.588832487309645,
      "grad_norm": 1.015625,
      "learning_rate": 6.572970485832525e-07,
      "loss": 0.2524,
      "step": 10230
    },
    {
      "epoch": 12.601138286417473,
      "grad_norm": 0.9453125,
      "learning_rate": 6.50722644479248e-07,
      "loss": 0.2337,
      "step": 10240
    },
    {
      "epoch": 12.613444085525304,
      "grad_norm": 0.96875,
      "learning_rate": 6.441789958659173e-07,
      "loss": 0.2634,
      "step": 10250
    },
    {
      "epoch": 12.625749884633134,
      "grad_norm": 1.0546875,
      "learning_rate": 6.376661490160319e-07,
      "loss": 0.2452,
      "step": 10260
    },
    {
      "epoch": 12.638055683740962,
      "grad_norm": 2.015625,
      "learning_rate": 6.311841499845522e-07,
      "loss": 0.2149,
      "step": 10270
    },
    {
      "epoch": 12.650361482848792,
      "grad_norm": 1.0234375,
      "learning_rate": 6.247330446083044e-07,
      "loss": 0.2446,
      "step": 10280
    },
    {
      "epoch": 12.662667281956622,
      "grad_norm": 0.89453125,
      "learning_rate": 6.183128785056497e-07,
      "loss": 0.2455,
      "step": 10290
    },
    {
      "epoch": 12.67497308106445,
      "grad_norm": 1.0703125,
      "learning_rate": 6.119236970761671e-07,
      "loss": 0.2507,
      "step": 10300
    },
    {
      "epoch": 12.687278880172281,
      "grad_norm": 0.84765625,
      "learning_rate": 6.055655455003289e-07,
      "loss": 0.2472,
      "step": 10310
    },
    {
      "epoch": 12.699584679280111,
      "grad_norm": 1.6796875,
      "learning_rate": 5.992384687391845e-07,
      "loss": 0.2286,
      "step": 10320
    },
    {
      "epoch": 12.71189047838794,
      "grad_norm": 1.078125,
      "learning_rate": 5.92942511534042e-07,
      "loss": 0.234,
      "step": 10330
    },
    {
      "epoch": 12.72419627749577,
      "grad_norm": 1.21875,
      "learning_rate": 5.866777184061468e-07,
      "loss": 0.2393,
      "step": 10340
    },
    {
      "epoch": 12.7365020766036,
      "grad_norm": 1.0,
      "learning_rate": 5.804441336563732e-07,
      "loss": 0.2169,
      "step": 10350
    },
    {
      "epoch": 12.74880787571143,
      "grad_norm": 0.94140625,
      "learning_rate": 5.742418013649065e-07,
      "loss": 0.2245,
      "step": 10360
    },
    {
      "epoch": 12.761113674819258,
      "grad_norm": 0.96484375,
      "learning_rate": 5.680707653909356e-07,
      "loss": 0.2495,
      "step": 10370
    },
    {
      "epoch": 12.773419473927088,
      "grad_norm": 1.1484375,
      "learning_rate": 5.619310693723407e-07,
      "loss": 0.2674,
      "step": 10380
    },
    {
      "epoch": 12.785725273034918,
      "grad_norm": 1.3125,
      "learning_rate": 5.558227567253832e-07,
      "loss": 0.2248,
      "step": 10390
    },
    {
      "epoch": 12.798031072142747,
      "grad_norm": 1.078125,
      "learning_rate": 5.497458706443992e-07,
      "loss": 0.2323,
      "step": 10400
    },
    {
      "epoch": 12.810336871250577,
      "grad_norm": 1.015625,
      "learning_rate": 5.437004541014951e-07,
      "loss": 0.2409,
      "step": 10410
    },
    {
      "epoch": 12.822642670358407,
      "grad_norm": 1.125,
      "learning_rate": 5.376865498462463e-07,
      "loss": 0.2392,
      "step": 10420
    },
    {
      "epoch": 12.834948469466235,
      "grad_norm": 1.0,
      "learning_rate": 5.317042004053913e-07,
      "loss": 0.2406,
      "step": 10430
    },
    {
      "epoch": 12.847254268574066,
      "grad_norm": 1.1875,
      "learning_rate": 5.257534480825272e-07,
      "loss": 0.2238,
      "step": 10440
    },
    {
      "epoch": 12.859560067681896,
      "grad_norm": 1.125,
      "learning_rate": 5.198343349578217e-07,
      "loss": 0.2407,
      "step": 10450
    },
    {
      "epoch": 12.871865866789724,
      "grad_norm": 0.90625,
      "learning_rate": 5.139469028877042e-07,
      "loss": 0.2442,
      "step": 10460
    },
    {
      "epoch": 12.884171665897554,
      "grad_norm": 1.0078125,
      "learning_rate": 5.080911935045779e-07,
      "loss": 0.241,
      "step": 10470
    },
    {
      "epoch": 12.896477465005384,
      "grad_norm": 1.03125,
      "learning_rate": 5.022672482165203e-07,
      "loss": 0.2578,
      "step": 10480
    },
    {
      "epoch": 12.908783264113213,
      "grad_norm": 0.96875,
      "learning_rate": 4.964751082069913e-07,
      "loss": 0.2245,
      "step": 10490
    },
    {
      "epoch": 12.921089063221043,
      "grad_norm": 0.9375,
      "learning_rate": 4.907148144345459e-07,
      "loss": 0.241,
      "step": 10500
    },
    {
      "epoch": 12.933394862328873,
      "grad_norm": 1.0859375,
      "learning_rate": 4.849864076325378e-07,
      "loss": 0.2536,
      "step": 10510
    },
    {
      "epoch": 12.945700661436701,
      "grad_norm": 1.0,
      "learning_rate": 4.792899283088392e-07,
      "loss": 0.2176,
      "step": 10520
    },
    {
      "epoch": 12.958006460544532,
      "grad_norm": 0.9921875,
      "learning_rate": 4.736254167455473e-07,
      "loss": 0.2565,
      "step": 10530
    },
    {
      "epoch": 12.970312259652362,
      "grad_norm": 1.125,
      "learning_rate": 4.6799291299870153e-07,
      "loss": 0.2661,
      "step": 10540
    },
    {
      "epoch": 12.98261805876019,
      "grad_norm": 0.9453125,
      "learning_rate": 4.623924568980059e-07,
      "loss": 0.2201,
      "step": 10550
    },
    {
      "epoch": 12.99492385786802,
      "grad_norm": 1.1328125,
      "learning_rate": 4.5682408804653746e-07,
      "loss": 0.2449,
      "step": 10560
    },
    {
      "epoch": 13.00722965697585,
      "grad_norm": 1.1328125,
      "learning_rate": 4.5128784582047336e-07,
      "loss": 0.2376,
      "step": 10570
    },
    {
      "epoch": 13.019535456083679,
      "grad_norm": 0.984375,
      "learning_rate": 4.457837693688122e-07,
      "loss": 0.2695,
      "step": 10580
    },
    {
      "epoch": 13.031841255191509,
      "grad_norm": 0.87890625,
      "learning_rate": 4.4031189761309156e-07,
      "loss": 0.2241,
      "step": 10590
    },
    {
      "epoch": 13.044147054299339,
      "grad_norm": 1.203125,
      "learning_rate": 4.3487226924712133e-07,
      "loss": 0.2554,
      "step": 10600
    },
    {
      "epoch": 13.056452853407167,
      "grad_norm": 1.0546875,
      "learning_rate": 4.294649227367026e-07,
      "loss": 0.2405,
      "step": 10610
    },
    {
      "epoch": 13.068758652514997,
      "grad_norm": 1.0078125,
      "learning_rate": 4.240898963193568e-07,
      "loss": 0.2371,
      "step": 10620
    },
    {
      "epoch": 13.081064451622828,
      "grad_norm": 0.81640625,
      "learning_rate": 4.187472280040611e-07,
      "loss": 0.2449,
      "step": 10630
    },
    {
      "epoch": 13.093370250730656,
      "grad_norm": 0.921875,
      "learning_rate": 4.1343695557097273e-07,
      "loss": 0.2258,
      "step": 10640
    },
    {
      "epoch": 13.105676049838486,
      "grad_norm": 0.83984375,
      "learning_rate": 4.081591165711657e-07,
      "loss": 0.2319,
      "step": 10650
    },
    {
      "epoch": 13.117981848946316,
      "grad_norm": 0.9765625,
      "learning_rate": 4.02913748326364e-07,
      "loss": 0.2124,
      "step": 10660
    },
    {
      "epoch": 13.130287648054146,
      "grad_norm": 0.98828125,
      "learning_rate": 3.9770088792867645e-07,
      "loss": 0.202,
      "step": 10670
    },
    {
      "epoch": 13.142593447161975,
      "grad_norm": 1.109375,
      "learning_rate": 3.925205722403386e-07,
      "loss": 0.22,
      "step": 10680
    },
    {
      "epoch": 13.154899246269805,
      "grad_norm": 1.0625,
      "learning_rate": 3.873728378934466e-07,
      "loss": 0.2487,
      "step": 10690
    },
    {
      "epoch": 13.167205045377635,
      "grad_norm": 0.77734375,
      "learning_rate": 3.822577212897016e-07,
      "loss": 0.2367,
      "step": 10700
    },
    {
      "epoch": 13.179510844485463,
      "grad_norm": 1.359375,
      "learning_rate": 3.77175258600152e-07,
      "loss": 0.2397,
      "step": 10710
    },
    {
      "epoch": 13.191816643593294,
      "grad_norm": 1.0390625,
      "learning_rate": 3.721254857649376e-07,
      "loss": 0.265,
      "step": 10720
    },
    {
      "epoch": 13.204122442701124,
      "grad_norm": 0.90234375,
      "learning_rate": 3.671084384930346e-07,
      "loss": 0.2477,
      "step": 10730
    },
    {
      "epoch": 13.216428241808952,
      "grad_norm": 0.85546875,
      "learning_rate": 3.621241522620039e-07,
      "loss": 0.2388,
      "step": 10740
    },
    {
      "epoch": 13.228734040916782,
      "grad_norm": 0.97265625,
      "learning_rate": 3.571726623177385e-07,
      "loss": 0.2544,
      "step": 10750
    },
    {
      "epoch": 13.241039840024612,
      "grad_norm": 1.046875,
      "learning_rate": 3.5225400367421616e-07,
      "loss": 0.2525,
      "step": 10760
    },
    {
      "epoch": 13.25334563913244,
      "grad_norm": 1.078125,
      "learning_rate": 3.473682111132526e-07,
      "loss": 0.2198,
      "step": 10770
    },
    {
      "epoch": 13.26565143824027,
      "grad_norm": 1.0703125,
      "learning_rate": 3.4251531918425395e-07,
      "loss": 0.2338,
      "step": 10780
    },
    {
      "epoch": 13.277957237348101,
      "grad_norm": 0.95703125,
      "learning_rate": 3.376953622039725e-07,
      "loss": 0.2427,
      "step": 10790
    },
    {
      "epoch": 13.29026303645593,
      "grad_norm": 0.98828125,
      "learning_rate": 3.329083742562628e-07,
      "loss": 0.2192,
      "step": 10800
    },
    {
      "epoch": 13.30256883556376,
      "grad_norm": 1.046875,
      "learning_rate": 3.281543891918426e-07,
      "loss": 0.2474,
      "step": 10810
    },
    {
      "epoch": 13.31487463467159,
      "grad_norm": 1.203125,
      "learning_rate": 3.2343344062805536e-07,
      "loss": 0.2544,
      "step": 10820
    },
    {
      "epoch": 13.327180433779418,
      "grad_norm": 1.0859375,
      "learning_rate": 3.187455619486296e-07,
      "loss": 0.2232,
      "step": 10830
    },
    {
      "epoch": 13.339486232887248,
      "grad_norm": 1.1171875,
      "learning_rate": 3.140907863034387e-07,
      "loss": 0.2463,
      "step": 10840
    },
    {
      "epoch": 13.351792031995078,
      "grad_norm": 0.89453125,
      "learning_rate": 3.094691466082772e-07,
      "loss": 0.2586,
      "step": 10850
    },
    {
      "epoch": 13.364097831102907,
      "grad_norm": 0.8125,
      "learning_rate": 3.048806755446182e-07,
      "loss": 0.2236,
      "step": 10860
    },
    {
      "epoch": 13.376403630210737,
      "grad_norm": 1.0546875,
      "learning_rate": 3.00325405559389e-07,
      "loss": 0.2304,
      "step": 10870
    },
    {
      "epoch": 13.388709429318567,
      "grad_norm": 1.7421875,
      "learning_rate": 2.958033688647355e-07,
      "loss": 0.2436,
      "step": 10880
    },
    {
      "epoch": 13.401015228426395,
      "grad_norm": 1.0625,
      "learning_rate": 2.9131459743779955e-07,
      "loss": 0.2639,
      "step": 10890
    },
    {
      "epoch": 13.413321027534225,
      "grad_norm": 1.125,
      "learning_rate": 2.868591230204909e-07,
      "loss": 0.2451,
      "step": 10900
    },
    {
      "epoch": 13.425626826642056,
      "grad_norm": 1.0390625,
      "learning_rate": 2.82436977119262e-07,
      "loss": 0.2434,
      "step": 10910
    },
    {
      "epoch": 13.437932625749884,
      "grad_norm": 1.0234375,
      "learning_rate": 2.780481910048871e-07,
      "loss": 0.2501,
      "step": 10920
    },
    {
      "epoch": 13.450238424857714,
      "grad_norm": 0.92578125,
      "learning_rate": 2.736927957122387e-07,
      "loss": 0.2712,
      "step": 10930
    },
    {
      "epoch": 13.462544223965544,
      "grad_norm": 1.0234375,
      "learning_rate": 2.6937082204006926e-07,
      "loss": 0.223,
      "step": 10940
    },
    {
      "epoch": 13.474850023073373,
      "grad_norm": 1.1171875,
      "learning_rate": 2.650823005507952e-07,
      "loss": 0.2357,
      "step": 10950
    },
    {
      "epoch": 13.487155822181203,
      "grad_norm": 0.921875,
      "learning_rate": 2.6082726157027727e-07,
      "loss": 0.2351,
      "step": 10960
    },
    {
      "epoch": 13.499461621289033,
      "grad_norm": 1.0859375,
      "learning_rate": 2.5660573518760833e-07,
      "loss": 0.2478,
      "step": 10970
    },
    {
      "epoch": 13.511767420396861,
      "grad_norm": 1.265625,
      "learning_rate": 2.52417751254902e-07,
      "loss": 0.2298,
      "step": 10980
    },
    {
      "epoch": 13.524073219504691,
      "grad_norm": 1.0234375,
      "learning_rate": 2.482633393870765e-07,
      "loss": 0.26,
      "step": 10990
    },
    {
      "epoch": 13.536379018612521,
      "grad_norm": 1.0546875,
      "learning_rate": 2.4414252896165225e-07,
      "loss": 0.2338,
      "step": 11000
    },
    {
      "epoch": 13.54868481772035,
      "grad_norm": 1.078125,
      "learning_rate": 2.4005534911853645e-07,
      "loss": 0.2426,
      "step": 11010
    },
    {
      "epoch": 13.56099061682818,
      "grad_norm": 1.1640625,
      "learning_rate": 2.3600182875982258e-07,
      "loss": 0.2304,
      "step": 11020
    },
    {
      "epoch": 13.57329641593601,
      "grad_norm": 1.0546875,
      "learning_rate": 2.3198199654958674e-07,
      "loss": 0.2225,
      "step": 11030
    },
    {
      "epoch": 13.585602215043838,
      "grad_norm": 1.15625,
      "learning_rate": 2.2799588091367786e-07,
      "loss": 0.2278,
      "step": 11040
    },
    {
      "epoch": 13.597908014151669,
      "grad_norm": 1.0390625,
      "learning_rate": 2.2404351003952662e-07,
      "loss": 0.2514,
      "step": 11050
    },
    {
      "epoch": 13.610213813259499,
      "grad_norm": 0.98828125,
      "learning_rate": 2.201249118759352e-07,
      "loss": 0.2334,
      "step": 11060
    },
    {
      "epoch": 13.622519612367329,
      "grad_norm": 1.0234375,
      "learning_rate": 2.162401141328896e-07,
      "loss": 0.2617,
      "step": 11070
    },
    {
      "epoch": 13.634825411475157,
      "grad_norm": 0.859375,
      "learning_rate": 2.123891442813597e-07,
      "loss": 0.205,
      "step": 11080
    },
    {
      "epoch": 13.647131210582987,
      "grad_norm": 1.09375,
      "learning_rate": 2.0857202955310184e-07,
      "loss": 0.268,
      "step": 11090
    },
    {
      "epoch": 13.659437009690818,
      "grad_norm": 0.84375,
      "learning_rate": 2.047887969404705e-07,
      "loss": 0.2458,
      "step": 11100
    },
    {
      "epoch": 13.671742808798646,
      "grad_norm": 1.171875,
      "learning_rate": 2.0103947319622564e-07,
      "loss": 0.2554,
      "step": 11110
    },
    {
      "epoch": 13.684048607906476,
      "grad_norm": 1.046875,
      "learning_rate": 1.9732408483334576e-07,
      "loss": 0.2546,
      "step": 11120
    },
    {
      "epoch": 13.696354407014306,
      "grad_norm": 0.9296875,
      "learning_rate": 1.936426581248374e-07,
      "loss": 0.2333,
      "step": 11130
    },
    {
      "epoch": 13.708660206122135,
      "grad_norm": 1.0859375,
      "learning_rate": 1.8999521910354978e-07,
      "loss": 0.2528,
      "step": 11140
    },
    {
      "epoch": 13.720966005229965,
      "grad_norm": 1.015625,
      "learning_rate": 1.8638179356199214e-07,
      "loss": 0.2122,
      "step": 11150
    },
    {
      "epoch": 13.733271804337795,
      "grad_norm": 1.0234375,
      "learning_rate": 1.8280240705215057e-07,
      "loss": 0.2195,
      "step": 11160
    },
    {
      "epoch": 13.745577603445623,
      "grad_norm": 1.0234375,
      "learning_rate": 1.792570848853087e-07,
      "loss": 0.2512,
      "step": 11170
    },
    {
      "epoch": 13.757883402553453,
      "grad_norm": 1.28125,
      "learning_rate": 1.7574585213186613e-07,
      "loss": 0.2541,
      "step": 11180
    },
    {
      "epoch": 13.770189201661283,
      "grad_norm": 1.03125,
      "learning_rate": 1.722687336211626e-07,
      "loss": 0.2383,
      "step": 11190
    },
    {
      "epoch": 13.782495000769112,
      "grad_norm": 0.93359375,
      "learning_rate": 1.6882575394130296e-07,
      "loss": 0.2219,
      "step": 11200
    },
    {
      "epoch": 13.794800799876942,
      "grad_norm": 0.92578125,
      "learning_rate": 1.6541693743898135e-07,
      "loss": 0.2326,
      "step": 11210
    },
    {
      "epoch": 13.807106598984772,
      "grad_norm": 1.2890625,
      "learning_rate": 1.6204230821931234e-07,
      "loss": 0.2433,
      "step": 11220
    },
    {
      "epoch": 13.8194123980926,
      "grad_norm": 1.3984375,
      "learning_rate": 1.5870189014565662e-07,
      "loss": 0.2467,
      "step": 11230
    },
    {
      "epoch": 13.83171819720043,
      "grad_norm": 1.1328125,
      "learning_rate": 1.5539570683945514e-07,
      "loss": 0.2302,
      "step": 11240
    },
    {
      "epoch": 13.84402399630826,
      "grad_norm": 0.890625,
      "learning_rate": 1.521237816800608e-07,
      "loss": 0.2266,
      "step": 11250
    },
    {
      "epoch": 13.85632979541609,
      "grad_norm": 0.96875,
      "learning_rate": 1.488861378045725e-07,
      "loss": 0.2606,
      "step": 11260
    },
    {
      "epoch": 13.86863559452392,
      "grad_norm": 0.9609375,
      "learning_rate": 1.4568279810767473e-07,
      "loss": 0.2565,
      "step": 11270
    },
    {
      "epoch": 13.88094139363175,
      "grad_norm": 0.96875,
      "learning_rate": 1.4251378524147098e-07,
      "loss": 0.2073,
      "step": 11280
    },
    {
      "epoch": 13.893247192739578,
      "grad_norm": 1.4140625,
      "learning_rate": 1.3937912161532564e-07,
      "loss": 0.2248,
      "step": 11290
    },
    {
      "epoch": 13.905552991847408,
      "grad_norm": 1.046875,
      "learning_rate": 1.3627882939570848e-07,
      "loss": 0.2446,
      "step": 11300
    },
    {
      "epoch": 13.917858790955238,
      "grad_norm": 1.3984375,
      "learning_rate": 1.3321293050603202e-07,
      "loss": 0.2421,
      "step": 11310
    },
    {
      "epoch": 13.930164590063066,
      "grad_norm": 1.234375,
      "learning_rate": 1.3018144662650334e-07,
      "loss": 0.2279,
      "step": 11320
    },
    {
      "epoch": 13.942470389170897,
      "grad_norm": 1.0234375,
      "learning_rate": 1.2718439919396308e-07,
      "loss": 0.2228,
      "step": 11330
    },
    {
      "epoch": 13.954776188278727,
      "grad_norm": 1.1015625,
      "learning_rate": 1.2422180940174056e-07,
      "loss": 0.2417,
      "step": 11340
    },
    {
      "epoch": 13.967081987386557,
      "grad_norm": 1.046875,
      "learning_rate": 1.212936981995011e-07,
      "loss": 0.2413,
      "step": 11350
    },
    {
      "epoch": 13.979387786494385,
      "grad_norm": 0.8671875,
      "learning_rate": 1.1840008629309674e-07,
      "loss": 0.2101,
      "step": 11360
    },
    {
      "epoch": 13.991693585602215,
      "grad_norm": 0.953125,
      "learning_rate": 1.1554099414442299e-07,
      "loss": 0.2502,
      "step": 11370
    },
    {
      "epoch": 14.003999384710045,
      "grad_norm": 1.1640625,
      "learning_rate": 1.1271644197126952e-07,
      "loss": 0.2482,
      "step": 11380
    },
    {
      "epoch": 14.016305183817874,
      "grad_norm": 1.046875,
      "learning_rate": 1.0992644974718247e-07,
      "loss": 0.2489,
      "step": 11390
    },
    {
      "epoch": 14.028610982925704,
      "grad_norm": 0.9921875,
      "learning_rate": 1.0717103720132016e-07,
      "loss": 0.2193,
      "step": 11400
    },
    {
      "epoch": 14.040916782033534,
      "grad_norm": 0.96875,
      "learning_rate": 1.0445022381831316e-07,
      "loss": 0.2581,
      "step": 11410
    },
    {
      "epoch": 14.053222581141362,
      "grad_norm": 0.9765625,
      "learning_rate": 1.0176402883812831e-07,
      "loss": 0.2133,
      "step": 11420
    },
    {
      "epoch": 14.065528380249193,
      "grad_norm": 0.9453125,
      "learning_rate": 9.911247125593048e-08,
      "loss": 0.2165,
      "step": 11430
    },
    {
      "epoch": 14.077834179357023,
      "grad_norm": 1.1171875,
      "learning_rate": 9.649556982195163e-08,
      "loss": 0.22,
      "step": 11440
    },
    {
      "epoch": 14.090139978464851,
      "grad_norm": 1.6015625,
      "learning_rate": 9.391334304135525e-08,
      "loss": 0.2835,
      "step": 11450
    },
    {
      "epoch": 14.102445777572681,
      "grad_norm": 1.1328125,
      "learning_rate": 9.136580917410486e-08,
      "loss": 0.2019,
      "step": 11460
    },
    {
      "epoch": 14.114751576680511,
      "grad_norm": 1.1015625,
      "learning_rate": 8.885298623483918e-08,
      "loss": 0.2599,
      "step": 11470
    },
    {
      "epoch": 14.12705737578834,
      "grad_norm": 1.0390625,
      "learning_rate": 8.63748919927393e-08,
      "loss": 0.2558,
      "step": 11480
    },
    {
      "epoch": 14.13936317489617,
      "grad_norm": 1.1640625,
      "learning_rate": 8.393154397140835e-08,
      "loss": 0.2369,
      "step": 11490
    },
    {
      "epoch": 14.151668974004,
      "grad_norm": 1.046875,
      "learning_rate": 8.152295944874267e-08,
      "loss": 0.2218,
      "step": 11500
    },
    {
      "epoch": 14.163974773111828,
      "grad_norm": 0.921875,
      "learning_rate": 7.914915545681245e-08,
      "loss": 0.2043,
      "step": 11510
    },
    {
      "epoch": 14.176280572219659,
      "grad_norm": 1.234375,
      "learning_rate": 7.681014878174187e-08,
      "loss": 0.238,
      "step": 11520
    },
    {
      "epoch": 14.188586371327489,
      "grad_norm": 0.8984375,
      "learning_rate": 7.450595596358856e-08,
      "loss": 0.2515,
      "step": 11530
    },
    {
      "epoch": 14.200892170435317,
      "grad_norm": 1.015625,
      "learning_rate": 7.223659329622712e-08,
      "loss": 0.2559,
      "step": 11540
    },
    {
      "epoch": 14.213197969543147,
      "grad_norm": 0.8984375,
      "learning_rate": 7.00020768272347e-08,
      "loss": 0.263,
      "step": 11550
    },
    {
      "epoch": 14.225503768650977,
      "grad_norm": 1.140625,
      "learning_rate": 6.780242235777557e-08,
      "loss": 0.2638,
      "step": 11560
    },
    {
      "epoch": 14.237809567758806,
      "grad_norm": 0.94921875,
      "learning_rate": 6.563764544249285e-08,
      "loss": 0.211,
      "step": 11570
    },
    {
      "epoch": 14.250115366866636,
      "grad_norm": 1.046875,
      "learning_rate": 6.350776138939474e-08,
      "loss": 0.2642,
      "step": 11580
    },
    {
      "epoch": 14.262421165974466,
      "grad_norm": 0.75,
      "learning_rate": 6.141278525974903e-08,
      "loss": 0.2208,
      "step": 11590
    },
    {
      "epoch": 14.274726965082294,
      "grad_norm": 1.046875,
      "learning_rate": 5.9352731867974857e-08,
      "loss": 0.2474,
      "step": 11600
    },
    {
      "epoch": 14.287032764190124,
      "grad_norm": 0.9765625,
      "learning_rate": 5.732761578153889e-08,
      "loss": 0.2677,
      "step": 11610
    },
    {
      "epoch": 14.299338563297955,
      "grad_norm": 0.98828125,
      "learning_rate": 5.533745132085266e-08,
      "loss": 0.2387,
      "step": 11620
    },
    {
      "epoch": 14.311644362405783,
      "grad_norm": 1.1875,
      "learning_rate": 5.338225255916929e-08,
      "loss": 0.2227,
      "step": 11630
    },
    {
      "epoch": 14.323950161513613,
      "grad_norm": 1.03125,
      "learning_rate": 5.146203332248578e-08,
      "loss": 0.2519,
      "step": 11640
    },
    {
      "epoch": 14.336255960621443,
      "grad_norm": 0.90625,
      "learning_rate": 4.9576807189446465e-08,
      "loss": 0.2518,
      "step": 11650
    },
    {
      "epoch": 14.348561759729272,
      "grad_norm": 0.9296875,
      "learning_rate": 4.7726587491243036e-08,
      "loss": 0.2449,
      "step": 11660
    },
    {
      "epoch": 14.360867558837102,
      "grad_norm": 0.9296875,
      "learning_rate": 4.591138731152467e-08,
      "loss": 0.2375,
      "step": 11670
    },
    {
      "epoch": 14.373173357944932,
      "grad_norm": 1.0546875,
      "learning_rate": 4.413121948630139e-08,
      "loss": 0.2278,
      "step": 11680
    },
    {
      "epoch": 14.38547915705276,
      "grad_norm": 0.98046875,
      "learning_rate": 4.238609660385695e-08,
      "loss": 0.2391,
      "step": 11690
    },
    {
      "epoch": 14.39778495616059,
      "grad_norm": 1.0,
      "learning_rate": 4.0676031004657225e-08,
      "loss": 0.2255,
      "step": 11700
    },
    {
      "epoch": 14.41009075526842,
      "grad_norm": 0.96484375,
      "learning_rate": 3.9001034781264714e-08,
      "loss": 0.2273,
      "step": 11710
    },
    {
      "epoch": 14.422396554376249,
      "grad_norm": 0.98828125,
      "learning_rate": 3.736111977825197e-08,
      "loss": 0.2497,
      "step": 11720
    },
    {
      "epoch": 14.434702353484079,
      "grad_norm": 0.8828125,
      "learning_rate": 3.575629759211718e-08,
      "loss": 0.2208,
      "step": 11730
    },
    {
      "epoch": 14.44700815259191,
      "grad_norm": 0.94921875,
      "learning_rate": 3.4186579571204856e-08,
      "loss": 0.2299,
      "step": 11740
    },
    {
      "epoch": 14.45931395169974,
      "grad_norm": 1.09375,
      "learning_rate": 3.265197681562249e-08,
      "loss": 0.2269,
      "step": 11750
    },
    {
      "epoch": 14.471619750807568,
      "grad_norm": 1.15625,
      "learning_rate": 3.115250017716398e-08,
      "loss": 0.2181,
      "step": 11760
    },
    {
      "epoch": 14.483925549915398,
      "grad_norm": 0.8359375,
      "learning_rate": 2.9688160259231934e-08,
      "loss": 0.2188,
      "step": 11770
    },
    {
      "epoch": 14.496231349023228,
      "grad_norm": 1.0,
      "learning_rate": 2.825896741676326e-08,
      "loss": 0.2769,
      "step": 11780
    },
    {
      "epoch": 14.508537148131056,
      "grad_norm": 1.25,
      "learning_rate": 2.6864931756156454e-08,
      "loss": 0.2267,
      "step": 11790
    },
    {
      "epoch": 14.520842947238886,
      "grad_norm": 1.15625,
      "learning_rate": 2.5506063135197768e-08,
      "loss": 0.2377,
      "step": 11800
    },
    {
      "epoch": 14.533148746346717,
      "grad_norm": 1.0859375,
      "learning_rate": 2.41823711629946e-08,
      "loss": 0.2632,
      "step": 11810
    },
    {
      "epoch": 14.545454545454545,
      "grad_norm": 1.1640625,
      "learning_rate": 2.2893865199905552e-08,
      "loss": 0.2597,
      "step": 11820
    },
    {
      "epoch": 14.557760344562375,
      "grad_norm": 1.1953125,
      "learning_rate": 2.1640554357474918e-08,
      "loss": 0.2358,
      "step": 11830
    },
    {
      "epoch": 14.570066143670205,
      "grad_norm": 0.83984375,
      "learning_rate": 2.042244749836775e-08,
      "loss": 0.1953,
      "step": 11840
    },
    {
      "epoch": 14.582371942778034,
      "grad_norm": 1.0234375,
      "learning_rate": 1.923955323630877e-08,
      "loss": 0.2454,
      "step": 11850
    },
    {
      "epoch": 14.594677741885864,
      "grad_norm": 1.1875,
      "learning_rate": 1.8091879936018574e-08,
      "loss": 0.2511,
      "step": 11860
    },
    {
      "epoch": 14.606983540993694,
      "grad_norm": 1.015625,
      "learning_rate": 1.6979435713157523e-08,
      "loss": 0.2871,
      "step": 11870
    },
    {
      "epoch": 14.619289340101522,
      "grad_norm": 1.0625,
      "learning_rate": 1.5902228434266366e-08,
      "loss": 0.2415,
      "step": 11880
    },
    {
      "epoch": 14.631595139209352,
      "grad_norm": 1.078125,
      "learning_rate": 1.4860265716710732e-08,
      "loss": 0.2187,
      "step": 11890
    },
    {
      "epoch": 14.643900938317183,
      "grad_norm": 1.09375,
      "learning_rate": 1.3853554928629498e-08,
      "loss": 0.2557,
      "step": 11900
    },
    {
      "epoch": 14.656206737425011,
      "grad_norm": 0.8203125,
      "learning_rate": 1.288210318887817e-08,
      "loss": 0.2602,
      "step": 11910
    },
    {
      "epoch": 14.668512536532841,
      "grad_norm": 0.9765625,
      "learning_rate": 1.1945917366985026e-08,
      "loss": 0.2274,
      "step": 11920
    },
    {
      "epoch": 14.680818335640671,
      "grad_norm": 0.90234375,
      "learning_rate": 1.1045004083095057e-08,
      "loss": 0.2584,
      "step": 11930
    },
    {
      "epoch": 14.6931241347485,
      "grad_norm": 1.0859375,
      "learning_rate": 1.0179369707929431e-08,
      "loss": 0.2361,
      "step": 11940
    },
    {
      "epoch": 14.70542993385633,
      "grad_norm": 0.85546875,
      "learning_rate": 9.349020362737216e-09,
      "loss": 0.2234,
      "step": 11950
    },
    {
      "epoch": 14.71773573296416,
      "grad_norm": 1.0,
      "learning_rate": 8.553961919252618e-09,
      "loss": 0.2061,
      "step": 11960
    },
    {
      "epoch": 14.730041532071988,
      "grad_norm": 0.8046875,
      "learning_rate": 7.794199999654473e-09,
      "loss": 0.2354,
      "step": 11970
    },
    {
      "epoch": 14.742347331179818,
      "grad_norm": 0.90625,
      "learning_rate": 7.069739976524603e-09,
      "loss": 0.2598,
      "step": 11980
    },
    {
      "epoch": 14.754653130287648,
      "grad_norm": 0.7421875,
      "learning_rate": 6.380586972811187e-09,
      "loss": 0.2459,
      "step": 11990
    },
    {
      "epoch": 14.766958929395477,
      "grad_norm": 0.91015625,
      "learning_rate": 5.7267458617926704e-09,
      "loss": 0.2057,
      "step": 12000
    },
    {
      "epoch": 14.779264728503307,
      "grad_norm": 1.5390625,
      "learning_rate": 5.108221267043356e-09,
      "loss": 0.2607,
      "step": 12010
    },
    {
      "epoch": 14.791570527611137,
      "grad_norm": 1.1171875,
      "learning_rate": 4.525017562398981e-09,
      "loss": 0.2365,
      "step": 12020
    },
    {
      "epoch": 14.803876326718967,
      "grad_norm": 1.0546875,
      "learning_rate": 3.977138871927299e-09,
      "loss": 0.2329,
      "step": 12030
    },
    {
      "epoch": 14.816182125826796,
      "grad_norm": 1.0625,
      "learning_rate": 3.4645890698997706e-09,
      "loss": 0.2328,
      "step": 12040
    },
    {
      "epoch": 14.828487924934626,
      "grad_norm": 1.1015625,
      "learning_rate": 2.987371780761583e-09,
      "loss": 0.206,
      "step": 12050
    },
    {
      "epoch": 14.840793724042456,
      "grad_norm": 0.97265625,
      "learning_rate": 2.54549037910945e-09,
      "loss": 0.2351,
      "step": 12060
    },
    {
      "epoch": 14.853099523150284,
      "grad_norm": 1.1953125,
      "learning_rate": 2.138947989663298e-09,
      "loss": 0.26,
      "step": 12070
    },
    {
      "epoch": 14.865405322258114,
      "grad_norm": 1.0625,
      "learning_rate": 1.7677474872490607e-09,
      "loss": 0.2429,
      "step": 12080
    },
    {
      "epoch": 14.877711121365945,
      "grad_norm": 0.87890625,
      "learning_rate": 1.4318914967742514e-09,
      "loss": 0.2641,
      "step": 12090
    },
    {
      "epoch": 14.890016920473773,
      "grad_norm": 0.90234375,
      "learning_rate": 1.1313823932118662e-09,
      "loss": 0.2059,
      "step": 12100
    },
    {
      "epoch": 14.902322719581603,
      "grad_norm": 1.1796875,
      "learning_rate": 8.662223015826199e-10,
      "loss": 0.2436,
      "step": 12110
    },
    {
      "epoch": 14.914628518689433,
      "grad_norm": 1.015625,
      "learning_rate": 6.364130969405135e-10,
      "loss": 0.2445,
      "step": 12120
    },
    {
      "epoch": 14.926934317797262,
      "grad_norm": 0.984375,
      "learning_rate": 4.4195640435840124e-10,
      "loss": 0.2428,
      "step": 12130
    },
    {
      "epoch": 14.939240116905092,
      "grad_norm": 0.96484375,
      "learning_rate": 2.8285359891855324e-10,
      "loss": 0.2389,
      "step": 12140
    },
    {
      "epoch": 14.951545916012922,
      "grad_norm": 1.0703125,
      "learning_rate": 1.5910580570099864e-10,
      "loss": 0.2437,
      "step": 12150
    },
    {
      "epoch": 14.96385171512075,
      "grad_norm": 1.1015625,
      "learning_rate": 7.071389977519883e-11,
      "loss": 0.2442,
      "step": 12160
    },
    {
      "epoch": 14.97615751422858,
      "grad_norm": 1.2265625,
      "learning_rate": 1.7678506196716627e-11,
      "loss": 0.2309,
      "step": 12170
    },
    {
      "epoch": 14.98846331333641,
      "grad_norm": 1.0390625,
      "learning_rate": 0.0,
      "loss": 0.247,
      "step": 12180
    },
    {
      "epoch": 14.98846331333641,
      "step": 12180,
      "total_flos": 3.685545841734451e+18,
      "train_loss": 0.24948551349941342,
      "train_runtime": 23280.5821,
      "train_samples_per_second": 33.506,
      "train_steps_per_second": 0.523
    }
  ],
  "logging_steps": 10,
  "max_steps": 12180,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 5000,
  "total_flos": 3.685545841734451e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
