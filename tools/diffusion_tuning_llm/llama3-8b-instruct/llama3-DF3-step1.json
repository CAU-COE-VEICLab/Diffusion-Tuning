{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 14.98846331333641,
  "eval_steps": 5000,
  "global_step": 12180,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0012305799107829565,
      "grad_norm": 0.474609375,
      "learning_rate": 2.73224043715847e-07,
      "loss": 0.2135,
      "step": 1
    },
    {
      "epoch": 0.012305799107829564,
      "grad_norm": 0.4296875,
      "learning_rate": 2.73224043715847e-06,
      "loss": 0.2806,
      "step": 10
    },
    {
      "epoch": 0.024611598215659128,
      "grad_norm": 0.37890625,
      "learning_rate": 5.46448087431694e-06,
      "loss": 0.303,
      "step": 20
    },
    {
      "epoch": 0.03691739732348869,
      "grad_norm": 0.4140625,
      "learning_rate": 8.196721311475409e-06,
      "loss": 0.2779,
      "step": 30
    },
    {
      "epoch": 0.049223196431318256,
      "grad_norm": 0.326171875,
      "learning_rate": 1.092896174863388e-05,
      "loss": 0.2922,
      "step": 40
    },
    {
      "epoch": 0.06152899553914783,
      "grad_norm": 0.431640625,
      "learning_rate": 1.3661202185792351e-05,
      "loss": 0.3001,
      "step": 50
    },
    {
      "epoch": 0.07383479464697738,
      "grad_norm": 0.46484375,
      "learning_rate": 1.6393442622950818e-05,
      "loss": 0.2816,
      "step": 60
    },
    {
      "epoch": 0.08614059375480695,
      "grad_norm": 0.39453125,
      "learning_rate": 1.912568306010929e-05,
      "loss": 0.2818,
      "step": 70
    },
    {
      "epoch": 0.09844639286263651,
      "grad_norm": 0.4140625,
      "learning_rate": 2.185792349726776e-05,
      "loss": 0.2863,
      "step": 80
    },
    {
      "epoch": 0.11075219197046608,
      "grad_norm": 0.423828125,
      "learning_rate": 2.459016393442623e-05,
      "loss": 0.2709,
      "step": 90
    },
    {
      "epoch": 0.12305799107829565,
      "grad_norm": 0.46484375,
      "learning_rate": 2.7322404371584703e-05,
      "loss": 0.2722,
      "step": 100
    },
    {
      "epoch": 0.1353637901861252,
      "grad_norm": 0.333984375,
      "learning_rate": 3.005464480874317e-05,
      "loss": 0.2995,
      "step": 110
    },
    {
      "epoch": 0.14766958929395477,
      "grad_norm": 0.39453125,
      "learning_rate": 3.2786885245901635e-05,
      "loss": 0.2969,
      "step": 120
    },
    {
      "epoch": 0.15997538840178435,
      "grad_norm": 0.33203125,
      "learning_rate": 3.551912568306011e-05,
      "loss": 0.3206,
      "step": 130
    },
    {
      "epoch": 0.1722811875096139,
      "grad_norm": 0.314453125,
      "learning_rate": 3.825136612021858e-05,
      "loss": 0.2792,
      "step": 140
    },
    {
      "epoch": 0.18458698661744347,
      "grad_norm": 0.359375,
      "learning_rate": 4.098360655737705e-05,
      "loss": 0.2602,
      "step": 150
    },
    {
      "epoch": 0.19689278572527302,
      "grad_norm": 0.3359375,
      "learning_rate": 4.371584699453552e-05,
      "loss": 0.291,
      "step": 160
    },
    {
      "epoch": 0.2091985848331026,
      "grad_norm": 0.3671875,
      "learning_rate": 4.644808743169399e-05,
      "loss": 0.2817,
      "step": 170
    },
    {
      "epoch": 0.22150438394093216,
      "grad_norm": 0.408203125,
      "learning_rate": 4.918032786885246e-05,
      "loss": 0.2864,
      "step": 180
    },
    {
      "epoch": 0.23381018304876172,
      "grad_norm": 0.3203125,
      "learning_rate": 5.1912568306010934e-05,
      "loss": 0.2681,
      "step": 190
    },
    {
      "epoch": 0.2461159821565913,
      "grad_norm": 0.328125,
      "learning_rate": 5.4644808743169406e-05,
      "loss": 0.2987,
      "step": 200
    },
    {
      "epoch": 0.25842178126442084,
      "grad_norm": 0.375,
      "learning_rate": 5.737704918032787e-05,
      "loss": 0.2867,
      "step": 210
    },
    {
      "epoch": 0.2707275803722504,
      "grad_norm": 0.37890625,
      "learning_rate": 6.010928961748634e-05,
      "loss": 0.3006,
      "step": 220
    },
    {
      "epoch": 0.28303337948008,
      "grad_norm": 0.5859375,
      "learning_rate": 6.284153005464482e-05,
      "loss": 0.2538,
      "step": 230
    },
    {
      "epoch": 0.29533917858790953,
      "grad_norm": 0.416015625,
      "learning_rate": 6.557377049180327e-05,
      "loss": 0.2647,
      "step": 240
    },
    {
      "epoch": 0.3076449776957391,
      "grad_norm": 0.32421875,
      "learning_rate": 6.830601092896175e-05,
      "loss": 0.2832,
      "step": 250
    },
    {
      "epoch": 0.3199507768035687,
      "grad_norm": 0.298828125,
      "learning_rate": 7.103825136612023e-05,
      "loss": 0.2945,
      "step": 260
    },
    {
      "epoch": 0.33225657591139823,
      "grad_norm": 0.341796875,
      "learning_rate": 7.377049180327869e-05,
      "loss": 0.3085,
      "step": 270
    },
    {
      "epoch": 0.3445623750192278,
      "grad_norm": 0.4453125,
      "learning_rate": 7.650273224043716e-05,
      "loss": 0.2872,
      "step": 280
    },
    {
      "epoch": 0.3568681741270574,
      "grad_norm": 0.32421875,
      "learning_rate": 7.923497267759563e-05,
      "loss": 0.3095,
      "step": 290
    },
    {
      "epoch": 0.36917397323488693,
      "grad_norm": 0.31640625,
      "learning_rate": 8.19672131147541e-05,
      "loss": 0.2847,
      "step": 300
    },
    {
      "epoch": 0.3814797723427165,
      "grad_norm": 0.357421875,
      "learning_rate": 8.469945355191258e-05,
      "loss": 0.2739,
      "step": 310
    },
    {
      "epoch": 0.39378557145054605,
      "grad_norm": 0.40234375,
      "learning_rate": 8.743169398907104e-05,
      "loss": 0.294,
      "step": 320
    },
    {
      "epoch": 0.40609137055837563,
      "grad_norm": 0.34765625,
      "learning_rate": 9.016393442622952e-05,
      "loss": 0.3071,
      "step": 330
    },
    {
      "epoch": 0.4183971696662052,
      "grad_norm": 0.349609375,
      "learning_rate": 9.289617486338798e-05,
      "loss": 0.2754,
      "step": 340
    },
    {
      "epoch": 0.43070296877403474,
      "grad_norm": 0.388671875,
      "learning_rate": 9.562841530054645e-05,
      "loss": 0.2968,
      "step": 350
    },
    {
      "epoch": 0.44300876788186433,
      "grad_norm": 0.453125,
      "learning_rate": 9.836065573770493e-05,
      "loss": 0.2973,
      "step": 360
    },
    {
      "epoch": 0.4553145669896939,
      "grad_norm": 0.455078125,
      "learning_rate": 9.99999717143761e-05,
      "loss": 0.267,
      "step": 370
    },
    {
      "epoch": 0.46762036609752344,
      "grad_norm": 0.400390625,
      "learning_rate": 9.999965350147456e-05,
      "loss": 0.2879,
      "step": 380
    },
    {
      "epoch": 0.47992616520535303,
      "grad_norm": 0.5078125,
      "learning_rate": 9.999898172089934e-05,
      "loss": 0.2861,
      "step": 390
    },
    {
      "epoch": 0.4922319643131826,
      "grad_norm": 0.482421875,
      "learning_rate": 9.999795637740084e-05,
      "loss": 0.2769,
      "step": 400
    },
    {
      "epoch": 0.5045377634210122,
      "grad_norm": 0.8984375,
      "learning_rate": 9.999657747822969e-05,
      "loss": 0.2899,
      "step": 410
    },
    {
      "epoch": 0.5168435625288417,
      "grad_norm": 0.462890625,
      "learning_rate": 9.999484503313661e-05,
      "loss": 0.3024,
      "step": 420
    },
    {
      "epoch": 0.5291493616366713,
      "grad_norm": 0.337890625,
      "learning_rate": 9.999275905437246e-05,
      "loss": 0.2879,
      "step": 430
    },
    {
      "epoch": 0.5414551607445008,
      "grad_norm": 0.51953125,
      "learning_rate": 9.9990319556688e-05,
      "loss": 0.3375,
      "step": 440
    },
    {
      "epoch": 0.5537609598523304,
      "grad_norm": 0.57421875,
      "learning_rate": 9.998752655733394e-05,
      "loss": 0.2941,
      "step": 450
    },
    {
      "epoch": 0.56606675896016,
      "grad_norm": 0.46875,
      "learning_rate": 9.998438007606065e-05,
      "loss": 0.2965,
      "step": 460
    },
    {
      "epoch": 0.5783725580679896,
      "grad_norm": 0.466796875,
      "learning_rate": 9.998088013511822e-05,
      "loss": 0.2933,
      "step": 470
    },
    {
      "epoch": 0.5906783571758191,
      "grad_norm": 0.43359375,
      "learning_rate": 9.997702675925612e-05,
      "loss": 0.3287,
      "step": 480
    },
    {
      "epoch": 0.6029841562836487,
      "grad_norm": 0.435546875,
      "learning_rate": 9.997281997572307e-05,
      "loss": 0.2761,
      "step": 490
    },
    {
      "epoch": 0.6152899553914782,
      "grad_norm": 0.5703125,
      "learning_rate": 9.996825981426701e-05,
      "loss": 0.3326,
      "step": 500
    },
    {
      "epoch": 0.6275957544993078,
      "grad_norm": 0.427734375,
      "learning_rate": 9.996334630713464e-05,
      "loss": 0.2901,
      "step": 510
    },
    {
      "epoch": 0.6399015536071374,
      "grad_norm": 0.53515625,
      "learning_rate": 9.995807948907134e-05,
      "loss": 0.266,
      "step": 520
    },
    {
      "epoch": 0.6522073527149669,
      "grad_norm": 0.55859375,
      "learning_rate": 9.995245939732092e-05,
      "loss": 0.3268,
      "step": 530
    },
    {
      "epoch": 0.6645131518227965,
      "grad_norm": 0.53125,
      "learning_rate": 9.994648607162529e-05,
      "loss": 0.3062,
      "step": 540
    },
    {
      "epoch": 0.676818950930626,
      "grad_norm": 0.6015625,
      "learning_rate": 9.994015955422427e-05,
      "loss": 0.2813,
      "step": 550
    },
    {
      "epoch": 0.6891247500384556,
      "grad_norm": 0.369140625,
      "learning_rate": 9.993347988985517e-05,
      "loss": 0.3021,
      "step": 560
    },
    {
      "epoch": 0.7014305491462852,
      "grad_norm": 0.59375,
      "learning_rate": 9.99264471257526e-05,
      "loss": 0.2916,
      "step": 570
    },
    {
      "epoch": 0.7137363482541148,
      "grad_norm": 0.53125,
      "learning_rate": 9.99190613116481e-05,
      "loss": 0.2983,
      "step": 580
    },
    {
      "epoch": 0.7260421473619443,
      "grad_norm": 0.486328125,
      "learning_rate": 9.991132249976969e-05,
      "loss": 0.3091,
      "step": 590
    },
    {
      "epoch": 0.7383479464697739,
      "grad_norm": 0.640625,
      "learning_rate": 9.990323074484163e-05,
      "loss": 0.2848,
      "step": 600
    },
    {
      "epoch": 0.7506537455776034,
      "grad_norm": 0.73828125,
      "learning_rate": 9.9894786104084e-05,
      "loss": 0.3058,
      "step": 610
    },
    {
      "epoch": 0.762959544685433,
      "grad_norm": 0.490234375,
      "learning_rate": 9.988598863721224e-05,
      "loss": 0.306,
      "step": 620
    },
    {
      "epoch": 0.7752653437932626,
      "grad_norm": 0.5,
      "learning_rate": 9.987683840643678e-05,
      "loss": 0.297,
      "step": 630
    },
    {
      "epoch": 0.7875711429010921,
      "grad_norm": 0.80078125,
      "learning_rate": 9.986733547646257e-05,
      "loss": 0.3233,
      "step": 640
    },
    {
      "epoch": 0.7998769420089217,
      "grad_norm": 0.609375,
      "learning_rate": 9.985747991448866e-05,
      "loss": 0.3103,
      "step": 650
    },
    {
      "epoch": 0.8121827411167513,
      "grad_norm": 0.453125,
      "learning_rate": 9.984727179020773e-05,
      "loss": 0.2979,
      "step": 660
    },
    {
      "epoch": 0.8244885402245808,
      "grad_norm": 0.421875,
      "learning_rate": 9.983671117580547e-05,
      "loss": 0.3264,
      "step": 670
    },
    {
      "epoch": 0.8367943393324104,
      "grad_norm": 0.51953125,
      "learning_rate": 9.98257981459603e-05,
      "loss": 0.2853,
      "step": 680
    },
    {
      "epoch": 0.84910013844024,
      "grad_norm": 0.81640625,
      "learning_rate": 9.981453277784261e-05,
      "loss": 0.326,
      "step": 690
    },
    {
      "epoch": 0.8614059375480695,
      "grad_norm": 0.400390625,
      "learning_rate": 9.980291515111436e-05,
      "loss": 0.344,
      "step": 700
    },
    {
      "epoch": 0.8737117366558991,
      "grad_norm": 0.6953125,
      "learning_rate": 9.979094534792843e-05,
      "loss": 0.2831,
      "step": 710
    },
    {
      "epoch": 0.8860175357637287,
      "grad_norm": 0.5703125,
      "learning_rate": 9.977862345292819e-05,
      "loss": 0.29,
      "step": 720
    },
    {
      "epoch": 0.8983233348715582,
      "grad_norm": 0.5546875,
      "learning_rate": 9.976594955324666e-05,
      "loss": 0.2924,
      "step": 730
    },
    {
      "epoch": 0.9106291339793878,
      "grad_norm": 0.4921875,
      "learning_rate": 9.975292373850611e-05,
      "loss": 0.302,
      "step": 740
    },
    {
      "epoch": 0.9229349330872173,
      "grad_norm": 0.51953125,
      "learning_rate": 9.973954610081732e-05,
      "loss": 0.3057,
      "step": 750
    },
    {
      "epoch": 0.9352407321950469,
      "grad_norm": 0.67578125,
      "learning_rate": 9.972581673477893e-05,
      "loss": 0.2953,
      "step": 760
    },
    {
      "epoch": 0.9475465313028765,
      "grad_norm": 0.53125,
      "learning_rate": 9.971173573747682e-05,
      "loss": 0.2999,
      "step": 770
    },
    {
      "epoch": 0.9598523304107061,
      "grad_norm": 0.5625,
      "learning_rate": 9.96973032084834e-05,
      "loss": 0.3088,
      "step": 780
    },
    {
      "epoch": 0.9721581295185356,
      "grad_norm": 0.482421875,
      "learning_rate": 9.96825192498569e-05,
      "loss": 0.2973,
      "step": 790
    },
    {
      "epoch": 0.9844639286263652,
      "grad_norm": 0.75390625,
      "learning_rate": 9.966738396614063e-05,
      "loss": 0.3193,
      "step": 800
    },
    {
      "epoch": 0.9967697277341947,
      "grad_norm": 0.53125,
      "learning_rate": 9.965189746436225e-05,
      "loss": 0.2968,
      "step": 810
    },
    {
      "epoch": 1.0090755268420244,
      "grad_norm": 0.7890625,
      "learning_rate": 9.963605985403309e-05,
      "loss": 0.2609,
      "step": 820
    },
    {
      "epoch": 1.0213813259498539,
      "grad_norm": 0.4609375,
      "learning_rate": 9.961987124714722e-05,
      "loss": 0.2949,
      "step": 830
    },
    {
      "epoch": 1.0336871250576833,
      "grad_norm": 1.0546875,
      "learning_rate": 9.960333175818084e-05,
      "loss": 0.2515,
      "step": 840
    },
    {
      "epoch": 1.045992924165513,
      "grad_norm": 0.89453125,
      "learning_rate": 9.958644150409131e-05,
      "loss": 0.2519,
      "step": 850
    },
    {
      "epoch": 1.0582987232733425,
      "grad_norm": 0.46484375,
      "learning_rate": 9.956920060431641e-05,
      "loss": 0.2592,
      "step": 860
    },
    {
      "epoch": 1.0706045223811722,
      "grad_norm": 0.80078125,
      "learning_rate": 9.95516091807735e-05,
      "loss": 0.2405,
      "step": 870
    },
    {
      "epoch": 1.0829103214890017,
      "grad_norm": 0.5546875,
      "learning_rate": 9.95336673578586e-05,
      "loss": 0.271,
      "step": 880
    },
    {
      "epoch": 1.0952161205968312,
      "grad_norm": 0.67578125,
      "learning_rate": 9.951537526244556e-05,
      "loss": 0.2919,
      "step": 890
    },
    {
      "epoch": 1.1075219197046609,
      "grad_norm": 0.578125,
      "learning_rate": 9.949673302388516e-05,
      "loss": 0.2506,
      "step": 900
    },
    {
      "epoch": 1.1198277188124903,
      "grad_norm": 0.5078125,
      "learning_rate": 9.947774077400416e-05,
      "loss": 0.2608,
      "step": 910
    },
    {
      "epoch": 1.13213351792032,
      "grad_norm": 0.6796875,
      "learning_rate": 9.945839864710442e-05,
      "loss": 0.274,
      "step": 920
    },
    {
      "epoch": 1.1444393170281495,
      "grad_norm": 0.66015625,
      "learning_rate": 9.943870677996189e-05,
      "loss": 0.2856,
      "step": 930
    },
    {
      "epoch": 1.156745116135979,
      "grad_norm": 0.62109375,
      "learning_rate": 9.941866531182568e-05,
      "loss": 0.2638,
      "step": 940
    },
    {
      "epoch": 1.1690509152438087,
      "grad_norm": 0.55078125,
      "learning_rate": 9.939827438441711e-05,
      "loss": 0.2459,
      "step": 950
    },
    {
      "epoch": 1.1813567143516381,
      "grad_norm": 1.1171875,
      "learning_rate": 9.937753414192861e-05,
      "loss": 0.2487,
      "step": 960
    },
    {
      "epoch": 1.1936625134594678,
      "grad_norm": 0.75390625,
      "learning_rate": 9.935644473102278e-05,
      "loss": 0.2939,
      "step": 970
    },
    {
      "epoch": 1.2059683125672973,
      "grad_norm": 0.953125,
      "learning_rate": 9.933500630083134e-05,
      "loss": 0.2336,
      "step": 980
    },
    {
      "epoch": 1.218274111675127,
      "grad_norm": 0.6640625,
      "learning_rate": 9.931321900295407e-05,
      "loss": 0.2691,
      "step": 990
    },
    {
      "epoch": 1.2305799107829565,
      "grad_norm": 0.921875,
      "learning_rate": 9.929108299145768e-05,
      "loss": 0.2792,
      "step": 1000
    },
    {
      "epoch": 1.242885709890786,
      "grad_norm": 0.62109375,
      "learning_rate": 9.926859842287486e-05,
      "loss": 0.2781,
      "step": 1010
    },
    {
      "epoch": 1.2551915089986156,
      "grad_norm": 0.5,
      "learning_rate": 9.924576545620305e-05,
      "loss": 0.2622,
      "step": 1020
    },
    {
      "epoch": 1.2674973081064451,
      "grad_norm": 0.63671875,
      "learning_rate": 9.92225842529033e-05,
      "loss": 0.2945,
      "step": 1030
    },
    {
      "epoch": 1.2798031072142746,
      "grad_norm": 0.7265625,
      "learning_rate": 9.919905497689928e-05,
      "loss": 0.2587,
      "step": 1040
    },
    {
      "epoch": 1.2921089063221043,
      "grad_norm": 0.609375,
      "learning_rate": 9.917517779457592e-05,
      "loss": 0.2791,
      "step": 1050
    },
    {
      "epoch": 1.304414705429934,
      "grad_norm": 0.57421875,
      "learning_rate": 9.915095287477843e-05,
      "loss": 0.2741,
      "step": 1060
    },
    {
      "epoch": 1.3167205045377635,
      "grad_norm": 0.578125,
      "learning_rate": 9.912638038881094e-05,
      "loss": 0.2843,
      "step": 1070
    },
    {
      "epoch": 1.329026303645593,
      "grad_norm": 1.0703125,
      "learning_rate": 9.910146051043541e-05,
      "loss": 0.2755,
      "step": 1080
    },
    {
      "epoch": 1.3413321027534226,
      "grad_norm": 0.5859375,
      "learning_rate": 9.907619341587031e-05,
      "loss": 0.2687,
      "step": 1090
    },
    {
      "epoch": 1.353637901861252,
      "grad_norm": 1.0546875,
      "learning_rate": 9.905057928378944e-05,
      "loss": 0.2711,
      "step": 1100
    },
    {
      "epoch": 1.3659437009690816,
      "grad_norm": 0.83984375,
      "learning_rate": 9.902461829532066e-05,
      "loss": 0.2659,
      "step": 1110
    },
    {
      "epoch": 1.3782495000769113,
      "grad_norm": 0.59765625,
      "learning_rate": 9.899831063404452e-05,
      "loss": 0.2639,
      "step": 1120
    },
    {
      "epoch": 1.3905552991847407,
      "grad_norm": 0.6796875,
      "learning_rate": 9.897165648599314e-05,
      "loss": 0.2681,
      "step": 1130
    },
    {
      "epoch": 1.4028610982925704,
      "grad_norm": 0.6640625,
      "learning_rate": 9.894465603964868e-05,
      "loss": 0.2708,
      "step": 1140
    },
    {
      "epoch": 1.4151668974004,
      "grad_norm": 0.7734375,
      "learning_rate": 9.891730948594218e-05,
      "loss": 0.2708,
      "step": 1150
    },
    {
      "epoch": 1.4274726965082296,
      "grad_norm": 0.9375,
      "learning_rate": 9.888961701825213e-05,
      "loss": 0.2782,
      "step": 1160
    },
    {
      "epoch": 1.439778495616059,
      "grad_norm": 1.5390625,
      "learning_rate": 9.886157883240313e-05,
      "loss": 0.2419,
      "step": 1170
    },
    {
      "epoch": 1.4520842947238886,
      "grad_norm": 0.86328125,
      "learning_rate": 9.883319512666444e-05,
      "loss": 0.2926,
      "step": 1180
    },
    {
      "epoch": 1.4643900938317183,
      "grad_norm": 0.71875,
      "learning_rate": 9.88044661017487e-05,
      "loss": 0.2691,
      "step": 1190
    },
    {
      "epoch": 1.4766958929395477,
      "grad_norm": 1.03125,
      "learning_rate": 9.87753919608104e-05,
      "loss": 0.2908,
      "step": 1200
    },
    {
      "epoch": 1.4890016920473772,
      "grad_norm": 0.98046875,
      "learning_rate": 9.874597290944447e-05,
      "loss": 0.2824,
      "step": 1210
    },
    {
      "epoch": 1.501307491155207,
      "grad_norm": 0.66015625,
      "learning_rate": 9.871620915568489e-05,
      "loss": 0.2778,
      "step": 1220
    },
    {
      "epoch": 1.5136132902630366,
      "grad_norm": 1.390625,
      "learning_rate": 9.868610091000314e-05,
      "loss": 0.2971,
      "step": 1230
    },
    {
      "epoch": 1.525919089370866,
      "grad_norm": 0.5,
      "learning_rate": 9.865564838530675e-05,
      "loss": 0.2711,
      "step": 1240
    },
    {
      "epoch": 1.5382248884786955,
      "grad_norm": 0.7109375,
      "learning_rate": 9.862485179693774e-05,
      "loss": 0.2693,
      "step": 1250
    },
    {
      "epoch": 1.5505306875865252,
      "grad_norm": 0.86328125,
      "learning_rate": 9.859371136267121e-05,
      "loss": 0.2911,
      "step": 1260
    },
    {
      "epoch": 1.5628364866943547,
      "grad_norm": 0.6015625,
      "learning_rate": 9.856222730271369e-05,
      "loss": 0.2713,
      "step": 1270
    },
    {
      "epoch": 1.5751422858021842,
      "grad_norm": 0.83984375,
      "learning_rate": 9.853039983970167e-05,
      "loss": 0.269,
      "step": 1280
    },
    {
      "epoch": 1.5874480849100139,
      "grad_norm": 0.5390625,
      "learning_rate": 9.849822919869993e-05,
      "loss": 0.2805,
      "step": 1290
    },
    {
      "epoch": 1.5997538840178436,
      "grad_norm": 0.53125,
      "learning_rate": 9.846571560720002e-05,
      "loss": 0.2542,
      "step": 1300
    },
    {
      "epoch": 1.6120596831256728,
      "grad_norm": 0.58203125,
      "learning_rate": 9.843285929511863e-05,
      "loss": 0.2934,
      "step": 1310
    },
    {
      "epoch": 1.6243654822335025,
      "grad_norm": 0.65234375,
      "learning_rate": 9.839966049479596e-05,
      "loss": 0.2469,
      "step": 1320
    },
    {
      "epoch": 1.6366712813413322,
      "grad_norm": 0.7265625,
      "learning_rate": 9.836611944099412e-05,
      "loss": 0.2499,
      "step": 1330
    },
    {
      "epoch": 1.6489770804491617,
      "grad_norm": 0.88671875,
      "learning_rate": 9.833223637089536e-05,
      "loss": 0.2675,
      "step": 1340
    },
    {
      "epoch": 1.6612828795569912,
      "grad_norm": 0.6875,
      "learning_rate": 9.829801152410053e-05,
      "loss": 0.2465,
      "step": 1350
    },
    {
      "epoch": 1.6735886786648209,
      "grad_norm": 1.0,
      "learning_rate": 9.82634451426273e-05,
      "loss": 0.249,
      "step": 1360
    },
    {
      "epoch": 1.6858944777726503,
      "grad_norm": 0.703125,
      "learning_rate": 9.822853747090846e-05,
      "loss": 0.3076,
      "step": 1370
    },
    {
      "epoch": 1.6982002768804798,
      "grad_norm": 0.66015625,
      "learning_rate": 9.819328875579018e-05,
      "loss": 0.2848,
      "step": 1380
    },
    {
      "epoch": 1.7105060759883095,
      "grad_norm": 0.70703125,
      "learning_rate": 9.815769924653035e-05,
      "loss": 0.2873,
      "step": 1390
    },
    {
      "epoch": 1.7228118750961392,
      "grad_norm": 0.5625,
      "learning_rate": 9.81217691947967e-05,
      "loss": 0.2634,
      "step": 1400
    },
    {
      "epoch": 1.7351176742039687,
      "grad_norm": 0.80859375,
      "learning_rate": 9.808549885466509e-05,
      "loss": 0.2806,
      "step": 1410
    },
    {
      "epoch": 1.7474234733117981,
      "grad_norm": 0.6484375,
      "learning_rate": 9.804888848261769e-05,
      "loss": 0.2548,
      "step": 1420
    },
    {
      "epoch": 1.7597292724196278,
      "grad_norm": 0.65234375,
      "learning_rate": 9.801193833754117e-05,
      "loss": 0.2434,
      "step": 1430
    },
    {
      "epoch": 1.7720350715274573,
      "grad_norm": 0.671875,
      "learning_rate": 9.797464868072488e-05,
      "loss": 0.2799,
      "step": 1440
    },
    {
      "epoch": 1.7843408706352868,
      "grad_norm": 1.3125,
      "learning_rate": 9.793701977585899e-05,
      "loss": 0.294,
      "step": 1450
    },
    {
      "epoch": 1.7966466697431165,
      "grad_norm": 0.75,
      "learning_rate": 9.789905188903263e-05,
      "loss": 0.2631,
      "step": 1460
    },
    {
      "epoch": 1.808952468850946,
      "grad_norm": 0.578125,
      "learning_rate": 9.786074528873203e-05,
      "loss": 0.2553,
      "step": 1470
    },
    {
      "epoch": 1.8212582679587754,
      "grad_norm": 0.58984375,
      "learning_rate": 9.782210024583857e-05,
      "loss": 0.2848,
      "step": 1480
    },
    {
      "epoch": 1.8335640670666051,
      "grad_norm": 0.87890625,
      "learning_rate": 9.778311703362688e-05,
      "loss": 0.2944,
      "step": 1490
    },
    {
      "epoch": 1.8458698661744348,
      "grad_norm": 0.66796875,
      "learning_rate": 9.774379592776295e-05,
      "loss": 0.2503,
      "step": 1500
    },
    {
      "epoch": 1.8581756652822643,
      "grad_norm": 0.7265625,
      "learning_rate": 9.770413720630217e-05,
      "loss": 0.257,
      "step": 1510
    },
    {
      "epoch": 1.8704814643900938,
      "grad_norm": 0.52734375,
      "learning_rate": 9.76641411496873e-05,
      "loss": 0.2602,
      "step": 1520
    },
    {
      "epoch": 1.8827872634979235,
      "grad_norm": 0.62890625,
      "learning_rate": 9.762380804074656e-05,
      "loss": 0.2834,
      "step": 1530
    },
    {
      "epoch": 1.895093062605753,
      "grad_norm": 1.21875,
      "learning_rate": 9.758313816469158e-05,
      "loss": 0.2573,
      "step": 1540
    },
    {
      "epoch": 1.9073988617135824,
      "grad_norm": 0.82421875,
      "learning_rate": 9.754213180911546e-05,
      "loss": 0.2659,
      "step": 1550
    },
    {
      "epoch": 1.9197046608214121,
      "grad_norm": 0.9140625,
      "learning_rate": 9.75007892639906e-05,
      "loss": 0.2761,
      "step": 1560
    },
    {
      "epoch": 1.9320104599292418,
      "grad_norm": 0.8984375,
      "learning_rate": 9.745911082166682e-05,
      "loss": 0.2703,
      "step": 1570
    },
    {
      "epoch": 1.944316259037071,
      "grad_norm": 0.94140625,
      "learning_rate": 9.741709677686912e-05,
      "loss": 0.2914,
      "step": 1580
    },
    {
      "epoch": 1.9566220581449008,
      "grad_norm": 0.5859375,
      "learning_rate": 9.737474742669575e-05,
      "loss": 0.262,
      "step": 1590
    },
    {
      "epoch": 1.9689278572527305,
      "grad_norm": 0.78515625,
      "learning_rate": 9.7332063070616e-05,
      "loss": 0.2735,
      "step": 1600
    },
    {
      "epoch": 1.98123365636056,
      "grad_norm": 0.91796875,
      "learning_rate": 9.728904401046812e-05,
      "loss": 0.2943,
      "step": 1610
    },
    {
      "epoch": 1.9935394554683894,
      "grad_norm": 0.77734375,
      "learning_rate": 9.724569055045722e-05,
      "loss": 0.2731,
      "step": 1620
    },
    {
      "epoch": 2.005845254576219,
      "grad_norm": 0.66015625,
      "learning_rate": 9.720200299715306e-05,
      "loss": 0.2456,
      "step": 1630
    },
    {
      "epoch": 2.018151053684049,
      "grad_norm": 0.90625,
      "learning_rate": 9.715798165948789e-05,
      "loss": 0.2313,
      "step": 1640
    },
    {
      "epoch": 2.030456852791878,
      "grad_norm": 0.62890625,
      "learning_rate": 9.711362684875432e-05,
      "loss": 0.2362,
      "step": 1650
    },
    {
      "epoch": 2.0427626518997077,
      "grad_norm": 0.62109375,
      "learning_rate": 9.706893887860306e-05,
      "loss": 0.2157,
      "step": 1660
    },
    {
      "epoch": 2.0550684510075374,
      "grad_norm": 0.71875,
      "learning_rate": 9.702391806504076e-05,
      "loss": 0.2558,
      "step": 1670
    },
    {
      "epoch": 2.0673742501153667,
      "grad_norm": 0.9453125,
      "learning_rate": 9.69785647264277e-05,
      "loss": 0.2041,
      "step": 1680
    },
    {
      "epoch": 2.0796800492231964,
      "grad_norm": 1.2421875,
      "learning_rate": 9.693287918347559e-05,
      "loss": 0.2032,
      "step": 1690
    },
    {
      "epoch": 2.091985848331026,
      "grad_norm": 0.71484375,
      "learning_rate": 9.688686175924528e-05,
      "loss": 0.2315,
      "step": 1700
    },
    {
      "epoch": 2.1042916474388558,
      "grad_norm": 0.57421875,
      "learning_rate": 9.68405127791445e-05,
      "loss": 0.2047,
      "step": 1710
    },
    {
      "epoch": 2.116597446546685,
      "grad_norm": 0.51171875,
      "learning_rate": 9.679383257092557e-05,
      "loss": 0.2393,
      "step": 1720
    },
    {
      "epoch": 2.1289032456545147,
      "grad_norm": 0.890625,
      "learning_rate": 9.6746821464683e-05,
      "loss": 0.2267,
      "step": 1730
    },
    {
      "epoch": 2.1412090447623444,
      "grad_norm": 0.75,
      "learning_rate": 9.669947979285126e-05,
      "loss": 0.2542,
      "step": 1740
    },
    {
      "epoch": 2.1535148438701737,
      "grad_norm": 0.7890625,
      "learning_rate": 9.665180789020233e-05,
      "loss": 0.2149,
      "step": 1750
    },
    {
      "epoch": 2.1658206429780034,
      "grad_norm": 0.88671875,
      "learning_rate": 9.660380609384347e-05,
      "loss": 0.2255,
      "step": 1760
    },
    {
      "epoch": 2.178126442085833,
      "grad_norm": 0.451171875,
      "learning_rate": 9.65554747432147e-05,
      "loss": 0.2107,
      "step": 1770
    },
    {
      "epoch": 2.1904322411936623,
      "grad_norm": 0.7421875,
      "learning_rate": 9.65068141800864e-05,
      "loss": 0.2396,
      "step": 1780
    },
    {
      "epoch": 2.202738040301492,
      "grad_norm": 0.61328125,
      "learning_rate": 9.645782474855705e-05,
      "loss": 0.1951,
      "step": 1790
    },
    {
      "epoch": 2.2150438394093217,
      "grad_norm": 0.52734375,
      "learning_rate": 9.64085067950506e-05,
      "loss": 0.2243,
      "step": 1800
    },
    {
      "epoch": 2.2273496385171514,
      "grad_norm": 0.66015625,
      "learning_rate": 9.63588606683142e-05,
      "loss": 0.2259,
      "step": 1810
    },
    {
      "epoch": 2.2396554376249806,
      "grad_norm": 0.62109375,
      "learning_rate": 9.630888671941553e-05,
      "loss": 0.2332,
      "step": 1820
    },
    {
      "epoch": 2.2519612367328103,
      "grad_norm": 0.62890625,
      "learning_rate": 9.625858530174052e-05,
      "loss": 0.237,
      "step": 1830
    },
    {
      "epoch": 2.26426703584064,
      "grad_norm": 1.0390625,
      "learning_rate": 9.620795677099077e-05,
      "loss": 0.2345,
      "step": 1840
    },
    {
      "epoch": 2.2765728349484693,
      "grad_norm": 0.65625,
      "learning_rate": 9.615700148518096e-05,
      "loss": 0.1999,
      "step": 1850
    },
    {
      "epoch": 2.288878634056299,
      "grad_norm": 0.6171875,
      "learning_rate": 9.610571980463644e-05,
      "loss": 0.2194,
      "step": 1860
    },
    {
      "epoch": 2.3011844331641287,
      "grad_norm": 0.765625,
      "learning_rate": 9.605411209199061e-05,
      "loss": 0.2282,
      "step": 1870
    },
    {
      "epoch": 2.313490232271958,
      "grad_norm": 0.6796875,
      "learning_rate": 9.600217871218238e-05,
      "loss": 0.2029,
      "step": 1880
    },
    {
      "epoch": 2.3257960313797876,
      "grad_norm": 0.8203125,
      "learning_rate": 9.594992003245358e-05,
      "loss": 0.2203,
      "step": 1890
    },
    {
      "epoch": 2.3381018304876173,
      "grad_norm": 0.79296875,
      "learning_rate": 9.589733642234637e-05,
      "loss": 0.2164,
      "step": 1900
    },
    {
      "epoch": 2.350407629595447,
      "grad_norm": 0.76953125,
      "learning_rate": 9.584442825370061e-05,
      "loss": 0.2296,
      "step": 1910
    },
    {
      "epoch": 2.3627134287032763,
      "grad_norm": 0.62109375,
      "learning_rate": 9.579119590065127e-05,
      "loss": 0.211,
      "step": 1920
    },
    {
      "epoch": 2.375019227811106,
      "grad_norm": 0.46875,
      "learning_rate": 9.573763973962572e-05,
      "loss": 0.2171,
      "step": 1930
    },
    {
      "epoch": 2.3873250269189357,
      "grad_norm": 0.66015625,
      "learning_rate": 9.568376014934115e-05,
      "loss": 0.2034,
      "step": 1940
    },
    {
      "epoch": 2.3996308260267654,
      "grad_norm": 0.6328125,
      "learning_rate": 9.562955751080182e-05,
      "loss": 0.2076,
      "step": 1950
    },
    {
      "epoch": 2.4119366251345946,
      "grad_norm": 0.87109375,
      "learning_rate": 9.557503220729642e-05,
      "loss": 0.2058,
      "step": 1960
    },
    {
      "epoch": 2.4242424242424243,
      "grad_norm": 0.609375,
      "learning_rate": 9.552018462439529e-05,
      "loss": 0.2184,
      "step": 1970
    },
    {
      "epoch": 2.436548223350254,
      "grad_norm": 0.7890625,
      "learning_rate": 9.546501514994779e-05,
      "loss": 0.2188,
      "step": 1980
    },
    {
      "epoch": 2.4488540224580833,
      "grad_norm": 0.79296875,
      "learning_rate": 9.540952417407945e-05,
      "loss": 0.2183,
      "step": 1990
    },
    {
      "epoch": 2.461159821565913,
      "grad_norm": 0.75390625,
      "learning_rate": 9.535371208918931e-05,
      "loss": 0.2534,
      "step": 2000
    },
    {
      "epoch": 2.4734656206737426,
      "grad_norm": 0.6640625,
      "learning_rate": 9.529757928994709e-05,
      "loss": 0.2351,
      "step": 2010
    },
    {
      "epoch": 2.485771419781572,
      "grad_norm": 0.7421875,
      "learning_rate": 9.52411261732904e-05,
      "loss": 0.2187,
      "step": 2020
    },
    {
      "epoch": 2.4980772188894016,
      "grad_norm": 0.9296875,
      "learning_rate": 9.518435313842194e-05,
      "loss": 0.2454,
      "step": 2030
    },
    {
      "epoch": 2.5103830179972313,
      "grad_norm": 2.328125,
      "learning_rate": 9.51272605868067e-05,
      "loss": 0.2536,
      "step": 2040
    },
    {
      "epoch": 2.5226888171050605,
      "grad_norm": 0.57421875,
      "learning_rate": 9.506984892216909e-05,
      "loss": 0.2135,
      "step": 2050
    },
    {
      "epoch": 2.5349946162128902,
      "grad_norm": 0.62109375,
      "learning_rate": 9.501211855049011e-05,
      "loss": 0.2163,
      "step": 2060
    },
    {
      "epoch": 2.54730041532072,
      "grad_norm": 0.92578125,
      "learning_rate": 9.495406988000441e-05,
      "loss": 0.204,
      "step": 2070
    },
    {
      "epoch": 2.559606214428549,
      "grad_norm": 0.796875,
      "learning_rate": 9.489570332119757e-05,
      "loss": 0.2252,
      "step": 2080
    },
    {
      "epoch": 2.571912013536379,
      "grad_norm": 0.8984375,
      "learning_rate": 9.483701928680295e-05,
      "loss": 0.2207,
      "step": 2090
    },
    {
      "epoch": 2.5842178126442086,
      "grad_norm": 0.9375,
      "learning_rate": 9.477801819179903e-05,
      "loss": 0.2383,
      "step": 2100
    },
    {
      "epoch": 2.5965236117520383,
      "grad_norm": 0.54296875,
      "learning_rate": 9.471870045340627e-05,
      "loss": 0.2162,
      "step": 2110
    },
    {
      "epoch": 2.608829410859868,
      "grad_norm": 0.734375,
      "learning_rate": 9.465906649108427e-05,
      "loss": 0.2287,
      "step": 2120
    },
    {
      "epoch": 2.621135209967697,
      "grad_norm": 0.84765625,
      "learning_rate": 9.459911672652879e-05,
      "loss": 0.2454,
      "step": 2130
    },
    {
      "epoch": 2.633441009075527,
      "grad_norm": 0.62109375,
      "learning_rate": 9.453885158366876e-05,
      "loss": 0.2016,
      "step": 2140
    },
    {
      "epoch": 2.6457468081833566,
      "grad_norm": 0.69140625,
      "learning_rate": 9.447827148866321e-05,
      "loss": 0.232,
      "step": 2150
    },
    {
      "epoch": 2.658052607291186,
      "grad_norm": 0.54296875,
      "learning_rate": 9.441737686989843e-05,
      "loss": 0.237,
      "step": 2160
    },
    {
      "epoch": 2.6703584063990156,
      "grad_norm": 0.63671875,
      "learning_rate": 9.435616815798475e-05,
      "loss": 0.2187,
      "step": 2170
    },
    {
      "epoch": 2.6826642055068453,
      "grad_norm": 0.71875,
      "learning_rate": 9.429464578575361e-05,
      "loss": 0.2069,
      "step": 2180
    },
    {
      "epoch": 2.6949700046146745,
      "grad_norm": 0.8125,
      "learning_rate": 9.423281018825447e-05,
      "loss": 0.2417,
      "step": 2190
    },
    {
      "epoch": 2.707275803722504,
      "grad_norm": 0.51953125,
      "learning_rate": 9.417066180275172e-05,
      "loss": 0.2289,
      "step": 2200
    },
    {
      "epoch": 2.719581602830334,
      "grad_norm": 0.7734375,
      "learning_rate": 9.410820106872162e-05,
      "loss": 0.2605,
      "step": 2210
    },
    {
      "epoch": 2.731887401938163,
      "grad_norm": 0.859375,
      "learning_rate": 9.404542842784913e-05,
      "loss": 0.2328,
      "step": 2220
    },
    {
      "epoch": 2.744193201045993,
      "grad_norm": 0.62109375,
      "learning_rate": 9.398234432402491e-05,
      "loss": 0.2486,
      "step": 2230
    },
    {
      "epoch": 2.7564990001538225,
      "grad_norm": 0.609375,
      "learning_rate": 9.3918949203342e-05,
      "loss": 0.2269,
      "step": 2240
    },
    {
      "epoch": 2.768804799261652,
      "grad_norm": 0.56640625,
      "learning_rate": 9.385524351409283e-05,
      "loss": 0.2354,
      "step": 2250
    },
    {
      "epoch": 2.7811105983694815,
      "grad_norm": 0.8125,
      "learning_rate": 9.379122770676598e-05,
      "loss": 0.2144,
      "step": 2260
    },
    {
      "epoch": 2.793416397477311,
      "grad_norm": 0.578125,
      "learning_rate": 9.372690223404297e-05,
      "loss": 0.2239,
      "step": 2270
    },
    {
      "epoch": 2.805722196585141,
      "grad_norm": 0.75390625,
      "learning_rate": 9.366226755079513e-05,
      "loss": 0.2383,
      "step": 2280
    },
    {
      "epoch": 2.8180279956929706,
      "grad_norm": 0.6171875,
      "learning_rate": 9.359732411408029e-05,
      "loss": 0.2306,
      "step": 2290
    },
    {
      "epoch": 2.8303337948008,
      "grad_norm": 0.7109375,
      "learning_rate": 9.353207238313964e-05,
      "loss": 0.2089,
      "step": 2300
    },
    {
      "epoch": 2.8426395939086295,
      "grad_norm": 0.859375,
      "learning_rate": 9.346651281939444e-05,
      "loss": 0.225,
      "step": 2310
    },
    {
      "epoch": 2.854945393016459,
      "grad_norm": 0.8046875,
      "learning_rate": 9.340064588644277e-05,
      "loss": 0.2381,
      "step": 2320
    },
    {
      "epoch": 2.8672511921242885,
      "grad_norm": 0.81640625,
      "learning_rate": 9.333447205005619e-05,
      "loss": 0.191,
      "step": 2330
    },
    {
      "epoch": 2.879556991232118,
      "grad_norm": 1.265625,
      "learning_rate": 9.326799177817654e-05,
      "loss": 0.2434,
      "step": 2340
    },
    {
      "epoch": 2.891862790339948,
      "grad_norm": 0.78515625,
      "learning_rate": 9.320120554091256e-05,
      "loss": 0.2307,
      "step": 2350
    },
    {
      "epoch": 2.904168589447777,
      "grad_norm": 0.83203125,
      "learning_rate": 9.313411381053664e-05,
      "loss": 0.2139,
      "step": 2360
    },
    {
      "epoch": 2.916474388555607,
      "grad_norm": 0.64453125,
      "learning_rate": 9.306671706148142e-05,
      "loss": 0.2611,
      "step": 2370
    },
    {
      "epoch": 2.9287801876634365,
      "grad_norm": 0.62109375,
      "learning_rate": 9.299901577033643e-05,
      "loss": 0.2331,
      "step": 2380
    },
    {
      "epoch": 2.9410859867712658,
      "grad_norm": 0.6640625,
      "learning_rate": 9.293101041584472e-05,
      "loss": 0.2481,
      "step": 2390
    },
    {
      "epoch": 2.9533917858790955,
      "grad_norm": 0.94921875,
      "learning_rate": 9.286270147889955e-05,
      "loss": 0.2188,
      "step": 2400
    },
    {
      "epoch": 2.965697584986925,
      "grad_norm": 0.8515625,
      "learning_rate": 9.27940894425409e-05,
      "loss": 0.2319,
      "step": 2410
    },
    {
      "epoch": 2.9780033840947544,
      "grad_norm": 1.0625,
      "learning_rate": 9.272517479195209e-05,
      "loss": 0.2104,
      "step": 2420
    },
    {
      "epoch": 2.990309183202584,
      "grad_norm": 0.80859375,
      "learning_rate": 9.265595801445634e-05,
      "loss": 0.2132,
      "step": 2430
    },
    {
      "epoch": 3.002614982310414,
      "grad_norm": 0.45703125,
      "learning_rate": 9.258643959951339e-05,
      "loss": 0.1975,
      "step": 2440
    },
    {
      "epoch": 3.0149207814182435,
      "grad_norm": 0.78125,
      "learning_rate": 9.251662003871587e-05,
      "loss": 0.163,
      "step": 2450
    },
    {
      "epoch": 3.0272265805260727,
      "grad_norm": 0.56640625,
      "learning_rate": 9.244649982578601e-05,
      "loss": 0.1649,
      "step": 2460
    },
    {
      "epoch": 3.0395323796339024,
      "grad_norm": 0.482421875,
      "learning_rate": 9.23760794565721e-05,
      "loss": 0.172,
      "step": 2470
    },
    {
      "epoch": 3.051838178741732,
      "grad_norm": 0.73046875,
      "learning_rate": 9.230535942904485e-05,
      "loss": 0.174,
      "step": 2480
    },
    {
      "epoch": 3.064143977849562,
      "grad_norm": 0.52734375,
      "learning_rate": 9.22343402432941e-05,
      "loss": 0.169,
      "step": 2490
    },
    {
      "epoch": 3.076449776957391,
      "grad_norm": 0.53515625,
      "learning_rate": 9.216302240152506e-05,
      "loss": 0.1754,
      "step": 2500
    },
    {
      "epoch": 3.0887555760652208,
      "grad_norm": 0.59375,
      "learning_rate": 9.20914064080549e-05,
      "loss": 0.1672,
      "step": 2510
    },
    {
      "epoch": 3.1010613751730505,
      "grad_norm": 0.5546875,
      "learning_rate": 9.201949276930912e-05,
      "loss": 0.1794,
      "step": 2520
    },
    {
      "epoch": 3.1133671742808797,
      "grad_norm": 0.41015625,
      "learning_rate": 9.194728199381802e-05,
      "loss": 0.1673,
      "step": 2530
    },
    {
      "epoch": 3.1256729733887094,
      "grad_norm": 0.73828125,
      "learning_rate": 9.187477459221307e-05,
      "loss": 0.1679,
      "step": 2540
    },
    {
      "epoch": 3.137978772496539,
      "grad_norm": 0.75,
      "learning_rate": 9.180197107722326e-05,
      "loss": 0.1851,
      "step": 2550
    },
    {
      "epoch": 3.1502845716043684,
      "grad_norm": 1.203125,
      "learning_rate": 9.172887196367156e-05,
      "loss": 0.1812,
      "step": 2560
    },
    {
      "epoch": 3.162590370712198,
      "grad_norm": 0.7578125,
      "learning_rate": 9.165547776847122e-05,
      "loss": 0.1607,
      "step": 2570
    },
    {
      "epoch": 3.1748961698200278,
      "grad_norm": 0.7109375,
      "learning_rate": 9.158178901062214e-05,
      "loss": 0.1735,
      "step": 2580
    },
    {
      "epoch": 3.1872019689278575,
      "grad_norm": 0.68359375,
      "learning_rate": 9.150780621120719e-05,
      "loss": 0.1984,
      "step": 2590
    },
    {
      "epoch": 3.1995077680356867,
      "grad_norm": 0.53515625,
      "learning_rate": 9.14335298933885e-05,
      "loss": 0.1566,
      "step": 2600
    },
    {
      "epoch": 3.2118135671435164,
      "grad_norm": 0.625,
      "learning_rate": 9.135896058240382e-05,
      "loss": 0.1793,
      "step": 2610
    },
    {
      "epoch": 3.224119366251346,
      "grad_norm": 0.58984375,
      "learning_rate": 9.128409880556277e-05,
      "loss": 0.1442,
      "step": 2620
    },
    {
      "epoch": 3.2364251653591753,
      "grad_norm": 0.45703125,
      "learning_rate": 9.12089450922431e-05,
      "loss": 0.1684,
      "step": 2630
    },
    {
      "epoch": 3.248730964467005,
      "grad_norm": 0.7578125,
      "learning_rate": 9.113349997388694e-05,
      "loss": 0.1813,
      "step": 2640
    },
    {
      "epoch": 3.2610367635748347,
      "grad_norm": 0.66796875,
      "learning_rate": 9.105776398399712e-05,
      "loss": 0.1733,
      "step": 2650
    },
    {
      "epoch": 3.2733425626826644,
      "grad_norm": 0.6875,
      "learning_rate": 9.09817376581333e-05,
      "loss": 0.1759,
      "step": 2660
    },
    {
      "epoch": 3.2856483617904937,
      "grad_norm": 1.0546875,
      "learning_rate": 9.09054215339082e-05,
      "loss": 0.1659,
      "step": 2670
    },
    {
      "epoch": 3.2979541608983234,
      "grad_norm": 0.6328125,
      "learning_rate": 9.082881615098389e-05,
      "loss": 0.1634,
      "step": 2680
    },
    {
      "epoch": 3.310259960006153,
      "grad_norm": 0.72265625,
      "learning_rate": 9.075192205106783e-05,
      "loss": 0.1822,
      "step": 2690
    },
    {
      "epoch": 3.3225657591139823,
      "grad_norm": 0.53515625,
      "learning_rate": 9.067473977790918e-05,
      "loss": 0.1622,
      "step": 2700
    },
    {
      "epoch": 3.334871558221812,
      "grad_norm": 0.50390625,
      "learning_rate": 9.059726987729487e-05,
      "loss": 0.173,
      "step": 2710
    },
    {
      "epoch": 3.3471773573296417,
      "grad_norm": 0.75,
      "learning_rate": 9.051951289704568e-05,
      "loss": 0.1713,
      "step": 2720
    },
    {
      "epoch": 3.359483156437471,
      "grad_norm": 1.03125,
      "learning_rate": 9.044146938701257e-05,
      "loss": 0.1997,
      "step": 2730
    },
    {
      "epoch": 3.3717889555453007,
      "grad_norm": 0.75390625,
      "learning_rate": 9.03631398990726e-05,
      "loss": 0.1747,
      "step": 2740
    },
    {
      "epoch": 3.3840947546531304,
      "grad_norm": 0.93359375,
      "learning_rate": 9.028452498712508e-05,
      "loss": 0.1583,
      "step": 2750
    },
    {
      "epoch": 3.3964005537609596,
      "grad_norm": 0.625,
      "learning_rate": 9.020562520708773e-05,
      "loss": 0.1565,
      "step": 2760
    },
    {
      "epoch": 3.4087063528687893,
      "grad_norm": 0.61328125,
      "learning_rate": 9.012644111689262e-05,
      "loss": 0.1816,
      "step": 2770
    },
    {
      "epoch": 3.421012151976619,
      "grad_norm": 0.84765625,
      "learning_rate": 9.004697327648234e-05,
      "loss": 0.1579,
      "step": 2780
    },
    {
      "epoch": 3.4333179510844487,
      "grad_norm": 0.60546875,
      "learning_rate": 8.996722224780598e-05,
      "loss": 0.1788,
      "step": 2790
    },
    {
      "epoch": 3.445623750192278,
      "grad_norm": 0.83984375,
      "learning_rate": 8.988718859481513e-05,
      "loss": 0.1732,
      "step": 2800
    },
    {
      "epoch": 3.4579295493001077,
      "grad_norm": 0.6875,
      "learning_rate": 8.980687288346e-05,
      "loss": 0.2024,
      "step": 2810
    },
    {
      "epoch": 3.4702353484079373,
      "grad_norm": 0.5625,
      "learning_rate": 8.972627568168527e-05,
      "loss": 0.1726,
      "step": 2820
    },
    {
      "epoch": 3.482541147515767,
      "grad_norm": 0.65234375,
      "learning_rate": 8.964539755942623e-05,
      "loss": 0.1913,
      "step": 2830
    },
    {
      "epoch": 3.4948469466235963,
      "grad_norm": 0.71875,
      "learning_rate": 8.956423908860461e-05,
      "loss": 0.1928,
      "step": 2840
    },
    {
      "epoch": 3.507152745731426,
      "grad_norm": 0.73828125,
      "learning_rate": 8.948280084312464e-05,
      "loss": 0.1762,
      "step": 2850
    },
    {
      "epoch": 3.5194585448392557,
      "grad_norm": 0.8046875,
      "learning_rate": 8.940108339886891e-05,
      "loss": 0.1686,
      "step": 2860
    },
    {
      "epoch": 3.531764343947085,
      "grad_norm": 1.6640625,
      "learning_rate": 8.931908733369438e-05,
      "loss": 0.1497,
      "step": 2870
    },
    {
      "epoch": 3.5440701430549146,
      "grad_norm": 0.69921875,
      "learning_rate": 8.923681322742821e-05,
      "loss": 0.1842,
      "step": 2880
    },
    {
      "epoch": 3.5563759421627443,
      "grad_norm": 0.671875,
      "learning_rate": 8.915426166186373e-05,
      "loss": 0.1696,
      "step": 2890
    },
    {
      "epoch": 3.5686817412705736,
      "grad_norm": 1.796875,
      "learning_rate": 8.907143322075628e-05,
      "loss": 0.1732,
      "step": 2900
    },
    {
      "epoch": 3.5809875403784033,
      "grad_norm": 1.0625,
      "learning_rate": 8.898832848981912e-05,
      "loss": 0.1914,
      "step": 2910
    },
    {
      "epoch": 3.593293339486233,
      "grad_norm": 0.7109375,
      "learning_rate": 8.890494805671923e-05,
      "loss": 0.1947,
      "step": 2920
    },
    {
      "epoch": 3.6055991385940622,
      "grad_norm": 0.6875,
      "learning_rate": 8.882129251107322e-05,
      "loss": 0.1838,
      "step": 2930
    },
    {
      "epoch": 3.617904937701892,
      "grad_norm": 0.8828125,
      "learning_rate": 8.873736244444311e-05,
      "loss": 0.1772,
      "step": 2940
    },
    {
      "epoch": 3.6302107368097216,
      "grad_norm": 0.51171875,
      "learning_rate": 8.86531584503322e-05,
      "loss": 0.1687,
      "step": 2950
    },
    {
      "epoch": 3.6425165359175513,
      "grad_norm": 0.6796875,
      "learning_rate": 8.85686811241808e-05,
      "loss": 0.1768,
      "step": 2960
    },
    {
      "epoch": 3.6548223350253806,
      "grad_norm": 0.68359375,
      "learning_rate": 8.848393106336212e-05,
      "loss": 0.1679,
      "step": 2970
    },
    {
      "epoch": 3.6671281341332103,
      "grad_norm": 0.57421875,
      "learning_rate": 8.839890886717792e-05,
      "loss": 0.1541,
      "step": 2980
    },
    {
      "epoch": 3.67943393324104,
      "grad_norm": 0.79296875,
      "learning_rate": 8.831361513685437e-05,
      "loss": 0.1981,
      "step": 2990
    },
    {
      "epoch": 3.6917397323488697,
      "grad_norm": 0.58203125,
      "learning_rate": 8.822805047553777e-05,
      "loss": 0.1993,
      "step": 3000
    },
    {
      "epoch": 3.704045531456699,
      "grad_norm": 0.5703125,
      "learning_rate": 8.81422154882903e-05,
      "loss": 0.1686,
      "step": 3010
    },
    {
      "epoch": 3.7163513305645286,
      "grad_norm": 0.5703125,
      "learning_rate": 8.805611078208567e-05,
      "loss": 0.1544,
      "step": 3020
    },
    {
      "epoch": 3.7286571296723583,
      "grad_norm": 0.71484375,
      "learning_rate": 8.796973696580492e-05,
      "loss": 0.1922,
      "step": 3030
    },
    {
      "epoch": 3.7409629287801875,
      "grad_norm": 0.474609375,
      "learning_rate": 8.788309465023208e-05,
      "loss": 0.1934,
      "step": 3040
    },
    {
      "epoch": 3.7532687278880172,
      "grad_norm": 0.51171875,
      "learning_rate": 8.779618444804982e-05,
      "loss": 0.1909,
      "step": 3050
    },
    {
      "epoch": 3.765574526995847,
      "grad_norm": 0.6875,
      "learning_rate": 8.770900697383519e-05,
      "loss": 0.1713,
      "step": 3060
    },
    {
      "epoch": 3.777880326103676,
      "grad_norm": 0.8359375,
      "learning_rate": 8.762156284405516e-05,
      "loss": 0.167,
      "step": 3070
    },
    {
      "epoch": 3.790186125211506,
      "grad_norm": 0.6015625,
      "learning_rate": 8.753385267706238e-05,
      "loss": 0.1913,
      "step": 3080
    },
    {
      "epoch": 3.8024919243193356,
      "grad_norm": 0.7734375,
      "learning_rate": 8.744587709309076e-05,
      "loss": 0.2058,
      "step": 3090
    },
    {
      "epoch": 3.814797723427165,
      "grad_norm": 0.76953125,
      "learning_rate": 8.735763671425104e-05,
      "loss": 0.1863,
      "step": 3100
    },
    {
      "epoch": 3.8271035225349945,
      "grad_norm": 1.2265625,
      "learning_rate": 8.726913216452646e-05,
      "loss": 0.1831,
      "step": 3110
    },
    {
      "epoch": 3.8394093216428242,
      "grad_norm": 0.75390625,
      "learning_rate": 8.71803640697683e-05,
      "loss": 0.1681,
      "step": 3120
    },
    {
      "epoch": 3.8517151207506535,
      "grad_norm": 0.890625,
      "learning_rate": 8.70913330576915e-05,
      "loss": 0.1784,
      "step": 3130
    },
    {
      "epoch": 3.864020919858483,
      "grad_norm": 1.0546875,
      "learning_rate": 8.700203975787019e-05,
      "loss": 0.1846,
      "step": 3140
    },
    {
      "epoch": 3.876326718966313,
      "grad_norm": 0.7109375,
      "learning_rate": 8.691248480173322e-05,
      "loss": 0.1637,
      "step": 3150
    },
    {
      "epoch": 3.8886325180741426,
      "grad_norm": 0.6328125,
      "learning_rate": 8.682266882255972e-05,
      "loss": 0.1631,
      "step": 3160
    },
    {
      "epoch": 3.9009383171819723,
      "grad_norm": 0.66796875,
      "learning_rate": 8.673259245547462e-05,
      "loss": 0.1877,
      "step": 3170
    },
    {
      "epoch": 3.9132441162898015,
      "grad_norm": 0.578125,
      "learning_rate": 8.66422563374442e-05,
      "loss": 0.1722,
      "step": 3180
    },
    {
      "epoch": 3.925549915397631,
      "grad_norm": 0.76953125,
      "learning_rate": 8.655166110727148e-05,
      "loss": 0.1798,
      "step": 3190
    },
    {
      "epoch": 3.937855714505461,
      "grad_norm": 0.76953125,
      "learning_rate": 8.646080740559183e-05,
      "loss": 0.1796,
      "step": 3200
    },
    {
      "epoch": 3.95016151361329,
      "grad_norm": 0.70703125,
      "learning_rate": 8.63696958748683e-05,
      "loss": 0.1712,
      "step": 3210
    },
    {
      "epoch": 3.96246731272112,
      "grad_norm": 0.7265625,
      "learning_rate": 8.62783271593872e-05,
      "loss": 0.1548,
      "step": 3220
    },
    {
      "epoch": 3.9747731118289495,
      "grad_norm": 0.8984375,
      "learning_rate": 8.618670190525352e-05,
      "loss": 0.1655,
      "step": 3230
    },
    {
      "epoch": 3.987078910936779,
      "grad_norm": 1.0859375,
      "learning_rate": 8.609482076038627e-05,
      "loss": 0.1788,
      "step": 3240
    },
    {
      "epoch": 3.9993847100446085,
      "grad_norm": 0.62890625,
      "learning_rate": 8.600268437451404e-05,
      "loss": 0.1887,
      "step": 3250
    },
    {
      "epoch": 4.011690509152438,
      "grad_norm": 0.6640625,
      "learning_rate": 8.591029339917028e-05,
      "loss": 0.1369,
      "step": 3260
    },
    {
      "epoch": 4.023996308260267,
      "grad_norm": 0.490234375,
      "learning_rate": 8.581764848768877e-05,
      "loss": 0.1168,
      "step": 3270
    },
    {
      "epoch": 4.036302107368098,
      "grad_norm": 0.46484375,
      "learning_rate": 8.572475029519896e-05,
      "loss": 0.1359,
      "step": 3280
    },
    {
      "epoch": 4.048607906475927,
      "grad_norm": 0.396484375,
      "learning_rate": 8.563159947862136e-05,
      "loss": 0.1315,
      "step": 3290
    },
    {
      "epoch": 4.060913705583756,
      "grad_norm": 0.50390625,
      "learning_rate": 8.55381966966629e-05,
      "loss": 0.1281,
      "step": 3300
    },
    {
      "epoch": 4.073219504691586,
      "grad_norm": 0.59375,
      "learning_rate": 8.54445426098122e-05,
      "loss": 0.121,
      "step": 3310
    },
    {
      "epoch": 4.0855253037994155,
      "grad_norm": 0.4921875,
      "learning_rate": 8.535063788033506e-05,
      "loss": 0.1374,
      "step": 3320
    },
    {
      "epoch": 4.097831102907245,
      "grad_norm": 0.59375,
      "learning_rate": 8.525648317226958e-05,
      "loss": 0.1316,
      "step": 3330
    },
    {
      "epoch": 4.110136902015075,
      "grad_norm": 0.65234375,
      "learning_rate": 8.51620791514216e-05,
      "loss": 0.1342,
      "step": 3340
    },
    {
      "epoch": 4.122442701122904,
      "grad_norm": 0.498046875,
      "learning_rate": 8.506742648535997e-05,
      "loss": 0.124,
      "step": 3350
    },
    {
      "epoch": 4.134748500230733,
      "grad_norm": 0.6640625,
      "learning_rate": 8.497252584341175e-05,
      "loss": 0.1099,
      "step": 3360
    },
    {
      "epoch": 4.1470542993385635,
      "grad_norm": 0.53125,
      "learning_rate": 8.487737789665759e-05,
      "loss": 0.1395,
      "step": 3370
    },
    {
      "epoch": 4.159360098446393,
      "grad_norm": 0.59375,
      "learning_rate": 8.478198331792695e-05,
      "loss": 0.1339,
      "step": 3380
    },
    {
      "epoch": 4.171665897554222,
      "grad_norm": 0.79296875,
      "learning_rate": 8.468634278179323e-05,
      "loss": 0.142,
      "step": 3390
    },
    {
      "epoch": 4.183971696662052,
      "grad_norm": 0.474609375,
      "learning_rate": 8.459045696456921e-05,
      "loss": 0.1153,
      "step": 3400
    },
    {
      "epoch": 4.196277495769881,
      "grad_norm": 0.6484375,
      "learning_rate": 8.449432654430206e-05,
      "loss": 0.1359,
      "step": 3410
    },
    {
      "epoch": 4.2085832948777115,
      "grad_norm": 0.609375,
      "learning_rate": 8.439795220076867e-05,
      "loss": 0.1281,
      "step": 3420
    },
    {
      "epoch": 4.220889093985541,
      "grad_norm": 0.56640625,
      "learning_rate": 8.430133461547085e-05,
      "loss": 0.1305,
      "step": 3430
    },
    {
      "epoch": 4.23319489309337,
      "grad_norm": 0.67578125,
      "learning_rate": 8.42044744716304e-05,
      "loss": 0.1363,
      "step": 3440
    },
    {
      "epoch": 4.2455006922012,
      "grad_norm": 0.470703125,
      "learning_rate": 8.410737245418437e-05,
      "loss": 0.1314,
      "step": 3450
    },
    {
      "epoch": 4.257806491309029,
      "grad_norm": 0.75390625,
      "learning_rate": 8.401002924978025e-05,
      "loss": 0.1331,
      "step": 3460
    },
    {
      "epoch": 4.270112290416859,
      "grad_norm": 0.55859375,
      "learning_rate": 8.391244554677098e-05,
      "loss": 0.1336,
      "step": 3470
    },
    {
      "epoch": 4.282418089524689,
      "grad_norm": 0.6953125,
      "learning_rate": 8.38146220352102e-05,
      "loss": 0.1266,
      "step": 3480
    },
    {
      "epoch": 4.294723888632518,
      "grad_norm": 0.55078125,
      "learning_rate": 8.371655940684737e-05,
      "loss": 0.1254,
      "step": 3490
    },
    {
      "epoch": 4.307029687740347,
      "grad_norm": 0.69140625,
      "learning_rate": 8.361825835512276e-05,
      "loss": 0.1398,
      "step": 3500
    },
    {
      "epoch": 4.3193354868481775,
      "grad_norm": 0.52734375,
      "learning_rate": 8.351971957516269e-05,
      "loss": 0.1311,
      "step": 3510
    },
    {
      "epoch": 4.331641285956007,
      "grad_norm": 0.83984375,
      "learning_rate": 8.342094376377453e-05,
      "loss": 0.1377,
      "step": 3520
    },
    {
      "epoch": 4.343947085063836,
      "grad_norm": 0.48828125,
      "learning_rate": 8.33219316194418e-05,
      "loss": 0.1401,
      "step": 3530
    },
    {
      "epoch": 4.356252884171666,
      "grad_norm": 0.458984375,
      "learning_rate": 8.322268384231922e-05,
      "loss": 0.1311,
      "step": 3540
    },
    {
      "epoch": 4.368558683279495,
      "grad_norm": 0.65625,
      "learning_rate": 8.312320113422776e-05,
      "loss": 0.142,
      "step": 3550
    },
    {
      "epoch": 4.380864482387325,
      "grad_norm": 0.482421875,
      "learning_rate": 8.302348419864972e-05,
      "loss": 0.1218,
      "step": 3560
    },
    {
      "epoch": 4.393170281495155,
      "grad_norm": 0.53125,
      "learning_rate": 8.292353374072363e-05,
      "loss": 0.1337,
      "step": 3570
    },
    {
      "epoch": 4.405476080602984,
      "grad_norm": 0.72265625,
      "learning_rate": 8.282335046723946e-05,
      "loss": 0.127,
      "step": 3580
    },
    {
      "epoch": 4.417781879710814,
      "grad_norm": 0.56640625,
      "learning_rate": 8.272293508663343e-05,
      "loss": 0.1336,
      "step": 3590
    },
    {
      "epoch": 4.430087678818643,
      "grad_norm": 0.609375,
      "learning_rate": 8.262228830898313e-05,
      "loss": 0.1195,
      "step": 3600
    },
    {
      "epoch": 4.442393477926473,
      "grad_norm": 0.5390625,
      "learning_rate": 8.25214108460024e-05,
      "loss": 0.1289,
      "step": 3610
    },
    {
      "epoch": 4.454699277034303,
      "grad_norm": 0.59375,
      "learning_rate": 8.242030341103642e-05,
      "loss": 0.1351,
      "step": 3620
    },
    {
      "epoch": 4.467005076142132,
      "grad_norm": 0.921875,
      "learning_rate": 8.231896671905652e-05,
      "loss": 0.1471,
      "step": 3630
    },
    {
      "epoch": 4.479310875249961,
      "grad_norm": 0.6328125,
      "learning_rate": 8.221740148665527e-05,
      "loss": 0.1366,
      "step": 3640
    },
    {
      "epoch": 4.491616674357791,
      "grad_norm": 0.97265625,
      "learning_rate": 8.211560843204129e-05,
      "loss": 0.1346,
      "step": 3650
    },
    {
      "epoch": 4.503922473465621,
      "grad_norm": 0.61328125,
      "learning_rate": 8.201358827503422e-05,
      "loss": 0.146,
      "step": 3660
    },
    {
      "epoch": 4.51622827257345,
      "grad_norm": 0.83984375,
      "learning_rate": 8.19113417370597e-05,
      "loss": 0.1494,
      "step": 3670
    },
    {
      "epoch": 4.52853407168128,
      "grad_norm": 0.6484375,
      "learning_rate": 8.18088695411441e-05,
      "loss": 0.1449,
      "step": 3680
    },
    {
      "epoch": 4.540839870789109,
      "grad_norm": 0.66015625,
      "learning_rate": 8.170617241190959e-05,
      "loss": 0.176,
      "step": 3690
    },
    {
      "epoch": 4.553145669896939,
      "grad_norm": 0.67578125,
      "learning_rate": 8.160325107556889e-05,
      "loss": 0.1324,
      "step": 3700
    },
    {
      "epoch": 4.565451469004769,
      "grad_norm": 0.515625,
      "learning_rate": 8.150010625992019e-05,
      "loss": 0.1335,
      "step": 3710
    },
    {
      "epoch": 4.577757268112598,
      "grad_norm": 0.625,
      "learning_rate": 8.139673869434201e-05,
      "loss": 0.1343,
      "step": 3720
    },
    {
      "epoch": 4.590063067220427,
      "grad_norm": 0.515625,
      "learning_rate": 8.129314910978803e-05,
      "loss": 0.1491,
      "step": 3730
    },
    {
      "epoch": 4.602368866328257,
      "grad_norm": 0.54296875,
      "learning_rate": 8.118933823878183e-05,
      "loss": 0.1286,
      "step": 3740
    },
    {
      "epoch": 4.614674665436087,
      "grad_norm": 0.62109375,
      "learning_rate": 8.108530681541192e-05,
      "loss": 0.1181,
      "step": 3750
    },
    {
      "epoch": 4.626980464543916,
      "grad_norm": 0.8203125,
      "learning_rate": 8.098105557532634e-05,
      "loss": 0.1412,
      "step": 3760
    },
    {
      "epoch": 4.639286263651746,
      "grad_norm": 0.546875,
      "learning_rate": 8.087658525572756e-05,
      "loss": 0.1466,
      "step": 3770
    },
    {
      "epoch": 4.651592062759575,
      "grad_norm": 0.578125,
      "learning_rate": 8.077189659536729e-05,
      "loss": 0.1185,
      "step": 3780
    },
    {
      "epoch": 4.6638978618674045,
      "grad_norm": 0.83203125,
      "learning_rate": 8.066699033454114e-05,
      "loss": 0.1556,
      "step": 3790
    },
    {
      "epoch": 4.676203660975235,
      "grad_norm": 0.625,
      "learning_rate": 8.056186721508355e-05,
      "loss": 0.1424,
      "step": 3800
    },
    {
      "epoch": 4.688509460083064,
      "grad_norm": 0.421875,
      "learning_rate": 8.045652798036236e-05,
      "loss": 0.166,
      "step": 3810
    },
    {
      "epoch": 4.700815259190894,
      "grad_norm": 0.53515625,
      "learning_rate": 8.035097337527374e-05,
      "loss": 0.1373,
      "step": 3820
    },
    {
      "epoch": 4.713121058298723,
      "grad_norm": 0.6484375,
      "learning_rate": 8.024520414623673e-05,
      "loss": 0.1401,
      "step": 3830
    },
    {
      "epoch": 4.7254268574065525,
      "grad_norm": 0.58984375,
      "learning_rate": 8.013922104118816e-05,
      "loss": 0.1328,
      "step": 3840
    },
    {
      "epoch": 4.737732656514383,
      "grad_norm": 0.66015625,
      "learning_rate": 8.003302480957724e-05,
      "loss": 0.144,
      "step": 3850
    },
    {
      "epoch": 4.750038455622212,
      "grad_norm": 0.75,
      "learning_rate": 7.992661620236022e-05,
      "loss": 0.1372,
      "step": 3860
    },
    {
      "epoch": 4.762344254730041,
      "grad_norm": 0.71484375,
      "learning_rate": 7.981999597199519e-05,
      "loss": 0.141,
      "step": 3870
    },
    {
      "epoch": 4.774650053837871,
      "grad_norm": 0.6015625,
      "learning_rate": 7.971316487243675e-05,
      "loss": 0.1436,
      "step": 3880
    },
    {
      "epoch": 4.786955852945701,
      "grad_norm": 0.67578125,
      "learning_rate": 7.960612365913058e-05,
      "loss": 0.1237,
      "step": 3890
    },
    {
      "epoch": 4.799261652053531,
      "grad_norm": 0.62109375,
      "learning_rate": 7.949887308900817e-05,
      "loss": 0.1296,
      "step": 3900
    },
    {
      "epoch": 4.81156745116136,
      "grad_norm": 0.8203125,
      "learning_rate": 7.93914139204815e-05,
      "loss": 0.1434,
      "step": 3910
    },
    {
      "epoch": 4.823873250269189,
      "grad_norm": 0.8671875,
      "learning_rate": 7.928374691343756e-05,
      "loss": 0.1484,
      "step": 3920
    },
    {
      "epoch": 4.836179049377019,
      "grad_norm": 0.8984375,
      "learning_rate": 7.917587282923311e-05,
      "loss": 0.1328,
      "step": 3930
    },
    {
      "epoch": 4.848484848484849,
      "grad_norm": 0.486328125,
      "learning_rate": 7.906779243068923e-05,
      "loss": 0.1349,
      "step": 3940
    },
    {
      "epoch": 4.860790647592678,
      "grad_norm": 0.83203125,
      "learning_rate": 7.89595064820859e-05,
      "loss": 0.1355,
      "step": 3950
    },
    {
      "epoch": 4.873096446700508,
      "grad_norm": 0.5859375,
      "learning_rate": 7.885101574915665e-05,
      "loss": 0.1419,
      "step": 3960
    },
    {
      "epoch": 4.885402245808337,
      "grad_norm": 0.59375,
      "learning_rate": 7.874232099908311e-05,
      "loss": 0.1409,
      "step": 3970
    },
    {
      "epoch": 4.8977080449161665,
      "grad_norm": 0.97265625,
      "learning_rate": 7.863342300048962e-05,
      "loss": 0.1577,
      "step": 3980
    },
    {
      "epoch": 4.910013844023997,
      "grad_norm": 0.83203125,
      "learning_rate": 7.852432252343775e-05,
      "loss": 0.1304,
      "step": 3990
    },
    {
      "epoch": 4.922319643131826,
      "grad_norm": 0.5625,
      "learning_rate": 7.84150203394209e-05,
      "loss": 0.1446,
      "step": 4000
    },
    {
      "epoch": 4.934625442239655,
      "grad_norm": 0.62109375,
      "learning_rate": 7.830551722135878e-05,
      "loss": 0.1319,
      "step": 4010
    },
    {
      "epoch": 4.946931241347485,
      "grad_norm": 0.5234375,
      "learning_rate": 7.8195813943592e-05,
      "loss": 0.1321,
      "step": 4020
    },
    {
      "epoch": 4.9592370404553145,
      "grad_norm": 0.5546875,
      "learning_rate": 7.808591128187663e-05,
      "loss": 0.1244,
      "step": 4030
    },
    {
      "epoch": 4.971542839563144,
      "grad_norm": 0.8671875,
      "learning_rate": 7.79758100133786e-05,
      "loss": 0.1359,
      "step": 4040
    },
    {
      "epoch": 4.983848638670974,
      "grad_norm": 1.1875,
      "learning_rate": 7.78655109166683e-05,
      "loss": 0.1465,
      "step": 4050
    },
    {
      "epoch": 4.996154437778803,
      "grad_norm": 0.99609375,
      "learning_rate": 7.775501477171502e-05,
      "loss": 0.1356,
      "step": 4060
    },
    {
      "epoch": 5.008460236886632,
      "grad_norm": 0.515625,
      "learning_rate": 7.76443223598815e-05,
      "loss": 0.0961,
      "step": 4070
    },
    {
      "epoch": 5.020766035994463,
      "grad_norm": 0.48046875,
      "learning_rate": 7.753343446391832e-05,
      "loss": 0.1107,
      "step": 4080
    },
    {
      "epoch": 5.033071835102292,
      "grad_norm": 0.60546875,
      "learning_rate": 7.742235186795841e-05,
      "loss": 0.1198,
      "step": 4090
    },
    {
      "epoch": 5.045377634210121,
      "grad_norm": 0.5078125,
      "learning_rate": 7.731107535751156e-05,
      "loss": 0.1022,
      "step": 4100
    },
    {
      "epoch": 5.057683433317951,
      "grad_norm": 0.83203125,
      "learning_rate": 7.719960571945871e-05,
      "loss": 0.1022,
      "step": 4110
    },
    {
      "epoch": 5.0699892324257805,
      "grad_norm": 0.53125,
      "learning_rate": 7.708794374204655e-05,
      "loss": 0.1157,
      "step": 4120
    },
    {
      "epoch": 5.082295031533611,
      "grad_norm": 0.3984375,
      "learning_rate": 7.697609021488187e-05,
      "loss": 0.1127,
      "step": 4130
    },
    {
      "epoch": 5.09460083064144,
      "grad_norm": 0.416015625,
      "learning_rate": 7.6864045928926e-05,
      "loss": 0.085,
      "step": 4140
    },
    {
      "epoch": 5.106906629749269,
      "grad_norm": 0.451171875,
      "learning_rate": 7.675181167648915e-05,
      "loss": 0.0989,
      "step": 4150
    },
    {
      "epoch": 5.119212428857099,
      "grad_norm": 0.84375,
      "learning_rate": 7.66393882512249e-05,
      "loss": 0.1094,
      "step": 4160
    },
    {
      "epoch": 5.1315182279649285,
      "grad_norm": 0.42578125,
      "learning_rate": 7.652677644812454e-05,
      "loss": 0.1009,
      "step": 4170
    },
    {
      "epoch": 5.143824027072758,
      "grad_norm": 0.69140625,
      "learning_rate": 7.641397706351144e-05,
      "loss": 0.107,
      "step": 4180
    },
    {
      "epoch": 5.156129826180588,
      "grad_norm": 0.5703125,
      "learning_rate": 7.630099089503546e-05,
      "loss": 0.1135,
      "step": 4190
    },
    {
      "epoch": 5.168435625288417,
      "grad_norm": 0.466796875,
      "learning_rate": 7.61878187416673e-05,
      "loss": 0.099,
      "step": 4200
    },
    {
      "epoch": 5.180741424396246,
      "grad_norm": 0.484375,
      "learning_rate": 7.607446140369275e-05,
      "loss": 0.1109,
      "step": 4210
    },
    {
      "epoch": 5.1930472235040765,
      "grad_norm": 0.8359375,
      "learning_rate": 7.596091968270723e-05,
      "loss": 0.1008,
      "step": 4220
    },
    {
      "epoch": 5.205353022611906,
      "grad_norm": 0.5625,
      "learning_rate": 7.584719438160988e-05,
      "loss": 0.0925,
      "step": 4230
    },
    {
      "epoch": 5.217658821719735,
      "grad_norm": 0.54296875,
      "learning_rate": 7.573328630459813e-05,
      "loss": 0.0867,
      "step": 4240
    },
    {
      "epoch": 5.229964620827565,
      "grad_norm": 0.7578125,
      "learning_rate": 7.56191962571618e-05,
      "loss": 0.1158,
      "step": 4250
    },
    {
      "epoch": 5.242270419935394,
      "grad_norm": 0.59375,
      "learning_rate": 7.55049250460776e-05,
      "loss": 0.1109,
      "step": 4260
    },
    {
      "epoch": 5.254576219043225,
      "grad_norm": 0.5703125,
      "learning_rate": 7.539047347940318e-05,
      "loss": 0.0988,
      "step": 4270
    },
    {
      "epoch": 5.266882018151054,
      "grad_norm": 0.6484375,
      "learning_rate": 7.527584236647165e-05,
      "loss": 0.0975,
      "step": 4280
    },
    {
      "epoch": 5.279187817258883,
      "grad_norm": 0.6640625,
      "learning_rate": 7.516103251788577e-05,
      "loss": 0.0997,
      "step": 4290
    },
    {
      "epoch": 5.291493616366713,
      "grad_norm": 0.451171875,
      "learning_rate": 7.504604474551217e-05,
      "loss": 0.0974,
      "step": 4300
    },
    {
      "epoch": 5.3037994154745425,
      "grad_norm": 0.53125,
      "learning_rate": 7.49308798624757e-05,
      "loss": 0.1067,
      "step": 4310
    },
    {
      "epoch": 5.316105214582372,
      "grad_norm": 0.357421875,
      "learning_rate": 7.481553868315357e-05,
      "loss": 0.0874,
      "step": 4320
    },
    {
      "epoch": 5.328411013690202,
      "grad_norm": 0.486328125,
      "learning_rate": 7.470002202316966e-05,
      "loss": 0.1114,
      "step": 4330
    },
    {
      "epoch": 5.340716812798031,
      "grad_norm": 0.484375,
      "learning_rate": 7.45843306993888e-05,
      "loss": 0.1028,
      "step": 4340
    },
    {
      "epoch": 5.35302261190586,
      "grad_norm": 0.478515625,
      "learning_rate": 7.446846552991092e-05,
      "loss": 0.1003,
      "step": 4350
    },
    {
      "epoch": 5.3653284110136905,
      "grad_norm": 0.57421875,
      "learning_rate": 7.435242733406521e-05,
      "loss": 0.1007,
      "step": 4360
    },
    {
      "epoch": 5.37763421012152,
      "grad_norm": 0.60546875,
      "learning_rate": 7.423621693240449e-05,
      "loss": 0.0966,
      "step": 4370
    },
    {
      "epoch": 5.389940009229349,
      "grad_norm": 0.6328125,
      "learning_rate": 7.411983514669929e-05,
      "loss": 0.1034,
      "step": 4380
    },
    {
      "epoch": 5.402245808337179,
      "grad_norm": 0.4921875,
      "learning_rate": 7.400328279993205e-05,
      "loss": 0.0929,
      "step": 4390
    },
    {
      "epoch": 5.414551607445008,
      "grad_norm": 0.5390625,
      "learning_rate": 7.388656071629131e-05,
      "loss": 0.1041,
      "step": 4400
    },
    {
      "epoch": 5.426857406552838,
      "grad_norm": 0.546875,
      "learning_rate": 7.376966972116593e-05,
      "loss": 0.1157,
      "step": 4410
    },
    {
      "epoch": 5.439163205660668,
      "grad_norm": 0.6640625,
      "learning_rate": 7.365261064113915e-05,
      "loss": 0.1186,
      "step": 4420
    },
    {
      "epoch": 5.451469004768497,
      "grad_norm": 0.5234375,
      "learning_rate": 7.353538430398286e-05,
      "loss": 0.0939,
      "step": 4430
    },
    {
      "epoch": 5.463774803876326,
      "grad_norm": 0.59765625,
      "learning_rate": 7.341799153865167e-05,
      "loss": 0.107,
      "step": 4440
    },
    {
      "epoch": 5.476080602984156,
      "grad_norm": 0.353515625,
      "learning_rate": 7.330043317527707e-05,
      "loss": 0.089,
      "step": 4450
    },
    {
      "epoch": 5.488386402091986,
      "grad_norm": 0.55859375,
      "learning_rate": 7.318271004516155e-05,
      "loss": 0.1005,
      "step": 4460
    },
    {
      "epoch": 5.500692201199815,
      "grad_norm": 0.76171875,
      "learning_rate": 7.306482298077275e-05,
      "loss": 0.1096,
      "step": 4470
    },
    {
      "epoch": 5.512998000307645,
      "grad_norm": 0.484375,
      "learning_rate": 7.294677281573757e-05,
      "loss": 0.1082,
      "step": 4480
    },
    {
      "epoch": 5.525303799415474,
      "grad_norm": 0.65625,
      "learning_rate": 7.282856038483619e-05,
      "loss": 0.1043,
      "step": 4490
    },
    {
      "epoch": 5.5376095985233045,
      "grad_norm": 0.62890625,
      "learning_rate": 7.271018652399635e-05,
      "loss": 0.0937,
      "step": 4500
    },
    {
      "epoch": 5.549915397631134,
      "grad_norm": 0.6171875,
      "learning_rate": 7.259165207028722e-05,
      "loss": 0.106,
      "step": 4510
    },
    {
      "epoch": 5.562221196738963,
      "grad_norm": 0.59765625,
      "learning_rate": 7.247295786191365e-05,
      "loss": 0.1031,
      "step": 4520
    },
    {
      "epoch": 5.574526995846793,
      "grad_norm": 0.4609375,
      "learning_rate": 7.235410473821014e-05,
      "loss": 0.1109,
      "step": 4530
    },
    {
      "epoch": 5.586832794954622,
      "grad_norm": 0.85546875,
      "learning_rate": 7.223509353963498e-05,
      "loss": 0.1183,
      "step": 4540
    },
    {
      "epoch": 5.599138594062452,
      "grad_norm": 0.546875,
      "learning_rate": 7.211592510776426e-05,
      "loss": 0.1091,
      "step": 4550
    },
    {
      "epoch": 5.611444393170282,
      "grad_norm": 0.63671875,
      "learning_rate": 7.19966002852859e-05,
      "loss": 0.1029,
      "step": 4560
    },
    {
      "epoch": 5.623750192278111,
      "grad_norm": 0.53125,
      "learning_rate": 7.187711991599376e-05,
      "loss": 0.1097,
      "step": 4570
    },
    {
      "epoch": 5.63605599138594,
      "grad_norm": 0.54296875,
      "learning_rate": 7.175748484478162e-05,
      "loss": 0.1028,
      "step": 4580
    },
    {
      "epoch": 5.64836179049377,
      "grad_norm": 0.4765625,
      "learning_rate": 7.163769591763723e-05,
      "loss": 0.1155,
      "step": 4590
    },
    {
      "epoch": 5.6606675896016,
      "grad_norm": 0.5703125,
      "learning_rate": 7.151775398163628e-05,
      "loss": 0.1135,
      "step": 4600
    },
    {
      "epoch": 5.67297338870943,
      "grad_norm": 0.58203125,
      "learning_rate": 7.13976598849365e-05,
      "loss": 0.1208,
      "step": 4610
    },
    {
      "epoch": 5.685279187817259,
      "grad_norm": 0.60546875,
      "learning_rate": 7.127741447677156e-05,
      "loss": 0.1018,
      "step": 4620
    },
    {
      "epoch": 5.697584986925088,
      "grad_norm": 0.62890625,
      "learning_rate": 7.115701860744514e-05,
      "loss": 0.1043,
      "step": 4630
    },
    {
      "epoch": 5.709890786032918,
      "grad_norm": 0.6015625,
      "learning_rate": 7.103647312832493e-05,
      "loss": 0.1176,
      "step": 4640
    },
    {
      "epoch": 5.722196585140748,
      "grad_norm": 0.6015625,
      "learning_rate": 7.091577889183647e-05,
      "loss": 0.098,
      "step": 4650
    },
    {
      "epoch": 5.734502384248577,
      "grad_norm": 0.490234375,
      "learning_rate": 7.079493675145733e-05,
      "loss": 0.1072,
      "step": 4660
    },
    {
      "epoch": 5.746808183356407,
      "grad_norm": 0.6328125,
      "learning_rate": 7.067394756171089e-05,
      "loss": 0.1163,
      "step": 4670
    },
    {
      "epoch": 5.759113982464236,
      "grad_norm": 0.478515625,
      "learning_rate": 7.055281217816042e-05,
      "loss": 0.1199,
      "step": 4680
    },
    {
      "epoch": 5.771419781572066,
      "grad_norm": 0.51171875,
      "learning_rate": 7.043153145740295e-05,
      "loss": 0.093,
      "step": 4690
    },
    {
      "epoch": 5.783725580679896,
      "grad_norm": 0.458984375,
      "learning_rate": 7.03101062570633e-05,
      "loss": 0.1024,
      "step": 4700
    },
    {
      "epoch": 5.796031379787725,
      "grad_norm": 0.671875,
      "learning_rate": 7.018853743578793e-05,
      "loss": 0.1017,
      "step": 4710
    },
    {
      "epoch": 5.808337178895554,
      "grad_norm": 0.6171875,
      "learning_rate": 7.006682585323889e-05,
      "loss": 0.0941,
      "step": 4720
    },
    {
      "epoch": 5.820642978003384,
      "grad_norm": 0.71484375,
      "learning_rate": 6.994497237008778e-05,
      "loss": 0.0848,
      "step": 4730
    },
    {
      "epoch": 5.832948777111214,
      "grad_norm": 0.56640625,
      "learning_rate": 6.982297784800959e-05,
      "loss": 0.1146,
      "step": 4740
    },
    {
      "epoch": 5.845254576219043,
      "grad_norm": 0.50390625,
      "learning_rate": 6.970084314967673e-05,
      "loss": 0.0907,
      "step": 4750
    },
    {
      "epoch": 5.857560375326873,
      "grad_norm": 0.5390625,
      "learning_rate": 6.957856913875279e-05,
      "loss": 0.1126,
      "step": 4760
    },
    {
      "epoch": 5.869866174434702,
      "grad_norm": 0.447265625,
      "learning_rate": 6.945615667988649e-05,
      "loss": 0.1094,
      "step": 4770
    },
    {
      "epoch": 5.8821719735425315,
      "grad_norm": 0.62109375,
      "learning_rate": 6.933360663870564e-05,
      "loss": 0.1085,
      "step": 4780
    },
    {
      "epoch": 5.894477772650362,
      "grad_norm": 0.7109375,
      "learning_rate": 6.921091988181088e-05,
      "loss": 0.1233,
      "step": 4790
    },
    {
      "epoch": 5.906783571758191,
      "grad_norm": 0.65234375,
      "learning_rate": 6.908809727676966e-05,
      "loss": 0.1438,
      "step": 4800
    },
    {
      "epoch": 5.91908937086602,
      "grad_norm": 0.6171875,
      "learning_rate": 6.896513969211003e-05,
      "loss": 0.119,
      "step": 4810
    },
    {
      "epoch": 5.93139516997385,
      "grad_norm": 0.6171875,
      "learning_rate": 6.884204799731457e-05,
      "loss": 0.1014,
      "step": 4820
    },
    {
      "epoch": 5.9437009690816796,
      "grad_norm": 0.84375,
      "learning_rate": 6.871882306281418e-05,
      "loss": 0.107,
      "step": 4830
    },
    {
      "epoch": 5.95600676818951,
      "grad_norm": 0.6953125,
      "learning_rate": 6.859546575998203e-05,
      "loss": 0.1061,
      "step": 4840
    },
    {
      "epoch": 5.968312567297339,
      "grad_norm": 0.5390625,
      "learning_rate": 6.847197696112717e-05,
      "loss": 0.0979,
      "step": 4850
    },
    {
      "epoch": 5.980618366405168,
      "grad_norm": 0.58203125,
      "learning_rate": 6.834835753948867e-05,
      "loss": 0.0993,
      "step": 4860
    },
    {
      "epoch": 5.992924165512998,
      "grad_norm": 0.69140625,
      "learning_rate": 6.822460836922917e-05,
      "loss": 0.1062,
      "step": 4870
    },
    {
      "epoch": 6.005229964620828,
      "grad_norm": 0.5859375,
      "learning_rate": 6.810073032542888e-05,
      "loss": 0.0967,
      "step": 4880
    },
    {
      "epoch": 6.017535763728657,
      "grad_norm": 0.57421875,
      "learning_rate": 6.79767242840793e-05,
      "loss": 0.0659,
      "step": 4890
    },
    {
      "epoch": 6.029841562836487,
      "grad_norm": 0.4140625,
      "learning_rate": 6.785259112207704e-05,
      "loss": 0.0928,
      "step": 4900
    },
    {
      "epoch": 6.042147361944316,
      "grad_norm": 0.5390625,
      "learning_rate": 6.77283317172177e-05,
      "loss": 0.0906,
      "step": 4910
    },
    {
      "epoch": 6.0544531610521455,
      "grad_norm": 0.42578125,
      "learning_rate": 6.76039469481895e-05,
      "loss": 0.0781,
      "step": 4920
    },
    {
      "epoch": 6.066758960159976,
      "grad_norm": 0.484375,
      "learning_rate": 6.747943769456719e-05,
      "loss": 0.0782,
      "step": 4930
    },
    {
      "epoch": 6.079064759267805,
      "grad_norm": 0.5859375,
      "learning_rate": 6.735480483680588e-05,
      "loss": 0.096,
      "step": 4940
    },
    {
      "epoch": 6.091370558375634,
      "grad_norm": 0.359375,
      "learning_rate": 6.723004925623461e-05,
      "loss": 0.0767,
      "step": 4950
    },
    {
      "epoch": 6.103676357483464,
      "grad_norm": 0.6875,
      "learning_rate": 6.710517183505031e-05,
      "loss": 0.0786,
      "step": 4960
    },
    {
      "epoch": 6.1159821565912935,
      "grad_norm": 0.64453125,
      "learning_rate": 6.698017345631153e-05,
      "loss": 0.0785,
      "step": 4970
    },
    {
      "epoch": 6.128287955699124,
      "grad_norm": 0.431640625,
      "learning_rate": 6.685505500393204e-05,
      "loss": 0.0842,
      "step": 4980
    },
    {
      "epoch": 6.140593754806953,
      "grad_norm": 0.5546875,
      "learning_rate": 6.672981736267485e-05,
      "loss": 0.0878,
      "step": 4990
    },
    {
      "epoch": 6.152899553914782,
      "grad_norm": 0.7734375,
      "learning_rate": 6.660446141814568e-05,
      "loss": 0.0771,
      "step": 5000
    },
    {
      "epoch": 6.152899553914782,
      "eval_loss": NaN,
      "eval_runtime": 434.412,
      "eval_samples_per_second": 119.707,
      "eval_steps_per_second": 14.965,
      "step": 5000
    },
    {
      "epoch": 6.165205353022612,
      "grad_norm": 0.53125,
      "learning_rate": 6.647898805678687e-05,
      "loss": 0.0812,
      "step": 5010
    },
    {
      "epoch": 6.1775111521304416,
      "grad_norm": 0.462890625,
      "learning_rate": 6.635339816587109e-05,
      "loss": 0.0876,
      "step": 5020
    },
    {
      "epoch": 6.189816951238271,
      "grad_norm": 0.546875,
      "learning_rate": 6.622769263349497e-05,
      "loss": 0.0747,
      "step": 5030
    },
    {
      "epoch": 6.202122750346101,
      "grad_norm": 0.474609375,
      "learning_rate": 6.610187234857294e-05,
      "loss": 0.0712,
      "step": 5040
    },
    {
      "epoch": 6.21442854945393,
      "grad_norm": 0.447265625,
      "learning_rate": 6.597593820083087e-05,
      "loss": 0.0809,
      "step": 5050
    },
    {
      "epoch": 6.2267343485617594,
      "grad_norm": 0.62890625,
      "learning_rate": 6.584989108079982e-05,
      "loss": 0.0999,
      "step": 5060
    },
    {
      "epoch": 6.23904014766959,
      "grad_norm": 0.71875,
      "learning_rate": 6.57237318798097e-05,
      "loss": 0.0976,
      "step": 5070
    },
    {
      "epoch": 6.251345946777419,
      "grad_norm": 0.53515625,
      "learning_rate": 6.559746148998296e-05,
      "loss": 0.09,
      "step": 5080
    },
    {
      "epoch": 6.263651745885248,
      "grad_norm": 0.609375,
      "learning_rate": 6.547108080422839e-05,
      "loss": 0.0755,
      "step": 5090
    },
    {
      "epoch": 6.275957544993078,
      "grad_norm": 0.51171875,
      "learning_rate": 6.534459071623468e-05,
      "loss": 0.0923,
      "step": 5100
    },
    {
      "epoch": 6.2882633441009075,
      "grad_norm": 0.6171875,
      "learning_rate": 6.521799212046415e-05,
      "loss": 0.0706,
      "step": 5110
    },
    {
      "epoch": 6.300569143208737,
      "grad_norm": 0.421875,
      "learning_rate": 6.50912859121464e-05,
      "loss": 0.0903,
      "step": 5120
    },
    {
      "epoch": 6.312874942316567,
      "grad_norm": 0.6015625,
      "learning_rate": 6.496447298727207e-05,
      "loss": 0.0853,
      "step": 5130
    },
    {
      "epoch": 6.325180741424396,
      "grad_norm": 0.52734375,
      "learning_rate": 6.483755424258633e-05,
      "loss": 0.0863,
      "step": 5140
    },
    {
      "epoch": 6.337486540532225,
      "grad_norm": 0.5234375,
      "learning_rate": 6.471053057558276e-05,
      "loss": 0.0912,
      "step": 5150
    },
    {
      "epoch": 6.3497923396400555,
      "grad_norm": 0.46484375,
      "learning_rate": 6.458340288449683e-05,
      "loss": 0.0825,
      "step": 5160
    },
    {
      "epoch": 6.362098138747885,
      "grad_norm": 0.5234375,
      "learning_rate": 6.445617206829957e-05,
      "loss": 0.0762,
      "step": 5170
    },
    {
      "epoch": 6.374403937855715,
      "grad_norm": 0.443359375,
      "learning_rate": 6.432883902669133e-05,
      "loss": 0.0739,
      "step": 5180
    },
    {
      "epoch": 6.386709736963544,
      "grad_norm": 0.77734375,
      "learning_rate": 6.420140466009527e-05,
      "loss": 0.0855,
      "step": 5190
    },
    {
      "epoch": 6.399015536071373,
      "grad_norm": 0.482421875,
      "learning_rate": 6.407386986965109e-05,
      "loss": 0.0752,
      "step": 5200
    },
    {
      "epoch": 6.4113213351792036,
      "grad_norm": 0.79296875,
      "learning_rate": 6.394623555720863e-05,
      "loss": 0.1023,
      "step": 5210
    },
    {
      "epoch": 6.423627134287033,
      "grad_norm": 0.72265625,
      "learning_rate": 6.38185026253215e-05,
      "loss": 0.0752,
      "step": 5220
    },
    {
      "epoch": 6.435932933394862,
      "grad_norm": 0.4609375,
      "learning_rate": 6.369067197724064e-05,
      "loss": 0.0866,
      "step": 5230
    },
    {
      "epoch": 6.448238732502692,
      "grad_norm": 0.703125,
      "learning_rate": 6.356274451690803e-05,
      "loss": 0.0876,
      "step": 5240
    },
    {
      "epoch": 6.4605445316105214,
      "grad_norm": 0.515625,
      "learning_rate": 6.343472114895021e-05,
      "loss": 0.0791,
      "step": 5250
    },
    {
      "epoch": 6.472850330718351,
      "grad_norm": 0.462890625,
      "learning_rate": 6.330660277867198e-05,
      "loss": 0.0796,
      "step": 5260
    },
    {
      "epoch": 6.485156129826181,
      "grad_norm": 1.296875,
      "learning_rate": 6.317839031204986e-05,
      "loss": 0.0823,
      "step": 5270
    },
    {
      "epoch": 6.49746192893401,
      "grad_norm": 0.62890625,
      "learning_rate": 6.305008465572583e-05,
      "loss": 0.0789,
      "step": 5280
    },
    {
      "epoch": 6.509767728041839,
      "grad_norm": 0.65234375,
      "learning_rate": 6.292168671700081e-05,
      "loss": 0.0862,
      "step": 5290
    },
    {
      "epoch": 6.5220735271496695,
      "grad_norm": 0.5390625,
      "learning_rate": 6.279319740382832e-05,
      "loss": 0.0822,
      "step": 5300
    },
    {
      "epoch": 6.534379326257499,
      "grad_norm": 0.7734375,
      "learning_rate": 6.2664617624808e-05,
      "loss": 0.0909,
      "step": 5310
    },
    {
      "epoch": 6.546685125365329,
      "grad_norm": 0.44921875,
      "learning_rate": 6.253594828917922e-05,
      "loss": 0.0762,
      "step": 5320
    },
    {
      "epoch": 6.558990924473158,
      "grad_norm": 0.53515625,
      "learning_rate": 6.240719030681462e-05,
      "loss": 0.0877,
      "step": 5330
    },
    {
      "epoch": 6.571296723580987,
      "grad_norm": 0.5390625,
      "learning_rate": 6.227834458821372e-05,
      "loss": 0.0865,
      "step": 5340
    },
    {
      "epoch": 6.5836025226888175,
      "grad_norm": 0.57421875,
      "learning_rate": 6.21494120444965e-05,
      "loss": 0.083,
      "step": 5350
    },
    {
      "epoch": 6.595908321796647,
      "grad_norm": 0.640625,
      "learning_rate": 6.202039358739681e-05,
      "loss": 0.0731,
      "step": 5360
    },
    {
      "epoch": 6.608214120904476,
      "grad_norm": 0.49609375,
      "learning_rate": 6.189129012925612e-05,
      "loss": 0.0821,
      "step": 5370
    },
    {
      "epoch": 6.620519920012306,
      "grad_norm": 0.609375,
      "learning_rate": 6.176210258301692e-05,
      "loss": 0.0835,
      "step": 5380
    },
    {
      "epoch": 6.632825719120135,
      "grad_norm": 0.5078125,
      "learning_rate": 6.163283186221638e-05,
      "loss": 0.0761,
      "step": 5390
    },
    {
      "epoch": 6.645131518227965,
      "grad_norm": 0.46484375,
      "learning_rate": 6.150347888097976e-05,
      "loss": 0.0826,
      "step": 5400
    },
    {
      "epoch": 6.657437317335795,
      "grad_norm": 0.5625,
      "learning_rate": 6.137404455401407e-05,
      "loss": 0.0911,
      "step": 5410
    },
    {
      "epoch": 6.669743116443624,
      "grad_norm": 0.50390625,
      "learning_rate": 6.124452979660154e-05,
      "loss": 0.0898,
      "step": 5420
    },
    {
      "epoch": 6.682048915551453,
      "grad_norm": 0.78125,
      "learning_rate": 6.111493552459312e-05,
      "loss": 0.0915,
      "step": 5430
    },
    {
      "epoch": 6.6943547146592834,
      "grad_norm": 0.470703125,
      "learning_rate": 6.098526265440207e-05,
      "loss": 0.1013,
      "step": 5440
    },
    {
      "epoch": 6.706660513767113,
      "grad_norm": 0.6015625,
      "learning_rate": 6.085551210299748e-05,
      "loss": 0.089,
      "step": 5450
    },
    {
      "epoch": 6.718966312874942,
      "grad_norm": 0.498046875,
      "learning_rate": 6.07256847878977e-05,
      "loss": 0.0808,
      "step": 5460
    },
    {
      "epoch": 6.731272111982772,
      "grad_norm": 0.75,
      "learning_rate": 6.0595781627163904e-05,
      "loss": 0.0889,
      "step": 5470
    },
    {
      "epoch": 6.743577911090601,
      "grad_norm": 0.46875,
      "learning_rate": 6.046580353939365e-05,
      "loss": 0.0905,
      "step": 5480
    },
    {
      "epoch": 6.755883710198431,
      "grad_norm": 0.341796875,
      "learning_rate": 6.033575144371432e-05,
      "loss": 0.0746,
      "step": 5490
    },
    {
      "epoch": 6.768189509306261,
      "grad_norm": 0.5078125,
      "learning_rate": 6.020562625977659e-05,
      "loss": 0.0904,
      "step": 5500
    },
    {
      "epoch": 6.78049530841409,
      "grad_norm": 0.490234375,
      "learning_rate": 6.007542890774805e-05,
      "loss": 0.0866,
      "step": 5510
    },
    {
      "epoch": 6.792801107521919,
      "grad_norm": 0.72265625,
      "learning_rate": 5.994516030830655e-05,
      "loss": 0.0789,
      "step": 5520
    },
    {
      "epoch": 6.805106906629749,
      "grad_norm": 0.4609375,
      "learning_rate": 5.981482138263381e-05,
      "loss": 0.0843,
      "step": 5530
    },
    {
      "epoch": 6.817412705737579,
      "grad_norm": 0.75,
      "learning_rate": 5.9684413052408784e-05,
      "loss": 0.0925,
      "step": 5540
    },
    {
      "epoch": 6.829718504845409,
      "grad_norm": 0.53515625,
      "learning_rate": 5.955393623980132e-05,
      "loss": 0.0645,
      "step": 5550
    },
    {
      "epoch": 6.842024303953238,
      "grad_norm": 0.54296875,
      "learning_rate": 5.942339186746544e-05,
      "loss": 0.0802,
      "step": 5560
    },
    {
      "epoch": 6.854330103061067,
      "grad_norm": 0.515625,
      "learning_rate": 5.929278085853296e-05,
      "loss": 0.0868,
      "step": 5570
    },
    {
      "epoch": 6.866635902168897,
      "grad_norm": 0.65234375,
      "learning_rate": 5.916210413660686e-05,
      "loss": 0.0742,
      "step": 5580
    },
    {
      "epoch": 6.878941701276727,
      "grad_norm": 0.62109375,
      "learning_rate": 5.903136262575488e-05,
      "loss": 0.1057,
      "step": 5590
    },
    {
      "epoch": 6.891247500384556,
      "grad_norm": 0.47265625,
      "learning_rate": 5.890055725050283e-05,
      "loss": 0.081,
      "step": 5600
    },
    {
      "epoch": 6.903553299492386,
      "grad_norm": 0.65234375,
      "learning_rate": 5.8769688935828185e-05,
      "loss": 0.0882,
      "step": 5610
    },
    {
      "epoch": 6.915859098600215,
      "grad_norm": 0.486328125,
      "learning_rate": 5.8638758607153464e-05,
      "loss": 0.0889,
      "step": 5620
    },
    {
      "epoch": 6.928164897708045,
      "grad_norm": 0.470703125,
      "learning_rate": 5.85077671903397e-05,
      "loss": 0.0891,
      "step": 5630
    },
    {
      "epoch": 6.940470696815875,
      "grad_norm": 0.984375,
      "learning_rate": 5.837671561167996e-05,
      "loss": 0.0668,
      "step": 5640
    },
    {
      "epoch": 6.952776495923704,
      "grad_norm": 0.69140625,
      "learning_rate": 5.8245604797892664e-05,
      "loss": 0.0954,
      "step": 5650
    },
    {
      "epoch": 6.965082295031534,
      "grad_norm": 0.60546875,
      "learning_rate": 5.8114435676115166e-05,
      "loss": 0.086,
      "step": 5660
    },
    {
      "epoch": 6.977388094139363,
      "grad_norm": 0.58203125,
      "learning_rate": 5.798320917389711e-05,
      "loss": 0.0839,
      "step": 5670
    },
    {
      "epoch": 6.989693893247193,
      "grad_norm": 0.54296875,
      "learning_rate": 5.785192621919392e-05,
      "loss": 0.0889,
      "step": 5680
    },
    {
      "epoch": 7.001999692355023,
      "grad_norm": 0.51171875,
      "learning_rate": 5.77205877403602e-05,
      "loss": 0.085,
      "step": 5690
    },
    {
      "epoch": 7.014305491462852,
      "grad_norm": 0.43359375,
      "learning_rate": 5.7589194666143184e-05,
      "loss": 0.0622,
      "step": 5700
    },
    {
      "epoch": 7.026611290570681,
      "grad_norm": 0.431640625,
      "learning_rate": 5.745774792567622e-05,
      "loss": 0.069,
      "step": 5710
    },
    {
      "epoch": 7.038917089678511,
      "grad_norm": 0.72265625,
      "learning_rate": 5.732624844847206e-05,
      "loss": 0.0698,
      "step": 5720
    },
    {
      "epoch": 7.051222888786341,
      "grad_norm": 0.578125,
      "learning_rate": 5.719469716441649e-05,
      "loss": 0.0616,
      "step": 5730
    },
    {
      "epoch": 7.06352868789417,
      "grad_norm": 0.74609375,
      "learning_rate": 5.706309500376152e-05,
      "loss": 0.0712,
      "step": 5740
    },
    {
      "epoch": 7.075834487002,
      "grad_norm": 0.56640625,
      "learning_rate": 5.693144289711907e-05,
      "loss": 0.0575,
      "step": 5750
    },
    {
      "epoch": 7.088140286109829,
      "grad_norm": 0.58984375,
      "learning_rate": 5.6799741775454126e-05,
      "loss": 0.0699,
      "step": 5760
    },
    {
      "epoch": 7.1004460852176585,
      "grad_norm": 0.515625,
      "learning_rate": 5.6667992570078346e-05,
      "loss": 0.0831,
      "step": 5770
    },
    {
      "epoch": 7.112751884325489,
      "grad_norm": 0.4609375,
      "learning_rate": 5.653619621264336e-05,
      "loss": 0.0736,
      "step": 5780
    },
    {
      "epoch": 7.125057683433318,
      "grad_norm": 0.439453125,
      "learning_rate": 5.6404353635134275e-05,
      "loss": 0.07,
      "step": 5790
    },
    {
      "epoch": 7.137363482541147,
      "grad_norm": 0.85546875,
      "learning_rate": 5.6272465769863026e-05,
      "loss": 0.0655,
      "step": 5800
    },
    {
      "epoch": 7.149669281648977,
      "grad_norm": 0.50390625,
      "learning_rate": 5.614053354946177e-05,
      "loss": 0.0712,
      "step": 5810
    },
    {
      "epoch": 7.1619750807568066,
      "grad_norm": 0.470703125,
      "learning_rate": 5.600855790687638e-05,
      "loss": 0.0696,
      "step": 5820
    },
    {
      "epoch": 7.174280879864636,
      "grad_norm": 0.3046875,
      "learning_rate": 5.5876539775359695e-05,
      "loss": 0.0683,
      "step": 5830
    },
    {
      "epoch": 7.186586678972466,
      "grad_norm": 0.66015625,
      "learning_rate": 5.5744480088465076e-05,
      "loss": 0.0794,
      "step": 5840
    },
    {
      "epoch": 7.198892478080295,
      "grad_norm": 0.353515625,
      "learning_rate": 5.561237978003973e-05,
      "loss": 0.0547,
      "step": 5850
    },
    {
      "epoch": 7.2111982771881245,
      "grad_norm": 0.462890625,
      "learning_rate": 5.548023978421809e-05,
      "loss": 0.0751,
      "step": 5860
    },
    {
      "epoch": 7.223504076295955,
      "grad_norm": 0.6640625,
      "learning_rate": 5.5348061035415253e-05,
      "loss": 0.0708,
      "step": 5870
    },
    {
      "epoch": 7.235809875403784,
      "grad_norm": 0.6171875,
      "learning_rate": 5.521584446832036e-05,
      "loss": 0.0766,
      "step": 5880
    },
    {
      "epoch": 7.248115674511614,
      "grad_norm": 0.419921875,
      "learning_rate": 5.508359101788996e-05,
      "loss": 0.066,
      "step": 5890
    },
    {
      "epoch": 7.260421473619443,
      "grad_norm": 0.51171875,
      "learning_rate": 5.495130161934143e-05,
      "loss": 0.072,
      "step": 5900
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 0.83203125,
      "learning_rate": 5.481897720814637e-05,
      "loss": 0.0712,
      "step": 5910
    },
    {
      "epoch": 7.285033071835103,
      "grad_norm": 0.43359375,
      "learning_rate": 5.468661872002393e-05,
      "loss": 0.0903,
      "step": 5920
    },
    {
      "epoch": 7.297338870942932,
      "grad_norm": 0.478515625,
      "learning_rate": 5.455422709093427e-05,
      "loss": 0.075,
      "step": 5930
    },
    {
      "epoch": 7.309644670050761,
      "grad_norm": 0.46484375,
      "learning_rate": 5.4421803257071846e-05,
      "loss": 0.0599,
      "step": 5940
    },
    {
      "epoch": 7.321950469158591,
      "grad_norm": 0.296875,
      "learning_rate": 5.428934815485892e-05,
      "loss": 0.0701,
      "step": 5950
    },
    {
      "epoch": 7.3342562682664205,
      "grad_norm": 0.54296875,
      "learning_rate": 5.415686272093882e-05,
      "loss": 0.0836,
      "step": 5960
    },
    {
      "epoch": 7.34656206737425,
      "grad_norm": 0.61328125,
      "learning_rate": 5.402434789216938e-05,
      "loss": 0.0676,
      "step": 5970
    },
    {
      "epoch": 7.35886786648208,
      "grad_norm": 0.4296875,
      "learning_rate": 5.389180460561627e-05,
      "loss": 0.0825,
      "step": 5980
    },
    {
      "epoch": 7.371173665589909,
      "grad_norm": 0.431640625,
      "learning_rate": 5.3759233798546425e-05,
      "loss": 0.0944,
      "step": 5990
    },
    {
      "epoch": 7.383479464697738,
      "grad_norm": 0.59375,
      "learning_rate": 5.362663640842137e-05,
      "loss": 0.0756,
      "step": 6000
    },
    {
      "epoch": 7.3957852638055686,
      "grad_norm": 0.59765625,
      "learning_rate": 5.349401337289064e-05,
      "loss": 0.0662,
      "step": 6010
    },
    {
      "epoch": 7.408091062913398,
      "grad_norm": 0.482421875,
      "learning_rate": 5.336136562978509e-05,
      "loss": 0.0735,
      "step": 6020
    },
    {
      "epoch": 7.420396862021228,
      "grad_norm": 0.3984375,
      "learning_rate": 5.322869411711029e-05,
      "loss": 0.0625,
      "step": 6030
    },
    {
      "epoch": 7.432702661129057,
      "grad_norm": 0.5859375,
      "learning_rate": 5.309599977303991e-05,
      "loss": 0.0636,
      "step": 6040
    },
    {
      "epoch": 7.4450084602368864,
      "grad_norm": 0.427734375,
      "learning_rate": 5.296328353590903e-05,
      "loss": 0.0648,
      "step": 6050
    },
    {
      "epoch": 7.457314259344717,
      "grad_norm": 0.41015625,
      "learning_rate": 5.283054634420764e-05,
      "loss": 0.0624,
      "step": 6060
    },
    {
      "epoch": 7.469620058452546,
      "grad_norm": 0.447265625,
      "learning_rate": 5.2697789136573816e-05,
      "loss": 0.0553,
      "step": 6070
    },
    {
      "epoch": 7.481925857560375,
      "grad_norm": 0.41015625,
      "learning_rate": 5.256501285178719e-05,
      "loss": 0.0681,
      "step": 6080
    },
    {
      "epoch": 7.494231656668205,
      "grad_norm": 0.353515625,
      "learning_rate": 5.243221842876235e-05,
      "loss": 0.074,
      "step": 6090
    },
    {
      "epoch": 7.5065374557760345,
      "grad_norm": 0.54296875,
      "learning_rate": 5.229940680654205e-05,
      "loss": 0.0722,
      "step": 6100
    },
    {
      "epoch": 7.518843254883864,
      "grad_norm": 0.4296875,
      "learning_rate": 5.216657892429078e-05,
      "loss": 0.064,
      "step": 6110
    },
    {
      "epoch": 7.531149053991694,
      "grad_norm": 0.369140625,
      "learning_rate": 5.203373572128792e-05,
      "loss": 0.0821,
      "step": 6120
    },
    {
      "epoch": 7.543454853099523,
      "grad_norm": 0.3515625,
      "learning_rate": 5.190087813692127e-05,
      "loss": 0.0739,
      "step": 6130
    },
    {
      "epoch": 7.555760652207352,
      "grad_norm": 0.349609375,
      "learning_rate": 5.1768007110680225e-05,
      "loss": 0.0665,
      "step": 6140
    },
    {
      "epoch": 7.5680664513151825,
      "grad_norm": 0.310546875,
      "learning_rate": 5.163512358214931e-05,
      "loss": 0.0521,
      "step": 6150
    },
    {
      "epoch": 7.580372250423012,
      "grad_norm": 0.59765625,
      "learning_rate": 5.150222849100146e-05,
      "loss": 0.0651,
      "step": 6160
    },
    {
      "epoch": 7.592678049530841,
      "grad_norm": 0.5859375,
      "learning_rate": 5.1369322776991335e-05,
      "loss": 0.0618,
      "step": 6170
    },
    {
      "epoch": 7.604983848638671,
      "grad_norm": 0.435546875,
      "learning_rate": 5.1236407379948726e-05,
      "loss": 0.0687,
      "step": 6180
    },
    {
      "epoch": 7.6172896477465,
      "grad_norm": 0.3515625,
      "learning_rate": 5.1103483239771896e-05,
      "loss": 0.0752,
      "step": 6190
    },
    {
      "epoch": 7.62959544685433,
      "grad_norm": 0.5703125,
      "learning_rate": 5.097055129642096e-05,
      "loss": 0.0844,
      "step": 6200
    },
    {
      "epoch": 7.64190124596216,
      "grad_norm": 0.625,
      "learning_rate": 5.083761248991117e-05,
      "loss": 0.0615,
      "step": 6210
    },
    {
      "epoch": 7.654207045069989,
      "grad_norm": 0.87109375,
      "learning_rate": 5.0704667760306354e-05,
      "loss": 0.0754,
      "step": 6220
    },
    {
      "epoch": 7.666512844177818,
      "grad_norm": 0.515625,
      "learning_rate": 5.057171804771219e-05,
      "loss": 0.07,
      "step": 6230
    },
    {
      "epoch": 7.6788186432856484,
      "grad_norm": 0.55078125,
      "learning_rate": 5.043876429226962e-05,
      "loss": 0.0767,
      "step": 6240
    },
    {
      "epoch": 7.691124442393478,
      "grad_norm": 0.5625,
      "learning_rate": 5.0305807434148114e-05,
      "loss": 0.0699,
      "step": 6250
    },
    {
      "epoch": 7.703430241501308,
      "grad_norm": 0.443359375,
      "learning_rate": 5.0172848413539184e-05,
      "loss": 0.0756,
      "step": 6260
    },
    {
      "epoch": 7.715736040609137,
      "grad_norm": 0.5078125,
      "learning_rate": 5.003988817064954e-05,
      "loss": 0.0604,
      "step": 6270
    },
    {
      "epoch": 7.728041839716966,
      "grad_norm": 0.67578125,
      "learning_rate": 4.990692764569459e-05,
      "loss": 0.0676,
      "step": 6280
    },
    {
      "epoch": 7.7403476388247965,
      "grad_norm": 0.337890625,
      "learning_rate": 4.977396777889173e-05,
      "loss": 0.0715,
      "step": 6290
    },
    {
      "epoch": 7.752653437932626,
      "grad_norm": 0.46484375,
      "learning_rate": 4.964100951045366e-05,
      "loss": 0.0735,
      "step": 6300
    },
    {
      "epoch": 7.764959237040455,
      "grad_norm": 0.8046875,
      "learning_rate": 4.9508053780581857e-05,
      "loss": 0.0722,
      "step": 6310
    },
    {
      "epoch": 7.777265036148285,
      "grad_norm": 0.412109375,
      "learning_rate": 4.937510152945973e-05,
      "loss": 0.0711,
      "step": 6320
    },
    {
      "epoch": 7.789570835256114,
      "grad_norm": 0.6953125,
      "learning_rate": 4.924215369724622e-05,
      "loss": 0.0648,
      "step": 6330
    },
    {
      "epoch": 7.801876634363944,
      "grad_norm": 0.4765625,
      "learning_rate": 4.9109211224068937e-05,
      "loss": 0.0826,
      "step": 6340
    },
    {
      "epoch": 7.814182433471774,
      "grad_norm": 0.65625,
      "learning_rate": 4.89762750500176e-05,
      "loss": 0.0626,
      "step": 6350
    },
    {
      "epoch": 7.826488232579603,
      "grad_norm": 0.578125,
      "learning_rate": 4.8843346115137425e-05,
      "loss": 0.0593,
      "step": 6360
    },
    {
      "epoch": 7.838794031687433,
      "grad_norm": 0.73046875,
      "learning_rate": 4.871042535942239e-05,
      "loss": 0.0761,
      "step": 6370
    },
    {
      "epoch": 7.851099830795262,
      "grad_norm": 0.39453125,
      "learning_rate": 4.857751372280865e-05,
      "loss": 0.0713,
      "step": 6380
    },
    {
      "epoch": 7.863405629903092,
      "grad_norm": 0.55859375,
      "learning_rate": 4.8444612145167915e-05,
      "loss": 0.0471,
      "step": 6390
    },
    {
      "epoch": 7.875711429010922,
      "grad_norm": 0.48046875,
      "learning_rate": 4.8311721566300714e-05,
      "loss": 0.081,
      "step": 6400
    },
    {
      "epoch": 7.888017228118751,
      "grad_norm": 0.55078125,
      "learning_rate": 4.817884292592981e-05,
      "loss": 0.0774,
      "step": 6410
    },
    {
      "epoch": 7.90032302722658,
      "grad_norm": 0.6328125,
      "learning_rate": 4.804597716369355e-05,
      "loss": 0.0603,
      "step": 6420
    },
    {
      "epoch": 7.9126288263344104,
      "grad_norm": 0.3828125,
      "learning_rate": 4.79131252191392e-05,
      "loss": 0.068,
      "step": 6430
    },
    {
      "epoch": 7.92493462544224,
      "grad_norm": 0.4375,
      "learning_rate": 4.778028803171639e-05,
      "loss": 0.0795,
      "step": 6440
    },
    {
      "epoch": 7.937240424550069,
      "grad_norm": 0.8203125,
      "learning_rate": 4.764746654077026e-05,
      "loss": 0.0693,
      "step": 6450
    },
    {
      "epoch": 7.949546223657899,
      "grad_norm": 0.435546875,
      "learning_rate": 4.751466168553509e-05,
      "loss": 0.0612,
      "step": 6460
    },
    {
      "epoch": 7.961852022765728,
      "grad_norm": 0.44921875,
      "learning_rate": 4.738187440512742e-05,
      "loss": 0.0779,
      "step": 6470
    },
    {
      "epoch": 7.974157821873558,
      "grad_norm": 0.6875,
      "learning_rate": 4.724910563853958e-05,
      "loss": 0.0833,
      "step": 6480
    },
    {
      "epoch": 7.986463620981388,
      "grad_norm": 0.50390625,
      "learning_rate": 4.711635632463294e-05,
      "loss": 0.0633,
      "step": 6490
    },
    {
      "epoch": 7.998769420089217,
      "grad_norm": 0.64453125,
      "learning_rate": 4.6983627402131334e-05,
      "loss": 0.0672,
      "step": 6500
    },
    {
      "epoch": 8.011075219197046,
      "grad_norm": 0.80078125,
      "learning_rate": 4.685091980961441e-05,
      "loss": 0.0706,
      "step": 6510
    },
    {
      "epoch": 8.023381018304876,
      "grad_norm": 0.318359375,
      "learning_rate": 4.671823448551092e-05,
      "loss": 0.0577,
      "step": 6520
    },
    {
      "epoch": 8.035686817412707,
      "grad_norm": 0.419921875,
      "learning_rate": 4.6585572368092235e-05,
      "loss": 0.0581,
      "step": 6530
    },
    {
      "epoch": 8.047992616520535,
      "grad_norm": 0.373046875,
      "learning_rate": 4.645293439546558e-05,
      "loss": 0.0675,
      "step": 6540
    },
    {
      "epoch": 8.060298415628365,
      "grad_norm": 0.4765625,
      "learning_rate": 4.6320321505567425e-05,
      "loss": 0.061,
      "step": 6550
    },
    {
      "epoch": 8.072604214736195,
      "grad_norm": 0.46875,
      "learning_rate": 4.61877346361569e-05,
      "loss": 0.0673,
      "step": 6560
    },
    {
      "epoch": 8.084910013844024,
      "grad_norm": 0.435546875,
      "learning_rate": 4.6055174724809117e-05,
      "loss": 0.0584,
      "step": 6570
    },
    {
      "epoch": 8.097215812951854,
      "grad_norm": 0.490234375,
      "learning_rate": 4.592264270890855e-05,
      "loss": 0.0563,
      "step": 6580
    },
    {
      "epoch": 8.109521612059684,
      "grad_norm": 0.3671875,
      "learning_rate": 4.5790139525642464e-05,
      "loss": 0.0752,
      "step": 6590
    },
    {
      "epoch": 8.121827411167512,
      "grad_norm": 0.66015625,
      "learning_rate": 4.565766611199415e-05,
      "loss": 0.0644,
      "step": 6600
    },
    {
      "epoch": 8.134133210275342,
      "grad_norm": 0.6875,
      "learning_rate": 4.552522340473647e-05,
      "loss": 0.0536,
      "step": 6610
    },
    {
      "epoch": 8.146439009383172,
      "grad_norm": 0.58203125,
      "learning_rate": 4.539281234042509e-05,
      "loss": 0.0744,
      "step": 6620
    },
    {
      "epoch": 8.158744808491,
      "grad_norm": 0.65625,
      "learning_rate": 4.526043385539193e-05,
      "loss": 0.0556,
      "step": 6630
    },
    {
      "epoch": 8.171050607598831,
      "grad_norm": 0.380859375,
      "learning_rate": 4.512808888573859e-05,
      "loss": 0.062,
      "step": 6640
    },
    {
      "epoch": 8.183356406706661,
      "grad_norm": 0.55078125,
      "learning_rate": 4.4995778367329546e-05,
      "loss": 0.0626,
      "step": 6650
    },
    {
      "epoch": 8.19566220581449,
      "grad_norm": 0.375,
      "learning_rate": 4.486350323578577e-05,
      "loss": 0.0556,
      "step": 6660
    },
    {
      "epoch": 8.20796800492232,
      "grad_norm": 0.4765625,
      "learning_rate": 4.473126442647795e-05,
      "loss": 0.0691,
      "step": 6670
    },
    {
      "epoch": 8.22027380403015,
      "grad_norm": 0.50390625,
      "learning_rate": 4.459906287451991e-05,
      "loss": 0.0719,
      "step": 6680
    },
    {
      "epoch": 8.232579603137978,
      "grad_norm": 0.337890625,
      "learning_rate": 4.446689951476207e-05,
      "loss": 0.0575,
      "step": 6690
    },
    {
      "epoch": 8.244885402245808,
      "grad_norm": 0.60546875,
      "learning_rate": 4.43347752817847e-05,
      "loss": 0.0608,
      "step": 6700
    },
    {
      "epoch": 8.257191201353638,
      "grad_norm": 0.41015625,
      "learning_rate": 4.420269110989146e-05,
      "loss": 0.0537,
      "step": 6710
    },
    {
      "epoch": 8.269497000461467,
      "grad_norm": 0.33203125,
      "learning_rate": 4.407064793310265e-05,
      "loss": 0.0621,
      "step": 6720
    },
    {
      "epoch": 8.281802799569297,
      "grad_norm": 0.423828125,
      "learning_rate": 4.393864668514875e-05,
      "loss": 0.0661,
      "step": 6730
    },
    {
      "epoch": 8.294108598677127,
      "grad_norm": 0.671875,
      "learning_rate": 4.3806688299463724e-05,
      "loss": 0.066,
      "step": 6740
    },
    {
      "epoch": 8.306414397784955,
      "grad_norm": 0.44140625,
      "learning_rate": 4.367477370917839e-05,
      "loss": 0.0567,
      "step": 6750
    },
    {
      "epoch": 8.318720196892786,
      "grad_norm": 0.37890625,
      "learning_rate": 4.3542903847113945e-05,
      "loss": 0.0714,
      "step": 6760
    },
    {
      "epoch": 8.331025996000616,
      "grad_norm": 0.57421875,
      "learning_rate": 4.341107964577522e-05,
      "loss": 0.0585,
      "step": 6770
    },
    {
      "epoch": 8.343331795108444,
      "grad_norm": 0.5859375,
      "learning_rate": 4.3279302037344215e-05,
      "loss": 0.055,
      "step": 6780
    },
    {
      "epoch": 8.355637594216274,
      "grad_norm": 0.392578125,
      "learning_rate": 4.314757195367347e-05,
      "loss": 0.0625,
      "step": 6790
    },
    {
      "epoch": 8.367943393324104,
      "grad_norm": 0.58203125,
      "learning_rate": 4.301589032627937e-05,
      "loss": 0.0695,
      "step": 6800
    },
    {
      "epoch": 8.380249192431933,
      "grad_norm": 0.55078125,
      "learning_rate": 4.288425808633575e-05,
      "loss": 0.0634,
      "step": 6810
    },
    {
      "epoch": 8.392554991539763,
      "grad_norm": 0.55078125,
      "learning_rate": 4.2752676164667124e-05,
      "loss": 0.0564,
      "step": 6820
    },
    {
      "epoch": 8.404860790647593,
      "grad_norm": 0.46875,
      "learning_rate": 4.262114549174222e-05,
      "loss": 0.0665,
      "step": 6830
    },
    {
      "epoch": 8.417166589755423,
      "grad_norm": 0.51953125,
      "learning_rate": 4.248966699766741e-05,
      "loss": 0.0549,
      "step": 6840
    },
    {
      "epoch": 8.429472388863251,
      "grad_norm": 1.09375,
      "learning_rate": 4.235824161217998e-05,
      "loss": 0.056,
      "step": 6850
    },
    {
      "epoch": 8.441778187971082,
      "grad_norm": 0.4296875,
      "learning_rate": 4.222687026464177e-05,
      "loss": 0.0527,
      "step": 6860
    },
    {
      "epoch": 8.454083987078912,
      "grad_norm": 0.5078125,
      "learning_rate": 4.2095553884032426e-05,
      "loss": 0.0677,
      "step": 6870
    },
    {
      "epoch": 8.46638978618674,
      "grad_norm": 0.4375,
      "learning_rate": 4.1964293398942945e-05,
      "loss": 0.0641,
      "step": 6880
    },
    {
      "epoch": 8.47869558529457,
      "grad_norm": 0.392578125,
      "learning_rate": 4.183308973756905e-05,
      "loss": 0.0706,
      "step": 6890
    },
    {
      "epoch": 8.4910013844024,
      "grad_norm": 0.330078125,
      "learning_rate": 4.1701943827704617e-05,
      "loss": 0.0514,
      "step": 6900
    },
    {
      "epoch": 8.503307183510229,
      "grad_norm": 0.33203125,
      "learning_rate": 4.157085659673518e-05,
      "loss": 0.0581,
      "step": 6910
    },
    {
      "epoch": 8.515612982618059,
      "grad_norm": 0.42578125,
      "learning_rate": 4.143982897163127e-05,
      "loss": 0.0632,
      "step": 6920
    },
    {
      "epoch": 8.527918781725889,
      "grad_norm": 0.3359375,
      "learning_rate": 4.130886187894201e-05,
      "loss": 0.0591,
      "step": 6930
    },
    {
      "epoch": 8.540224580833717,
      "grad_norm": 0.70703125,
      "learning_rate": 4.11779562447884e-05,
      "loss": 0.069,
      "step": 6940
    },
    {
      "epoch": 8.552530379941548,
      "grad_norm": 0.515625,
      "learning_rate": 4.104711299485687e-05,
      "loss": 0.0638,
      "step": 6950
    },
    {
      "epoch": 8.564836179049378,
      "grad_norm": 0.35546875,
      "learning_rate": 4.0916333054392705e-05,
      "loss": 0.0647,
      "step": 6960
    },
    {
      "epoch": 8.577141978157206,
      "grad_norm": 0.32421875,
      "learning_rate": 4.0785617348193484e-05,
      "loss": 0.0782,
      "step": 6970
    },
    {
      "epoch": 8.589447777265036,
      "grad_norm": 0.50390625,
      "learning_rate": 4.0654966800602575e-05,
      "loss": 0.0685,
      "step": 6980
    },
    {
      "epoch": 8.601753576372866,
      "grad_norm": 0.380859375,
      "learning_rate": 4.052438233550262e-05,
      "loss": 0.0748,
      "step": 6990
    },
    {
      "epoch": 8.614059375480695,
      "grad_norm": 0.353515625,
      "learning_rate": 4.039386487630889e-05,
      "loss": 0.0432,
      "step": 7000
    },
    {
      "epoch": 8.626365174588525,
      "grad_norm": 0.416015625,
      "learning_rate": 4.0263415345962895e-05,
      "loss": 0.0653,
      "step": 7010
    },
    {
      "epoch": 8.638670973696355,
      "grad_norm": 0.5546875,
      "learning_rate": 4.013303466692575e-05,
      "loss": 0.0631,
      "step": 7020
    },
    {
      "epoch": 8.650976772804183,
      "grad_norm": 0.486328125,
      "learning_rate": 4.000272376117171e-05,
      "loss": 0.0574,
      "step": 7030
    },
    {
      "epoch": 8.663282571912013,
      "grad_norm": 0.5078125,
      "learning_rate": 3.9872483550181674e-05,
      "loss": 0.0457,
      "step": 7040
    },
    {
      "epoch": 8.675588371019844,
      "grad_norm": 0.55078125,
      "learning_rate": 3.9742314954936534e-05,
      "loss": 0.0504,
      "step": 7050
    },
    {
      "epoch": 8.687894170127672,
      "grad_norm": 0.54296875,
      "learning_rate": 3.961221889591087e-05,
      "loss": 0.0671,
      "step": 7060
    },
    {
      "epoch": 8.700199969235502,
      "grad_norm": 0.29296875,
      "learning_rate": 3.948219629306624e-05,
      "loss": 0.0576,
      "step": 7070
    },
    {
      "epoch": 8.712505768343332,
      "grad_norm": 0.353515625,
      "learning_rate": 3.935224806584481e-05,
      "loss": 0.052,
      "step": 7080
    },
    {
      "epoch": 8.72481156745116,
      "grad_norm": 0.439453125,
      "learning_rate": 3.922237513316282e-05,
      "loss": 0.0673,
      "step": 7090
    },
    {
      "epoch": 8.73711736655899,
      "grad_norm": 0.55078125,
      "learning_rate": 3.909257841340401e-05,
      "loss": 0.0683,
      "step": 7100
    },
    {
      "epoch": 8.74942316566682,
      "grad_norm": 0.4140625,
      "learning_rate": 3.8962858824413255e-05,
      "loss": 0.0666,
      "step": 7110
    },
    {
      "epoch": 8.76172896477465,
      "grad_norm": 0.376953125,
      "learning_rate": 3.883321728348995e-05,
      "loss": 0.0605,
      "step": 7120
    },
    {
      "epoch": 8.77403476388248,
      "grad_norm": 0.380859375,
      "learning_rate": 3.870365470738163e-05,
      "loss": 0.0691,
      "step": 7130
    },
    {
      "epoch": 8.78634056299031,
      "grad_norm": 0.341796875,
      "learning_rate": 3.8574172012277435e-05,
      "loss": 0.0588,
      "step": 7140
    },
    {
      "epoch": 8.79864636209814,
      "grad_norm": 0.5703125,
      "learning_rate": 3.844477011380157e-05,
      "loss": 0.0668,
      "step": 7150
    },
    {
      "epoch": 8.810952161205968,
      "grad_norm": 0.48046875,
      "learning_rate": 3.831544992700698e-05,
      "loss": 0.0597,
      "step": 7160
    },
    {
      "epoch": 8.823257960313798,
      "grad_norm": 0.2490234375,
      "learning_rate": 3.818621236636873e-05,
      "loss": 0.069,
      "step": 7170
    },
    {
      "epoch": 8.835563759421628,
      "grad_norm": 0.5,
      "learning_rate": 3.805705834577762e-05,
      "loss": 0.0549,
      "step": 7180
    },
    {
      "epoch": 8.847869558529457,
      "grad_norm": 0.453125,
      "learning_rate": 3.792798877853375e-05,
      "loss": 0.0589,
      "step": 7190
    },
    {
      "epoch": 8.860175357637287,
      "grad_norm": 0.37890625,
      "learning_rate": 3.7799004577339947e-05,
      "loss": 0.0657,
      "step": 7200
    },
    {
      "epoch": 8.872481156745117,
      "grad_norm": 0.353515625,
      "learning_rate": 3.767010665429543e-05,
      "loss": 0.0806,
      "step": 7210
    },
    {
      "epoch": 8.884786955852945,
      "grad_norm": 0.83984375,
      "learning_rate": 3.7541295920889266e-05,
      "loss": 0.0581,
      "step": 7220
    },
    {
      "epoch": 8.897092754960775,
      "grad_norm": 0.46484375,
      "learning_rate": 3.7412573287993995e-05,
      "loss": 0.0608,
      "step": 7230
    },
    {
      "epoch": 8.909398554068606,
      "grad_norm": 0.306640625,
      "learning_rate": 3.728393966585921e-05,
      "loss": 0.0592,
      "step": 7240
    },
    {
      "epoch": 8.921704353176434,
      "grad_norm": 0.4140625,
      "learning_rate": 3.715539596410497e-05,
      "loss": 0.0605,
      "step": 7250
    },
    {
      "epoch": 8.934010152284264,
      "grad_norm": 0.56640625,
      "learning_rate": 3.702694309171555e-05,
      "loss": 0.0568,
      "step": 7260
    },
    {
      "epoch": 8.946315951392094,
      "grad_norm": 0.294921875,
      "learning_rate": 3.689858195703291e-05,
      "loss": 0.0663,
      "step": 7270
    },
    {
      "epoch": 8.958621750499923,
      "grad_norm": 0.734375,
      "learning_rate": 3.677031346775029e-05,
      "loss": 0.064,
      "step": 7280
    },
    {
      "epoch": 8.970927549607753,
      "grad_norm": 0.392578125,
      "learning_rate": 3.6642138530905815e-05,
      "loss": 0.0587,
      "step": 7290
    },
    {
      "epoch": 8.983233348715583,
      "grad_norm": 0.388671875,
      "learning_rate": 3.6514058052876033e-05,
      "loss": 0.0529,
      "step": 7300
    },
    {
      "epoch": 8.995539147823411,
      "grad_norm": 0.357421875,
      "learning_rate": 3.638607293936958e-05,
      "loss": 0.0629,
      "step": 7310
    },
    {
      "epoch": 9.007844946931241,
      "grad_norm": 0.36328125,
      "learning_rate": 3.6258184095420654e-05,
      "loss": 0.06,
      "step": 7320
    },
    {
      "epoch": 9.020150746039072,
      "grad_norm": 0.431640625,
      "learning_rate": 3.6130392425382806e-05,
      "loss": 0.0576,
      "step": 7330
    },
    {
      "epoch": 9.0324565451469,
      "grad_norm": 0.408203125,
      "learning_rate": 3.6002698832922335e-05,
      "loss": 0.0518,
      "step": 7340
    },
    {
      "epoch": 9.04476234425473,
      "grad_norm": 0.41015625,
      "learning_rate": 3.587510422101203e-05,
      "loss": 0.0748,
      "step": 7350
    },
    {
      "epoch": 9.05706814336256,
      "grad_norm": 0.41796875,
      "learning_rate": 3.574760949192476e-05,
      "loss": 0.051,
      "step": 7360
    },
    {
      "epoch": 9.069373942470389,
      "grad_norm": 0.55078125,
      "learning_rate": 3.562021554722704e-05,
      "loss": 0.0615,
      "step": 7370
    },
    {
      "epoch": 9.081679741578219,
      "grad_norm": 0.421875,
      "learning_rate": 3.549292328777273e-05,
      "loss": 0.0507,
      "step": 7380
    },
    {
      "epoch": 9.093985540686049,
      "grad_norm": 0.5,
      "learning_rate": 3.536573361369667e-05,
      "loss": 0.0503,
      "step": 7390
    },
    {
      "epoch": 9.106291339793877,
      "grad_norm": 0.5546875,
      "learning_rate": 3.5238647424408196e-05,
      "loss": 0.0587,
      "step": 7400
    },
    {
      "epoch": 9.118597138901707,
      "grad_norm": 0.82421875,
      "learning_rate": 3.5111665618584925e-05,
      "loss": 0.0601,
      "step": 7410
    },
    {
      "epoch": 9.130902938009537,
      "grad_norm": 0.46484375,
      "learning_rate": 3.4984789094166287e-05,
      "loss": 0.0531,
      "step": 7420
    },
    {
      "epoch": 9.143208737117366,
      "grad_norm": 0.271484375,
      "learning_rate": 3.485801874834728e-05,
      "loss": 0.0486,
      "step": 7430
    },
    {
      "epoch": 9.155514536225196,
      "grad_norm": 0.275390625,
      "learning_rate": 3.473135547757202e-05,
      "loss": 0.0609,
      "step": 7440
    },
    {
      "epoch": 9.167820335333026,
      "grad_norm": 0.416015625,
      "learning_rate": 3.460480017752747e-05,
      "loss": 0.0542,
      "step": 7450
    },
    {
      "epoch": 9.180126134440854,
      "grad_norm": 0.306640625,
      "learning_rate": 3.447835374313713e-05,
      "loss": 0.0531,
      "step": 7460
    },
    {
      "epoch": 9.192431933548685,
      "grad_norm": 0.5703125,
      "learning_rate": 3.435201706855459e-05,
      "loss": 0.0465,
      "step": 7470
    },
    {
      "epoch": 9.204737732656515,
      "grad_norm": 0.640625,
      "learning_rate": 3.422579104715735e-05,
      "loss": 0.068,
      "step": 7480
    },
    {
      "epoch": 9.217043531764343,
      "grad_norm": 0.498046875,
      "learning_rate": 3.409967657154038e-05,
      "loss": 0.0602,
      "step": 7490
    },
    {
      "epoch": 9.229349330872173,
      "grad_norm": 0.6171875,
      "learning_rate": 3.397367453350993e-05,
      "loss": 0.0593,
      "step": 7500
    },
    {
      "epoch": 9.241655129980003,
      "grad_norm": 0.5,
      "learning_rate": 3.3847785824077105e-05,
      "loss": 0.0552,
      "step": 7510
    },
    {
      "epoch": 9.253960929087832,
      "grad_norm": 0.291015625,
      "learning_rate": 3.3722011333451626e-05,
      "loss": 0.0496,
      "step": 7520
    },
    {
      "epoch": 9.266266728195662,
      "grad_norm": 0.77734375,
      "learning_rate": 3.3596351951035584e-05,
      "loss": 0.0505,
      "step": 7530
    },
    {
      "epoch": 9.278572527303492,
      "grad_norm": 0.7109375,
      "learning_rate": 3.3470808565416976e-05,
      "loss": 0.0482,
      "step": 7540
    },
    {
      "epoch": 9.290878326411322,
      "grad_norm": 0.625,
      "learning_rate": 3.3345382064363674e-05,
      "loss": 0.0536,
      "step": 7550
    },
    {
      "epoch": 9.30318412551915,
      "grad_norm": 0.427734375,
      "learning_rate": 3.322007333481693e-05,
      "loss": 0.0619,
      "step": 7560
    },
    {
      "epoch": 9.31548992462698,
      "grad_norm": 0.3984375,
      "learning_rate": 3.309488326288518e-05,
      "loss": 0.0606,
      "step": 7570
    },
    {
      "epoch": 9.32779572373481,
      "grad_norm": 1.4609375,
      "learning_rate": 3.296981273383784e-05,
      "loss": 0.0461,
      "step": 7580
    },
    {
      "epoch": 9.34010152284264,
      "grad_norm": 0.72265625,
      "learning_rate": 3.284486263209893e-05,
      "loss": 0.0545,
      "step": 7590
    },
    {
      "epoch": 9.35240732195047,
      "grad_norm": 0.435546875,
      "learning_rate": 3.272003384124094e-05,
      "loss": 0.0558,
      "step": 7600
    },
    {
      "epoch": 9.3647131210583,
      "grad_norm": 0.34765625,
      "learning_rate": 3.259532724397848e-05,
      "loss": 0.0518,
      "step": 7610
    },
    {
      "epoch": 9.377018920166128,
      "grad_norm": 0.31640625,
      "learning_rate": 3.247074372216208e-05,
      "loss": 0.0484,
      "step": 7620
    },
    {
      "epoch": 9.389324719273958,
      "grad_norm": 0.33203125,
      "learning_rate": 3.2346284156771984e-05,
      "loss": 0.0525,
      "step": 7630
    },
    {
      "epoch": 9.401630518381788,
      "grad_norm": 0.52734375,
      "learning_rate": 3.222194942791185e-05,
      "loss": 0.0631,
      "step": 7640
    },
    {
      "epoch": 9.413936317489616,
      "grad_norm": 0.408203125,
      "learning_rate": 3.2097740414802584e-05,
      "loss": 0.0726,
      "step": 7650
    },
    {
      "epoch": 9.426242116597447,
      "grad_norm": 0.306640625,
      "learning_rate": 3.197365799577615e-05,
      "loss": 0.06,
      "step": 7660
    },
    {
      "epoch": 9.438547915705277,
      "grad_norm": 0.5234375,
      "learning_rate": 3.184970304826923e-05,
      "loss": 0.0442,
      "step": 7670
    },
    {
      "epoch": 9.450853714813105,
      "grad_norm": 0.5625,
      "learning_rate": 3.172587644881718e-05,
      "loss": 0.0473,
      "step": 7680
    },
    {
      "epoch": 9.463159513920935,
      "grad_norm": 0.28515625,
      "learning_rate": 3.160217907304769e-05,
      "loss": 0.0553,
      "step": 7690
    },
    {
      "epoch": 9.475465313028765,
      "grad_norm": 0.408203125,
      "learning_rate": 3.1478611795674714e-05,
      "loss": 0.0578,
      "step": 7700
    },
    {
      "epoch": 9.487771112136594,
      "grad_norm": 0.49609375,
      "learning_rate": 3.13551754904922e-05,
      "loss": 0.0536,
      "step": 7710
    },
    {
      "epoch": 9.500076911244424,
      "grad_norm": 0.33203125,
      "learning_rate": 3.123187103036792e-05,
      "loss": 0.0579,
      "step": 7720
    },
    {
      "epoch": 9.512382710352254,
      "grad_norm": 0.6875,
      "learning_rate": 3.110869928723738e-05,
      "loss": 0.0556,
      "step": 7730
    },
    {
      "epoch": 9.524688509460082,
      "grad_norm": 0.52734375,
      "learning_rate": 3.0985661132097496e-05,
      "loss": 0.0618,
      "step": 7740
    },
    {
      "epoch": 9.536994308567913,
      "grad_norm": 0.72265625,
      "learning_rate": 3.0862757435000635e-05,
      "loss": 0.0485,
      "step": 7750
    },
    {
      "epoch": 9.549300107675743,
      "grad_norm": 0.3515625,
      "learning_rate": 3.0739989065048285e-05,
      "loss": 0.0525,
      "step": 7760
    },
    {
      "epoch": 9.561605906783571,
      "grad_norm": 0.3515625,
      "learning_rate": 3.0617356890385e-05,
      "loss": 0.0561,
      "step": 7770
    },
    {
      "epoch": 9.573911705891401,
      "grad_norm": 0.361328125,
      "learning_rate": 3.049486177819224e-05,
      "loss": 0.065,
      "step": 7780
    },
    {
      "epoch": 9.586217504999231,
      "grad_norm": 0.47265625,
      "learning_rate": 3.0372504594682237e-05,
      "loss": 0.0492,
      "step": 7790
    },
    {
      "epoch": 9.59852330410706,
      "grad_norm": 0.55859375,
      "learning_rate": 3.0250286205091904e-05,
      "loss": 0.0619,
      "step": 7800
    },
    {
      "epoch": 9.61082910321489,
      "grad_norm": 0.41796875,
      "learning_rate": 3.0128207473676663e-05,
      "loss": 0.0689,
      "step": 7810
    },
    {
      "epoch": 9.62313490232272,
      "grad_norm": 0.400390625,
      "learning_rate": 3.0006269263704334e-05,
      "loss": 0.0561,
      "step": 7820
    },
    {
      "epoch": 9.635440701430548,
      "grad_norm": 0.34375,
      "learning_rate": 2.9884472437449114e-05,
      "loss": 0.0589,
      "step": 7830
    },
    {
      "epoch": 9.647746500538378,
      "grad_norm": 0.4921875,
      "learning_rate": 2.9762817856185344e-05,
      "loss": 0.0536,
      "step": 7840
    },
    {
      "epoch": 9.660052299646209,
      "grad_norm": 0.46875,
      "learning_rate": 2.9641306380181533e-05,
      "loss": 0.0639,
      "step": 7850
    },
    {
      "epoch": 9.672358098754039,
      "grad_norm": 0.4375,
      "learning_rate": 2.9519938868694286e-05,
      "loss": 0.0609,
      "step": 7860
    },
    {
      "epoch": 9.684663897861867,
      "grad_norm": 0.41796875,
      "learning_rate": 2.939871617996205e-05,
      "loss": 0.0585,
      "step": 7870
    },
    {
      "epoch": 9.696969696969697,
      "grad_norm": 0.71484375,
      "learning_rate": 2.927763917119931e-05,
      "loss": 0.0495,
      "step": 7880
    },
    {
      "epoch": 9.709275496077527,
      "grad_norm": 0.427734375,
      "learning_rate": 2.9156708698590274e-05,
      "loss": 0.0568,
      "step": 7890
    },
    {
      "epoch": 9.721581295185356,
      "grad_norm": 0.337890625,
      "learning_rate": 2.903592561728304e-05,
      "loss": 0.0528,
      "step": 7900
    },
    {
      "epoch": 9.733887094293186,
      "grad_norm": 0.494140625,
      "learning_rate": 2.8915290781383354e-05,
      "loss": 0.0699,
      "step": 7910
    },
    {
      "epoch": 9.746192893401016,
      "grad_norm": 0.35546875,
      "learning_rate": 2.8794805043948682e-05,
      "loss": 0.0588,
      "step": 7920
    },
    {
      "epoch": 9.758498692508844,
      "grad_norm": 0.35546875,
      "learning_rate": 2.8674469256982196e-05,
      "loss": 0.0509,
      "step": 7930
    },
    {
      "epoch": 9.770804491616675,
      "grad_norm": 0.318359375,
      "learning_rate": 2.8554284271426668e-05,
      "loss": 0.0626,
      "step": 7940
    },
    {
      "epoch": 9.783110290724505,
      "grad_norm": 0.369140625,
      "learning_rate": 2.843425093715849e-05,
      "loss": 0.0465,
      "step": 7950
    },
    {
      "epoch": 9.795416089832333,
      "grad_norm": 0.412109375,
      "learning_rate": 2.8314370102981702e-05,
      "loss": 0.0618,
      "step": 7960
    },
    {
      "epoch": 9.807721888940163,
      "grad_norm": 0.400390625,
      "learning_rate": 2.8194642616621904e-05,
      "loss": 0.0508,
      "step": 7970
    },
    {
      "epoch": 9.820027688047993,
      "grad_norm": 0.4609375,
      "learning_rate": 2.807506932472037e-05,
      "loss": 0.0632,
      "step": 7980
    },
    {
      "epoch": 9.832333487155822,
      "grad_norm": 0.578125,
      "learning_rate": 2.795565107282796e-05,
      "loss": 0.0537,
      "step": 7990
    },
    {
      "epoch": 9.844639286263652,
      "grad_norm": 0.322265625,
      "learning_rate": 2.783638870539918e-05,
      "loss": 0.0491,
      "step": 8000
    },
    {
      "epoch": 9.856945085371482,
      "grad_norm": 0.36328125,
      "learning_rate": 2.7717283065786264e-05,
      "loss": 0.0637,
      "step": 8010
    },
    {
      "epoch": 9.86925088447931,
      "grad_norm": 0.4765625,
      "learning_rate": 2.7598334996233087e-05,
      "loss": 0.0632,
      "step": 8020
    },
    {
      "epoch": 9.88155668358714,
      "grad_norm": 0.44140625,
      "learning_rate": 2.7479545337869388e-05,
      "loss": 0.0639,
      "step": 8030
    },
    {
      "epoch": 9.89386248269497,
      "grad_norm": 0.49609375,
      "learning_rate": 2.736091493070457e-05,
      "loss": 0.0682,
      "step": 8040
    },
    {
      "epoch": 9.906168281802799,
      "grad_norm": 0.412109375,
      "learning_rate": 2.724244461362202e-05,
      "loss": 0.0614,
      "step": 8050
    },
    {
      "epoch": 9.918474080910629,
      "grad_norm": 0.4609375,
      "learning_rate": 2.712413522437306e-05,
      "loss": 0.0629,
      "step": 8060
    },
    {
      "epoch": 9.93077988001846,
      "grad_norm": 0.640625,
      "learning_rate": 2.700598759957098e-05,
      "loss": 0.064,
      "step": 8070
    },
    {
      "epoch": 9.943085679126288,
      "grad_norm": 0.396484375,
      "learning_rate": 2.6888002574685183e-05,
      "loss": 0.0676,
      "step": 8080
    },
    {
      "epoch": 9.955391478234118,
      "grad_norm": 0.60546875,
      "learning_rate": 2.6770180984035246e-05,
      "loss": 0.0679,
      "step": 8090
    },
    {
      "epoch": 9.967697277341948,
      "grad_norm": 0.4140625,
      "learning_rate": 2.6652523660785085e-05,
      "loss": 0.0524,
      "step": 8100
    },
    {
      "epoch": 9.980003076449776,
      "grad_norm": 0.390625,
      "learning_rate": 2.6535031436936996e-05,
      "loss": 0.074,
      "step": 8110
    },
    {
      "epoch": 9.992308875557606,
      "grad_norm": 0.375,
      "learning_rate": 2.6417705143325767e-05,
      "loss": 0.0623,
      "step": 8120
    },
    {
      "epoch": 10.004614674665437,
      "grad_norm": 0.365234375,
      "learning_rate": 2.6300545609612837e-05,
      "loss": 0.0561,
      "step": 8130
    },
    {
      "epoch": 10.016920473773265,
      "grad_norm": 0.4140625,
      "learning_rate": 2.6183553664280408e-05,
      "loss": 0.0581,
      "step": 8140
    },
    {
      "epoch": 10.029226272881095,
      "grad_norm": 0.4453125,
      "learning_rate": 2.606673013462564e-05,
      "loss": 0.0574,
      "step": 8150
    },
    {
      "epoch": 10.041532071988925,
      "grad_norm": 0.400390625,
      "learning_rate": 2.595007584675475e-05,
      "loss": 0.0509,
      "step": 8160
    },
    {
      "epoch": 10.053837871096754,
      "grad_norm": 0.42578125,
      "learning_rate": 2.5833591625577093e-05,
      "loss": 0.0617,
      "step": 8170
    },
    {
      "epoch": 10.066143670204584,
      "grad_norm": 0.55078125,
      "learning_rate": 2.571727829479954e-05,
      "loss": 0.0506,
      "step": 8180
    },
    {
      "epoch": 10.078449469312414,
      "grad_norm": 0.35546875,
      "learning_rate": 2.5601136676920423e-05,
      "loss": 0.0528,
      "step": 8190
    },
    {
      "epoch": 10.090755268420242,
      "grad_norm": 0.349609375,
      "learning_rate": 2.5485167593223903e-05,
      "loss": 0.0578,
      "step": 8200
    },
    {
      "epoch": 10.103061067528072,
      "grad_norm": 0.5546875,
      "learning_rate": 2.5369371863774034e-05,
      "loss": 0.0721,
      "step": 8210
    },
    {
      "epoch": 10.115366866635902,
      "grad_norm": 0.58203125,
      "learning_rate": 2.5253750307408997e-05,
      "loss": 0.0586,
      "step": 8220
    },
    {
      "epoch": 10.127672665743733,
      "grad_norm": 0.28125,
      "learning_rate": 2.5138303741735393e-05,
      "loss": 0.0503,
      "step": 8230
    },
    {
      "epoch": 10.139978464851561,
      "grad_norm": 0.48046875,
      "learning_rate": 2.5023032983122317e-05,
      "loss": 0.0584,
      "step": 8240
    },
    {
      "epoch": 10.152284263959391,
      "grad_norm": 0.7890625,
      "learning_rate": 2.4907938846695733e-05,
      "loss": 0.0531,
      "step": 8250
    },
    {
      "epoch": 10.164590063067221,
      "grad_norm": 0.400390625,
      "learning_rate": 2.479302214633259e-05,
      "loss": 0.0532,
      "step": 8260
    },
    {
      "epoch": 10.17689586217505,
      "grad_norm": 0.32421875,
      "learning_rate": 2.4678283694655095e-05,
      "loss": 0.0582,
      "step": 8270
    },
    {
      "epoch": 10.18920166128288,
      "grad_norm": 0.396484375,
      "learning_rate": 2.456372430302507e-05,
      "loss": 0.0524,
      "step": 8280
    },
    {
      "epoch": 10.20150746039071,
      "grad_norm": 0.419921875,
      "learning_rate": 2.4449344781538043e-05,
      "loss": 0.0464,
      "step": 8290
    },
    {
      "epoch": 10.213813259498538,
      "grad_norm": 0.54296875,
      "learning_rate": 2.4335145939017673e-05,
      "loss": 0.0527,
      "step": 8300
    },
    {
      "epoch": 10.226119058606368,
      "grad_norm": 0.400390625,
      "learning_rate": 2.4221128583009922e-05,
      "loss": 0.0611,
      "step": 8310
    },
    {
      "epoch": 10.238424857714199,
      "grad_norm": 0.38671875,
      "learning_rate": 2.4107293519777397e-05,
      "loss": 0.0558,
      "step": 8320
    },
    {
      "epoch": 10.250730656822027,
      "grad_norm": 0.263671875,
      "learning_rate": 2.399364155429367e-05,
      "loss": 0.0549,
      "step": 8330
    },
    {
      "epoch": 10.263036455929857,
      "grad_norm": 0.30859375,
      "learning_rate": 2.388017349023752e-05,
      "loss": 0.0471,
      "step": 8340
    },
    {
      "epoch": 10.275342255037687,
      "grad_norm": 0.34765625,
      "learning_rate": 2.376689012998728e-05,
      "loss": 0.0539,
      "step": 8350
    },
    {
      "epoch": 10.287648054145516,
      "grad_norm": 0.3828125,
      "learning_rate": 2.3653792274615212e-05,
      "loss": 0.0543,
      "step": 8360
    },
    {
      "epoch": 10.299953853253346,
      "grad_norm": 0.29296875,
      "learning_rate": 2.354088072388174e-05,
      "loss": 0.0469,
      "step": 8370
    },
    {
      "epoch": 10.312259652361176,
      "grad_norm": 0.29296875,
      "learning_rate": 2.3428156276229923e-05,
      "loss": 0.0641,
      "step": 8380
    },
    {
      "epoch": 10.324565451469004,
      "grad_norm": 0.34375,
      "learning_rate": 2.3315619728779676e-05,
      "loss": 0.0574,
      "step": 8390
    },
    {
      "epoch": 10.336871250576834,
      "grad_norm": 0.41796875,
      "learning_rate": 2.32032718773222e-05,
      "loss": 0.0585,
      "step": 8400
    },
    {
      "epoch": 10.349177049684664,
      "grad_norm": 0.333984375,
      "learning_rate": 2.3091113516314417e-05,
      "loss": 0.044,
      "step": 8410
    },
    {
      "epoch": 10.361482848792493,
      "grad_norm": 0.412109375,
      "learning_rate": 2.297914543887319e-05,
      "loss": 0.0681,
      "step": 8420
    },
    {
      "epoch": 10.373788647900323,
      "grad_norm": 0.40625,
      "learning_rate": 2.2867368436769927e-05,
      "loss": 0.062,
      "step": 8430
    },
    {
      "epoch": 10.386094447008153,
      "grad_norm": 0.357421875,
      "learning_rate": 2.275578330042471e-05,
      "loss": 0.0558,
      "step": 8440
    },
    {
      "epoch": 10.398400246115981,
      "grad_norm": 0.416015625,
      "learning_rate": 2.2644390818900996e-05,
      "loss": 0.0593,
      "step": 8450
    },
    {
      "epoch": 10.410706045223812,
      "grad_norm": 0.357421875,
      "learning_rate": 2.253319177989987e-05,
      "loss": 0.0503,
      "step": 8460
    },
    {
      "epoch": 10.423011844331642,
      "grad_norm": 0.353515625,
      "learning_rate": 2.242218696975447e-05,
      "loss": 0.0602,
      "step": 8470
    },
    {
      "epoch": 10.43531764343947,
      "grad_norm": 0.3828125,
      "learning_rate": 2.2311377173424495e-05,
      "loss": 0.0496,
      "step": 8480
    },
    {
      "epoch": 10.4476234425473,
      "grad_norm": 0.5703125,
      "learning_rate": 2.220076317449059e-05,
      "loss": 0.0614,
      "step": 8490
    },
    {
      "epoch": 10.45992924165513,
      "grad_norm": 0.46875,
      "learning_rate": 2.2090345755148877e-05,
      "loss": 0.0562,
      "step": 8500
    },
    {
      "epoch": 10.472235040762959,
      "grad_norm": 0.28515625,
      "learning_rate": 2.198012569620539e-05,
      "loss": 0.0511,
      "step": 8510
    },
    {
      "epoch": 10.484540839870789,
      "grad_norm": 0.306640625,
      "learning_rate": 2.1870103777070507e-05,
      "loss": 0.0579,
      "step": 8520
    },
    {
      "epoch": 10.496846638978619,
      "grad_norm": 0.63671875,
      "learning_rate": 2.17602807757535e-05,
      "loss": 0.0518,
      "step": 8530
    },
    {
      "epoch": 10.50915243808645,
      "grad_norm": 0.46484375,
      "learning_rate": 2.1650657468856994e-05,
      "loss": 0.052,
      "step": 8540
    },
    {
      "epoch": 10.521458237194278,
      "grad_norm": 0.37109375,
      "learning_rate": 2.1541234631571533e-05,
      "loss": 0.0675,
      "step": 8550
    },
    {
      "epoch": 10.533764036302108,
      "grad_norm": 0.55859375,
      "learning_rate": 2.143201303767008e-05,
      "loss": 0.0571,
      "step": 8560
    },
    {
      "epoch": 10.546069835409938,
      "grad_norm": 0.302734375,
      "learning_rate": 2.1322993459502404e-05,
      "loss": 0.0537,
      "step": 8570
    },
    {
      "epoch": 10.558375634517766,
      "grad_norm": 0.373046875,
      "learning_rate": 2.1214176667989876e-05,
      "loss": 0.0501,
      "step": 8580
    },
    {
      "epoch": 10.570681433625596,
      "grad_norm": 0.388671875,
      "learning_rate": 2.1105563432619796e-05,
      "loss": 0.0651,
      "step": 8590
    },
    {
      "epoch": 10.582987232733426,
      "grad_norm": 0.453125,
      "learning_rate": 2.09971545214401e-05,
      "loss": 0.0577,
      "step": 8600
    },
    {
      "epoch": 10.595293031841255,
      "grad_norm": 0.5703125,
      "learning_rate": 2.0888950701053804e-05,
      "loss": 0.0607,
      "step": 8610
    },
    {
      "epoch": 10.607598830949085,
      "grad_norm": 0.3046875,
      "learning_rate": 2.0780952736613663e-05,
      "loss": 0.0483,
      "step": 8620
    },
    {
      "epoch": 10.619904630056915,
      "grad_norm": 0.33984375,
      "learning_rate": 2.0673161391816788e-05,
      "loss": 0.0536,
      "step": 8630
    },
    {
      "epoch": 10.632210429164743,
      "grad_norm": 0.44921875,
      "learning_rate": 2.0565577428899113e-05,
      "loss": 0.0548,
      "step": 8640
    },
    {
      "epoch": 10.644516228272574,
      "grad_norm": 0.4375,
      "learning_rate": 2.045820160863019e-05,
      "loss": 0.0506,
      "step": 8650
    },
    {
      "epoch": 10.656822027380404,
      "grad_norm": 0.3046875,
      "learning_rate": 2.0351034690307635e-05,
      "loss": 0.0533,
      "step": 8660
    },
    {
      "epoch": 10.669127826488232,
      "grad_norm": 0.44140625,
      "learning_rate": 2.024407743175185e-05,
      "loss": 0.0497,
      "step": 8670
    },
    {
      "epoch": 10.681433625596062,
      "grad_norm": 0.314453125,
      "learning_rate": 2.0137330589300686e-05,
      "loss": 0.0501,
      "step": 8680
    },
    {
      "epoch": 10.693739424703892,
      "grad_norm": 0.39453125,
      "learning_rate": 2.003079491780399e-05,
      "loss": 0.0602,
      "step": 8690
    },
    {
      "epoch": 10.70604522381172,
      "grad_norm": 0.419921875,
      "learning_rate": 1.992447117061842e-05,
      "loss": 0.0634,
      "step": 8700
    },
    {
      "epoch": 10.71835102291955,
      "grad_norm": 0.5234375,
      "learning_rate": 1.981836009960196e-05,
      "loss": 0.0567,
      "step": 8710
    },
    {
      "epoch": 10.730656822027381,
      "grad_norm": 0.43359375,
      "learning_rate": 1.971246245510869e-05,
      "loss": 0.0538,
      "step": 8720
    },
    {
      "epoch": 10.74296262113521,
      "grad_norm": 0.578125,
      "learning_rate": 1.9606778985983498e-05,
      "loss": 0.0388,
      "step": 8730
    },
    {
      "epoch": 10.75526842024304,
      "grad_norm": 0.357421875,
      "learning_rate": 1.950131043955673e-05,
      "loss": 0.0596,
      "step": 8740
    },
    {
      "epoch": 10.76757421935087,
      "grad_norm": 0.41796875,
      "learning_rate": 1.9396057561638892e-05,
      "loss": 0.0554,
      "step": 8750
    },
    {
      "epoch": 10.779880018458698,
      "grad_norm": 0.431640625,
      "learning_rate": 1.9291021096515494e-05,
      "loss": 0.0459,
      "step": 8760
    },
    {
      "epoch": 10.792185817566528,
      "grad_norm": 0.408203125,
      "learning_rate": 1.918620178694161e-05,
      "loss": 0.0516,
      "step": 8770
    },
    {
      "epoch": 10.804491616674358,
      "grad_norm": 0.390625,
      "learning_rate": 1.908160037413681e-05,
      "loss": 0.0598,
      "step": 8780
    },
    {
      "epoch": 10.816797415782187,
      "grad_norm": 0.33203125,
      "learning_rate": 1.8977217597779762e-05,
      "loss": 0.0533,
      "step": 8790
    },
    {
      "epoch": 10.829103214890017,
      "grad_norm": 0.388671875,
      "learning_rate": 1.887305419600307e-05,
      "loss": 0.0671,
      "step": 8800
    },
    {
      "epoch": 10.841409013997847,
      "grad_norm": 0.4140625,
      "learning_rate": 1.876911090538811e-05,
      "loss": 0.0656,
      "step": 8810
    },
    {
      "epoch": 10.853714813105675,
      "grad_norm": 0.53125,
      "learning_rate": 1.8665388460959687e-05,
      "loss": 0.0584,
      "step": 8820
    },
    {
      "epoch": 10.866020612213505,
      "grad_norm": 0.453125,
      "learning_rate": 1.8561887596181003e-05,
      "loss": 0.0564,
      "step": 8830
    },
    {
      "epoch": 10.878326411321336,
      "grad_norm": 0.326171875,
      "learning_rate": 1.8458609042948265e-05,
      "loss": 0.0485,
      "step": 8840
    },
    {
      "epoch": 10.890632210429164,
      "grad_norm": 0.3203125,
      "learning_rate": 1.835555353158573e-05,
      "loss": 0.0502,
      "step": 8850
    },
    {
      "epoch": 10.902938009536994,
      "grad_norm": 0.4375,
      "learning_rate": 1.8252721790840395e-05,
      "loss": 0.0475,
      "step": 8860
    },
    {
      "epoch": 10.915243808644824,
      "grad_norm": 0.5546875,
      "learning_rate": 1.8150114547876885e-05,
      "loss": 0.0535,
      "step": 8870
    },
    {
      "epoch": 10.927549607752653,
      "grad_norm": 0.3046875,
      "learning_rate": 1.804773252827231e-05,
      "loss": 0.0461,
      "step": 8880
    },
    {
      "epoch": 10.939855406860483,
      "grad_norm": 0.36328125,
      "learning_rate": 1.7945576456011115e-05,
      "loss": 0.0485,
      "step": 8890
    },
    {
      "epoch": 10.952161205968313,
      "grad_norm": 0.75,
      "learning_rate": 1.7843647053480022e-05,
      "loss": 0.0539,
      "step": 8900
    },
    {
      "epoch": 10.964467005076141,
      "grad_norm": 0.40234375,
      "learning_rate": 1.7741945041462876e-05,
      "loss": 0.0487,
      "step": 8910
    },
    {
      "epoch": 10.976772804183971,
      "grad_norm": 0.365234375,
      "learning_rate": 1.7640471139135528e-05,
      "loss": 0.0463,
      "step": 8920
    },
    {
      "epoch": 10.989078603291802,
      "grad_norm": 0.44140625,
      "learning_rate": 1.7539226064060777e-05,
      "loss": 0.0489,
      "step": 8930
    },
    {
      "epoch": 11.001384402399632,
      "grad_norm": 0.625,
      "learning_rate": 1.7438210532183275e-05,
      "loss": 0.0562,
      "step": 8940
    },
    {
      "epoch": 11.01369020150746,
      "grad_norm": 0.365234375,
      "learning_rate": 1.733742525782453e-05,
      "loss": 0.0526,
      "step": 8950
    },
    {
      "epoch": 11.02599600061529,
      "grad_norm": 0.33984375,
      "learning_rate": 1.723687095367781e-05,
      "loss": 0.053,
      "step": 8960
    },
    {
      "epoch": 11.03830179972312,
      "grad_norm": 0.36328125,
      "learning_rate": 1.7136548330803004e-05,
      "loss": 0.0543,
      "step": 8970
    },
    {
      "epoch": 11.050607598830949,
      "grad_norm": 0.296875,
      "learning_rate": 1.703645809862181e-05,
      "loss": 0.0606,
      "step": 8980
    },
    {
      "epoch": 11.062913397938779,
      "grad_norm": 0.3125,
      "learning_rate": 1.6936600964912506e-05,
      "loss": 0.0495,
      "step": 8990
    },
    {
      "epoch": 11.075219197046609,
      "grad_norm": 0.34375,
      "learning_rate": 1.683697763580511e-05,
      "loss": 0.0543,
      "step": 9000
    },
    {
      "epoch": 11.087524996154437,
      "grad_norm": 0.404296875,
      "learning_rate": 1.673758881577626e-05,
      "loss": 0.0693,
      "step": 9010
    },
    {
      "epoch": 11.099830795262267,
      "grad_norm": 0.34765625,
      "learning_rate": 1.663843520764429e-05,
      "loss": 0.051,
      "step": 9020
    },
    {
      "epoch": 11.112136594370098,
      "grad_norm": 0.416015625,
      "learning_rate": 1.6539517512564305e-05,
      "loss": 0.0478,
      "step": 9030
    },
    {
      "epoch": 11.124442393477926,
      "grad_norm": 0.42578125,
      "learning_rate": 1.6440836430023105e-05,
      "loss": 0.0465,
      "step": 9040
    },
    {
      "epoch": 11.136748192585756,
      "grad_norm": 0.6328125,
      "learning_rate": 1.6342392657834372e-05,
      "loss": 0.0534,
      "step": 9050
    },
    {
      "epoch": 11.149053991693586,
      "grad_norm": 0.52734375,
      "learning_rate": 1.6244186892133628e-05,
      "loss": 0.0514,
      "step": 9060
    },
    {
      "epoch": 11.161359790801415,
      "grad_norm": 0.3203125,
      "learning_rate": 1.6146219827373343e-05,
      "loss": 0.0411,
      "step": 9070
    },
    {
      "epoch": 11.173665589909245,
      "grad_norm": 0.66796875,
      "learning_rate": 1.6048492156318106e-05,
      "loss": 0.0547,
      "step": 9080
    },
    {
      "epoch": 11.185971389017075,
      "grad_norm": 0.7421875,
      "learning_rate": 1.5951004570039575e-05,
      "loss": 0.0602,
      "step": 9090
    },
    {
      "epoch": 11.198277188124903,
      "grad_norm": 0.279296875,
      "learning_rate": 1.5853757757911735e-05,
      "loss": 0.0507,
      "step": 9100
    },
    {
      "epoch": 11.210582987232733,
      "grad_norm": 0.349609375,
      "learning_rate": 1.575675240760593e-05,
      "loss": 0.051,
      "step": 9110
    },
    {
      "epoch": 11.222888786340564,
      "grad_norm": 0.365234375,
      "learning_rate": 1.565998920508601e-05,
      "loss": 0.051,
      "step": 9120
    },
    {
      "epoch": 11.235194585448392,
      "grad_norm": 0.41796875,
      "learning_rate": 1.5563468834603562e-05,
      "loss": 0.0565,
      "step": 9130
    },
    {
      "epoch": 11.247500384556222,
      "grad_norm": 0.384765625,
      "learning_rate": 1.546719197869296e-05,
      "loss": 0.0543,
      "step": 9140
    },
    {
      "epoch": 11.259806183664052,
      "grad_norm": 0.37890625,
      "learning_rate": 1.5371159318166572e-05,
      "loss": 0.0474,
      "step": 9150
    },
    {
      "epoch": 11.27211198277188,
      "grad_norm": 0.380859375,
      "learning_rate": 1.5275371532110035e-05,
      "loss": 0.0509,
      "step": 9160
    },
    {
      "epoch": 11.28441778187971,
      "grad_norm": 0.40234375,
      "learning_rate": 1.5179829297877302e-05,
      "loss": 0.0543,
      "step": 9170
    },
    {
      "epoch": 11.29672358098754,
      "grad_norm": 0.6484375,
      "learning_rate": 1.5084533291085994e-05,
      "loss": 0.0512,
      "step": 9180
    },
    {
      "epoch": 11.30902938009537,
      "grad_norm": 0.75390625,
      "learning_rate": 1.4989484185612524e-05,
      "loss": 0.05,
      "step": 9190
    },
    {
      "epoch": 11.3213351792032,
      "grad_norm": 0.466796875,
      "learning_rate": 1.4894682653587345e-05,
      "loss": 0.0673,
      "step": 9200
    },
    {
      "epoch": 11.33364097831103,
      "grad_norm": 0.337890625,
      "learning_rate": 1.4800129365390281e-05,
      "loss": 0.0609,
      "step": 9210
    },
    {
      "epoch": 11.345946777418858,
      "grad_norm": 0.3359375,
      "learning_rate": 1.4705824989645655e-05,
      "loss": 0.0591,
      "step": 9220
    },
    {
      "epoch": 11.358252576526688,
      "grad_norm": 0.38671875,
      "learning_rate": 1.4611770193217716e-05,
      "loss": 0.064,
      "step": 9230
    },
    {
      "epoch": 11.370558375634518,
      "grad_norm": 0.416015625,
      "learning_rate": 1.4517965641205716e-05,
      "loss": 0.0515,
      "step": 9240
    },
    {
      "epoch": 11.382864174742348,
      "grad_norm": 0.5546875,
      "learning_rate": 1.442441199693943e-05,
      "loss": 0.0565,
      "step": 9250
    },
    {
      "epoch": 11.395169973850177,
      "grad_norm": 0.30859375,
      "learning_rate": 1.433110992197435e-05,
      "loss": 0.061,
      "step": 9260
    },
    {
      "epoch": 11.407475772958007,
      "grad_norm": 0.3359375,
      "learning_rate": 1.4238060076086978e-05,
      "loss": 0.0541,
      "step": 9270
    },
    {
      "epoch": 11.419781572065837,
      "grad_norm": 0.48828125,
      "learning_rate": 1.4145263117270225e-05,
      "loss": 0.0558,
      "step": 9280
    },
    {
      "epoch": 11.432087371173665,
      "grad_norm": 0.361328125,
      "learning_rate": 1.4052719701728723e-05,
      "loss": 0.0464,
      "step": 9290
    },
    {
      "epoch": 11.444393170281495,
      "grad_norm": 0.396484375,
      "learning_rate": 1.3960430483874232e-05,
      "loss": 0.0625,
      "step": 9300
    },
    {
      "epoch": 11.456698969389326,
      "grad_norm": 0.373046875,
      "learning_rate": 1.386839611632096e-05,
      "loss": 0.0469,
      "step": 9310
    },
    {
      "epoch": 11.469004768497154,
      "grad_norm": 0.3984375,
      "learning_rate": 1.3776617249880946e-05,
      "loss": 0.0616,
      "step": 9320
    },
    {
      "epoch": 11.481310567604984,
      "grad_norm": 0.30859375,
      "learning_rate": 1.36850945335595e-05,
      "loss": 0.0573,
      "step": 9330
    },
    {
      "epoch": 11.493616366712814,
      "grad_norm": 0.318359375,
      "learning_rate": 1.3593828614550574e-05,
      "loss": 0.0347,
      "step": 9340
    },
    {
      "epoch": 11.505922165820643,
      "grad_norm": 0.40625,
      "learning_rate": 1.350282013823223e-05,
      "loss": 0.0462,
      "step": 9350
    },
    {
      "epoch": 11.518227964928473,
      "grad_norm": 0.4296875,
      "learning_rate": 1.3412069748162032e-05,
      "loss": 0.0508,
      "step": 9360
    },
    {
      "epoch": 11.530533764036303,
      "grad_norm": 0.388671875,
      "learning_rate": 1.3321578086072494e-05,
      "loss": 0.0498,
      "step": 9370
    },
    {
      "epoch": 11.542839563144131,
      "grad_norm": 0.251953125,
      "learning_rate": 1.3231345791866606e-05,
      "loss": 0.0582,
      "step": 9380
    },
    {
      "epoch": 11.555145362251961,
      "grad_norm": 0.384765625,
      "learning_rate": 1.3141373503613207e-05,
      "loss": 0.0423,
      "step": 9390
    },
    {
      "epoch": 11.567451161359791,
      "grad_norm": 0.53515625,
      "learning_rate": 1.3051661857542596e-05,
      "loss": 0.0461,
      "step": 9400
    },
    {
      "epoch": 11.57975696046762,
      "grad_norm": 0.41796875,
      "learning_rate": 1.2962211488041908e-05,
      "loss": 0.058,
      "step": 9410
    },
    {
      "epoch": 11.59206275957545,
      "grad_norm": 0.310546875,
      "learning_rate": 1.2873023027650694e-05,
      "loss": 0.0554,
      "step": 9420
    },
    {
      "epoch": 11.60436855868328,
      "grad_norm": 0.310546875,
      "learning_rate": 1.2784097107056481e-05,
      "loss": 0.0516,
      "step": 9430
    },
    {
      "epoch": 11.616674357791108,
      "grad_norm": 0.416015625,
      "learning_rate": 1.2695434355090225e-05,
      "loss": 0.0519,
      "step": 9440
    },
    {
      "epoch": 11.628980156898939,
      "grad_norm": 0.404296875,
      "learning_rate": 1.2607035398721944e-05,
      "loss": 0.0516,
      "step": 9450
    },
    {
      "epoch": 11.641285956006769,
      "grad_norm": 0.345703125,
      "learning_rate": 1.2518900863056237e-05,
      "loss": 0.0602,
      "step": 9460
    },
    {
      "epoch": 11.653591755114597,
      "grad_norm": 0.32421875,
      "learning_rate": 1.2431031371327856e-05,
      "loss": 0.0527,
      "step": 9470
    },
    {
      "epoch": 11.665897554222427,
      "grad_norm": 0.3515625,
      "learning_rate": 1.2343427544897367e-05,
      "loss": 0.0546,
      "step": 9480
    },
    {
      "epoch": 11.678203353330257,
      "grad_norm": 0.4453125,
      "learning_rate": 1.2256090003246684e-05,
      "loss": 0.0551,
      "step": 9490
    },
    {
      "epoch": 11.690509152438086,
      "grad_norm": 0.439453125,
      "learning_rate": 1.2169019363974704e-05,
      "loss": 0.0602,
      "step": 9500
    },
    {
      "epoch": 11.702814951545916,
      "grad_norm": 0.361328125,
      "learning_rate": 1.2082216242792955e-05,
      "loss": 0.0461,
      "step": 9510
    },
    {
      "epoch": 11.715120750653746,
      "grad_norm": 0.287109375,
      "learning_rate": 1.1995681253521251e-05,
      "loss": 0.0517,
      "step": 9520
    },
    {
      "epoch": 11.727426549761574,
      "grad_norm": 0.384765625,
      "learning_rate": 1.1909415008083346e-05,
      "loss": 0.0443,
      "step": 9530
    },
    {
      "epoch": 11.739732348869405,
      "grad_norm": 0.44921875,
      "learning_rate": 1.1823418116502565e-05,
      "loss": 0.0574,
      "step": 9540
    },
    {
      "epoch": 11.752038147977235,
      "grad_norm": 0.478515625,
      "learning_rate": 1.1737691186897554e-05,
      "loss": 0.0525,
      "step": 9550
    },
    {
      "epoch": 11.764343947085063,
      "grad_norm": 0.416015625,
      "learning_rate": 1.1652234825477903e-05,
      "loss": 0.0571,
      "step": 9560
    },
    {
      "epoch": 11.776649746192893,
      "grad_norm": 0.3671875,
      "learning_rate": 1.1567049636539961e-05,
      "loss": 0.0488,
      "step": 9570
    },
    {
      "epoch": 11.788955545300723,
      "grad_norm": 0.51953125,
      "learning_rate": 1.1482136222462497e-05,
      "loss": 0.0638,
      "step": 9580
    },
    {
      "epoch": 11.801261344408552,
      "grad_norm": 0.58203125,
      "learning_rate": 1.1397495183702427e-05,
      "loss": 0.0513,
      "step": 9590
    },
    {
      "epoch": 11.813567143516382,
      "grad_norm": 0.72265625,
      "learning_rate": 1.1313127118790595e-05,
      "loss": 0.0546,
      "step": 9600
    },
    {
      "epoch": 11.825872942624212,
      "grad_norm": 0.384765625,
      "learning_rate": 1.122903262432754e-05,
      "loss": 0.0537,
      "step": 9610
    },
    {
      "epoch": 11.83817874173204,
      "grad_norm": 0.318359375,
      "learning_rate": 1.1145212294979284e-05,
      "loss": 0.0543,
      "step": 9620
    },
    {
      "epoch": 11.85048454083987,
      "grad_norm": 0.515625,
      "learning_rate": 1.106166672347314e-05,
      "loss": 0.0594,
      "step": 9630
    },
    {
      "epoch": 11.8627903399477,
      "grad_norm": 0.578125,
      "learning_rate": 1.0978396500593425e-05,
      "loss": 0.0524,
      "step": 9640
    },
    {
      "epoch": 11.87509613905553,
      "grad_norm": 0.400390625,
      "learning_rate": 1.0895402215177425e-05,
      "loss": 0.0479,
      "step": 9650
    },
    {
      "epoch": 11.887401938163359,
      "grad_norm": 0.349609375,
      "learning_rate": 1.0812684454111121e-05,
      "loss": 0.0552,
      "step": 9660
    },
    {
      "epoch": 11.89970773727119,
      "grad_norm": 0.41796875,
      "learning_rate": 1.0730243802325112e-05,
      "loss": 0.0578,
      "step": 9670
    },
    {
      "epoch": 11.91201353637902,
      "grad_norm": 0.291015625,
      "learning_rate": 1.064808084279042e-05,
      "loss": 0.0579,
      "step": 9680
    },
    {
      "epoch": 11.924319335486848,
      "grad_norm": 0.3671875,
      "learning_rate": 1.056619615651438e-05,
      "loss": 0.0534,
      "step": 9690
    },
    {
      "epoch": 11.936625134594678,
      "grad_norm": 0.439453125,
      "learning_rate": 1.0484590322536603e-05,
      "loss": 0.0561,
      "step": 9700
    },
    {
      "epoch": 11.948930933702508,
      "grad_norm": 0.451171875,
      "learning_rate": 1.040326391792475e-05,
      "loss": 0.0501,
      "step": 9710
    },
    {
      "epoch": 11.961236732810336,
      "grad_norm": 0.419921875,
      "learning_rate": 1.0322217517770589e-05,
      "loss": 0.0649,
      "step": 9720
    },
    {
      "epoch": 11.973542531918167,
      "grad_norm": 0.6484375,
      "learning_rate": 1.0241451695185828e-05,
      "loss": 0.0608,
      "step": 9730
    },
    {
      "epoch": 11.985848331025997,
      "grad_norm": 0.3828125,
      "learning_rate": 1.0160967021298079e-05,
      "loss": 0.0572,
      "step": 9740
    },
    {
      "epoch": 11.998154130133825,
      "grad_norm": 0.421875,
      "learning_rate": 1.00807640652469e-05,
      "loss": 0.041,
      "step": 9750
    },
    {
      "epoch": 12.010459929241655,
      "grad_norm": 0.33984375,
      "learning_rate": 1.000084339417966e-05,
      "loss": 0.0616,
      "step": 9760
    },
    {
      "epoch": 12.022765728349485,
      "grad_norm": 0.470703125,
      "learning_rate": 9.921205573247576e-06,
      "loss": 0.0411,
      "step": 9770
    },
    {
      "epoch": 12.035071527457314,
      "grad_norm": 0.259765625,
      "learning_rate": 9.841851165601757e-06,
      "loss": 0.0513,
      "step": 9780
    },
    {
      "epoch": 12.047377326565144,
      "grad_norm": 0.36328125,
      "learning_rate": 9.762780732389131e-06,
      "loss": 0.0491,
      "step": 9790
    },
    {
      "epoch": 12.059683125672974,
      "grad_norm": 0.294921875,
      "learning_rate": 9.683994832748588e-06,
      "loss": 0.0457,
      "step": 9800
    },
    {
      "epoch": 12.071988924780802,
      "grad_norm": 0.353515625,
      "learning_rate": 9.60549402380691e-06,
      "loss": 0.0515,
      "step": 9810
    },
    {
      "epoch": 12.084294723888632,
      "grad_norm": 0.41015625,
      "learning_rate": 9.52727886067491e-06,
      "loss": 0.0619,
      "step": 9820
    },
    {
      "epoch": 12.096600522996463,
      "grad_norm": 0.462890625,
      "learning_rate": 9.44934989644351e-06,
      "loss": 0.0528,
      "step": 9830
    },
    {
      "epoch": 12.108906322104291,
      "grad_norm": 0.44140625,
      "learning_rate": 9.371707682179747e-06,
      "loss": 0.0485,
      "step": 9840
    },
    {
      "epoch": 12.121212121212121,
      "grad_norm": 0.3671875,
      "learning_rate": 9.294352766922998e-06,
      "loss": 0.049,
      "step": 9850
    },
    {
      "epoch": 12.133517920319951,
      "grad_norm": 0.279296875,
      "learning_rate": 9.217285697680994e-06,
      "loss": 0.0578,
      "step": 9860
    },
    {
      "epoch": 12.14582371942778,
      "grad_norm": 0.85546875,
      "learning_rate": 9.140507019425981e-06,
      "loss": 0.0506,
      "step": 9870
    },
    {
      "epoch": 12.15812951853561,
      "grad_norm": 0.267578125,
      "learning_rate": 9.064017275090924e-06,
      "loss": 0.0454,
      "step": 9880
    },
    {
      "epoch": 12.17043531764344,
      "grad_norm": 0.37109375,
      "learning_rate": 8.98781700556558e-06,
      "loss": 0.0609,
      "step": 9890
    },
    {
      "epoch": 12.182741116751268,
      "grad_norm": 0.38671875,
      "learning_rate": 8.911906749692717e-06,
      "loss": 0.0428,
      "step": 9900
    },
    {
      "epoch": 12.195046915859098,
      "grad_norm": 0.376953125,
      "learning_rate": 8.836287044264292e-06,
      "loss": 0.0528,
      "step": 9910
    },
    {
      "epoch": 12.207352714966929,
      "grad_norm": 0.302734375,
      "learning_rate": 8.760958424017702e-06,
      "loss": 0.0498,
      "step": 9920
    },
    {
      "epoch": 12.219658514074757,
      "grad_norm": 0.4140625,
      "learning_rate": 8.685921421631937e-06,
      "loss": 0.0508,
      "step": 9930
    },
    {
      "epoch": 12.231964313182587,
      "grad_norm": 0.41796875,
      "learning_rate": 8.611176567723844e-06,
      "loss": 0.0632,
      "step": 9940
    },
    {
      "epoch": 12.244270112290417,
      "grad_norm": 0.30859375,
      "learning_rate": 8.536724390844358e-06,
      "loss": 0.0496,
      "step": 9950
    },
    {
      "epoch": 12.256575911398247,
      "grad_norm": 0.34375,
      "learning_rate": 8.462565417474778e-06,
      "loss": 0.0676,
      "step": 9960
    },
    {
      "epoch": 12.268881710506076,
      "grad_norm": 0.546875,
      "learning_rate": 8.388700172023062e-06,
      "loss": 0.0583,
      "step": 9970
    },
    {
      "epoch": 12.281187509613906,
      "grad_norm": 0.30859375,
      "learning_rate": 8.315129176820108e-06,
      "loss": 0.0523,
      "step": 9980
    },
    {
      "epoch": 12.293493308721736,
      "grad_norm": 0.61328125,
      "learning_rate": 8.241852952116014e-06,
      "loss": 0.0574,
      "step": 9990
    },
    {
      "epoch": 12.305799107829564,
      "grad_norm": 0.25390625,
      "learning_rate": 8.168872016076462e-06,
      "loss": 0.0637,
      "step": 10000
    },
    {
      "epoch": 12.305799107829564,
      "eval_loss": NaN,
      "eval_runtime": 443.6494,
      "eval_samples_per_second": 117.214,
      "eval_steps_per_second": 14.653,
      "step": 10000
    },
    {
      "epoch": 12.318104906937394,
      "grad_norm": 0.35546875,
      "learning_rate": 8.096186884779011e-06,
      "loss": 0.0604,
      "step": 10010
    },
    {
      "epoch": 12.330410706045225,
      "grad_norm": 0.55078125,
      "learning_rate": 8.023798072209488e-06,
      "loss": 0.0609,
      "step": 10020
    },
    {
      "epoch": 12.342716505153053,
      "grad_norm": 0.494140625,
      "learning_rate": 7.951706090258354e-06,
      "loss": 0.0599,
      "step": 10030
    },
    {
      "epoch": 12.355022304260883,
      "grad_norm": 0.39453125,
      "learning_rate": 7.87991144871697e-06,
      "loss": 0.0578,
      "step": 10040
    },
    {
      "epoch": 12.367328103368713,
      "grad_norm": 0.349609375,
      "learning_rate": 7.808414655274183e-06,
      "loss": 0.0504,
      "step": 10050
    },
    {
      "epoch": 12.379633902476542,
      "grad_norm": 0.52734375,
      "learning_rate": 7.737216215512571e-06,
      "loss": 0.049,
      "step": 10060
    },
    {
      "epoch": 12.391939701584372,
      "grad_norm": 0.318359375,
      "learning_rate": 7.666316632904985e-06,
      "loss": 0.0574,
      "step": 10070
    },
    {
      "epoch": 12.404245500692202,
      "grad_norm": 0.443359375,
      "learning_rate": 7.595716408810888e-06,
      "loss": 0.0338,
      "step": 10080
    },
    {
      "epoch": 12.41655129980003,
      "grad_norm": 0.3203125,
      "learning_rate": 7.525416042472877e-06,
      "loss": 0.0386,
      "step": 10090
    },
    {
      "epoch": 12.42885709890786,
      "grad_norm": 0.287109375,
      "learning_rate": 7.455416031013157e-06,
      "loss": 0.0515,
      "step": 10100
    },
    {
      "epoch": 12.44116289801569,
      "grad_norm": 0.396484375,
      "learning_rate": 7.385716869429959e-06,
      "loss": 0.0618,
      "step": 10110
    },
    {
      "epoch": 12.453468697123519,
      "grad_norm": 0.51171875,
      "learning_rate": 7.3163190505941335e-06,
      "loss": 0.053,
      "step": 10120
    },
    {
      "epoch": 12.465774496231349,
      "grad_norm": 0.337890625,
      "learning_rate": 7.2472230652455734e-06,
      "loss": 0.0622,
      "step": 10130
    },
    {
      "epoch": 12.47808029533918,
      "grad_norm": 0.37890625,
      "learning_rate": 7.178429401989789e-06,
      "loss": 0.0556,
      "step": 10140
    },
    {
      "epoch": 12.490386094447008,
      "grad_norm": 0.314453125,
      "learning_rate": 7.109938547294482e-06,
      "loss": 0.0586,
      "step": 10150
    },
    {
      "epoch": 12.502691893554838,
      "grad_norm": 0.369140625,
      "learning_rate": 7.041750985486045e-06,
      "loss": 0.0444,
      "step": 10160
    },
    {
      "epoch": 12.514997692662668,
      "grad_norm": 0.40234375,
      "learning_rate": 6.973867198746159e-06,
      "loss": 0.0526,
      "step": 10170
    },
    {
      "epoch": 12.527303491770496,
      "grad_norm": 0.515625,
      "learning_rate": 6.906287667108424e-06,
      "loss": 0.0561,
      "step": 10180
    },
    {
      "epoch": 12.539609290878326,
      "grad_norm": 0.43359375,
      "learning_rate": 6.839012868454886e-06,
      "loss": 0.061,
      "step": 10190
    },
    {
      "epoch": 12.551915089986156,
      "grad_norm": 0.5703125,
      "learning_rate": 6.7720432785127465e-06,
      "loss": 0.0577,
      "step": 10200
    },
    {
      "epoch": 12.564220889093985,
      "grad_norm": 0.3671875,
      "learning_rate": 6.705379370850917e-06,
      "loss": 0.0606,
      "step": 10210
    },
    {
      "epoch": 12.576526688201815,
      "grad_norm": 0.390625,
      "learning_rate": 6.639021616876706e-06,
      "loss": 0.0574,
      "step": 10220
    },
    {
      "epoch": 12.588832487309645,
      "grad_norm": 0.349609375,
      "learning_rate": 6.572970485832525e-06,
      "loss": 0.0616,
      "step": 10230
    },
    {
      "epoch": 12.601138286417473,
      "grad_norm": 0.314453125,
      "learning_rate": 6.5072264447924806e-06,
      "loss": 0.047,
      "step": 10240
    },
    {
      "epoch": 12.613444085525304,
      "grad_norm": 0.373046875,
      "learning_rate": 6.441789958659172e-06,
      "loss": 0.0563,
      "step": 10250
    },
    {
      "epoch": 12.625749884633134,
      "grad_norm": 0.458984375,
      "learning_rate": 6.376661490160318e-06,
      "loss": 0.0692,
      "step": 10260
    },
    {
      "epoch": 12.638055683740962,
      "grad_norm": 0.62109375,
      "learning_rate": 6.311841499845522e-06,
      "loss": 0.0464,
      "step": 10270
    },
    {
      "epoch": 12.650361482848792,
      "grad_norm": 0.365234375,
      "learning_rate": 6.247330446083044e-06,
      "loss": 0.0538,
      "step": 10280
    },
    {
      "epoch": 12.662667281956622,
      "grad_norm": 0.50390625,
      "learning_rate": 6.183128785056497e-06,
      "loss": 0.0519,
      "step": 10290
    },
    {
      "epoch": 12.67497308106445,
      "grad_norm": 0.376953125,
      "learning_rate": 6.119236970761671e-06,
      "loss": 0.0516,
      "step": 10300
    },
    {
      "epoch": 12.687278880172281,
      "grad_norm": 0.3125,
      "learning_rate": 6.055655455003289e-06,
      "loss": 0.0594,
      "step": 10310
    },
    {
      "epoch": 12.699584679280111,
      "grad_norm": 0.3359375,
      "learning_rate": 5.992384687391845e-06,
      "loss": 0.0616,
      "step": 10320
    },
    {
      "epoch": 12.71189047838794,
      "grad_norm": 0.44140625,
      "learning_rate": 5.92942511534042e-06,
      "loss": 0.0573,
      "step": 10330
    },
    {
      "epoch": 12.72419627749577,
      "grad_norm": 0.3671875,
      "learning_rate": 5.866777184061467e-06,
      "loss": 0.0591,
      "step": 10340
    },
    {
      "epoch": 12.7365020766036,
      "grad_norm": 0.330078125,
      "learning_rate": 5.804441336563732e-06,
      "loss": 0.0665,
      "step": 10350
    },
    {
      "epoch": 12.74880787571143,
      "grad_norm": 0.36328125,
      "learning_rate": 5.742418013649065e-06,
      "loss": 0.0571,
      "step": 10360
    },
    {
      "epoch": 12.761113674819258,
      "grad_norm": 0.55859375,
      "learning_rate": 5.680707653909356e-06,
      "loss": 0.0514,
      "step": 10370
    },
    {
      "epoch": 12.773419473927088,
      "grad_norm": 0.62890625,
      "learning_rate": 5.619310693723406e-06,
      "loss": 0.0658,
      "step": 10380
    },
    {
      "epoch": 12.785725273034918,
      "grad_norm": 0.416015625,
      "learning_rate": 5.558227567253832e-06,
      "loss": 0.05,
      "step": 10390
    },
    {
      "epoch": 12.798031072142747,
      "grad_norm": 0.5078125,
      "learning_rate": 5.497458706443992e-06,
      "loss": 0.045,
      "step": 10400
    },
    {
      "epoch": 12.810336871250577,
      "grad_norm": 0.5546875,
      "learning_rate": 5.43700454101495e-06,
      "loss": 0.0448,
      "step": 10410
    },
    {
      "epoch": 12.822642670358407,
      "grad_norm": 0.408203125,
      "learning_rate": 5.376865498462463e-06,
      "loss": 0.0478,
      "step": 10420
    },
    {
      "epoch": 12.834948469466235,
      "grad_norm": 0.33984375,
      "learning_rate": 5.317042004053912e-06,
      "loss": 0.0519,
      "step": 10430
    },
    {
      "epoch": 12.847254268574066,
      "grad_norm": 0.30078125,
      "learning_rate": 5.257534480825272e-06,
      "loss": 0.0493,
      "step": 10440
    },
    {
      "epoch": 12.859560067681896,
      "grad_norm": 0.57421875,
      "learning_rate": 5.198343349578216e-06,
      "loss": 0.0596,
      "step": 10450
    },
    {
      "epoch": 12.871865866789724,
      "grad_norm": 0.3671875,
      "learning_rate": 5.139469028877042e-06,
      "loss": 0.0557,
      "step": 10460
    },
    {
      "epoch": 12.884171665897554,
      "grad_norm": 0.32421875,
      "learning_rate": 5.080911935045779e-06,
      "loss": 0.0549,
      "step": 10470
    },
    {
      "epoch": 12.896477465005384,
      "grad_norm": 0.3984375,
      "learning_rate": 5.022672482165203e-06,
      "loss": 0.039,
      "step": 10480
    },
    {
      "epoch": 12.908783264113213,
      "grad_norm": 0.40625,
      "learning_rate": 4.964751082069913e-06,
      "loss": 0.0475,
      "step": 10490
    },
    {
      "epoch": 12.921089063221043,
      "grad_norm": 0.35546875,
      "learning_rate": 4.907148144345458e-06,
      "loss": 0.0332,
      "step": 10500
    },
    {
      "epoch": 12.933394862328873,
      "grad_norm": 0.5859375,
      "learning_rate": 4.849864076325378e-06,
      "loss": 0.0432,
      "step": 10510
    },
    {
      "epoch": 12.945700661436701,
      "grad_norm": 0.32421875,
      "learning_rate": 4.7928992830883925e-06,
      "loss": 0.0622,
      "step": 10520
    },
    {
      "epoch": 12.958006460544532,
      "grad_norm": 0.5625,
      "learning_rate": 4.736254167455473e-06,
      "loss": 0.0394,
      "step": 10530
    },
    {
      "epoch": 12.970312259652362,
      "grad_norm": 0.337890625,
      "learning_rate": 4.679929129987015e-06,
      "loss": 0.0436,
      "step": 10540
    },
    {
      "epoch": 12.98261805876019,
      "grad_norm": 0.52734375,
      "learning_rate": 4.6239245689800595e-06,
      "loss": 0.0497,
      "step": 10550
    },
    {
      "epoch": 12.99492385786802,
      "grad_norm": 0.302734375,
      "learning_rate": 4.568240880465374e-06,
      "loss": 0.0589,
      "step": 10560
    },
    {
      "epoch": 13.00722965697585,
      "grad_norm": 0.6328125,
      "learning_rate": 4.512878458204734e-06,
      "loss": 0.0577,
      "step": 10570
    },
    {
      "epoch": 13.019535456083679,
      "grad_norm": 0.341796875,
      "learning_rate": 4.457837693688121e-06,
      "loss": 0.0537,
      "step": 10580
    },
    {
      "epoch": 13.031841255191509,
      "grad_norm": 0.30859375,
      "learning_rate": 4.403118976130915e-06,
      "loss": 0.0527,
      "step": 10590
    },
    {
      "epoch": 13.044147054299339,
      "grad_norm": 0.396484375,
      "learning_rate": 4.348722692471213e-06,
      "loss": 0.0507,
      "step": 10600
    },
    {
      "epoch": 13.056452853407167,
      "grad_norm": 0.361328125,
      "learning_rate": 4.294649227367026e-06,
      "loss": 0.0569,
      "step": 10610
    },
    {
      "epoch": 13.068758652514997,
      "grad_norm": 0.35546875,
      "learning_rate": 4.240898963193568e-06,
      "loss": 0.0476,
      "step": 10620
    },
    {
      "epoch": 13.081064451622828,
      "grad_norm": 0.48828125,
      "learning_rate": 4.1874722800406105e-06,
      "loss": 0.0525,
      "step": 10630
    },
    {
      "epoch": 13.093370250730656,
      "grad_norm": 0.2421875,
      "learning_rate": 4.134369555709728e-06,
      "loss": 0.0485,
      "step": 10640
    },
    {
      "epoch": 13.105676049838486,
      "grad_norm": 0.384765625,
      "learning_rate": 4.081591165711657e-06,
      "loss": 0.0495,
      "step": 10650
    },
    {
      "epoch": 13.117981848946316,
      "grad_norm": 0.3984375,
      "learning_rate": 4.02913748326364e-06,
      "loss": 0.0453,
      "step": 10660
    },
    {
      "epoch": 13.130287648054146,
      "grad_norm": 0.3671875,
      "learning_rate": 3.977008879286765e-06,
      "loss": 0.0471,
      "step": 10670
    },
    {
      "epoch": 13.142593447161975,
      "grad_norm": 0.431640625,
      "learning_rate": 3.925205722403385e-06,
      "loss": 0.0586,
      "step": 10680
    },
    {
      "epoch": 13.154899246269805,
      "grad_norm": 0.328125,
      "learning_rate": 3.8737283789344655e-06,
      "loss": 0.0477,
      "step": 10690
    },
    {
      "epoch": 13.167205045377635,
      "grad_norm": 0.392578125,
      "learning_rate": 3.822577212897016e-06,
      "loss": 0.0563,
      "step": 10700
    },
    {
      "epoch": 13.179510844485463,
      "grad_norm": 0.380859375,
      "learning_rate": 3.77175258600152e-06,
      "loss": 0.051,
      "step": 10710
    },
    {
      "epoch": 13.191816643593294,
      "grad_norm": 0.5234375,
      "learning_rate": 3.7212548576493756e-06,
      "loss": 0.0456,
      "step": 10720
    },
    {
      "epoch": 13.204122442701124,
      "grad_norm": 0.83203125,
      "learning_rate": 3.6710843849303454e-06,
      "loss": 0.05,
      "step": 10730
    },
    {
      "epoch": 13.216428241808952,
      "grad_norm": 0.322265625,
      "learning_rate": 3.621241522620039e-06,
      "loss": 0.058,
      "step": 10740
    },
    {
      "epoch": 13.228734040916782,
      "grad_norm": 0.3515625,
      "learning_rate": 3.571726623177385e-06,
      "loss": 0.0549,
      "step": 10750
    },
    {
      "epoch": 13.241039840024612,
      "grad_norm": 0.349609375,
      "learning_rate": 3.522540036742161e-06,
      "loss": 0.0424,
      "step": 10760
    },
    {
      "epoch": 13.25334563913244,
      "grad_norm": 0.30078125,
      "learning_rate": 3.473682111132526e-06,
      "loss": 0.0543,
      "step": 10770
    },
    {
      "epoch": 13.26565143824027,
      "grad_norm": 0.54296875,
      "learning_rate": 3.4251531918425394e-06,
      "loss": 0.0479,
      "step": 10780
    },
    {
      "epoch": 13.277957237348101,
      "grad_norm": 0.341796875,
      "learning_rate": 3.3769536220397247e-06,
      "loss": 0.0539,
      "step": 10790
    },
    {
      "epoch": 13.29026303645593,
      "grad_norm": 0.3046875,
      "learning_rate": 3.3290837425626274e-06,
      "loss": 0.06,
      "step": 10800
    },
    {
      "epoch": 13.30256883556376,
      "grad_norm": 0.267578125,
      "learning_rate": 3.281543891918426e-06,
      "loss": 0.0643,
      "step": 10810
    },
    {
      "epoch": 13.31487463467159,
      "grad_norm": 0.39453125,
      "learning_rate": 3.2343344062805536e-06,
      "loss": 0.0514,
      "step": 10820
    },
    {
      "epoch": 13.327180433779418,
      "grad_norm": 0.388671875,
      "learning_rate": 3.187455619486296e-06,
      "loss": 0.0504,
      "step": 10830
    },
    {
      "epoch": 13.339486232887248,
      "grad_norm": 0.328125,
      "learning_rate": 3.1409078630343867e-06,
      "loss": 0.0445,
      "step": 10840
    },
    {
      "epoch": 13.351792031995078,
      "grad_norm": 0.32421875,
      "learning_rate": 3.094691466082772e-06,
      "loss": 0.0561,
      "step": 10850
    },
    {
      "epoch": 13.364097831102907,
      "grad_norm": 0.349609375,
      "learning_rate": 3.0488067554461818e-06,
      "loss": 0.0524,
      "step": 10860
    },
    {
      "epoch": 13.376403630210737,
      "grad_norm": 0.359375,
      "learning_rate": 3.0032540555938904e-06,
      "loss": 0.0488,
      "step": 10870
    },
    {
      "epoch": 13.388709429318567,
      "grad_norm": 0.4140625,
      "learning_rate": 2.9580336886473548e-06,
      "loss": 0.0562,
      "step": 10880
    },
    {
      "epoch": 13.401015228426395,
      "grad_norm": 0.373046875,
      "learning_rate": 2.9131459743779955e-06,
      "loss": 0.0526,
      "step": 10890
    },
    {
      "epoch": 13.413321027534225,
      "grad_norm": 0.33203125,
      "learning_rate": 2.868591230204909e-06,
      "loss": 0.0439,
      "step": 10900
    },
    {
      "epoch": 13.425626826642056,
      "grad_norm": 0.400390625,
      "learning_rate": 2.8243697711926197e-06,
      "loss": 0.0561,
      "step": 10910
    },
    {
      "epoch": 13.437932625749884,
      "grad_norm": 0.58984375,
      "learning_rate": 2.780481910048871e-06,
      "loss": 0.0515,
      "step": 10920
    },
    {
      "epoch": 13.450238424857714,
      "grad_norm": 0.2890625,
      "learning_rate": 2.736927957122387e-06,
      "loss": 0.0534,
      "step": 10930
    },
    {
      "epoch": 13.462544223965544,
      "grad_norm": 0.56640625,
      "learning_rate": 2.6937082204006926e-06,
      "loss": 0.0528,
      "step": 10940
    },
    {
      "epoch": 13.474850023073373,
      "grad_norm": 0.279296875,
      "learning_rate": 2.650823005507952e-06,
      "loss": 0.0601,
      "step": 10950
    },
    {
      "epoch": 13.487155822181203,
      "grad_norm": 0.294921875,
      "learning_rate": 2.6082726157027726e-06,
      "loss": 0.0539,
      "step": 10960
    },
    {
      "epoch": 13.499461621289033,
      "grad_norm": 0.39453125,
      "learning_rate": 2.5660573518760835e-06,
      "loss": 0.0491,
      "step": 10970
    },
    {
      "epoch": 13.511767420396861,
      "grad_norm": 0.412109375,
      "learning_rate": 2.5241775125490197e-06,
      "loss": 0.0609,
      "step": 10980
    },
    {
      "epoch": 13.524073219504691,
      "grad_norm": 0.42578125,
      "learning_rate": 2.4826333938707648e-06,
      "loss": 0.052,
      "step": 10990
    },
    {
      "epoch": 13.536379018612521,
      "grad_norm": 0.59765625,
      "learning_rate": 2.4414252896165224e-06,
      "loss": 0.0563,
      "step": 11000
    },
    {
      "epoch": 13.54868481772035,
      "grad_norm": 0.25390625,
      "learning_rate": 2.4005534911853646e-06,
      "loss": 0.0527,
      "step": 11010
    },
    {
      "epoch": 13.56099061682818,
      "grad_norm": 0.3046875,
      "learning_rate": 2.3600182875982257e-06,
      "loss": 0.0624,
      "step": 11020
    },
    {
      "epoch": 13.57329641593601,
      "grad_norm": 0.365234375,
      "learning_rate": 2.3198199654958676e-06,
      "loss": 0.0467,
      "step": 11030
    },
    {
      "epoch": 13.585602215043838,
      "grad_norm": 0.408203125,
      "learning_rate": 2.2799588091367786e-06,
      "loss": 0.0645,
      "step": 11040
    },
    {
      "epoch": 13.597908014151669,
      "grad_norm": 0.51953125,
      "learning_rate": 2.2404351003952663e-06,
      "loss": 0.051,
      "step": 11050
    },
    {
      "epoch": 13.610213813259499,
      "grad_norm": 0.396484375,
      "learning_rate": 2.201249118759352e-06,
      "loss": 0.0407,
      "step": 11060
    },
    {
      "epoch": 13.622519612367329,
      "grad_norm": 0.326171875,
      "learning_rate": 2.1624011413288957e-06,
      "loss": 0.0531,
      "step": 11070
    },
    {
      "epoch": 13.634825411475157,
      "grad_norm": 0.400390625,
      "learning_rate": 2.123891442813597e-06,
      "loss": 0.0591,
      "step": 11080
    },
    {
      "epoch": 13.647131210582987,
      "grad_norm": 0.3671875,
      "learning_rate": 2.0857202955310183e-06,
      "loss": 0.055,
      "step": 11090
    },
    {
      "epoch": 13.659437009690818,
      "grad_norm": 0.322265625,
      "learning_rate": 2.047887969404705e-06,
      "loss": 0.0529,
      "step": 11100
    },
    {
      "epoch": 13.671742808798646,
      "grad_norm": 0.40234375,
      "learning_rate": 2.0103947319622564e-06,
      "loss": 0.0639,
      "step": 11110
    },
    {
      "epoch": 13.684048607906476,
      "grad_norm": 0.34765625,
      "learning_rate": 1.9732408483334573e-06,
      "loss": 0.06,
      "step": 11120
    },
    {
      "epoch": 13.696354407014306,
      "grad_norm": 0.375,
      "learning_rate": 1.9364265812483737e-06,
      "loss": 0.0457,
      "step": 11130
    },
    {
      "epoch": 13.708660206122135,
      "grad_norm": 0.376953125,
      "learning_rate": 1.8999521910354978e-06,
      "loss": 0.0609,
      "step": 11140
    },
    {
      "epoch": 13.720966005229965,
      "grad_norm": 0.51171875,
      "learning_rate": 1.8638179356199214e-06,
      "loss": 0.0505,
      "step": 11150
    },
    {
      "epoch": 13.733271804337795,
      "grad_norm": 0.392578125,
      "learning_rate": 1.8280240705215057e-06,
      "loss": 0.0497,
      "step": 11160
    },
    {
      "epoch": 13.745577603445623,
      "grad_norm": 0.443359375,
      "learning_rate": 1.7925708488530868e-06,
      "loss": 0.0474,
      "step": 11170
    },
    {
      "epoch": 13.757883402553453,
      "grad_norm": 0.392578125,
      "learning_rate": 1.757458521318661e-06,
      "loss": 0.0561,
      "step": 11180
    },
    {
      "epoch": 13.770189201661283,
      "grad_norm": 0.3203125,
      "learning_rate": 1.7226873362116257e-06,
      "loss": 0.0602,
      "step": 11190
    },
    {
      "epoch": 13.782495000769112,
      "grad_norm": 0.392578125,
      "learning_rate": 1.6882575394130296e-06,
      "loss": 0.061,
      "step": 11200
    },
    {
      "epoch": 13.794800799876942,
      "grad_norm": 0.31640625,
      "learning_rate": 1.6541693743898135e-06,
      "loss": 0.0536,
      "step": 11210
    },
    {
      "epoch": 13.807106598984772,
      "grad_norm": 0.328125,
      "learning_rate": 1.6204230821931232e-06,
      "loss": 0.038,
      "step": 11220
    },
    {
      "epoch": 13.8194123980926,
      "grad_norm": 0.390625,
      "learning_rate": 1.587018901456566e-06,
      "loss": 0.0558,
      "step": 11230
    },
    {
      "epoch": 13.83171819720043,
      "grad_norm": 0.455078125,
      "learning_rate": 1.5539570683945515e-06,
      "loss": 0.0565,
      "step": 11240
    },
    {
      "epoch": 13.84402399630826,
      "grad_norm": 0.380859375,
      "learning_rate": 1.521237816800608e-06,
      "loss": 0.0543,
      "step": 11250
    },
    {
      "epoch": 13.85632979541609,
      "grad_norm": 0.49609375,
      "learning_rate": 1.488861378045725e-06,
      "loss": 0.0446,
      "step": 11260
    },
    {
      "epoch": 13.86863559452392,
      "grad_norm": 0.43359375,
      "learning_rate": 1.456827981076747e-06,
      "loss": 0.0613,
      "step": 11270
    },
    {
      "epoch": 13.88094139363175,
      "grad_norm": 0.4453125,
      "learning_rate": 1.4251378524147097e-06,
      "loss": 0.0417,
      "step": 11280
    },
    {
      "epoch": 13.893247192739578,
      "grad_norm": 0.4609375,
      "learning_rate": 1.3937912161532562e-06,
      "loss": 0.0554,
      "step": 11290
    },
    {
      "epoch": 13.905552991847408,
      "grad_norm": 0.375,
      "learning_rate": 1.3627882939570846e-06,
      "loss": 0.0452,
      "step": 11300
    },
    {
      "epoch": 13.917858790955238,
      "grad_norm": 0.294921875,
      "learning_rate": 1.33212930506032e-06,
      "loss": 0.0501,
      "step": 11310
    },
    {
      "epoch": 13.930164590063066,
      "grad_norm": 0.484375,
      "learning_rate": 1.3018144662650334e-06,
      "loss": 0.0651,
      "step": 11320
    },
    {
      "epoch": 13.942470389170897,
      "grad_norm": 0.474609375,
      "learning_rate": 1.2718439919396309e-06,
      "loss": 0.0533,
      "step": 11330
    },
    {
      "epoch": 13.954776188278727,
      "grad_norm": 0.365234375,
      "learning_rate": 1.2422180940174056e-06,
      "loss": 0.0594,
      "step": 11340
    },
    {
      "epoch": 13.967081987386557,
      "grad_norm": 0.404296875,
      "learning_rate": 1.212936981995011e-06,
      "loss": 0.0577,
      "step": 11350
    },
    {
      "epoch": 13.979387786494385,
      "grad_norm": 0.5,
      "learning_rate": 1.1840008629309673e-06,
      "loss": 0.0561,
      "step": 11360
    },
    {
      "epoch": 13.991693585602215,
      "grad_norm": 0.57421875,
      "learning_rate": 1.15540994144423e-06,
      "loss": 0.0571,
      "step": 11370
    },
    {
      "epoch": 14.003999384710045,
      "grad_norm": 0.384765625,
      "learning_rate": 1.1271644197126952e-06,
      "loss": 0.0441,
      "step": 11380
    },
    {
      "epoch": 14.016305183817874,
      "grad_norm": 0.3125,
      "learning_rate": 1.0992644974718247e-06,
      "loss": 0.0442,
      "step": 11390
    },
    {
      "epoch": 14.028610982925704,
      "grad_norm": 0.384765625,
      "learning_rate": 1.0717103720132016e-06,
      "loss": 0.0551,
      "step": 11400
    },
    {
      "epoch": 14.040916782033534,
      "grad_norm": 0.37890625,
      "learning_rate": 1.0445022381831315e-06,
      "loss": 0.0491,
      "step": 11410
    },
    {
      "epoch": 14.053222581141362,
      "grad_norm": 0.388671875,
      "learning_rate": 1.017640288381283e-06,
      "loss": 0.0625,
      "step": 11420
    },
    {
      "epoch": 14.065528380249193,
      "grad_norm": 0.3671875,
      "learning_rate": 9.911247125593047e-07,
      "loss": 0.0475,
      "step": 11430
    },
    {
      "epoch": 14.077834179357023,
      "grad_norm": 0.400390625,
      "learning_rate": 9.649556982195163e-07,
      "loss": 0.0546,
      "step": 11440
    },
    {
      "epoch": 14.090139978464851,
      "grad_norm": 0.291015625,
      "learning_rate": 9.391334304135524e-07,
      "loss": 0.0612,
      "step": 11450
    },
    {
      "epoch": 14.102445777572681,
      "grad_norm": 0.43359375,
      "learning_rate": 9.136580917410486e-07,
      "loss": 0.0642,
      "step": 11460
    },
    {
      "epoch": 14.114751576680511,
      "grad_norm": 0.337890625,
      "learning_rate": 8.885298623483918e-07,
      "loss": 0.0636,
      "step": 11470
    },
    {
      "epoch": 14.12705737578834,
      "grad_norm": 0.373046875,
      "learning_rate": 8.63748919927393e-07,
      "loss": 0.0443,
      "step": 11480
    },
    {
      "epoch": 14.13936317489617,
      "grad_norm": 0.314453125,
      "learning_rate": 8.393154397140834e-07,
      "loss": 0.0431,
      "step": 11490
    },
    {
      "epoch": 14.151668974004,
      "grad_norm": 0.4453125,
      "learning_rate": 8.152295944874266e-07,
      "loss": 0.0593,
      "step": 11500
    },
    {
      "epoch": 14.163974773111828,
      "grad_norm": 0.390625,
      "learning_rate": 7.914915545681245e-07,
      "loss": 0.0573,
      "step": 11510
    },
    {
      "epoch": 14.176280572219659,
      "grad_norm": 0.40625,
      "learning_rate": 7.681014878174187e-07,
      "loss": 0.0541,
      "step": 11520
    },
    {
      "epoch": 14.188586371327489,
      "grad_norm": 0.46875,
      "learning_rate": 7.450595596358855e-07,
      "loss": 0.0556,
      "step": 11530
    },
    {
      "epoch": 14.200892170435317,
      "grad_norm": 0.412109375,
      "learning_rate": 7.223659329622712e-07,
      "loss": 0.0595,
      "step": 11540
    },
    {
      "epoch": 14.213197969543147,
      "grad_norm": 0.494140625,
      "learning_rate": 7.00020768272347e-07,
      "loss": 0.0625,
      "step": 11550
    },
    {
      "epoch": 14.225503768650977,
      "grad_norm": 0.416015625,
      "learning_rate": 6.780242235777557e-07,
      "loss": 0.0467,
      "step": 11560
    },
    {
      "epoch": 14.237809567758806,
      "grad_norm": 0.404296875,
      "learning_rate": 6.563764544249285e-07,
      "loss": 0.0551,
      "step": 11570
    },
    {
      "epoch": 14.250115366866636,
      "grad_norm": 0.365234375,
      "learning_rate": 6.350776138939474e-07,
      "loss": 0.0693,
      "step": 11580
    },
    {
      "epoch": 14.262421165974466,
      "grad_norm": 0.34765625,
      "learning_rate": 6.141278525974903e-07,
      "loss": 0.0502,
      "step": 11590
    },
    {
      "epoch": 14.274726965082294,
      "grad_norm": 0.41796875,
      "learning_rate": 5.935273186797485e-07,
      "loss": 0.0603,
      "step": 11600
    },
    {
      "epoch": 14.287032764190124,
      "grad_norm": 0.890625,
      "learning_rate": 5.73276157815389e-07,
      "loss": 0.0642,
      "step": 11610
    },
    {
      "epoch": 14.299338563297955,
      "grad_norm": 0.40234375,
      "learning_rate": 5.533745132085266e-07,
      "loss": 0.0559,
      "step": 11620
    },
    {
      "epoch": 14.311644362405783,
      "grad_norm": 0.71484375,
      "learning_rate": 5.338225255916929e-07,
      "loss": 0.054,
      "step": 11630
    },
    {
      "epoch": 14.323950161513613,
      "grad_norm": 0.33203125,
      "learning_rate": 5.146203332248578e-07,
      "loss": 0.0606,
      "step": 11640
    },
    {
      "epoch": 14.336255960621443,
      "grad_norm": 0.373046875,
      "learning_rate": 4.957680718944647e-07,
      "loss": 0.0453,
      "step": 11650
    },
    {
      "epoch": 14.348561759729272,
      "grad_norm": 0.30078125,
      "learning_rate": 4.772658749124304e-07,
      "loss": 0.0499,
      "step": 11660
    },
    {
      "epoch": 14.360867558837102,
      "grad_norm": 0.349609375,
      "learning_rate": 4.591138731152467e-07,
      "loss": 0.0588,
      "step": 11670
    },
    {
      "epoch": 14.373173357944932,
      "grad_norm": 0.3671875,
      "learning_rate": 4.413121948630139e-07,
      "loss": 0.0705,
      "step": 11680
    },
    {
      "epoch": 14.38547915705276,
      "grad_norm": 0.369140625,
      "learning_rate": 4.238609660385695e-07,
      "loss": 0.051,
      "step": 11690
    },
    {
      "epoch": 14.39778495616059,
      "grad_norm": 0.318359375,
      "learning_rate": 4.0676031004657224e-07,
      "loss": 0.057,
      "step": 11700
    },
    {
      "epoch": 14.41009075526842,
      "grad_norm": 0.53125,
      "learning_rate": 3.9001034781264714e-07,
      "loss": 0.0482,
      "step": 11710
    },
    {
      "epoch": 14.422396554376249,
      "grad_norm": 0.369140625,
      "learning_rate": 3.736111977825196e-07,
      "loss": 0.0526,
      "step": 11720
    },
    {
      "epoch": 14.434702353484079,
      "grad_norm": 0.427734375,
      "learning_rate": 3.575629759211718e-07,
      "loss": 0.0625,
      "step": 11730
    },
    {
      "epoch": 14.44700815259191,
      "grad_norm": 0.5,
      "learning_rate": 3.418657957120486e-07,
      "loss": 0.0555,
      "step": 11740
    },
    {
      "epoch": 14.45931395169974,
      "grad_norm": 0.34375,
      "learning_rate": 3.2651976815622484e-07,
      "loss": 0.0533,
      "step": 11750
    },
    {
      "epoch": 14.471619750807568,
      "grad_norm": 0.546875,
      "learning_rate": 3.1152500177163977e-07,
      "loss": 0.0674,
      "step": 11760
    },
    {
      "epoch": 14.483925549915398,
      "grad_norm": 0.341796875,
      "learning_rate": 2.968816025923193e-07,
      "loss": 0.0485,
      "step": 11770
    },
    {
      "epoch": 14.496231349023228,
      "grad_norm": 0.486328125,
      "learning_rate": 2.825896741676326e-07,
      "loss": 0.0451,
      "step": 11780
    },
    {
      "epoch": 14.508537148131056,
      "grad_norm": 0.46484375,
      "learning_rate": 2.6864931756156455e-07,
      "loss": 0.0551,
      "step": 11790
    },
    {
      "epoch": 14.520842947238886,
      "grad_norm": 0.251953125,
      "learning_rate": 2.550606313519777e-07,
      "loss": 0.0547,
      "step": 11800
    },
    {
      "epoch": 14.533148746346717,
      "grad_norm": 0.341796875,
      "learning_rate": 2.41823711629946e-07,
      "loss": 0.0392,
      "step": 11810
    },
    {
      "epoch": 14.545454545454545,
      "grad_norm": 0.609375,
      "learning_rate": 2.289386519990555e-07,
      "loss": 0.0472,
      "step": 11820
    },
    {
      "epoch": 14.557760344562375,
      "grad_norm": 0.353515625,
      "learning_rate": 2.1640554357474917e-07,
      "loss": 0.0495,
      "step": 11830
    },
    {
      "epoch": 14.570066143670205,
      "grad_norm": 0.263671875,
      "learning_rate": 2.0422447498367748e-07,
      "loss": 0.0485,
      "step": 11840
    },
    {
      "epoch": 14.582371942778034,
      "grad_norm": 0.5234375,
      "learning_rate": 1.923955323630877e-07,
      "loss": 0.0412,
      "step": 11850
    },
    {
      "epoch": 14.594677741885864,
      "grad_norm": 0.431640625,
      "learning_rate": 1.8091879936018574e-07,
      "loss": 0.0571,
      "step": 11860
    },
    {
      "epoch": 14.606983540993694,
      "grad_norm": 0.30859375,
      "learning_rate": 1.697943571315752e-07,
      "loss": 0.0542,
      "step": 11870
    },
    {
      "epoch": 14.619289340101522,
      "grad_norm": 0.56640625,
      "learning_rate": 1.5902228434266364e-07,
      "loss": 0.0487,
      "step": 11880
    },
    {
      "epoch": 14.631595139209352,
      "grad_norm": 0.29296875,
      "learning_rate": 1.4860265716710732e-07,
      "loss": 0.0586,
      "step": 11890
    },
    {
      "epoch": 14.643900938317183,
      "grad_norm": 0.3671875,
      "learning_rate": 1.3853554928629496e-07,
      "loss": 0.0488,
      "step": 11900
    },
    {
      "epoch": 14.656206737425011,
      "grad_norm": 0.416015625,
      "learning_rate": 1.2882103188878169e-07,
      "loss": 0.0583,
      "step": 11910
    },
    {
      "epoch": 14.668512536532841,
      "grad_norm": 0.3359375,
      "learning_rate": 1.1945917366985025e-07,
      "loss": 0.0497,
      "step": 11920
    },
    {
      "epoch": 14.680818335640671,
      "grad_norm": 0.412109375,
      "learning_rate": 1.1045004083095056e-07,
      "loss": 0.0509,
      "step": 11930
    },
    {
      "epoch": 14.6931241347485,
      "grad_norm": 0.341796875,
      "learning_rate": 1.0179369707929432e-07,
      "loss": 0.0386,
      "step": 11940
    },
    {
      "epoch": 14.70542993385633,
      "grad_norm": 0.44921875,
      "learning_rate": 9.349020362737215e-08,
      "loss": 0.0492,
      "step": 11950
    },
    {
      "epoch": 14.71773573296416,
      "grad_norm": 0.3671875,
      "learning_rate": 8.553961919252617e-08,
      "loss": 0.0505,
      "step": 11960
    },
    {
      "epoch": 14.730041532071988,
      "grad_norm": 0.43359375,
      "learning_rate": 7.794199999654473e-08,
      "loss": 0.0575,
      "step": 11970
    },
    {
      "epoch": 14.742347331179818,
      "grad_norm": 0.50390625,
      "learning_rate": 7.069739976524603e-08,
      "loss": 0.0502,
      "step": 11980
    },
    {
      "epoch": 14.754653130287648,
      "grad_norm": 0.478515625,
      "learning_rate": 6.380586972811186e-08,
      "loss": 0.0576,
      "step": 11990
    },
    {
      "epoch": 14.766958929395477,
      "grad_norm": 0.34375,
      "learning_rate": 5.726745861792671e-08,
      "loss": 0.0544,
      "step": 12000
    },
    {
      "epoch": 14.779264728503307,
      "grad_norm": 0.3828125,
      "learning_rate": 5.108221267043356e-08,
      "loss": 0.0503,
      "step": 12010
    },
    {
      "epoch": 14.791570527611137,
      "grad_norm": 0.4296875,
      "learning_rate": 4.525017562398981e-08,
      "loss": 0.0412,
      "step": 12020
    },
    {
      "epoch": 14.803876326718967,
      "grad_norm": 0.349609375,
      "learning_rate": 3.977138871927299e-08,
      "loss": 0.0519,
      "step": 12030
    },
    {
      "epoch": 14.816182125826796,
      "grad_norm": 0.3515625,
      "learning_rate": 3.464589069899771e-08,
      "loss": 0.05,
      "step": 12040
    },
    {
      "epoch": 14.828487924934626,
      "grad_norm": 0.443359375,
      "learning_rate": 2.987371780761583e-08,
      "loss": 0.0493,
      "step": 12050
    },
    {
      "epoch": 14.840793724042456,
      "grad_norm": 0.376953125,
      "learning_rate": 2.54549037910945e-08,
      "loss": 0.0548,
      "step": 12060
    },
    {
      "epoch": 14.853099523150284,
      "grad_norm": 0.380859375,
      "learning_rate": 2.138947989663298e-08,
      "loss": 0.053,
      "step": 12070
    },
    {
      "epoch": 14.865405322258114,
      "grad_norm": 0.326171875,
      "learning_rate": 1.7677474872490607e-08,
      "loss": 0.0525,
      "step": 12080
    },
    {
      "epoch": 14.877711121365945,
      "grad_norm": 0.48828125,
      "learning_rate": 1.4318914967742514e-08,
      "loss": 0.0497,
      "step": 12090
    },
    {
      "epoch": 14.890016920473773,
      "grad_norm": 0.435546875,
      "learning_rate": 1.1313823932118662e-08,
      "loss": 0.062,
      "step": 12100
    },
    {
      "epoch": 14.902322719581603,
      "grad_norm": 0.703125,
      "learning_rate": 8.662223015826199e-09,
      "loss": 0.0415,
      "step": 12110
    },
    {
      "epoch": 14.914628518689433,
      "grad_norm": 0.369140625,
      "learning_rate": 6.3641309694051355e-09,
      "loss": 0.0505,
      "step": 12120
    },
    {
      "epoch": 14.926934317797262,
      "grad_norm": 0.2734375,
      "learning_rate": 4.4195640435840125e-09,
      "loss": 0.0531,
      "step": 12130
    },
    {
      "epoch": 14.939240116905092,
      "grad_norm": 0.375,
      "learning_rate": 2.8285359891855323e-09,
      "loss": 0.0464,
      "step": 12140
    },
    {
      "epoch": 14.951545916012922,
      "grad_norm": 0.32421875,
      "learning_rate": 1.5910580570099864e-09,
      "loss": 0.0339,
      "step": 12150
    },
    {
      "epoch": 14.96385171512075,
      "grad_norm": 0.35546875,
      "learning_rate": 7.071389977519882e-10,
      "loss": 0.0516,
      "step": 12160
    },
    {
      "epoch": 14.97615751422858,
      "grad_norm": 0.310546875,
      "learning_rate": 1.7678506196716628e-10,
      "loss": 0.057,
      "step": 12170
    },
    {
      "epoch": 14.98846331333641,
      "grad_norm": 0.375,
      "learning_rate": 0.0,
      "loss": 0.071,
      "step": 12180
    },
    {
      "epoch": 14.98846331333641,
      "step": 12180,
      "total_flos": 3.685575352052089e+18,
      "train_loss": 0.11660404325216667,
      "train_runtime": 20592.3802,
      "train_samples_per_second": 37.88,
      "train_steps_per_second": 0.591
    }
  ],
  "logging_steps": 10,
  "max_steps": 12180,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 5000,
  "total_flos": 3.685575352052089e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
