{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 21050,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 0.00039992399049881236,
      "loss": 0.4214,
      "step": 10
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00039973396674584325,
      "loss": 0.4151,
      "step": 20
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00039954394299287414,
      "loss": 0.5521,
      "step": 30
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.00039939192399049883,
      "loss": 0.5174,
      "step": 40
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0003992019002375297,
      "loss": 0.3911,
      "step": 50
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0003990308788598575,
      "loss": 0.4478,
      "step": 60
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00039884085510688837,
      "loss": 0.5072,
      "step": 70
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00039865083135391926,
      "loss": 0.4366,
      "step": 80
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00039846080760095015,
      "loss": 0.5298,
      "step": 90
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00039827078384798104,
      "loss": 0.4686,
      "step": 100
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0003980807600950119,
      "loss": 0.4737,
      "step": 110
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00039789073634204276,
      "loss": 0.5002,
      "step": 120
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00039770071258907365,
      "loss": 0.5061,
      "step": 130
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00039751068883610454,
      "loss": 0.4835,
      "step": 140
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0003973206650831354,
      "loss": 0.6463,
      "step": 150
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0003971306413301663,
      "loss": 0.5181,
      "step": 160
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00039694061757719715,
      "loss": 0.4514,
      "step": 170
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00039675059382422804,
      "loss": 0.5467,
      "step": 180
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00039656057007125893,
      "loss": 0.5186,
      "step": 190
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0003963705463182898,
      "loss": 0.5941,
      "step": 200
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0003961805225653207,
      "loss": 0.4997,
      "step": 210
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00039599049881235154,
      "loss": 0.5133,
      "step": 220
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00039580047505938243,
      "loss": 0.5084,
      "step": 230
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0003956104513064133,
      "loss": 0.5436,
      "step": 240
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0003954204275534442,
      "loss": 0.4827,
      "step": 250
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0003952304038004751,
      "loss": 0.4279,
      "step": 260
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00039504038004750593,
      "loss": 0.5783,
      "step": 270
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0003948503562945368,
      "loss": 0.5915,
      "step": 280
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00039466033254156776,
      "loss": 0.8238,
      "step": 290
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0003944703087885986,
      "loss": 0.5106,
      "step": 300
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0003942802850356295,
      "loss": 0.501,
      "step": 310
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0003940902612826603,
      "loss": 0.4656,
      "step": 320
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0003939002375296912,
      "loss": 0.5555,
      "step": 330
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00039371021377672215,
      "loss": 0.5859,
      "step": 340
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.000393520190023753,
      "loss": 0.5039,
      "step": 350
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0003933301662707839,
      "loss": 0.5317,
      "step": 360
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00039315914489311164,
      "loss": 0.4699,
      "step": 370
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0003929691211401425,
      "loss": 0.5236,
      "step": 380
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0003927790973871734,
      "loss": 0.5425,
      "step": 390
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0003925890736342043,
      "loss": 0.5799,
      "step": 400
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0003923990498812352,
      "loss": 0.5033,
      "step": 410
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.000392209026128266,
      "loss": 0.5809,
      "step": 420
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0003920190023752969,
      "loss": 0.5323,
      "step": 430
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0003918289786223278,
      "loss": 0.535,
      "step": 440
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0003916389548693587,
      "loss": 0.4854,
      "step": 450
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0003914489311163896,
      "loss": 0.5327,
      "step": 460
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0003912589073634204,
      "loss": 0.5487,
      "step": 470
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0003910688836104513,
      "loss": 0.5155,
      "step": 480
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0003908788598574822,
      "loss": 0.5219,
      "step": 490
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0003906888361045131,
      "loss": 0.5452,
      "step": 500
    },
    {
      "epoch": 0.24,
      "eval_accuracy": 0.7717889908256881,
      "eval_loss": 0.5153636336326599,
      "eval_runtime": 0.5004,
      "eval_samples_per_second": 1742.584,
      "eval_steps_per_second": 13.989,
      "step": 500
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00039049881235154397,
      "loss": 0.5285,
      "step": 510
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0003903087885985748,
      "loss": 0.574,
      "step": 520
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00039011876484560575,
      "loss": 0.6473,
      "step": 530
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00038992874109263664,
      "loss": 0.5261,
      "step": 540
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00038973871733966747,
      "loss": 0.5318,
      "step": 550
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00038954869358669836,
      "loss": 0.5102,
      "step": 560
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0003893586698337292,
      "loss": 0.6123,
      "step": 570
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00038916864608076014,
      "loss": 0.6456,
      "step": 580
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.000388978622327791,
      "loss": 0.6551,
      "step": 590
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00038878859857482186,
      "loss": 0.6727,
      "step": 600
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00038859857482185275,
      "loss": 0.7257,
      "step": 610
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0003884085510688836,
      "loss": 0.6725,
      "step": 620
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00038821852731591453,
      "loss": 0.6853,
      "step": 630
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0003880285035629454,
      "loss": 0.7166,
      "step": 640
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00038783847980997625,
      "loss": 0.6734,
      "step": 650
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00038764845605700714,
      "loss": 0.7282,
      "step": 660
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00038745843230403803,
      "loss": 0.7102,
      "step": 670
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0003872684085510689,
      "loss": 0.7019,
      "step": 680
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0003870783847980998,
      "loss": 0.7584,
      "step": 690
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00038688836104513064,
      "loss": 0.698,
      "step": 700
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00038669833729216153,
      "loss": 0.7021,
      "step": 710
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0003865083135391924,
      "loss": 0.6836,
      "step": 720
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0003863182897862233,
      "loss": 0.69,
      "step": 730
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0003861282660332542,
      "loss": 0.6915,
      "step": 740
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00038593824228028503,
      "loss": 0.6795,
      "step": 750
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0003857482185273159,
      "loss": 0.7055,
      "step": 760
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0003855581947743468,
      "loss": 0.7012,
      "step": 770
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0003853681710213777,
      "loss": 0.6797,
      "step": 780
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0003851781472684086,
      "loss": 0.6928,
      "step": 790
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0003849881235154395,
      "loss": 0.67,
      "step": 800
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0003847980997624703,
      "loss": 0.6693,
      "step": 810
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0003846080760095012,
      "loss": 0.6886,
      "step": 820
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0003844180522565321,
      "loss": 0.6927,
      "step": 830
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.000384228028503563,
      "loss": 0.6899,
      "step": 840
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00038403800475059386,
      "loss": 0.6919,
      "step": 850
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0003838479809976247,
      "loss": 0.6915,
      "step": 860
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0003836579572446556,
      "loss": 0.6983,
      "step": 870
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0003834679334916865,
      "loss": 0.6781,
      "step": 880
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00038327790973871737,
      "loss": 0.7062,
      "step": 890
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00038308788598574825,
      "loss": 0.7039,
      "step": 900
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0003828978622327791,
      "loss": 0.6843,
      "step": 910
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00038270783847981,
      "loss": 0.6886,
      "step": 920
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0003825178147268409,
      "loss": 0.6964,
      "step": 930
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00038232779097387176,
      "loss": 0.6783,
      "step": 940
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00038213776722090264,
      "loss": 0.6919,
      "step": 950
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0003819477434679335,
      "loss": 0.681,
      "step": 960
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00038175771971496437,
      "loss": 0.6753,
      "step": 970
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0003815676959619953,
      "loss": 0.6958,
      "step": 980
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00038137767220902614,
      "loss": 0.6725,
      "step": 990
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00038118764845605703,
      "loss": 0.6959,
      "step": 1000
    },
    {
      "epoch": 0.48,
      "eval_accuracy": 0.4908256880733945,
      "eval_loss": 0.6936191916465759,
      "eval_runtime": 0.502,
      "eval_samples_per_second": 1737.084,
      "eval_steps_per_second": 13.944,
      "step": 1000
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00038099762470308787,
      "loss": 0.6972,
      "step": 1010
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00038080760095011876,
      "loss": 0.6836,
      "step": 1020
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0003806175771971497,
      "loss": 0.6808,
      "step": 1030
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00038042755344418053,
      "loss": 0.7069,
      "step": 1040
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0003802375296912114,
      "loss": 0.6897,
      "step": 1050
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00038004750593824226,
      "loss": 0.6877,
      "step": 1060
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00037985748218527315,
      "loss": 0.707,
      "step": 1070
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0003796674584323041,
      "loss": 0.6859,
      "step": 1080
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0003794774346793349,
      "loss": 0.6772,
      "step": 1090
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0003792874109263658,
      "loss": 0.6906,
      "step": 1100
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0003790973871733967,
      "loss": 0.6714,
      "step": 1110
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00037890736342042754,
      "loss": 0.6934,
      "step": 1120
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0003787173396674585,
      "loss": 0.7037,
      "step": 1130
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0003785273159144893,
      "loss": 0.6953,
      "step": 1140
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0003783372921615202,
      "loss": 0.6907,
      "step": 1150
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0003781472684085511,
      "loss": 0.6879,
      "step": 1160
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.000377957244655582,
      "loss": 0.7007,
      "step": 1170
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00037776722090261287,
      "loss": 0.6898,
      "step": 1180
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0003775771971496437,
      "loss": 0.6875,
      "step": 1190
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0003773871733966746,
      "loss": 0.6815,
      "step": 1200
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0003771971496437055,
      "loss": 0.6613,
      "step": 1210
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00037700712589073637,
      "loss": 0.6992,
      "step": 1220
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00037681710213776726,
      "loss": 0.6854,
      "step": 1230
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00037662707838479815,
      "loss": 0.6932,
      "step": 1240
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.000376437054631829,
      "loss": 0.6954,
      "step": 1250
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00037624703087885987,
      "loss": 0.7024,
      "step": 1260
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00037605700712589076,
      "loss": 0.6789,
      "step": 1270
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00037586698337292165,
      "loss": 0.691,
      "step": 1280
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00037567695961995254,
      "loss": 0.6731,
      "step": 1290
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00037548693586698337,
      "loss": 0.6692,
      "step": 1300
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00037529691211401426,
      "loss": 0.6773,
      "step": 1310
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00037510688836104515,
      "loss": 0.6973,
      "step": 1320
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00037491686460807604,
      "loss": 0.6807,
      "step": 1330
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00037472684085510693,
      "loss": 0.6951,
      "step": 1340
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00037453681710213776,
      "loss": 0.7037,
      "step": 1350
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00037434679334916865,
      "loss": 0.6916,
      "step": 1360
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00037415676959619954,
      "loss": 0.6898,
      "step": 1370
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00037396674584323043,
      "loss": 0.6939,
      "step": 1380
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0003737767220902613,
      "loss": 0.6846,
      "step": 1390
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00037358669833729215,
      "loss": 0.6908,
      "step": 1400
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00037339667458432304,
      "loss": 0.6925,
      "step": 1410
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00037320665083135393,
      "loss": 0.7042,
      "step": 1420
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0003730166270783848,
      "loss": 0.6896,
      "step": 1430
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0003728266033254157,
      "loss": 0.689,
      "step": 1440
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00037263657957244654,
      "loss": 0.6956,
      "step": 1450
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00037244655581947743,
      "loss": 0.6898,
      "step": 1460
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0003722565320665083,
      "loss": 0.6862,
      "step": 1470
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0003720665083135392,
      "loss": 0.6773,
      "step": 1480
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0003718764845605701,
      "loss": 0.6916,
      "step": 1490
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.000371686460807601,
      "loss": 0.6727,
      "step": 1500
    },
    {
      "epoch": 0.71,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.71812903881073,
      "eval_runtime": 0.4988,
      "eval_samples_per_second": 1748.175,
      "eval_steps_per_second": 14.034,
      "step": 1500
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0003714964370546318,
      "loss": 0.6863,
      "step": 1510
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00037130641330166276,
      "loss": 0.6935,
      "step": 1520
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0003711163895486936,
      "loss": 0.6944,
      "step": 1530
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0003709263657957245,
      "loss": 0.7033,
      "step": 1540
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0003707363420427554,
      "loss": 0.688,
      "step": 1550
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0003705463182897862,
      "loss": 0.6957,
      "step": 1560
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00037035629453681715,
      "loss": 0.6958,
      "step": 1570
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.000370166270783848,
      "loss": 0.6902,
      "step": 1580
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0003699762470308789,
      "loss": 0.6964,
      "step": 1590
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00036978622327790976,
      "loss": 0.6844,
      "step": 1600
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0003695961995249406,
      "loss": 0.7067,
      "step": 1610
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00036940617577197154,
      "loss": 0.6791,
      "step": 1620
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00036921615201900243,
      "loss": 0.697,
      "step": 1630
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00036902612826603327,
      "loss": 0.6928,
      "step": 1640
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00036883610451306415,
      "loss": 0.6944,
      "step": 1650
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.000368646080760095,
      "loss": 0.6853,
      "step": 1660
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00036845605700712593,
      "loss": 0.6647,
      "step": 1670
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0003682660332541568,
      "loss": 0.7111,
      "step": 1680
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00036807600950118766,
      "loss": 0.6882,
      "step": 1690
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00036788598574821854,
      "loss": 0.6944,
      "step": 1700
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0003676959619952494,
      "loss": 0.6981,
      "step": 1710
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0003675059382422803,
      "loss": 0.6867,
      "step": 1720
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0003673159144893112,
      "loss": 0.6908,
      "step": 1730
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00036712589073634205,
      "loss": 0.6963,
      "step": 1740
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00036693586698337293,
      "loss": 0.6926,
      "step": 1750
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0003667458432304038,
      "loss": 0.6895,
      "step": 1760
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0003665558194774347,
      "loss": 0.6863,
      "step": 1770
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0003663657957244656,
      "loss": 0.6718,
      "step": 1780
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00036617577197149644,
      "loss": 0.6725,
      "step": 1790
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0003659857482185273,
      "loss": 0.6874,
      "step": 1800
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0003657957244655582,
      "loss": 0.6888,
      "step": 1810
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0003656057007125891,
      "loss": 0.691,
      "step": 1820
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00036541567695962,
      "loss": 0.6941,
      "step": 1830
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0003652256532066508,
      "loss": 0.7015,
      "step": 1840
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0003650356294536817,
      "loss": 0.7002,
      "step": 1850
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0003648456057007126,
      "loss": 0.6954,
      "step": 1860
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0003646555819477435,
      "loss": 0.6968,
      "step": 1870
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0003644655581947744,
      "loss": 0.6966,
      "step": 1880
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0003642755344418052,
      "loss": 0.6881,
      "step": 1890
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0003640855106888361,
      "loss": 0.6919,
      "step": 1900
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.000363895486935867,
      "loss": 0.6875,
      "step": 1910
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0003637054631828979,
      "loss": 0.6887,
      "step": 1920
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00036351543942992877,
      "loss": 0.6809,
      "step": 1930
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00036332541567695966,
      "loss": 0.6708,
      "step": 1940
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0003631353919239905,
      "loss": 0.6855,
      "step": 1950
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0003629453681710214,
      "loss": 0.6921,
      "step": 1960
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00036275534441805227,
      "loss": 0.6899,
      "step": 1970
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00036256532066508316,
      "loss": 0.6954,
      "step": 1980
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00036237529691211405,
      "loss": 0.6855,
      "step": 1990
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0003621852731591449,
      "loss": 0.6776,
      "step": 2000
    },
    {
      "epoch": 0.95,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7201938629150391,
      "eval_runtime": 0.5006,
      "eval_samples_per_second": 1741.896,
      "eval_steps_per_second": 13.983,
      "step": 2000
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00036199524940617577,
      "loss": 0.6973,
      "step": 2010
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00036180522565320666,
      "loss": 0.6984,
      "step": 2020
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00036161520190023755,
      "loss": 0.6916,
      "step": 2030
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00036142517814726844,
      "loss": 0.7036,
      "step": 2040
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00036123515439429927,
      "loss": 0.6971,
      "step": 2050
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00036104513064133016,
      "loss": 0.7013,
      "step": 2060
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0003608551068883611,
      "loss": 0.6834,
      "step": 2070
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00036066508313539194,
      "loss": 0.6945,
      "step": 2080
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00036047505938242283,
      "loss": 0.6945,
      "step": 2090
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00036028503562945366,
      "loss": 0.6906,
      "step": 2100
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00036009501187648455,
      "loss": 0.6901,
      "step": 2110
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0003599049881235155,
      "loss": 0.6944,
      "step": 2120
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00035971496437054633,
      "loss": 0.7141,
      "step": 2130
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0003595249406175772,
      "loss": 0.6979,
      "step": 2140
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00035933491686460805,
      "loss": 0.6892,
      "step": 2150
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.000359144893111639,
      "loss": 0.6884,
      "step": 2160
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0003589548693586699,
      "loss": 0.6943,
      "step": 2170
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0003587648456057007,
      "loss": 0.69,
      "step": 2180
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0003585748218527316,
      "loss": 0.6707,
      "step": 2190
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0003583847980997625,
      "loss": 0.6941,
      "step": 2200
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0003581947743467934,
      "loss": 0.6921,
      "step": 2210
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0003580047505938243,
      "loss": 0.6782,
      "step": 2220
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0003578147268408551,
      "loss": 0.6944,
      "step": 2230
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.000357624703087886,
      "loss": 0.6814,
      "step": 2240
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0003574346793349169,
      "loss": 0.6882,
      "step": 2250
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0003572446555819478,
      "loss": 0.6995,
      "step": 2260
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00035705463182897866,
      "loss": 0.6988,
      "step": 2270
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0003568646080760095,
      "loss": 0.6934,
      "step": 2280
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0003566745843230404,
      "loss": 0.6816,
      "step": 2290
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0003564845605700713,
      "loss": 0.6949,
      "step": 2300
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00035629453681710216,
      "loss": 0.6893,
      "step": 2310
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00035610451306413305,
      "loss": 0.6958,
      "step": 2320
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00035591448931116394,
      "loss": 0.6779,
      "step": 2330
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0003557244655581948,
      "loss": 0.693,
      "step": 2340
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00035553444180522567,
      "loss": 0.6899,
      "step": 2350
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00035534441805225655,
      "loss": 0.6797,
      "step": 2360
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00035515439429928744,
      "loss": 0.6981,
      "step": 2370
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00035496437054631833,
      "loss": 0.683,
      "step": 2380
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00035477434679334917,
      "loss": 0.6793,
      "step": 2390
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00035458432304038006,
      "loss": 0.6981,
      "step": 2400
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00035439429928741094,
      "loss": 0.7016,
      "step": 2410
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00035420427553444183,
      "loss": 0.6926,
      "step": 2420
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0003540142517814727,
      "loss": 0.6915,
      "step": 2430
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0003538432304038005,
      "loss": 0.689,
      "step": 2440
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00035365320665083137,
      "loss": 0.6815,
      "step": 2450
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00035346318289786226,
      "loss": 0.6897,
      "step": 2460
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00035327315914489315,
      "loss": 0.7009,
      "step": 2470
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.000353083135391924,
      "loss": 0.6846,
      "step": 2480
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0003528931116389549,
      "loss": 0.6986,
      "step": 2490
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00035270308788598576,
      "loss": 0.7048,
      "step": 2500
    },
    {
      "epoch": 1.19,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6934131383895874,
      "eval_runtime": 0.4999,
      "eval_samples_per_second": 1744.491,
      "eval_steps_per_second": 14.004,
      "step": 2500
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00035251306413301665,
      "loss": 0.6886,
      "step": 2510
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00035232304038004754,
      "loss": 0.6856,
      "step": 2520
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0003521330166270784,
      "loss": 0.6831,
      "step": 2530
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00035194299287410926,
      "loss": 0.6815,
      "step": 2540
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00035175296912114015,
      "loss": 0.6704,
      "step": 2550
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00035156294536817104,
      "loss": 0.7013,
      "step": 2560
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00035137292161520193,
      "loss": 0.6848,
      "step": 2570
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0003511828978622328,
      "loss": 0.7058,
      "step": 2580
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00035099287410926365,
      "loss": 0.7004,
      "step": 2590
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00035080285035629454,
      "loss": 0.6945,
      "step": 2600
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00035061282660332543,
      "loss": 0.683,
      "step": 2610
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0003504228028503563,
      "loss": 0.6995,
      "step": 2620
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0003502327790973872,
      "loss": 0.6913,
      "step": 2630
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00035004275534441804,
      "loss": 0.6957,
      "step": 2640
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00034985273159144893,
      "loss": 0.7005,
      "step": 2650
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0003496627078384798,
      "loss": 0.6921,
      "step": 2660
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0003494726840855107,
      "loss": 0.6899,
      "step": 2670
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0003492826603325416,
      "loss": 0.6932,
      "step": 2680
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00034909263657957243,
      "loss": 0.6889,
      "step": 2690
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0003489026128266033,
      "loss": 0.6912,
      "step": 2700
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0003487125890736342,
      "loss": 0.6789,
      "step": 2710
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0003485225653206651,
      "loss": 0.6805,
      "step": 2720
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.000348332541567696,
      "loss": 0.6797,
      "step": 2730
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0003481425178147268,
      "loss": 0.69,
      "step": 2740
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00034795249406175776,
      "loss": 0.6873,
      "step": 2750
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00034776247030878865,
      "loss": 0.6818,
      "step": 2760
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0003475724465558195,
      "loss": 0.6937,
      "step": 2770
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0003473824228028504,
      "loss": 0.6926,
      "step": 2780
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0003471923990498812,
      "loss": 0.6938,
      "step": 2790
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00034700237529691215,
      "loss": 0.6881,
      "step": 2800
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00034681235154394304,
      "loss": 0.6837,
      "step": 2810
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0003466223277909739,
      "loss": 0.693,
      "step": 2820
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00034643230403800477,
      "loss": 0.6928,
      "step": 2830
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0003462422802850356,
      "loss": 0.6908,
      "step": 2840
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00034605225653206654,
      "loss": 0.6892,
      "step": 2850
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00034586223277909743,
      "loss": 0.6855,
      "step": 2860
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00034567220902612827,
      "loss": 0.6785,
      "step": 2870
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00034548218527315916,
      "loss": 0.6869,
      "step": 2880
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00034529216152019005,
      "loss": 0.6942,
      "step": 2890
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00034510213776722093,
      "loss": 0.6867,
      "step": 2900
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0003449121140142518,
      "loss": 0.6874,
      "step": 2910
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00034472209026128266,
      "loss": 0.6884,
      "step": 2920
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00034453206650831355,
      "loss": 0.6891,
      "step": 2930
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00034434204275534444,
      "loss": 0.6848,
      "step": 2940
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0003441520190023753,
      "loss": 0.6834,
      "step": 2950
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0003439619952494062,
      "loss": 0.694,
      "step": 2960
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00034377197149643705,
      "loss": 0.6893,
      "step": 2970
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00034358194774346794,
      "loss": 0.6893,
      "step": 2980
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0003433919239904988,
      "loss": 0.6752,
      "step": 2990
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003432019002375297,
      "loss": 0.6858,
      "step": 3000
    },
    {
      "epoch": 1.43,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7024508118629456,
      "eval_runtime": 0.4985,
      "eval_samples_per_second": 1749.078,
      "eval_steps_per_second": 14.041,
      "step": 3000
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003430118764845606,
      "loss": 0.688,
      "step": 3010
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00034284085510688836,
      "loss": 0.6959,
      "step": 3020
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00034265083135391925,
      "loss": 0.7023,
      "step": 3030
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00034246080760095014,
      "loss": 0.6824,
      "step": 3040
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00034227078384798103,
      "loss": 0.6987,
      "step": 3050
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003420807600950119,
      "loss": 0.6917,
      "step": 3060
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00034189073634204275,
      "loss": 0.6918,
      "step": 3070
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00034170071258907364,
      "loss": 0.6759,
      "step": 3080
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034151068883610453,
      "loss": 0.6844,
      "step": 3090
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003413206650831354,
      "loss": 0.6908,
      "step": 3100
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0003411306413301663,
      "loss": 0.6896,
      "step": 3110
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00034094061757719714,
      "loss": 0.6908,
      "step": 3120
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00034075059382422803,
      "loss": 0.6776,
      "step": 3130
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003405605700712589,
      "loss": 0.6727,
      "step": 3140
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003403705463182898,
      "loss": 0.6919,
      "step": 3150
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0003401805225653207,
      "loss": 0.6816,
      "step": 3160
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00033999049881235153,
      "loss": 0.6914,
      "step": 3170
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00033981947743467935,
      "loss": 0.6897,
      "step": 3180
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00033962945368171024,
      "loss": 0.6913,
      "step": 3190
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00033943942992874113,
      "loss": 0.6917,
      "step": 3200
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00033924940617577196,
      "loss": 0.6886,
      "step": 3210
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00033905938242280285,
      "loss": 0.6735,
      "step": 3220
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00033886935866983374,
      "loss": 0.69,
      "step": 3230
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00033867933491686463,
      "loss": 0.6852,
      "step": 3240
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0003384893111638955,
      "loss": 0.6828,
      "step": 3250
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0003382992874109264,
      "loss": 0.6893,
      "step": 3260
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00033810926365795724,
      "loss": 0.6962,
      "step": 3270
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00033791923990498813,
      "loss": 0.6841,
      "step": 3280
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.000337729216152019,
      "loss": 0.6931,
      "step": 3290
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0003375391923990499,
      "loss": 0.6936,
      "step": 3300
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0003373491686460808,
      "loss": 0.6932,
      "step": 3310
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00033715914489311163,
      "loss": 0.6878,
      "step": 3320
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00033698812351543945,
      "loss": 0.6875,
      "step": 3330
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00033679809976247034,
      "loss": 0.6934,
      "step": 3340
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0003366080760095012,
      "loss": 0.6975,
      "step": 3350
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00033641805225653206,
      "loss": 0.6898,
      "step": 3360
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00033622802850356295,
      "loss": 0.7009,
      "step": 3370
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00033603800475059384,
      "loss": 0.6918,
      "step": 3380
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0003358479809976247,
      "loss": 0.6922,
      "step": 3390
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0003356579572446556,
      "loss": 0.69,
      "step": 3400
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00033546793349168645,
      "loss": 0.6945,
      "step": 3410
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00033527790973871734,
      "loss": 0.6903,
      "step": 3420
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0003350878859857482,
      "loss": 0.6867,
      "step": 3430
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0003348978622327791,
      "loss": 0.6895,
      "step": 3440
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00033470783847981,
      "loss": 0.6895,
      "step": 3450
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00033451781472684084,
      "loss": 0.6953,
      "step": 3460
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0003343277909738717,
      "loss": 0.704,
      "step": 3470
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0003341377672209026,
      "loss": 0.7007,
      "step": 3480
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0003339477434679335,
      "loss": 0.6903,
      "step": 3490
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0003337577197149644,
      "loss": 0.699,
      "step": 3500
    },
    {
      "epoch": 1.66,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.704197883605957,
      "eval_runtime": 0.501,
      "eval_samples_per_second": 1740.445,
      "eval_steps_per_second": 13.971,
      "step": 3500
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0003335676959619953,
      "loss": 0.6737,
      "step": 3510
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0003333776722090261,
      "loss": 0.7025,
      "step": 3520
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00033318764845605706,
      "loss": 0.6895,
      "step": 3530
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0003329976247030879,
      "loss": 0.7053,
      "step": 3540
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0003328076009501188,
      "loss": 0.7041,
      "step": 3550
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00033261757719714967,
      "loss": 0.6893,
      "step": 3560
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0003324275534441805,
      "loss": 0.7006,
      "step": 3570
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00033223752969121145,
      "loss": 0.6972,
      "step": 3580
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0003320475059382423,
      "loss": 0.6837,
      "step": 3590
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00033185748218527317,
      "loss": 0.6767,
      "step": 3600
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00033166745843230406,
      "loss": 0.6855,
      "step": 3610
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0003314774346793349,
      "loss": 0.7109,
      "step": 3620
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00033128741092636584,
      "loss": 0.6944,
      "step": 3630
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00033109738717339673,
      "loss": 0.681,
      "step": 3640
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00033090736342042756,
      "loss": 0.6907,
      "step": 3650
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00033071733966745845,
      "loss": 0.6845,
      "step": 3660
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0003305273159144893,
      "loss": 0.6849,
      "step": 3670
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00033033729216152023,
      "loss": 0.6896,
      "step": 3680
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0003301472684085511,
      "loss": 0.6826,
      "step": 3690
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00032995724465558195,
      "loss": 0.7145,
      "step": 3700
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00032976722090261284,
      "loss": 0.6761,
      "step": 3710
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0003295771971496437,
      "loss": 0.6947,
      "step": 3720
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0003293871733966746,
      "loss": 0.6942,
      "step": 3730
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0003291971496437055,
      "loss": 0.6783,
      "step": 3740
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00032900712589073634,
      "loss": 0.6926,
      "step": 3750
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00032881710213776723,
      "loss": 0.6968,
      "step": 3760
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0003286270783847981,
      "loss": 0.6843,
      "step": 3770
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.000328437054631829,
      "loss": 0.6848,
      "step": 3780
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0003282470308788599,
      "loss": 0.6975,
      "step": 3790
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.00032805700712589073,
      "loss": 0.6848,
      "step": 3800
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0003278669833729216,
      "loss": 0.6944,
      "step": 3810
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0003276769596199525,
      "loss": 0.699,
      "step": 3820
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0003274869358669834,
      "loss": 0.6976,
      "step": 3830
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0003272969121140143,
      "loss": 0.6937,
      "step": 3840
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0003271068883610451,
      "loss": 0.7018,
      "step": 3850
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.000326916864608076,
      "loss": 0.6906,
      "step": 3860
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0003267268408551069,
      "loss": 0.6979,
      "step": 3870
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0003265368171021378,
      "loss": 0.6891,
      "step": 3880
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0003263467933491687,
      "loss": 0.6993,
      "step": 3890
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0003261567695961995,
      "loss": 0.684,
      "step": 3900
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0003259667458432304,
      "loss": 0.6863,
      "step": 3910
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0003257767220902613,
      "loss": 0.6976,
      "step": 3920
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0003255866983372922,
      "loss": 0.673,
      "step": 3930
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00032539667458432307,
      "loss": 0.6902,
      "step": 3940
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00032520665083135396,
      "loss": 0.6913,
      "step": 3950
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0003250166270783848,
      "loss": 0.6919,
      "step": 3960
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0003248266033254157,
      "loss": 0.6735,
      "step": 3970
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00032463657957244657,
      "loss": 0.674,
      "step": 3980
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00032444655581947746,
      "loss": 0.6939,
      "step": 3990
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00032425653206650834,
      "loss": 0.6914,
      "step": 4000
    },
    {
      "epoch": 1.9,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6931639313697815,
      "eval_runtime": 0.5018,
      "eval_samples_per_second": 1737.873,
      "eval_steps_per_second": 13.951,
      "step": 4000
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0003240665083135392,
      "loss": 0.7022,
      "step": 4010
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00032387648456057007,
      "loss": 0.685,
      "step": 4020
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00032368646080760096,
      "loss": 0.6571,
      "step": 4030
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00032349643705463185,
      "loss": 0.7034,
      "step": 4040
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00032330641330166273,
      "loss": 0.6941,
      "step": 4050
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00032311638954869357,
      "loss": 0.6835,
      "step": 4060
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00032292636579572446,
      "loss": 0.6897,
      "step": 4070
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0003227363420427554,
      "loss": 0.6783,
      "step": 4080
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.00032254631828978624,
      "loss": 0.6904,
      "step": 4090
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0003223562945368171,
      "loss": 0.6943,
      "step": 4100
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00032216627078384796,
      "loss": 0.6932,
      "step": 4110
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00032197624703087885,
      "loss": 0.6871,
      "step": 4120
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0003217862232779098,
      "loss": 0.7131,
      "step": 4130
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0003215961995249406,
      "loss": 0.7,
      "step": 4140
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0003214061757719715,
      "loss": 0.6914,
      "step": 4150
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00032121615201900235,
      "loss": 0.7032,
      "step": 4160
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0003210261282660333,
      "loss": 0.692,
      "step": 4170
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0003208361045130642,
      "loss": 0.6994,
      "step": 4180
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.000320646080760095,
      "loss": 0.6904,
      "step": 4190
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0003204560570071259,
      "loss": 0.6865,
      "step": 4200
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0003202660332541568,
      "loss": 0.6895,
      "step": 4210
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0003200950118764846,
      "loss": 0.6913,
      "step": 4220
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.00031990498812351544,
      "loss": 0.6901,
      "step": 4230
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.00031971496437054633,
      "loss": 0.6867,
      "step": 4240
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0003195249406175772,
      "loss": 0.6895,
      "step": 4250
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.00031933491686460806,
      "loss": 0.6924,
      "step": 4260
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.000319144893111639,
      "loss": 0.6871,
      "step": 4270
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00031895486935866983,
      "loss": 0.6889,
      "step": 4280
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0003187648456057007,
      "loss": 0.6926,
      "step": 4290
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0003185748218527316,
      "loss": 0.6683,
      "step": 4300
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.00031838479809976245,
      "loss": 0.725,
      "step": 4310
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0003181947743467934,
      "loss": 0.6873,
      "step": 4320
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0003180047505938243,
      "loss": 0.6978,
      "step": 4330
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0003178147268408551,
      "loss": 0.6765,
      "step": 4340
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.000317624703087886,
      "loss": 0.6887,
      "step": 4350
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0003174346793349169,
      "loss": 0.6778,
      "step": 4360
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0003172446555819478,
      "loss": 0.6808,
      "step": 4370
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.00031705463182897867,
      "loss": 0.6889,
      "step": 4380
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0003168646080760095,
      "loss": 0.6952,
      "step": 4390
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0003166745843230404,
      "loss": 0.688,
      "step": 4400
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0003164845605700713,
      "loss": 0.6757,
      "step": 4410
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.00031629453681710217,
      "loss": 0.6839,
      "step": 4420
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.00031610451306413306,
      "loss": 0.6844,
      "step": 4430
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0003159144893111639,
      "loss": 0.7154,
      "step": 4440
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0003157244655581948,
      "loss": 0.7116,
      "step": 4450
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00031553444180522567,
      "loss": 0.6766,
      "step": 4460
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00031534441805225656,
      "loss": 0.6818,
      "step": 4470
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00031515439429928745,
      "loss": 0.6808,
      "step": 4480
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0003149643705463183,
      "loss": 0.6993,
      "step": 4490
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.00031477434679334917,
      "loss": 0.6975,
      "step": 4500
    },
    {
      "epoch": 2.14,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6931056976318359,
      "eval_runtime": 0.4986,
      "eval_samples_per_second": 1748.855,
      "eval_steps_per_second": 14.039,
      "step": 4500
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.00031458432304038006,
      "loss": 0.6885,
      "step": 4510
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00031439429928741095,
      "loss": 0.6862,
      "step": 4520
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00031420427553444184,
      "loss": 0.6985,
      "step": 4530
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00031401425178147267,
      "loss": 0.6933,
      "step": 4540
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00031382422802850356,
      "loss": 0.6931,
      "step": 4550
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.00031363420427553445,
      "loss": 0.6915,
      "step": 4560
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.00031344418052256534,
      "loss": 0.6891,
      "step": 4570
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0003132541567695962,
      "loss": 0.6961,
      "step": 4580
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0003130641330166271,
      "loss": 0.6887,
      "step": 4590
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00031287410926365795,
      "loss": 0.6838,
      "step": 4600
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00031268408551068884,
      "loss": 0.6923,
      "step": 4610
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0003124940617577197,
      "loss": 0.6959,
      "step": 4620
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0003123040380047506,
      "loss": 0.692,
      "step": 4630
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0003121140142517815,
      "loss": 0.687,
      "step": 4640
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00031192399049881234,
      "loss": 0.679,
      "step": 4650
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00031173396674584323,
      "loss": 0.6999,
      "step": 4660
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0003115439429928741,
      "loss": 0.6674,
      "step": 4670
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.000311353919239905,
      "loss": 0.6959,
      "step": 4680
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0003111638954869359,
      "loss": 0.6922,
      "step": 4690
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.00031097387173396673,
      "loss": 0.6839,
      "step": 4700
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0003107838479809976,
      "loss": 0.6972,
      "step": 4710
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00031059382422802856,
      "loss": 0.6861,
      "step": 4720
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0003104038004750594,
      "loss": 0.6918,
      "step": 4730
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0003102137767220903,
      "loss": 0.6772,
      "step": 4740
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0003100237529691211,
      "loss": 0.7101,
      "step": 4750
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00030983372921615206,
      "loss": 0.6856,
      "step": 4760
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00030964370546318295,
      "loss": 0.6782,
      "step": 4770
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0003094536817102138,
      "loss": 0.6983,
      "step": 4780
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0003092636579572447,
      "loss": 0.6995,
      "step": 4790
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0003090736342042755,
      "loss": 0.6992,
      "step": 4800
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00030888361045130645,
      "loss": 0.7015,
      "step": 4810
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00030869358669833734,
      "loss": 0.6841,
      "step": 4820
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0003085035629453682,
      "loss": 0.6897,
      "step": 4830
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.00030831353919239906,
      "loss": 0.6941,
      "step": 4840
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0003081235154394299,
      "loss": 0.68,
      "step": 4850
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.00030793349168646084,
      "loss": 0.6927,
      "step": 4860
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.00030774346793349173,
      "loss": 0.6662,
      "step": 4870
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00030755344418052256,
      "loss": 0.6894,
      "step": 4880
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00030736342042755345,
      "loss": 0.6848,
      "step": 4890
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.00030717339667458434,
      "loss": 0.6628,
      "step": 4900
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.00030698337292161523,
      "loss": 0.6831,
      "step": 4910
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0003067933491686461,
      "loss": 0.6792,
      "step": 4920
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.00030660332541567695,
      "loss": 0.6829,
      "step": 4930
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.00030641330166270784,
      "loss": 0.6868,
      "step": 4940
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.00030622327790973873,
      "loss": 0.6971,
      "step": 4950
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0003060332541567696,
      "loss": 0.7002,
      "step": 4960
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0003058432304038005,
      "loss": 0.6863,
      "step": 4970
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.00030565320665083134,
      "loss": 0.6846,
      "step": 4980
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.00030546318289786223,
      "loss": 0.6895,
      "step": 4990
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0003052731591448931,
      "loss": 0.6881,
      "step": 5000
    },
    {
      "epoch": 2.38,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7015542984008789,
      "eval_runtime": 0.5052,
      "eval_samples_per_second": 1726.182,
      "eval_steps_per_second": 13.857,
      "step": 5000
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.000305083135391924,
      "loss": 0.6978,
      "step": 5010
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0003048931116389549,
      "loss": 0.6879,
      "step": 5020
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0003047030878859858,
      "loss": 0.6851,
      "step": 5030
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0003045130641330166,
      "loss": 0.6842,
      "step": 5040
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0003043230403800475,
      "loss": 0.6927,
      "step": 5050
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0003041330166270784,
      "loss": 0.6979,
      "step": 5060
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0003039429928741093,
      "loss": 0.6752,
      "step": 5070
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0003037529691211402,
      "loss": 0.6782,
      "step": 5080
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.000303562945368171,
      "loss": 0.6963,
      "step": 5090
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0003033729216152019,
      "loss": 0.6999,
      "step": 5100
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0003031828978622328,
      "loss": 0.6901,
      "step": 5110
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0003029928741092637,
      "loss": 0.7011,
      "step": 5120
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.00030280285035629457,
      "loss": 0.6726,
      "step": 5130
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0003026128266033254,
      "loss": 0.6982,
      "step": 5140
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0003024228028503563,
      "loss": 0.7022,
      "step": 5150
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00030223277909738723,
      "loss": 0.7101,
      "step": 5160
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00030204275534441807,
      "loss": 0.6886,
      "step": 5170
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00030185273159144896,
      "loss": 0.7009,
      "step": 5180
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0003016627078384798,
      "loss": 0.6941,
      "step": 5190
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0003014726840855107,
      "loss": 0.6942,
      "step": 5200
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0003012826603325416,
      "loss": 0.6813,
      "step": 5210
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00030109263657957246,
      "loss": 0.6936,
      "step": 5220
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00030090261282660335,
      "loss": 0.6912,
      "step": 5230
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0003007125890736342,
      "loss": 0.697,
      "step": 5240
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.00030052256532066507,
      "loss": 0.685,
      "step": 5250
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.000300332541567696,
      "loss": 0.6897,
      "step": 5260
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.00030014251781472685,
      "loss": 0.6841,
      "step": 5270
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00029995249406175774,
      "loss": 0.686,
      "step": 5280
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0002997624703087886,
      "loss": 0.6778,
      "step": 5290
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.00029957244655581946,
      "loss": 0.6933,
      "step": 5300
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0002993824228028504,
      "loss": 0.6885,
      "step": 5310
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.00029919239904988124,
      "loss": 0.6916,
      "step": 5320
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0002990023752969121,
      "loss": 0.6845,
      "step": 5330
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.000298812351543943,
      "loss": 0.6953,
      "step": 5340
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0002986223277909739,
      "loss": 0.6999,
      "step": 5350
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0002984323040380048,
      "loss": 0.6871,
      "step": 5360
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.00029824228028503563,
      "loss": 0.6802,
      "step": 5370
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0002980522565320665,
      "loss": 0.7084,
      "step": 5380
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0002978622327790974,
      "loss": 0.7087,
      "step": 5390
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0002976722090261283,
      "loss": 0.7016,
      "step": 5400
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0002974821852731592,
      "loss": 0.6961,
      "step": 5410
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00029729216152019007,
      "loss": 0.693,
      "step": 5420
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0002971021377672209,
      "loss": 0.6883,
      "step": 5430
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0002969121140142518,
      "loss": 0.7004,
      "step": 5440
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0002967220902612827,
      "loss": 0.6912,
      "step": 5450
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00029653206650831357,
      "loss": 0.6858,
      "step": 5460
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00029634204275534446,
      "loss": 0.7032,
      "step": 5470
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0002961520190023753,
      "loss": 0.6884,
      "step": 5480
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0002959619952494062,
      "loss": 0.6958,
      "step": 5490
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0002957719714964371,
      "loss": 0.7104,
      "step": 5500
    },
    {
      "epoch": 2.61,
      "eval_accuracy": 0.4908256880733945,
      "eval_loss": 0.693674623966217,
      "eval_runtime": 0.5031,
      "eval_samples_per_second": 1733.138,
      "eval_steps_per_second": 13.913,
      "step": 5500
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.00029558194774346796,
      "loss": 0.6875,
      "step": 5510
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.00029539192399049885,
      "loss": 0.6967,
      "step": 5520
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0002952019002375297,
      "loss": 0.6868,
      "step": 5530
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0002950118764845606,
      "loss": 0.6959,
      "step": 5540
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00029482185273159146,
      "loss": 0.6699,
      "step": 5550
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00029463182897862235,
      "loss": 0.6872,
      "step": 5560
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.00029444180522565324,
      "loss": 0.6835,
      "step": 5570
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0002942517814726841,
      "loss": 0.695,
      "step": 5580
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00029406175771971496,
      "loss": 0.6961,
      "step": 5590
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00029387173396674585,
      "loss": 0.7041,
      "step": 5600
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00029368171021377674,
      "loss": 0.6796,
      "step": 5610
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00029349168646080763,
      "loss": 0.6871,
      "step": 5620
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00029330166270783846,
      "loss": 0.6883,
      "step": 5630
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.00029311163895486935,
      "loss": 0.6925,
      "step": 5640
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.00029292161520190024,
      "loss": 0.6923,
      "step": 5650
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.00029273159144893113,
      "loss": 0.6891,
      "step": 5660
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.000292541567695962,
      "loss": 0.6872,
      "step": 5670
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.00029235154394299285,
      "loss": 0.6866,
      "step": 5680
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.00029216152019002374,
      "loss": 0.6865,
      "step": 5690
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.00029197149643705463,
      "loss": 0.6834,
      "step": 5700
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0002917814726840855,
      "loss": 0.6917,
      "step": 5710
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0002915914489311164,
      "loss": 0.6908,
      "step": 5720
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0002914014251781473,
      "loss": 0.6916,
      "step": 5730
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00029121140142517813,
      "loss": 0.6853,
      "step": 5740
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0002910213776722091,
      "loss": 0.6921,
      "step": 5750
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0002908313539192399,
      "loss": 0.7073,
      "step": 5760
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0002906413301662708,
      "loss": 0.6862,
      "step": 5770
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0002904513064133017,
      "loss": 0.6833,
      "step": 5780
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0002902612826603325,
      "loss": 0.6855,
      "step": 5790
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00029007125890736347,
      "loss": 0.6914,
      "step": 5800
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0002898812351543943,
      "loss": 0.6749,
      "step": 5810
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0002896912114014252,
      "loss": 0.688,
      "step": 5820
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0002895011876484561,
      "loss": 0.6891,
      "step": 5830
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0002893111638954869,
      "loss": 0.6825,
      "step": 5840
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.00028912114014251786,
      "loss": 0.6704,
      "step": 5850
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.00028893111638954874,
      "loss": 0.7068,
      "step": 5860
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0002887410926365796,
      "loss": 0.6974,
      "step": 5870
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.00028855106888361047,
      "loss": 0.6947,
      "step": 5880
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0002883610451306413,
      "loss": 0.6889,
      "step": 5890
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.00028817102137767225,
      "loss": 0.6935,
      "step": 5900
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00028798099762470313,
      "loss": 0.6711,
      "step": 5910
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00028779097387173397,
      "loss": 0.6994,
      "step": 5920
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00028760095011876486,
      "loss": 0.6753,
      "step": 5930
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0002874109263657957,
      "loss": 0.6979,
      "step": 5940
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00028722090261282664,
      "loss": 0.6895,
      "step": 5950
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0002870308788598575,
      "loss": 0.6895,
      "step": 5960
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00028684085510688836,
      "loss": 0.6877,
      "step": 5970
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00028665083135391925,
      "loss": 0.6908,
      "step": 5980
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00028646080760095014,
      "loss": 0.6867,
      "step": 5990
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.000286270783847981,
      "loss": 0.6913,
      "step": 6000
    },
    {
      "epoch": 2.85,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7044246792793274,
      "eval_runtime": 0.4982,
      "eval_samples_per_second": 1750.187,
      "eval_steps_per_second": 14.05,
      "step": 6000
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0002860807600950119,
      "loss": 0.6928,
      "step": 6010
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.00028589073634204275,
      "loss": 0.6881,
      "step": 6020
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.00028570071258907364,
      "loss": 0.6987,
      "step": 6030
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.0002855106888361045,
      "loss": 0.6901,
      "step": 6040
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.0002853206650831354,
      "loss": 0.6874,
      "step": 6050
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.0002851306413301663,
      "loss": 0.6941,
      "step": 6060
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00028494061757719714,
      "loss": 0.6936,
      "step": 6070
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.000284750593824228,
      "loss": 0.6867,
      "step": 6080
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0002845605700712589,
      "loss": 0.6854,
      "step": 6090
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0002843705463182898,
      "loss": 0.6898,
      "step": 6100
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0002841805225653207,
      "loss": 0.6898,
      "step": 6110
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0002839904988123516,
      "loss": 0.6665,
      "step": 6120
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0002838004750593824,
      "loss": 0.6842,
      "step": 6130
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0002836104513064133,
      "loss": 0.6838,
      "step": 6140
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0002834204275534442,
      "loss": 0.6875,
      "step": 6150
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.0002832304038004751,
      "loss": 0.7084,
      "step": 6160
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00028304038004750597,
      "loss": 0.6948,
      "step": 6170
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0002828503562945368,
      "loss": 0.6994,
      "step": 6180
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0002826603325415677,
      "loss": 0.7014,
      "step": 6190
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0002824703087885986,
      "loss": 0.6943,
      "step": 6200
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00028228028503562947,
      "loss": 0.6947,
      "step": 6210
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00028209026128266036,
      "loss": 0.6864,
      "step": 6220
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0002819002375296912,
      "loss": 0.6902,
      "step": 6230
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0002817102137767221,
      "loss": 0.6879,
      "step": 6240
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.000281520190023753,
      "loss": 0.7163,
      "step": 6250
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00028133016627078386,
      "loss": 0.6964,
      "step": 6260
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00028114014251781475,
      "loss": 0.7017,
      "step": 6270
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.0002809501187648456,
      "loss": 0.6955,
      "step": 6280
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0002807600950118765,
      "loss": 0.6806,
      "step": 6290
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0002805700712589074,
      "loss": 0.7025,
      "step": 6300
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00028038004750593825,
      "loss": 0.6784,
      "step": 6310
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00028019002375296914,
      "loss": 0.6998,
      "step": 6320
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.00028,
      "loss": 0.6783,
      "step": 6330
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0002798099762470309,
      "loss": 0.6836,
      "step": 6340
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.0002796199524940618,
      "loss": 0.6852,
      "step": 6350
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00027942992874109264,
      "loss": 0.6952,
      "step": 6360
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00027923990498812353,
      "loss": 0.6923,
      "step": 6370
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00027904988123515437,
      "loss": 0.691,
      "step": 6380
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.0002788598574821853,
      "loss": 0.694,
      "step": 6390
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.0002786698337292162,
      "loss": 0.6893,
      "step": 6400
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.00027847980997624703,
      "loss": 0.6823,
      "step": 6410
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0002782897862232779,
      "loss": 0.6842,
      "step": 6420
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0002780997624703088,
      "loss": 0.703,
      "step": 6430
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.0002779097387173397,
      "loss": 0.6895,
      "step": 6440
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.0002777197149643706,
      "loss": 0.688,
      "step": 6450
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0002775296912114014,
      "loss": 0.6887,
      "step": 6460
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0002773396674584323,
      "loss": 0.6906,
      "step": 6470
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.0002771496437054632,
      "loss": 0.7021,
      "step": 6480
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.0002769596199524941,
      "loss": 0.6889,
      "step": 6490
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.000276769596199525,
      "loss": 0.6958,
      "step": 6500
    },
    {
      "epoch": 3.09,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.700744092464447,
      "eval_runtime": 0.4985,
      "eval_samples_per_second": 1749.179,
      "eval_steps_per_second": 14.042,
      "step": 6500
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.0002765795724465558,
      "loss": 0.6908,
      "step": 6510
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.0002763895486935867,
      "loss": 0.6886,
      "step": 6520
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.0002761995249406176,
      "loss": 0.6806,
      "step": 6530
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.0002760095011876485,
      "loss": 0.6826,
      "step": 6540
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00027581947743467937,
      "loss": 0.6907,
      "step": 6550
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00027562945368171026,
      "loss": 0.7053,
      "step": 6560
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.0002754394299287411,
      "loss": 0.6854,
      "step": 6570
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.000275249406175772,
      "loss": 0.6886,
      "step": 6580
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00027505938242280287,
      "loss": 0.6824,
      "step": 6590
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00027486935866983376,
      "loss": 0.6848,
      "step": 6600
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00027467933491686464,
      "loss": 0.6942,
      "step": 6610
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.0002744893111638955,
      "loss": 0.6991,
      "step": 6620
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00027429928741092637,
      "loss": 0.6958,
      "step": 6630
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00027410926365795726,
      "loss": 0.6918,
      "step": 6640
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00027391923990498815,
      "loss": 0.693,
      "step": 6650
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00027372921615201903,
      "loss": 0.6825,
      "step": 6660
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.00027353919239904987,
      "loss": 0.6681,
      "step": 6670
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.00027334916864608076,
      "loss": 0.6885,
      "step": 6680
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00027315914489311165,
      "loss": 0.6742,
      "step": 6690
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00027296912114014254,
      "loss": 0.685,
      "step": 6700
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.0002727790973871734,
      "loss": 0.6946,
      "step": 6710
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00027258907363420426,
      "loss": 0.6971,
      "step": 6720
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00027239904988123515,
      "loss": 0.687,
      "step": 6730
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.0002722090261282661,
      "loss": 0.6902,
      "step": 6740
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.0002720190023752969,
      "loss": 0.7025,
      "step": 6750
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.0002718289786223278,
      "loss": 0.6948,
      "step": 6760
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.00027163895486935865,
      "loss": 0.7002,
      "step": 6770
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.00027144893111638954,
      "loss": 0.6921,
      "step": 6780
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.0002712589073634205,
      "loss": 0.686,
      "step": 6790
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.0002710688836104513,
      "loss": 0.6919,
      "step": 6800
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.0002708788598574822,
      "loss": 0.6871,
      "step": 6810
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00027068883610451304,
      "loss": 0.6889,
      "step": 6820
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00027049881235154393,
      "loss": 0.7104,
      "step": 6830
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.00027030878859857487,
      "loss": 0.6887,
      "step": 6840
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.0002701187648456057,
      "loss": 0.6835,
      "step": 6850
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0002699287410926366,
      "loss": 0.6951,
      "step": 6860
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0002697387173396675,
      "loss": 0.684,
      "step": 6870
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.0002695486935866983,
      "loss": 0.6901,
      "step": 6880
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.00026935866983372926,
      "loss": 0.6868,
      "step": 6890
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.0002691686460807601,
      "loss": 0.6937,
      "step": 6900
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.000268978622327791,
      "loss": 0.6812,
      "step": 6910
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00026878859857482187,
      "loss": 0.6861,
      "step": 6920
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.0002685985748218527,
      "loss": 0.6865,
      "step": 6930
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00026840855106888365,
      "loss": 0.6922,
      "step": 6940
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.0002682185273159145,
      "loss": 0.701,
      "step": 6950
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0002680285035629454,
      "loss": 0.6828,
      "step": 6960
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.00026783847980997626,
      "loss": 0.6962,
      "step": 6970
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00026764845605700715,
      "loss": 0.6911,
      "step": 6980
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00026745843230403804,
      "loss": 0.6941,
      "step": 6990
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00026726840855106893,
      "loss": 0.6905,
      "step": 7000
    },
    {
      "epoch": 3.33,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6977326273918152,
      "eval_runtime": 0.4956,
      "eval_samples_per_second": 1759.655,
      "eval_steps_per_second": 14.126,
      "step": 7000
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00026707838479809976,
      "loss": 0.685,
      "step": 7010
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00026688836104513065,
      "loss": 0.6875,
      "step": 7020
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00026669833729216154,
      "loss": 0.6885,
      "step": 7030
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00026650831353919243,
      "loss": 0.6706,
      "step": 7040
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.0002663182897862233,
      "loss": 0.6806,
      "step": 7050
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00026612826603325415,
      "loss": 0.7019,
      "step": 7060
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00026593824228028504,
      "loss": 0.6744,
      "step": 7070
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00026574821852731593,
      "loss": 0.7064,
      "step": 7080
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.0002655581947743468,
      "loss": 0.6978,
      "step": 7090
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.0002653681710213777,
      "loss": 0.6929,
      "step": 7100
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.00026517814726840854,
      "loss": 0.6865,
      "step": 7110
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.00026498812351543943,
      "loss": 0.6904,
      "step": 7120
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.0002647980997624703,
      "loss": 0.6844,
      "step": 7130
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.0002646080760095012,
      "loss": 0.6973,
      "step": 7140
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.0002644180522565321,
      "loss": 0.6907,
      "step": 7150
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00026422802850356293,
      "loss": 0.6901,
      "step": 7160
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.00026405700712589075,
      "loss": 0.6834,
      "step": 7170
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.00026386698337292164,
      "loss": 0.6955,
      "step": 7180
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.0002636769596199525,
      "loss": 0.6874,
      "step": 7190
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00026348693586698336,
      "loss": 0.6862,
      "step": 7200
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00026329691211401425,
      "loss": 0.6927,
      "step": 7210
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00026310688836104514,
      "loss": 0.6895,
      "step": 7220
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.000262916864608076,
      "loss": 0.6967,
      "step": 7230
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0002627268408551069,
      "loss": 0.6861,
      "step": 7240
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0002625368171021378,
      "loss": 0.6891,
      "step": 7250
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00026234679334916864,
      "loss": 0.6992,
      "step": 7260
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00026215676959619953,
      "loss": 0.6872,
      "step": 7270
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.0002619667458432304,
      "loss": 0.6961,
      "step": 7280
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.0002617767220902613,
      "loss": 0.6847,
      "step": 7290
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.0002615866983372922,
      "loss": 0.6863,
      "step": 7300
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.00026139667458432303,
      "loss": 0.6934,
      "step": 7310
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0002612066508313539,
      "loss": 0.6758,
      "step": 7320
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0002610166270783848,
      "loss": 0.6967,
      "step": 7330
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0002608266033254157,
      "loss": 0.6994,
      "step": 7340
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0002606365795724466,
      "loss": 0.6873,
      "step": 7350
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.0002604465558194774,
      "loss": 0.6978,
      "step": 7360
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.0002602565320665083,
      "loss": 0.6885,
      "step": 7370
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00026006650831353925,
      "loss": 0.712,
      "step": 7380
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.0002598764845605701,
      "loss": 0.6883,
      "step": 7390
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.000259686460807601,
      "loss": 0.6819,
      "step": 7400
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.0002594964370546318,
      "loss": 0.6846,
      "step": 7410
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.0002593064133016627,
      "loss": 0.7055,
      "step": 7420
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.00025911638954869364,
      "loss": 0.6874,
      "step": 7430
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.0002589263657957245,
      "loss": 0.6905,
      "step": 7440
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00025873634204275536,
      "loss": 0.692,
      "step": 7450
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.0002585463182897862,
      "loss": 0.6718,
      "step": 7460
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.0002583562945368171,
      "loss": 0.6844,
      "step": 7470
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00025816627078384803,
      "loss": 0.688,
      "step": 7480
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00025797624703087886,
      "loss": 0.6847,
      "step": 7490
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00025778622327790975,
      "loss": 0.6914,
      "step": 7500
    },
    {
      "epoch": 3.56,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6982130408287048,
      "eval_runtime": 0.4969,
      "eval_samples_per_second": 1754.79,
      "eval_steps_per_second": 14.087,
      "step": 7500
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00025759619952494064,
      "loss": 0.6952,
      "step": 7510
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.0002574061757719715,
      "loss": 0.6794,
      "step": 7520
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.0002572161520190024,
      "loss": 0.6909,
      "step": 7530
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00025702612826603325,
      "loss": 0.6775,
      "step": 7540
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.00025683610451306414,
      "loss": 0.7071,
      "step": 7550
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.00025664608076009503,
      "loss": 0.6941,
      "step": 7560
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.0002564560570071259,
      "loss": 0.6755,
      "step": 7570
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.0002562660332541568,
      "loss": 0.6901,
      "step": 7580
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00025607600950118764,
      "loss": 0.6933,
      "step": 7590
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00025588598574821853,
      "loss": 0.6841,
      "step": 7600
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.0002556959619952494,
      "loss": 0.6851,
      "step": 7610
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.0002555059382422803,
      "loss": 0.6916,
      "step": 7620
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.0002553159144893112,
      "loss": 0.6778,
      "step": 7630
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.0002551258907363421,
      "loss": 0.6908,
      "step": 7640
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.0002549358669833729,
      "loss": 0.6937,
      "step": 7650
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.0002547458432304038,
      "loss": 0.6965,
      "step": 7660
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.0002545558194774347,
      "loss": 0.6765,
      "step": 7670
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.0002543657957244656,
      "loss": 0.6775,
      "step": 7680
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.0002541757719714965,
      "loss": 0.6704,
      "step": 7690
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.0002539857482185273,
      "loss": 0.674,
      "step": 7700
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.0002537957244655582,
      "loss": 0.6861,
      "step": 7710
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.0002536057007125891,
      "loss": 0.6882,
      "step": 7720
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00025341567695962,
      "loss": 0.6932,
      "step": 7730
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.00025322565320665087,
      "loss": 0.6895,
      "step": 7740
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0002530356294536817,
      "loss": 0.6958,
      "step": 7750
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.0002528456057007126,
      "loss": 0.6877,
      "step": 7760
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.0002526555819477435,
      "loss": 0.696,
      "step": 7770
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00025246555819477437,
      "loss": 0.6781,
      "step": 7780
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00025227553444180526,
      "loss": 0.687,
      "step": 7790
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.0002520855106888361,
      "loss": 0.6854,
      "step": 7800
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.000251895486935867,
      "loss": 0.6931,
      "step": 7810
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00025170546318289787,
      "loss": 0.6897,
      "step": 7820
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00025151543942992876,
      "loss": 0.6891,
      "step": 7830
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00025132541567695965,
      "loss": 0.6859,
      "step": 7840
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.0002511353919239905,
      "loss": 0.6807,
      "step": 7850
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00025094536817102137,
      "loss": 0.6994,
      "step": 7860
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00025075534441805226,
      "loss": 0.7127,
      "step": 7870
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00025056532066508315,
      "loss": 0.691,
      "step": 7880
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00025037529691211404,
      "loss": 0.7035,
      "step": 7890
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00025018527315914487,
      "loss": 0.6896,
      "step": 7900
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00024999524940617576,
      "loss": 0.694,
      "step": 7910
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.0002498052256532067,
      "loss": 0.6847,
      "step": 7920
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00024961520190023754,
      "loss": 0.6918,
      "step": 7930
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.0002494251781472684,
      "loss": 0.6935,
      "step": 7940
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.0002492351543942993,
      "loss": 0.686,
      "step": 7950
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00024904513064133015,
      "loss": 0.6872,
      "step": 7960
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.0002488551068883611,
      "loss": 0.6799,
      "step": 7970
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00024866508313539193,
      "loss": 0.6861,
      "step": 7980
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0002484750593824228,
      "loss": 0.6884,
      "step": 7990
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0002482850356294537,
      "loss": 0.6906,
      "step": 8000
    },
    {
      "epoch": 3.8,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.69525146484375,
      "eval_runtime": 0.4953,
      "eval_samples_per_second": 1760.432,
      "eval_steps_per_second": 14.132,
      "step": 8000
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00024809501187648454,
      "loss": 0.6934,
      "step": 8010
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.0002479049881235155,
      "loss": 0.6917,
      "step": 8020
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.0002477149643705463,
      "loss": 0.6797,
      "step": 8030
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.0002475249406175772,
      "loss": 0.6902,
      "step": 8040
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.0002473349168646081,
      "loss": 0.6957,
      "step": 8050
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00024714489311163893,
      "loss": 0.68,
      "step": 8060
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00024695486935866987,
      "loss": 0.6936,
      "step": 8070
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00024676484560570076,
      "loss": 0.6876,
      "step": 8080
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.0002465748218527316,
      "loss": 0.6911,
      "step": 8090
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0002463847980997625,
      "loss": 0.6854,
      "step": 8100
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0002461947743467933,
      "loss": 0.6861,
      "step": 8110
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.00024600475059382426,
      "loss": 0.6901,
      "step": 8120
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.00024581472684085515,
      "loss": 0.6869,
      "step": 8130
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.000245624703087886,
      "loss": 0.706,
      "step": 8140
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.0002454346793349169,
      "loss": 0.6871,
      "step": 8150
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.0002452446555819477,
      "loss": 0.6905,
      "step": 8160
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00024505463182897865,
      "loss": 0.687,
      "step": 8170
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00024486460807600954,
      "loss": 0.6783,
      "step": 8180
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.0002446745843230404,
      "loss": 0.6911,
      "step": 8190
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00024448456057007126,
      "loss": 0.7051,
      "step": 8200
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00024429453681710215,
      "loss": 0.6833,
      "step": 8210
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00024410451306413301,
      "loss": 0.6943,
      "step": 8220
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00024391448931116393,
      "loss": 0.6915,
      "step": 8230
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00024372446555819476,
      "loss": 0.6793,
      "step": 8240
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00024353444180522565,
      "loss": 0.6982,
      "step": 8250
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00024334441805225657,
      "loss": 0.6705,
      "step": 8260
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.0002431543942992874,
      "loss": 0.6937,
      "step": 8270
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00024296437054631832,
      "loss": 0.6894,
      "step": 8280
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00024277434679334915,
      "loss": 0.688,
      "step": 8290
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00024258432304038007,
      "loss": 0.6728,
      "step": 8300
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00024239429928741096,
      "loss": 0.676,
      "step": 8310
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.0002422042755344418,
      "loss": 0.6923,
      "step": 8320
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.0002420142517814727,
      "loss": 0.6935,
      "step": 8330
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.0002418242280285036,
      "loss": 0.6763,
      "step": 8340
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00024163420427553446,
      "loss": 0.6746,
      "step": 8350
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00024144418052256535,
      "loss": 0.6754,
      "step": 8360
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00024125415676959618,
      "loss": 0.7055,
      "step": 8370
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.0002410641330166271,
      "loss": 0.6894,
      "step": 8380
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.000240874109263658,
      "loss": 0.6931,
      "step": 8390
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00024068408551068885,
      "loss": 0.6889,
      "step": 8400
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00024049406175771974,
      "loss": 0.6961,
      "step": 8410
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.0002403040380047506,
      "loss": 0.6743,
      "step": 8420
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.0002401140142517815,
      "loss": 0.6879,
      "step": 8430
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00023992399049881238,
      "loss": 0.7068,
      "step": 8440
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00023973396674584324,
      "loss": 0.6898,
      "step": 8450
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00023954394299287413,
      "loss": 0.6914,
      "step": 8460
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.000239353919239905,
      "loss": 0.6858,
      "step": 8470
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00023916389548693588,
      "loss": 0.7,
      "step": 8480
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00023897387173396677,
      "loss": 0.6862,
      "step": 8490
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00023878384798099763,
      "loss": 0.6853,
      "step": 8500
    },
    {
      "epoch": 4.04,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7008230090141296,
      "eval_runtime": 0.4998,
      "eval_samples_per_second": 1744.78,
      "eval_steps_per_second": 14.006,
      "step": 8500
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00023859382422802852,
      "loss": 0.6779,
      "step": 8510
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.0002384038004750594,
      "loss": 0.6934,
      "step": 8520
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00023821377672209027,
      "loss": 0.6796,
      "step": 8530
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.00023802375296912116,
      "loss": 0.6974,
      "step": 8540
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.00023783372921615202,
      "loss": 0.6847,
      "step": 8550
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.0002376437054631829,
      "loss": 0.6932,
      "step": 8560
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.0002374536817102138,
      "loss": 0.6869,
      "step": 8570
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00023726365795724466,
      "loss": 0.6811,
      "step": 8580
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00023707363420427555,
      "loss": 0.7153,
      "step": 8590
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.0002368836104513064,
      "loss": 0.6778,
      "step": 8600
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.0002366935866983373,
      "loss": 0.685,
      "step": 8610
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00023650356294536819,
      "loss": 0.6888,
      "step": 8620
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00023631353919239905,
      "loss": 0.6885,
      "step": 8630
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00023612351543942994,
      "loss": 0.6955,
      "step": 8640
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00023593349168646083,
      "loss": 0.6818,
      "step": 8650
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.0002357434679334917,
      "loss": 0.6839,
      "step": 8660
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00023555344418052258,
      "loss": 0.7022,
      "step": 8670
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00023536342042755344,
      "loss": 0.7038,
      "step": 8680
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00023517339667458433,
      "loss": 0.6921,
      "step": 8690
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00023498337292161524,
      "loss": 0.6916,
      "step": 8700
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.00023479334916864608,
      "loss": 0.6856,
      "step": 8710
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.00023460332541567697,
      "loss": 0.6833,
      "step": 8720
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00023441330166270783,
      "loss": 0.6868,
      "step": 8730
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00023422327790973872,
      "loss": 0.6797,
      "step": 8740
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.00023403325415676963,
      "loss": 0.6909,
      "step": 8750
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.00023384323040380047,
      "loss": 0.6892,
      "step": 8760
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00023365320665083136,
      "loss": 0.6878,
      "step": 8770
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00023346318289786227,
      "loss": 0.7004,
      "step": 8780
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.0002332731591448931,
      "loss": 0.6787,
      "step": 8790
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00023308313539192402,
      "loss": 0.6838,
      "step": 8800
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00023289311163895486,
      "loss": 0.6934,
      "step": 8810
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00023270308788598577,
      "loss": 0.6904,
      "step": 8820
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00023251306413301666,
      "loss": 0.686,
      "step": 8830
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.0002323230403800475,
      "loss": 0.697,
      "step": 8840
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.0002321330166270784,
      "loss": 0.6857,
      "step": 8850
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00023194299287410925,
      "loss": 0.6941,
      "step": 8860
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00023175296912114016,
      "loss": 0.6822,
      "step": 8870
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00023156294536817105,
      "loss": 0.69,
      "step": 8880
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00023137292161520189,
      "loss": 0.6924,
      "step": 8890
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.0002311828978622328,
      "loss": 0.6849,
      "step": 8900
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.0002309928741092637,
      "loss": 0.6895,
      "step": 8910
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00023080285035629455,
      "loss": 0.6897,
      "step": 8920
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00023061282660332544,
      "loss": 0.6881,
      "step": 8930
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.0002304228028503563,
      "loss": 0.6876,
      "step": 8940
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.0002302327790973872,
      "loss": 0.6877,
      "step": 8950
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00023004275534441808,
      "loss": 0.695,
      "step": 8960
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00022985273159144894,
      "loss": 0.6922,
      "step": 8970
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00022966270783847983,
      "loss": 0.6847,
      "step": 8980
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.0002294726840855107,
      "loss": 0.6781,
      "step": 8990
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00022928266033254158,
      "loss": 0.679,
      "step": 9000
    },
    {
      "epoch": 4.28,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7171653509140015,
      "eval_runtime": 0.5008,
      "eval_samples_per_second": 1741.178,
      "eval_steps_per_second": 13.977,
      "step": 9000
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00022909263657957247,
      "loss": 0.6879,
      "step": 9010
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00022890261282660333,
      "loss": 0.6984,
      "step": 9020
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00022871258907363422,
      "loss": 0.6884,
      "step": 9030
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.0002285225653206651,
      "loss": 0.688,
      "step": 9040
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00022833254156769597,
      "loss": 0.6926,
      "step": 9050
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00022814251781472686,
      "loss": 0.6889,
      "step": 9060
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00022795249406175772,
      "loss": 0.6999,
      "step": 9070
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.0002277624703087886,
      "loss": 0.6845,
      "step": 9080
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.0002275724465558195,
      "loss": 0.6902,
      "step": 9090
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00022738242280285036,
      "loss": 0.6926,
      "step": 9100
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00022719239904988125,
      "loss": 0.6839,
      "step": 9110
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.0002270023752969121,
      "loss": 0.6881,
      "step": 9120
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.000226812351543943,
      "loss": 0.6965,
      "step": 9130
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.0002266223277909739,
      "loss": 0.6929,
      "step": 9140
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.00022643230403800475,
      "loss": 0.6965,
      "step": 9150
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.00022624228028503564,
      "loss": 0.6873,
      "step": 9160
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.0002260522565320665,
      "loss": 0.6793,
      "step": 9170
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.0002258622327790974,
      "loss": 0.6823,
      "step": 9180
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.00022567220902612828,
      "loss": 0.7044,
      "step": 9190
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.00022548218527315914,
      "loss": 0.6862,
      "step": 9200
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00022529216152019003,
      "loss": 0.6979,
      "step": 9210
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00022510213776722094,
      "loss": 0.6898,
      "step": 9220
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00022491211401425178,
      "loss": 0.6959,
      "step": 9230
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.00022472209026128267,
      "loss": 0.6856,
      "step": 9240
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.00022453206650831353,
      "loss": 0.7177,
      "step": 9250
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00022434204275534442,
      "loss": 0.6834,
      "step": 9260
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00022415201900237533,
      "loss": 0.6987,
      "step": 9270
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.00022396199524940617,
      "loss": 0.6948,
      "step": 9280
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.00022377197149643708,
      "loss": 0.6867,
      "step": 9290
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.00022358194774346792,
      "loss": 0.6815,
      "step": 9300
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.0002233919239904988,
      "loss": 0.7031,
      "step": 9310
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.00022320190023752972,
      "loss": 0.6844,
      "step": 9320
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.00022301187648456056,
      "loss": 0.6896,
      "step": 9330
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.00022282185273159147,
      "loss": 0.6895,
      "step": 9340
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.00022263182897862236,
      "loss": 0.6869,
      "step": 9350
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.0002224418052256532,
      "loss": 0.6818,
      "step": 9360
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.00022225178147268411,
      "loss": 0.6761,
      "step": 9370
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.00022206175771971495,
      "loss": 0.6867,
      "step": 9380
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.00022187173396674586,
      "loss": 0.6947,
      "step": 9390
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.00022168171021377675,
      "loss": 0.6971,
      "step": 9400
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.00022149168646080761,
      "loss": 0.6906,
      "step": 9410
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.0002213016627078385,
      "loss": 0.6828,
      "step": 9420
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00022111163895486934,
      "loss": 0.6752,
      "step": 9430
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00022092161520190025,
      "loss": 0.6922,
      "step": 9440
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.00022073159144893114,
      "loss": 0.6974,
      "step": 9450
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.000220541567695962,
      "loss": 0.6898,
      "step": 9460
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.0002203515439429929,
      "loss": 0.6874,
      "step": 9470
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.00022016152019002378,
      "loss": 0.7009,
      "step": 9480
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.00021997149643705464,
      "loss": 0.6823,
      "step": 9490
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.00021978147268408553,
      "loss": 0.6849,
      "step": 9500
    },
    {
      "epoch": 4.51,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7013645172119141,
      "eval_runtime": 0.5002,
      "eval_samples_per_second": 1743.288,
      "eval_steps_per_second": 13.994,
      "step": 9500
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.0002195914489311164,
      "loss": 0.6868,
      "step": 9510
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.00021940142517814728,
      "loss": 0.6873,
      "step": 9520
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.00021921140142517817,
      "loss": 0.6864,
      "step": 9530
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.00021902137767220903,
      "loss": 0.6941,
      "step": 9540
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00021883135391923992,
      "loss": 0.6894,
      "step": 9550
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00021864133016627078,
      "loss": 0.6935,
      "step": 9560
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.00021845130641330167,
      "loss": 0.6864,
      "step": 9570
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.00021826128266033256,
      "loss": 0.6811,
      "step": 9580
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.00021807125890736342,
      "loss": 0.7023,
      "step": 9590
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.0002178812351543943,
      "loss": 0.6838,
      "step": 9600
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.0002176912114014252,
      "loss": 0.6958,
      "step": 9610
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00021750118764845606,
      "loss": 0.6857,
      "step": 9620
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00021731116389548695,
      "loss": 0.6861,
      "step": 9630
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.0002171211401425178,
      "loss": 0.6802,
      "step": 9640
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.0002169311163895487,
      "loss": 0.6919,
      "step": 9650
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.0002167410926365796,
      "loss": 0.6858,
      "step": 9660
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.00021655106888361045,
      "loss": 0.6865,
      "step": 9670
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.00021636104513064134,
      "loss": 0.6918,
      "step": 9680
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.0002161710213776722,
      "loss": 0.6853,
      "step": 9690
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.0002159809976247031,
      "loss": 0.694,
      "step": 9700
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.00021579097387173398,
      "loss": 0.6856,
      "step": 9710
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.00021560095011876484,
      "loss": 0.6798,
      "step": 9720
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.00021541092636579573,
      "loss": 0.6711,
      "step": 9730
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.0002152209026128266,
      "loss": 0.7,
      "step": 9740
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.00021503087885985748,
      "loss": 0.6938,
      "step": 9750
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.00021484085510688837,
      "loss": 0.6965,
      "step": 9760
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.00021465083135391923,
      "loss": 0.6829,
      "step": 9770
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.00021446080760095012,
      "loss": 0.6792,
      "step": 9780
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.00021427078384798104,
      "loss": 0.6805,
      "step": 9790
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.00021408076009501187,
      "loss": 0.6767,
      "step": 9800
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.0002138907363420428,
      "loss": 0.6794,
      "step": 9810
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00021370071258907362,
      "loss": 0.6966,
      "step": 9820
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.0002135106888361045,
      "loss": 0.6847,
      "step": 9830
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00021332066508313543,
      "loss": 0.6839,
      "step": 9840
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00021313064133016626,
      "loss": 0.6996,
      "step": 9850
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00021294061757719718,
      "loss": 0.6768,
      "step": 9860
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.000212750593824228,
      "loss": 0.7004,
      "step": 9870
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.0002125605700712589,
      "loss": 0.6866,
      "step": 9880
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.00021237054631828982,
      "loss": 0.6929,
      "step": 9890
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.00021218052256532065,
      "loss": 0.6895,
      "step": 9900
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.00021199049881235157,
      "loss": 0.6927,
      "step": 9910
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.00021180047505938246,
      "loss": 0.6811,
      "step": 9920
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.00021161045130641332,
      "loss": 0.6824,
      "step": 9930
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.0002114204275534442,
      "loss": 0.7051,
      "step": 9940
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.00021123040380047504,
      "loss": 0.6886,
      "step": 9950
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.00021104038004750596,
      "loss": 0.6936,
      "step": 9960
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.00021085035629453685,
      "loss": 0.6881,
      "step": 9970
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.0002106603325415677,
      "loss": 0.6947,
      "step": 9980
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.0002104703087885986,
      "loss": 0.69,
      "step": 9990
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00021028028503562943,
      "loss": 0.693,
      "step": 10000
    },
    {
      "epoch": 4.75,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7026613354682922,
      "eval_runtime": 0.4984,
      "eval_samples_per_second": 1749.715,
      "eval_steps_per_second": 14.046,
      "step": 10000
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.00021009026128266035,
      "loss": 0.6863,
      "step": 10010
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.00020990023752969123,
      "loss": 0.6789,
      "step": 10020
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.0002097102137767221,
      "loss": 0.6845,
      "step": 10030
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.00020952019002375299,
      "loss": 0.6747,
      "step": 10040
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.00020933016627078387,
      "loss": 0.6973,
      "step": 10050
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.00020914014251781474,
      "loss": 0.6769,
      "step": 10060
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.00020895011876484562,
      "loss": 0.6905,
      "step": 10070
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.00020876009501187649,
      "loss": 0.6799,
      "step": 10080
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.00020857007125890738,
      "loss": 0.6817,
      "step": 10090
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.00020838004750593826,
      "loss": 0.6835,
      "step": 10100
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.00020819002375296913,
      "loss": 0.691,
      "step": 10110
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.00020800000000000001,
      "loss": 0.6954,
      "step": 10120
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.00020780997624703088,
      "loss": 0.6845,
      "step": 10130
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00020761995249406176,
      "loss": 0.6951,
      "step": 10140
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00020742992874109265,
      "loss": 0.6874,
      "step": 10150
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.00020723990498812352,
      "loss": 0.685,
      "step": 10160
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.0002070498812351544,
      "loss": 0.7007,
      "step": 10170
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.0002068598574821853,
      "loss": 0.6749,
      "step": 10180
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.00020666983372921615,
      "loss": 0.689,
      "step": 10190
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.00020647980997624704,
      "loss": 0.6832,
      "step": 10200
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.0002062897862232779,
      "loss": 0.6825,
      "step": 10210
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.0002060997624703088,
      "loss": 0.6853,
      "step": 10220
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.00020590973871733968,
      "loss": 0.6752,
      "step": 10230
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.00020571971496437054,
      "loss": 0.691,
      "step": 10240
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.00020552969121140143,
      "loss": 0.6949,
      "step": 10250
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.0002053396674584323,
      "loss": 0.6857,
      "step": 10260
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00020514964370546318,
      "loss": 0.6719,
      "step": 10270
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.0002049596199524941,
      "loss": 0.6858,
      "step": 10280
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.00020476959619952493,
      "loss": 0.6975,
      "step": 10290
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.00020457957244655582,
      "loss": 0.6879,
      "step": 10300
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.00020438954869358674,
      "loss": 0.6929,
      "step": 10310
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.00020419952494061757,
      "loss": 0.6914,
      "step": 10320
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.0002040095011876485,
      "loss": 0.674,
      "step": 10330
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.00020381947743467932,
      "loss": 0.6923,
      "step": 10340
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.0002036294536817102,
      "loss": 0.6819,
      "step": 10350
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.00020343942992874113,
      "loss": 0.6861,
      "step": 10360
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.00020324940617577196,
      "loss": 0.6852,
      "step": 10370
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.00020305938242280288,
      "loss": 0.6885,
      "step": 10380
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.0002028693586698337,
      "loss": 0.6714,
      "step": 10390
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.00020267933491686463,
      "loss": 0.6793,
      "step": 10400
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00020248931116389552,
      "loss": 0.6885,
      "step": 10410
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00020229928741092635,
      "loss": 0.7016,
      "step": 10420
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00020210926365795727,
      "loss": 0.6909,
      "step": 10430
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.0002019192399049881,
      "loss": 0.6925,
      "step": 10440
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.00020172921615201902,
      "loss": 0.6773,
      "step": 10450
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.0002015391923990499,
      "loss": 0.6892,
      "step": 10460
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.00020134916864608074,
      "loss": 0.6721,
      "step": 10470
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.00020115914489311166,
      "loss": 0.6795,
      "step": 10480
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.00020096912114014255,
      "loss": 0.6948,
      "step": 10490
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.0002007790973871734,
      "loss": 0.6823,
      "step": 10500
    },
    {
      "epoch": 4.99,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6992433667182922,
      "eval_runtime": 0.4981,
      "eval_samples_per_second": 1750.756,
      "eval_steps_per_second": 14.054,
      "step": 10500
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.0002005890736342043,
      "loss": 0.6919,
      "step": 10510
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.00020039904988123513,
      "loss": 0.6797,
      "step": 10520
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.00020020902612826605,
      "loss": 0.6833,
      "step": 10530
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.00020001900237529694,
      "loss": 0.6973,
      "step": 10540
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.0001998289786223278,
      "loss": 0.6993,
      "step": 10550
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.0001996389548693587,
      "loss": 0.6816,
      "step": 10560
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.00019944893111638955,
      "loss": 0.6891,
      "step": 10570
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.00019925890736342044,
      "loss": 0.6869,
      "step": 10580
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.0001990688836104513,
      "loss": 0.6816,
      "step": 10590
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.00019887885985748222,
      "loss": 0.6813,
      "step": 10600
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.00019868883610451308,
      "loss": 0.6851,
      "step": 10610
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.00019849881235154394,
      "loss": 0.6805,
      "step": 10620
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.00019830878859857483,
      "loss": 0.6888,
      "step": 10630
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.00019811876484560572,
      "loss": 0.6998,
      "step": 10640
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.0001979287410926366,
      "loss": 0.687,
      "step": 10650
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.00019773871733966747,
      "loss": 0.6905,
      "step": 10660
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.00019754869358669833,
      "loss": 0.6854,
      "step": 10670
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.00019735866983372922,
      "loss": 0.6879,
      "step": 10680
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.0001971686460807601,
      "loss": 0.694,
      "step": 10690
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.000196978622327791,
      "loss": 0.6851,
      "step": 10700
    },
    {
      "epoch": 5.09,
      "learning_rate": 0.00019678859857482186,
      "loss": 0.6895,
      "step": 10710
    },
    {
      "epoch": 5.09,
      "learning_rate": 0.00019659857482185275,
      "loss": 0.7022,
      "step": 10720
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.00019640855106888363,
      "loss": 0.6993,
      "step": 10730
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.0001962185273159145,
      "loss": 0.6897,
      "step": 10740
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.00019602850356294538,
      "loss": 0.687,
      "step": 10750
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.00019583847980997625,
      "loss": 0.6877,
      "step": 10760
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.00019564845605700714,
      "loss": 0.6951,
      "step": 10770
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.00019545843230403802,
      "loss": 0.6799,
      "step": 10780
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.00019526840855106889,
      "loss": 0.7009,
      "step": 10790
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.00019507838479809977,
      "loss": 0.6881,
      "step": 10800
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.00019488836104513064,
      "loss": 0.6767,
      "step": 10810
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.00019469833729216152,
      "loss": 0.6925,
      "step": 10820
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.00019450831353919241,
      "loss": 0.6709,
      "step": 10830
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.00019431828978622328,
      "loss": 0.6971,
      "step": 10840
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.00019412826603325416,
      "loss": 0.6971,
      "step": 10850
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.00019393824228028505,
      "loss": 0.6949,
      "step": 10860
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.00019374821852731591,
      "loss": 0.6913,
      "step": 10870
    },
    {
      "epoch": 5.17,
      "learning_rate": 0.0001935581947743468,
      "loss": 0.7009,
      "step": 10880
    },
    {
      "epoch": 5.17,
      "learning_rate": 0.00019336817102137767,
      "loss": 0.6857,
      "step": 10890
    },
    {
      "epoch": 5.18,
      "learning_rate": 0.00019317814726840858,
      "loss": 0.6693,
      "step": 10900
    },
    {
      "epoch": 5.18,
      "learning_rate": 0.00019298812351543944,
      "loss": 0.688,
      "step": 10910
    },
    {
      "epoch": 5.19,
      "learning_rate": 0.00019279809976247033,
      "loss": 0.6944,
      "step": 10920
    },
    {
      "epoch": 5.19,
      "learning_rate": 0.0001926080760095012,
      "loss": 0.6882,
      "step": 10930
    },
    {
      "epoch": 5.2,
      "learning_rate": 0.00019241805225653205,
      "loss": 0.6832,
      "step": 10940
    },
    {
      "epoch": 5.2,
      "learning_rate": 0.00019222802850356297,
      "loss": 0.6867,
      "step": 10950
    },
    {
      "epoch": 5.21,
      "learning_rate": 0.00019203800475059383,
      "loss": 0.6842,
      "step": 10960
    },
    {
      "epoch": 5.21,
      "learning_rate": 0.00019184798099762472,
      "loss": 0.6954,
      "step": 10970
    },
    {
      "epoch": 5.22,
      "learning_rate": 0.00019165795724465558,
      "loss": 0.6876,
      "step": 10980
    },
    {
      "epoch": 5.22,
      "learning_rate": 0.00019146793349168647,
      "loss": 0.6767,
      "step": 10990
    },
    {
      "epoch": 5.23,
      "learning_rate": 0.00019127790973871736,
      "loss": 0.6894,
      "step": 11000
    },
    {
      "epoch": 5.23,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7162693738937378,
      "eval_runtime": 0.4985,
      "eval_samples_per_second": 1749.331,
      "eval_steps_per_second": 14.043,
      "step": 11000
    },
    {
      "epoch": 5.23,
      "learning_rate": 0.00019108788598574822,
      "loss": 0.6871,
      "step": 11010
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.0001908978622327791,
      "loss": 0.6872,
      "step": 11020
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.00019070783847980997,
      "loss": 0.6913,
      "step": 11030
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.00019051781472684086,
      "loss": 0.6909,
      "step": 11040
    },
    {
      "epoch": 5.25,
      "learning_rate": 0.00019032779097387175,
      "loss": 0.688,
      "step": 11050
    },
    {
      "epoch": 5.25,
      "learning_rate": 0.0001901377672209026,
      "loss": 0.6897,
      "step": 11060
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.0001899477434679335,
      "loss": 0.6796,
      "step": 11070
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.0001897577197149644,
      "loss": 0.6903,
      "step": 11080
    },
    {
      "epoch": 5.27,
      "learning_rate": 0.00018956769596199525,
      "loss": 0.6875,
      "step": 11090
    },
    {
      "epoch": 5.27,
      "learning_rate": 0.00018937767220902614,
      "loss": 0.6914,
      "step": 11100
    },
    {
      "epoch": 5.28,
      "learning_rate": 0.000189187648456057,
      "loss": 0.6888,
      "step": 11110
    },
    {
      "epoch": 5.28,
      "learning_rate": 0.00018899762470308792,
      "loss": 0.6803,
      "step": 11120
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.00018880760095011878,
      "loss": 0.6842,
      "step": 11130
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.00018861757719714964,
      "loss": 0.7028,
      "step": 11140
    },
    {
      "epoch": 5.3,
      "learning_rate": 0.00018842755344418053,
      "loss": 0.6961,
      "step": 11150
    },
    {
      "epoch": 5.3,
      "learning_rate": 0.0001882375296912114,
      "loss": 0.6924,
      "step": 11160
    },
    {
      "epoch": 5.31,
      "learning_rate": 0.0001880475059382423,
      "loss": 0.69,
      "step": 11170
    },
    {
      "epoch": 5.31,
      "learning_rate": 0.00018785748218527317,
      "loss": 0.6962,
      "step": 11180
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.00018766745843230403,
      "loss": 0.6965,
      "step": 11190
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.00018747743467933492,
      "loss": 0.6867,
      "step": 11200
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.0001872874109263658,
      "loss": 0.6887,
      "step": 11210
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.0001870973871733967,
      "loss": 0.6808,
      "step": 11220
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.00018690736342042756,
      "loss": 0.6803,
      "step": 11230
    },
    {
      "epoch": 5.34,
      "learning_rate": 0.00018671733966745845,
      "loss": 0.6908,
      "step": 11240
    },
    {
      "epoch": 5.34,
      "learning_rate": 0.00018652731591448934,
      "loss": 0.695,
      "step": 11250
    },
    {
      "epoch": 5.35,
      "learning_rate": 0.0001863372921615202,
      "loss": 0.6809,
      "step": 11260
    },
    {
      "epoch": 5.35,
      "learning_rate": 0.0001861472684085511,
      "loss": 0.6777,
      "step": 11270
    },
    {
      "epoch": 5.36,
      "learning_rate": 0.00018595724465558195,
      "loss": 0.6899,
      "step": 11280
    },
    {
      "epoch": 5.36,
      "learning_rate": 0.00018576722090261284,
      "loss": 0.7011,
      "step": 11290
    },
    {
      "epoch": 5.37,
      "learning_rate": 0.00018557719714964373,
      "loss": 0.683,
      "step": 11300
    },
    {
      "epoch": 5.37,
      "learning_rate": 0.0001853871733966746,
      "loss": 0.6885,
      "step": 11310
    },
    {
      "epoch": 5.38,
      "learning_rate": 0.00018519714964370548,
      "loss": 0.698,
      "step": 11320
    },
    {
      "epoch": 5.38,
      "learning_rate": 0.00018500712589073634,
      "loss": 0.6849,
      "step": 11330
    },
    {
      "epoch": 5.39,
      "learning_rate": 0.00018481710213776723,
      "loss": 0.6882,
      "step": 11340
    },
    {
      "epoch": 5.39,
      "learning_rate": 0.00018462707838479812,
      "loss": 0.6816,
      "step": 11350
    },
    {
      "epoch": 5.4,
      "learning_rate": 0.00018443705463182898,
      "loss": 0.6984,
      "step": 11360
    },
    {
      "epoch": 5.4,
      "learning_rate": 0.00018424703087885987,
      "loss": 0.6988,
      "step": 11370
    },
    {
      "epoch": 5.41,
      "learning_rate": 0.00018405700712589073,
      "loss": 0.6862,
      "step": 11380
    },
    {
      "epoch": 5.41,
      "learning_rate": 0.00018386698337292164,
      "loss": 0.6871,
      "step": 11390
    },
    {
      "epoch": 5.42,
      "learning_rate": 0.0001836769596199525,
      "loss": 0.6958,
      "step": 11400
    },
    {
      "epoch": 5.42,
      "learning_rate": 0.00018348693586698337,
      "loss": 0.6851,
      "step": 11410
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.00018329691211401426,
      "loss": 0.6815,
      "step": 11420
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.00018310688836104514,
      "loss": 0.6889,
      "step": 11430
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.00018291686460807603,
      "loss": 0.6972,
      "step": 11440
    },
    {
      "epoch": 5.44,
      "learning_rate": 0.0001827268408551069,
      "loss": 0.6964,
      "step": 11450
    },
    {
      "epoch": 5.44,
      "learning_rate": 0.00018253681710213776,
      "loss": 0.6925,
      "step": 11460
    },
    {
      "epoch": 5.45,
      "learning_rate": 0.00018234679334916867,
      "loss": 0.6955,
      "step": 11470
    },
    {
      "epoch": 5.45,
      "learning_rate": 0.00018215676959619953,
      "loss": 0.6884,
      "step": 11480
    },
    {
      "epoch": 5.46,
      "learning_rate": 0.00018196674584323042,
      "loss": 0.6943,
      "step": 11490
    },
    {
      "epoch": 5.46,
      "learning_rate": 0.00018177672209026129,
      "loss": 0.6918,
      "step": 11500
    },
    {
      "epoch": 5.46,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6960068345069885,
      "eval_runtime": 0.4995,
      "eval_samples_per_second": 1745.785,
      "eval_steps_per_second": 14.014,
      "step": 11500
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.00018158669833729217,
      "loss": 0.6729,
      "step": 11510
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.00018139667458432306,
      "loss": 0.6808,
      "step": 11520
    },
    {
      "epoch": 5.48,
      "learning_rate": 0.00018120665083135392,
      "loss": 0.6805,
      "step": 11530
    },
    {
      "epoch": 5.48,
      "learning_rate": 0.0001810166270783848,
      "loss": 0.685,
      "step": 11540
    },
    {
      "epoch": 5.49,
      "learning_rate": 0.00018082660332541567,
      "loss": 0.6763,
      "step": 11550
    },
    {
      "epoch": 5.49,
      "learning_rate": 0.00018063657957244656,
      "loss": 0.6849,
      "step": 11560
    },
    {
      "epoch": 5.5,
      "learning_rate": 0.00018044655581947745,
      "loss": 0.6862,
      "step": 11570
    },
    {
      "epoch": 5.5,
      "learning_rate": 0.00018025653206650831,
      "loss": 0.7019,
      "step": 11580
    },
    {
      "epoch": 5.51,
      "learning_rate": 0.0001800665083135392,
      "loss": 0.6949,
      "step": 11590
    },
    {
      "epoch": 5.51,
      "learning_rate": 0.00017987648456057006,
      "loss": 0.6877,
      "step": 11600
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.00017968646080760095,
      "loss": 0.6829,
      "step": 11610
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.00017949643705463184,
      "loss": 0.6879,
      "step": 11620
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.0001793064133016627,
      "loss": 0.6892,
      "step": 11630
    },
    {
      "epoch": 5.53,
      "learning_rate": 0.0001791163895486936,
      "loss": 0.6958,
      "step": 11640
    },
    {
      "epoch": 5.53,
      "learning_rate": 0.00017892636579572448,
      "loss": 0.6914,
      "step": 11650
    },
    {
      "epoch": 5.54,
      "learning_rate": 0.00017873634204275534,
      "loss": 0.69,
      "step": 11660
    },
    {
      "epoch": 5.54,
      "learning_rate": 0.00017854631828978623,
      "loss": 0.6992,
      "step": 11670
    },
    {
      "epoch": 5.55,
      "learning_rate": 0.0001783562945368171,
      "loss": 0.6866,
      "step": 11680
    },
    {
      "epoch": 5.55,
      "learning_rate": 0.000178166270783848,
      "loss": 0.6788,
      "step": 11690
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.00017797624703087887,
      "loss": 0.6971,
      "step": 11700
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.00017778622327790976,
      "loss": 0.6845,
      "step": 11710
    },
    {
      "epoch": 5.57,
      "learning_rate": 0.00017759619952494062,
      "loss": 0.6804,
      "step": 11720
    },
    {
      "epoch": 5.57,
      "learning_rate": 0.00017740617577197148,
      "loss": 0.6861,
      "step": 11730
    },
    {
      "epoch": 5.58,
      "learning_rate": 0.0001772161520190024,
      "loss": 0.697,
      "step": 11740
    },
    {
      "epoch": 5.58,
      "learning_rate": 0.00017702612826603326,
      "loss": 0.6878,
      "step": 11750
    },
    {
      "epoch": 5.59,
      "learning_rate": 0.00017683610451306415,
      "loss": 0.6898,
      "step": 11760
    },
    {
      "epoch": 5.59,
      "learning_rate": 0.000176646080760095,
      "loss": 0.6957,
      "step": 11770
    },
    {
      "epoch": 5.6,
      "learning_rate": 0.0001764560570071259,
      "loss": 0.685,
      "step": 11780
    },
    {
      "epoch": 5.6,
      "learning_rate": 0.0001762660332541568,
      "loss": 0.6835,
      "step": 11790
    },
    {
      "epoch": 5.61,
      "learning_rate": 0.00017607600950118765,
      "loss": 0.6839,
      "step": 11800
    },
    {
      "epoch": 5.61,
      "learning_rate": 0.00017588598574821854,
      "loss": 0.6927,
      "step": 11810
    },
    {
      "epoch": 5.62,
      "learning_rate": 0.00017569596199524943,
      "loss": 0.6808,
      "step": 11820
    },
    {
      "epoch": 5.62,
      "learning_rate": 0.0001755059382422803,
      "loss": 0.6808,
      "step": 11830
    },
    {
      "epoch": 5.62,
      "learning_rate": 0.00017531591448931118,
      "loss": 0.6919,
      "step": 11840
    },
    {
      "epoch": 5.63,
      "learning_rate": 0.00017512589073634204,
      "loss": 0.6949,
      "step": 11850
    },
    {
      "epoch": 5.63,
      "learning_rate": 0.00017493586698337293,
      "loss": 0.6954,
      "step": 11860
    },
    {
      "epoch": 5.64,
      "learning_rate": 0.00017474584323040382,
      "loss": 0.692,
      "step": 11870
    },
    {
      "epoch": 5.64,
      "learning_rate": 0.00017455581947743468,
      "loss": 0.6878,
      "step": 11880
    },
    {
      "epoch": 5.65,
      "learning_rate": 0.00017436579572446557,
      "loss": 0.6944,
      "step": 11890
    },
    {
      "epoch": 5.65,
      "learning_rate": 0.00017417577197149643,
      "loss": 0.6806,
      "step": 11900
    },
    {
      "epoch": 5.66,
      "learning_rate": 0.00017398574821852735,
      "loss": 0.6867,
      "step": 11910
    },
    {
      "epoch": 5.66,
      "learning_rate": 0.0001737957244655582,
      "loss": 0.6709,
      "step": 11920
    },
    {
      "epoch": 5.67,
      "learning_rate": 0.00017360570071258907,
      "loss": 0.6804,
      "step": 11930
    },
    {
      "epoch": 5.67,
      "learning_rate": 0.00017341567695961996,
      "loss": 0.6971,
      "step": 11940
    },
    {
      "epoch": 5.68,
      "learning_rate": 0.00017322565320665082,
      "loss": 0.6873,
      "step": 11950
    },
    {
      "epoch": 5.68,
      "learning_rate": 0.00017303562945368174,
      "loss": 0.6821,
      "step": 11960
    },
    {
      "epoch": 5.69,
      "learning_rate": 0.0001728456057007126,
      "loss": 0.6639,
      "step": 11970
    },
    {
      "epoch": 5.69,
      "learning_rate": 0.00017265558194774346,
      "loss": 0.6649,
      "step": 11980
    },
    {
      "epoch": 5.7,
      "learning_rate": 0.00017246555819477435,
      "loss": 0.7063,
      "step": 11990
    },
    {
      "epoch": 5.7,
      "learning_rate": 0.00017227553444180524,
      "loss": 0.6864,
      "step": 12000
    },
    {
      "epoch": 5.7,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6978054046630859,
      "eval_runtime": 0.4993,
      "eval_samples_per_second": 1746.523,
      "eval_steps_per_second": 14.02,
      "step": 12000
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.00017208551068883613,
      "loss": 0.691,
      "step": 12010
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.000171895486935867,
      "loss": 0.6845,
      "step": 12020
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.00017170546318289788,
      "loss": 0.6826,
      "step": 12030
    },
    {
      "epoch": 5.72,
      "learning_rate": 0.00017151543942992876,
      "loss": 0.7015,
      "step": 12040
    },
    {
      "epoch": 5.72,
      "learning_rate": 0.00017132541567695963,
      "loss": 0.6937,
      "step": 12050
    },
    {
      "epoch": 5.73,
      "learning_rate": 0.00017113539192399052,
      "loss": 0.681,
      "step": 12060
    },
    {
      "epoch": 5.73,
      "learning_rate": 0.00017094536817102138,
      "loss": 0.6942,
      "step": 12070
    },
    {
      "epoch": 5.74,
      "learning_rate": 0.00017075534441805227,
      "loss": 0.6951,
      "step": 12080
    },
    {
      "epoch": 5.74,
      "learning_rate": 0.00017056532066508315,
      "loss": 0.692,
      "step": 12090
    },
    {
      "epoch": 5.75,
      "learning_rate": 0.00017037529691211402,
      "loss": 0.6926,
      "step": 12100
    },
    {
      "epoch": 5.75,
      "learning_rate": 0.0001701852731591449,
      "loss": 0.6788,
      "step": 12110
    },
    {
      "epoch": 5.76,
      "learning_rate": 0.00016999524940617577,
      "loss": 0.687,
      "step": 12120
    },
    {
      "epoch": 5.76,
      "learning_rate": 0.00016980522565320666,
      "loss": 0.689,
      "step": 12130
    },
    {
      "epoch": 5.77,
      "learning_rate": 0.00016961520190023754,
      "loss": 0.6711,
      "step": 12140
    },
    {
      "epoch": 5.77,
      "learning_rate": 0.0001694251781472684,
      "loss": 0.7045,
      "step": 12150
    },
    {
      "epoch": 5.78,
      "learning_rate": 0.00016925415676959622,
      "loss": 0.694,
      "step": 12160
    },
    {
      "epoch": 5.78,
      "learning_rate": 0.00016906413301662708,
      "loss": 0.6841,
      "step": 12170
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.00016887410926365797,
      "loss": 0.6767,
      "step": 12180
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.00016868408551068883,
      "loss": 0.6854,
      "step": 12190
    },
    {
      "epoch": 5.8,
      "learning_rate": 0.00016849406175771972,
      "loss": 0.6774,
      "step": 12200
    },
    {
      "epoch": 5.8,
      "learning_rate": 0.0001683040380047506,
      "loss": 0.6935,
      "step": 12210
    },
    {
      "epoch": 5.81,
      "learning_rate": 0.00016811401425178147,
      "loss": 0.6841,
      "step": 12220
    },
    {
      "epoch": 5.81,
      "learning_rate": 0.00016792399049881236,
      "loss": 0.6943,
      "step": 12230
    },
    {
      "epoch": 5.81,
      "learning_rate": 0.00016773396674584322,
      "loss": 0.6891,
      "step": 12240
    },
    {
      "epoch": 5.82,
      "learning_rate": 0.0001675439429928741,
      "loss": 0.685,
      "step": 12250
    },
    {
      "epoch": 5.82,
      "learning_rate": 0.000167353919239905,
      "loss": 0.692,
      "step": 12260
    },
    {
      "epoch": 5.83,
      "learning_rate": 0.00016716389548693586,
      "loss": 0.6959,
      "step": 12270
    },
    {
      "epoch": 5.83,
      "learning_rate": 0.00016697387173396675,
      "loss": 0.6841,
      "step": 12280
    },
    {
      "epoch": 5.84,
      "learning_rate": 0.00016678384798099764,
      "loss": 0.6813,
      "step": 12290
    },
    {
      "epoch": 5.84,
      "learning_rate": 0.00016659382422802853,
      "loss": 0.6704,
      "step": 12300
    },
    {
      "epoch": 5.85,
      "learning_rate": 0.0001664038004750594,
      "loss": 0.6794,
      "step": 12310
    },
    {
      "epoch": 5.85,
      "learning_rate": 0.00016621377672209025,
      "loss": 0.6842,
      "step": 12320
    },
    {
      "epoch": 5.86,
      "learning_rate": 0.00016602375296912114,
      "loss": 0.6886,
      "step": 12330
    },
    {
      "epoch": 5.86,
      "learning_rate": 0.00016583372921615203,
      "loss": 0.698,
      "step": 12340
    },
    {
      "epoch": 5.87,
      "learning_rate": 0.00016564370546318292,
      "loss": 0.694,
      "step": 12350
    },
    {
      "epoch": 5.87,
      "learning_rate": 0.00016545368171021378,
      "loss": 0.6866,
      "step": 12360
    },
    {
      "epoch": 5.88,
      "learning_rate": 0.00016526365795724464,
      "loss": 0.6904,
      "step": 12370
    },
    {
      "epoch": 5.88,
      "learning_rate": 0.00016507363420427556,
      "loss": 0.698,
      "step": 12380
    },
    {
      "epoch": 5.89,
      "learning_rate": 0.00016488361045130642,
      "loss": 0.6868,
      "step": 12390
    },
    {
      "epoch": 5.89,
      "learning_rate": 0.0001646935866983373,
      "loss": 0.6825,
      "step": 12400
    },
    {
      "epoch": 5.9,
      "learning_rate": 0.00016450356294536817,
      "loss": 0.6835,
      "step": 12410
    },
    {
      "epoch": 5.9,
      "learning_rate": 0.00016431353919239906,
      "loss": 0.6707,
      "step": 12420
    },
    {
      "epoch": 5.9,
      "learning_rate": 0.00016412351543942995,
      "loss": 0.6949,
      "step": 12430
    },
    {
      "epoch": 5.91,
      "learning_rate": 0.0001639334916864608,
      "loss": 0.6916,
      "step": 12440
    },
    {
      "epoch": 5.91,
      "learning_rate": 0.0001637434679334917,
      "loss": 0.6813,
      "step": 12450
    },
    {
      "epoch": 5.92,
      "learning_rate": 0.00016355344418052256,
      "loss": 0.6936,
      "step": 12460
    },
    {
      "epoch": 5.92,
      "learning_rate": 0.00016336342042755345,
      "loss": 0.6832,
      "step": 12470
    },
    {
      "epoch": 5.93,
      "learning_rate": 0.00016317339667458434,
      "loss": 0.6793,
      "step": 12480
    },
    {
      "epoch": 5.93,
      "learning_rate": 0.0001629833729216152,
      "loss": 0.6862,
      "step": 12490
    },
    {
      "epoch": 5.94,
      "learning_rate": 0.0001627933491686461,
      "loss": 0.6917,
      "step": 12500
    },
    {
      "epoch": 5.94,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7050400376319885,
      "eval_runtime": 0.5008,
      "eval_samples_per_second": 1741.211,
      "eval_steps_per_second": 13.978,
      "step": 12500
    },
    {
      "epoch": 5.94,
      "learning_rate": 0.00016260332541567698,
      "loss": 0.6873,
      "step": 12510
    },
    {
      "epoch": 5.95,
      "learning_rate": 0.00016241330166270784,
      "loss": 0.6967,
      "step": 12520
    },
    {
      "epoch": 5.95,
      "learning_rate": 0.00016222327790973873,
      "loss": 0.6749,
      "step": 12530
    },
    {
      "epoch": 5.96,
      "learning_rate": 0.0001620332541567696,
      "loss": 0.687,
      "step": 12540
    },
    {
      "epoch": 5.96,
      "learning_rate": 0.00016184323040380048,
      "loss": 0.7013,
      "step": 12550
    },
    {
      "epoch": 5.97,
      "learning_rate": 0.00016165320665083137,
      "loss": 0.6859,
      "step": 12560
    },
    {
      "epoch": 5.97,
      "learning_rate": 0.00016146318289786223,
      "loss": 0.6881,
      "step": 12570
    },
    {
      "epoch": 5.98,
      "learning_rate": 0.00016127315914489312,
      "loss": 0.686,
      "step": 12580
    },
    {
      "epoch": 5.98,
      "learning_rate": 0.00016108313539192398,
      "loss": 0.6873,
      "step": 12590
    },
    {
      "epoch": 5.99,
      "learning_rate": 0.0001608931116389549,
      "loss": 0.6868,
      "step": 12600
    },
    {
      "epoch": 5.99,
      "learning_rate": 0.00016070308788598576,
      "loss": 0.681,
      "step": 12610
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.00016051306413301665,
      "loss": 0.6815,
      "step": 12620
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.0001603230403800475,
      "loss": 0.6864,
      "step": 12630
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.0001601330166270784,
      "loss": 0.6995,
      "step": 12640
    },
    {
      "epoch": 6.01,
      "learning_rate": 0.00015994299287410929,
      "loss": 0.6988,
      "step": 12650
    },
    {
      "epoch": 6.01,
      "learning_rate": 0.00015975296912114015,
      "loss": 0.6952,
      "step": 12660
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.00015956294536817104,
      "loss": 0.6957,
      "step": 12670
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.0001593729216152019,
      "loss": 0.6893,
      "step": 12680
    },
    {
      "epoch": 6.03,
      "learning_rate": 0.00015918289786223279,
      "loss": 0.6786,
      "step": 12690
    },
    {
      "epoch": 6.03,
      "learning_rate": 0.00015899287410926367,
      "loss": 0.6947,
      "step": 12700
    },
    {
      "epoch": 6.04,
      "learning_rate": 0.00015880285035629454,
      "loss": 0.6896,
      "step": 12710
    },
    {
      "epoch": 6.04,
      "learning_rate": 0.00015861282660332543,
      "loss": 0.6905,
      "step": 12720
    },
    {
      "epoch": 6.05,
      "learning_rate": 0.00015842280285035631,
      "loss": 0.688,
      "step": 12730
    },
    {
      "epoch": 6.05,
      "learning_rate": 0.00015823277909738718,
      "loss": 0.6977,
      "step": 12740
    },
    {
      "epoch": 6.06,
      "learning_rate": 0.00015804275534441806,
      "loss": 0.6962,
      "step": 12750
    },
    {
      "epoch": 6.06,
      "learning_rate": 0.00015785273159144893,
      "loss": 0.6907,
      "step": 12760
    },
    {
      "epoch": 6.07,
      "learning_rate": 0.00015766270783847982,
      "loss": 0.6884,
      "step": 12770
    },
    {
      "epoch": 6.07,
      "learning_rate": 0.0001574726840855107,
      "loss": 0.6922,
      "step": 12780
    },
    {
      "epoch": 6.08,
      "learning_rate": 0.00015728266033254157,
      "loss": 0.6777,
      "step": 12790
    },
    {
      "epoch": 6.08,
      "learning_rate": 0.00015709263657957245,
      "loss": 0.6818,
      "step": 12800
    },
    {
      "epoch": 6.09,
      "learning_rate": 0.00015690261282660332,
      "loss": 0.6939,
      "step": 12810
    },
    {
      "epoch": 6.09,
      "learning_rate": 0.00015671258907363423,
      "loss": 0.6967,
      "step": 12820
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.0001565225653206651,
      "loss": 0.6938,
      "step": 12830
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.00015633254156769596,
      "loss": 0.6981,
      "step": 12840
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.00015614251781472684,
      "loss": 0.6879,
      "step": 12850
    },
    {
      "epoch": 6.11,
      "learning_rate": 0.00015595249406175773,
      "loss": 0.6767,
      "step": 12860
    },
    {
      "epoch": 6.11,
      "learning_rate": 0.00015576247030878862,
      "loss": 0.6872,
      "step": 12870
    },
    {
      "epoch": 6.12,
      "learning_rate": 0.00015557244655581948,
      "loss": 0.6975,
      "step": 12880
    },
    {
      "epoch": 6.12,
      "learning_rate": 0.00015538242280285035,
      "loss": 0.6901,
      "step": 12890
    },
    {
      "epoch": 6.13,
      "learning_rate": 0.00015519239904988123,
      "loss": 0.6813,
      "step": 12900
    },
    {
      "epoch": 6.13,
      "learning_rate": 0.00015500237529691212,
      "loss": 0.6918,
      "step": 12910
    },
    {
      "epoch": 6.14,
      "learning_rate": 0.000154812351543943,
      "loss": 0.6943,
      "step": 12920
    },
    {
      "epoch": 6.14,
      "learning_rate": 0.00015462232779097387,
      "loss": 0.6889,
      "step": 12930
    },
    {
      "epoch": 6.15,
      "learning_rate": 0.00015443230403800476,
      "loss": 0.6834,
      "step": 12940
    },
    {
      "epoch": 6.15,
      "learning_rate": 0.00015424228028503565,
      "loss": 0.6816,
      "step": 12950
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.0001540522565320665,
      "loss": 0.6727,
      "step": 12960
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.0001538622327790974,
      "loss": 0.6963,
      "step": 12970
    },
    {
      "epoch": 6.17,
      "learning_rate": 0.00015367220902612826,
      "loss": 0.6864,
      "step": 12980
    },
    {
      "epoch": 6.17,
      "learning_rate": 0.00015348218527315915,
      "loss": 0.6896,
      "step": 12990
    },
    {
      "epoch": 6.18,
      "learning_rate": 0.00015329216152019004,
      "loss": 0.6988,
      "step": 13000
    },
    {
      "epoch": 6.18,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7039761543273926,
      "eval_runtime": 0.5004,
      "eval_samples_per_second": 1742.544,
      "eval_steps_per_second": 13.988,
      "step": 13000
    },
    {
      "epoch": 6.18,
      "learning_rate": 0.0001531021377672209,
      "loss": 0.6809,
      "step": 13010
    },
    {
      "epoch": 6.19,
      "learning_rate": 0.0001529121140142518,
      "loss": 0.6822,
      "step": 13020
    },
    {
      "epoch": 6.19,
      "learning_rate": 0.00015272209026128265,
      "loss": 0.6752,
      "step": 13030
    },
    {
      "epoch": 6.19,
      "learning_rate": 0.00015253206650831354,
      "loss": 0.7045,
      "step": 13040
    },
    {
      "epoch": 6.2,
      "learning_rate": 0.00015234204275534443,
      "loss": 0.6944,
      "step": 13050
    },
    {
      "epoch": 6.2,
      "learning_rate": 0.0001521520190023753,
      "loss": 0.6936,
      "step": 13060
    },
    {
      "epoch": 6.21,
      "learning_rate": 0.00015196199524940618,
      "loss": 0.6965,
      "step": 13070
    },
    {
      "epoch": 6.21,
      "learning_rate": 0.00015177197149643707,
      "loss": 0.6885,
      "step": 13080
    },
    {
      "epoch": 6.22,
      "learning_rate": 0.00015158194774346793,
      "loss": 0.6904,
      "step": 13090
    },
    {
      "epoch": 6.22,
      "learning_rate": 0.00015139192399049882,
      "loss": 0.6872,
      "step": 13100
    },
    {
      "epoch": 6.23,
      "learning_rate": 0.00015120190023752968,
      "loss": 0.6863,
      "step": 13110
    },
    {
      "epoch": 6.23,
      "learning_rate": 0.0001510118764845606,
      "loss": 0.6856,
      "step": 13120
    },
    {
      "epoch": 6.24,
      "learning_rate": 0.00015082185273159146,
      "loss": 0.687,
      "step": 13130
    },
    {
      "epoch": 6.24,
      "learning_rate": 0.00015063182897862235,
      "loss": 0.6701,
      "step": 13140
    },
    {
      "epoch": 6.25,
      "learning_rate": 0.0001504418052256532,
      "loss": 0.6723,
      "step": 13150
    },
    {
      "epoch": 6.25,
      "learning_rate": 0.00015025178147268407,
      "loss": 0.6967,
      "step": 13160
    },
    {
      "epoch": 6.26,
      "learning_rate": 0.000150061757719715,
      "loss": 0.6948,
      "step": 13170
    },
    {
      "epoch": 6.26,
      "learning_rate": 0.00014987173396674585,
      "loss": 0.6814,
      "step": 13180
    },
    {
      "epoch": 6.27,
      "learning_rate": 0.00014968171021377674,
      "loss": 0.6905,
      "step": 13190
    },
    {
      "epoch": 6.27,
      "learning_rate": 0.0001494916864608076,
      "loss": 0.6812,
      "step": 13200
    },
    {
      "epoch": 6.28,
      "learning_rate": 0.0001493016627078385,
      "loss": 0.6911,
      "step": 13210
    },
    {
      "epoch": 6.28,
      "learning_rate": 0.00014911163895486938,
      "loss": 0.6831,
      "step": 13220
    },
    {
      "epoch": 6.29,
      "learning_rate": 0.00014892161520190024,
      "loss": 0.6918,
      "step": 13230
    },
    {
      "epoch": 6.29,
      "learning_rate": 0.00014873159144893113,
      "loss": 0.6972,
      "step": 13240
    },
    {
      "epoch": 6.29,
      "learning_rate": 0.000148541567695962,
      "loss": 0.6847,
      "step": 13250
    },
    {
      "epoch": 6.3,
      "learning_rate": 0.00014835154394299288,
      "loss": 0.6815,
      "step": 13260
    },
    {
      "epoch": 6.3,
      "learning_rate": 0.00014816152019002377,
      "loss": 0.6898,
      "step": 13270
    },
    {
      "epoch": 6.31,
      "learning_rate": 0.00014797149643705463,
      "loss": 0.681,
      "step": 13280
    },
    {
      "epoch": 6.31,
      "learning_rate": 0.00014778147268408552,
      "loss": 0.6969,
      "step": 13290
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.0001475914489311164,
      "loss": 0.6894,
      "step": 13300
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.00014740142517814727,
      "loss": 0.6885,
      "step": 13310
    },
    {
      "epoch": 6.33,
      "learning_rate": 0.00014721140142517816,
      "loss": 0.6881,
      "step": 13320
    },
    {
      "epoch": 6.33,
      "learning_rate": 0.00014702137767220902,
      "loss": 0.6878,
      "step": 13330
    },
    {
      "epoch": 6.34,
      "learning_rate": 0.00014683135391923993,
      "loss": 0.6796,
      "step": 13340
    },
    {
      "epoch": 6.34,
      "learning_rate": 0.0001466413301662708,
      "loss": 0.6949,
      "step": 13350
    },
    {
      "epoch": 6.35,
      "learning_rate": 0.00014645130641330166,
      "loss": 0.6998,
      "step": 13360
    },
    {
      "epoch": 6.35,
      "learning_rate": 0.00014626128266033255,
      "loss": 0.6844,
      "step": 13370
    },
    {
      "epoch": 6.36,
      "learning_rate": 0.0001460712589073634,
      "loss": 0.6872,
      "step": 13380
    },
    {
      "epoch": 6.36,
      "learning_rate": 0.00014588123515439432,
      "loss": 0.679,
      "step": 13390
    },
    {
      "epoch": 6.37,
      "learning_rate": 0.00014569121140142519,
      "loss": 0.6908,
      "step": 13400
    },
    {
      "epoch": 6.37,
      "learning_rate": 0.00014550118764845607,
      "loss": 0.6981,
      "step": 13410
    },
    {
      "epoch": 6.38,
      "learning_rate": 0.00014531116389548694,
      "loss": 0.6919,
      "step": 13420
    },
    {
      "epoch": 6.38,
      "learning_rate": 0.00014512114014251782,
      "loss": 0.688,
      "step": 13430
    },
    {
      "epoch": 6.38,
      "learning_rate": 0.00014493111638954871,
      "loss": 0.6898,
      "step": 13440
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.00014474109263657958,
      "loss": 0.6895,
      "step": 13450
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.00014455106888361046,
      "loss": 0.6862,
      "step": 13460
    },
    {
      "epoch": 6.4,
      "learning_rate": 0.00014436104513064135,
      "loss": 0.6699,
      "step": 13470
    },
    {
      "epoch": 6.4,
      "learning_rate": 0.00014417102137767221,
      "loss": 0.664,
      "step": 13480
    },
    {
      "epoch": 6.41,
      "learning_rate": 0.0001439809976247031,
      "loss": 0.6827,
      "step": 13490
    },
    {
      "epoch": 6.41,
      "learning_rate": 0.00014379097387173397,
      "loss": 0.7119,
      "step": 13500
    },
    {
      "epoch": 6.41,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7113440036773682,
      "eval_runtime": 0.4993,
      "eval_samples_per_second": 1746.403,
      "eval_steps_per_second": 14.019,
      "step": 13500
    },
    {
      "epoch": 6.42,
      "learning_rate": 0.00014360095011876485,
      "loss": 0.6805,
      "step": 13510
    },
    {
      "epoch": 6.42,
      "learning_rate": 0.00014341092636579574,
      "loss": 0.6884,
      "step": 13520
    },
    {
      "epoch": 6.43,
      "learning_rate": 0.0001432209026128266,
      "loss": 0.6848,
      "step": 13530
    },
    {
      "epoch": 6.43,
      "learning_rate": 0.0001430308788598575,
      "loss": 0.6937,
      "step": 13540
    },
    {
      "epoch": 6.44,
      "learning_rate": 0.00014284085510688835,
      "loss": 0.6914,
      "step": 13550
    },
    {
      "epoch": 6.44,
      "learning_rate": 0.00014265083135391924,
      "loss": 0.6783,
      "step": 13560
    },
    {
      "epoch": 6.45,
      "learning_rate": 0.00014246080760095013,
      "loss": 0.675,
      "step": 13570
    },
    {
      "epoch": 6.45,
      "learning_rate": 0.000142270783847981,
      "loss": 0.6866,
      "step": 13580
    },
    {
      "epoch": 6.46,
      "learning_rate": 0.00014208076009501188,
      "loss": 0.6952,
      "step": 13590
    },
    {
      "epoch": 6.46,
      "learning_rate": 0.00014189073634204274,
      "loss": 0.6759,
      "step": 13600
    },
    {
      "epoch": 6.47,
      "learning_rate": 0.00014170071258907366,
      "loss": 0.6775,
      "step": 13610
    },
    {
      "epoch": 6.47,
      "learning_rate": 0.00014151068883610452,
      "loss": 0.6944,
      "step": 13620
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.00014132066508313538,
      "loss": 0.6795,
      "step": 13630
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.00014113064133016627,
      "loss": 0.6765,
      "step": 13640
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.00014094061757719716,
      "loss": 0.6905,
      "step": 13650
    },
    {
      "epoch": 6.49,
      "learning_rate": 0.00014075059382422805,
      "loss": 0.6913,
      "step": 13660
    },
    {
      "epoch": 6.49,
      "learning_rate": 0.0001405605700712589,
      "loss": 0.6911,
      "step": 13670
    },
    {
      "epoch": 6.5,
      "learning_rate": 0.00014037054631828977,
      "loss": 0.684,
      "step": 13680
    },
    {
      "epoch": 6.5,
      "learning_rate": 0.0001401805225653207,
      "loss": 0.6889,
      "step": 13690
    },
    {
      "epoch": 6.51,
      "learning_rate": 0.00013999049881235155,
      "loss": 0.6737,
      "step": 13700
    },
    {
      "epoch": 6.51,
      "learning_rate": 0.00013980047505938244,
      "loss": 0.6812,
      "step": 13710
    },
    {
      "epoch": 6.52,
      "learning_rate": 0.0001396104513064133,
      "loss": 0.6756,
      "step": 13720
    },
    {
      "epoch": 6.52,
      "learning_rate": 0.0001394204275534442,
      "loss": 0.6915,
      "step": 13730
    },
    {
      "epoch": 6.53,
      "learning_rate": 0.00013923040380047508,
      "loss": 0.6887,
      "step": 13740
    },
    {
      "epoch": 6.53,
      "learning_rate": 0.00013904038004750594,
      "loss": 0.6842,
      "step": 13750
    },
    {
      "epoch": 6.54,
      "learning_rate": 0.00013885035629453683,
      "loss": 0.6953,
      "step": 13760
    },
    {
      "epoch": 6.54,
      "learning_rate": 0.0001386603325415677,
      "loss": 0.6863,
      "step": 13770
    },
    {
      "epoch": 6.55,
      "learning_rate": 0.00013847030878859858,
      "loss": 0.6942,
      "step": 13780
    },
    {
      "epoch": 6.55,
      "learning_rate": 0.00013828028503562947,
      "loss": 0.6915,
      "step": 13790
    },
    {
      "epoch": 6.56,
      "learning_rate": 0.00013809026128266033,
      "loss": 0.6814,
      "step": 13800
    },
    {
      "epoch": 6.56,
      "learning_rate": 0.00013790023752969122,
      "loss": 0.6937,
      "step": 13810
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.0001377102137767221,
      "loss": 0.6901,
      "step": 13820
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.00013752019002375297,
      "loss": 0.6767,
      "step": 13830
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.00013733016627078386,
      "loss": 0.6804,
      "step": 13840
    },
    {
      "epoch": 6.58,
      "learning_rate": 0.00013714014251781472,
      "loss": 0.6971,
      "step": 13850
    },
    {
      "epoch": 6.58,
      "learning_rate": 0.0001369501187648456,
      "loss": 0.6928,
      "step": 13860
    },
    {
      "epoch": 6.59,
      "learning_rate": 0.0001367600950118765,
      "loss": 0.6886,
      "step": 13870
    },
    {
      "epoch": 6.59,
      "learning_rate": 0.00013657007125890736,
      "loss": 0.696,
      "step": 13880
    },
    {
      "epoch": 6.6,
      "learning_rate": 0.00013638004750593825,
      "loss": 0.6945,
      "step": 13890
    },
    {
      "epoch": 6.6,
      "learning_rate": 0.0001361900237529691,
      "loss": 0.6885,
      "step": 13900
    },
    {
      "epoch": 6.61,
      "learning_rate": 0.00013600000000000003,
      "loss": 0.6929,
      "step": 13910
    },
    {
      "epoch": 6.61,
      "learning_rate": 0.0001358099762470309,
      "loss": 0.6997,
      "step": 13920
    },
    {
      "epoch": 6.62,
      "learning_rate": 0.00013561995249406178,
      "loss": 0.6913,
      "step": 13930
    },
    {
      "epoch": 6.62,
      "learning_rate": 0.00013542992874109264,
      "loss": 0.6939,
      "step": 13940
    },
    {
      "epoch": 6.63,
      "learning_rate": 0.0001352399049881235,
      "loss": 0.6692,
      "step": 13950
    },
    {
      "epoch": 6.63,
      "learning_rate": 0.00013504988123515442,
      "loss": 0.6807,
      "step": 13960
    },
    {
      "epoch": 6.64,
      "learning_rate": 0.00013485985748218528,
      "loss": 0.6827,
      "step": 13970
    },
    {
      "epoch": 6.64,
      "learning_rate": 0.00013466983372921617,
      "loss": 0.6876,
      "step": 13980
    },
    {
      "epoch": 6.65,
      "learning_rate": 0.00013447980997624703,
      "loss": 0.6728,
      "step": 13990
    },
    {
      "epoch": 6.65,
      "learning_rate": 0.00013428978622327792,
      "loss": 0.6793,
      "step": 14000
    },
    {
      "epoch": 6.65,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7130166292190552,
      "eval_runtime": 0.4964,
      "eval_samples_per_second": 1756.716,
      "eval_steps_per_second": 14.102,
      "step": 14000
    },
    {
      "epoch": 6.66,
      "learning_rate": 0.0001340997624703088,
      "loss": 0.6969,
      "step": 14010
    },
    {
      "epoch": 6.66,
      "learning_rate": 0.00013390973871733967,
      "loss": 0.6859,
      "step": 14020
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.00013371971496437056,
      "loss": 0.6879,
      "step": 14030
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.00013352969121140144,
      "loss": 0.6842,
      "step": 14040
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.0001333396674584323,
      "loss": 0.6917,
      "step": 14050
    },
    {
      "epoch": 6.68,
      "learning_rate": 0.0001331496437054632,
      "loss": 0.6858,
      "step": 14060
    },
    {
      "epoch": 6.68,
      "learning_rate": 0.00013295961995249406,
      "loss": 0.6919,
      "step": 14070
    },
    {
      "epoch": 6.69,
      "learning_rate": 0.00013276959619952495,
      "loss": 0.6895,
      "step": 14080
    },
    {
      "epoch": 6.69,
      "learning_rate": 0.00013257957244655583,
      "loss": 0.6924,
      "step": 14090
    },
    {
      "epoch": 6.7,
      "learning_rate": 0.0001323895486935867,
      "loss": 0.6894,
      "step": 14100
    },
    {
      "epoch": 6.7,
      "learning_rate": 0.00013219952494061759,
      "loss": 0.6879,
      "step": 14110
    },
    {
      "epoch": 6.71,
      "learning_rate": 0.00013200950118764845,
      "loss": 0.6921,
      "step": 14120
    },
    {
      "epoch": 6.71,
      "learning_rate": 0.00013181947743467936,
      "loss": 0.6899,
      "step": 14130
    },
    {
      "epoch": 6.72,
      "learning_rate": 0.00013162945368171022,
      "loss": 0.6983,
      "step": 14140
    },
    {
      "epoch": 6.72,
      "learning_rate": 0.00013143942992874109,
      "loss": 0.6912,
      "step": 14150
    },
    {
      "epoch": 6.73,
      "learning_rate": 0.00013124940617577197,
      "loss": 0.684,
      "step": 14160
    },
    {
      "epoch": 6.73,
      "learning_rate": 0.00013105938242280286,
      "loss": 0.6973,
      "step": 14170
    },
    {
      "epoch": 6.74,
      "learning_rate": 0.00013086935866983375,
      "loss": 0.6909,
      "step": 14180
    },
    {
      "epoch": 6.74,
      "learning_rate": 0.00013067933491686461,
      "loss": 0.6841,
      "step": 14190
    },
    {
      "epoch": 6.75,
      "learning_rate": 0.00013048931116389548,
      "loss": 0.689,
      "step": 14200
    },
    {
      "epoch": 6.75,
      "learning_rate": 0.00013029928741092636,
      "loss": 0.6913,
      "step": 14210
    },
    {
      "epoch": 6.76,
      "learning_rate": 0.00013010926365795725,
      "loss": 0.6937,
      "step": 14220
    },
    {
      "epoch": 6.76,
      "learning_rate": 0.00012991923990498814,
      "loss": 0.69,
      "step": 14230
    },
    {
      "epoch": 6.76,
      "learning_rate": 0.000129729216152019,
      "loss": 0.6712,
      "step": 14240
    },
    {
      "epoch": 6.77,
      "learning_rate": 0.0001295391923990499,
      "loss": 0.675,
      "step": 14250
    },
    {
      "epoch": 6.77,
      "learning_rate": 0.00012934916864608078,
      "loss": 0.6867,
      "step": 14260
    },
    {
      "epoch": 6.78,
      "learning_rate": 0.00012915914489311164,
      "loss": 0.6921,
      "step": 14270
    },
    {
      "epoch": 6.78,
      "learning_rate": 0.00012896912114014253,
      "loss": 0.6962,
      "step": 14280
    },
    {
      "epoch": 6.79,
      "learning_rate": 0.0001287790973871734,
      "loss": 0.6951,
      "step": 14290
    },
    {
      "epoch": 6.79,
      "learning_rate": 0.00012858907363420428,
      "loss": 0.7015,
      "step": 14300
    },
    {
      "epoch": 6.8,
      "learning_rate": 0.00012839904988123517,
      "loss": 0.6838,
      "step": 14310
    },
    {
      "epoch": 6.8,
      "learning_rate": 0.00012820902612826603,
      "loss": 0.6919,
      "step": 14320
    },
    {
      "epoch": 6.81,
      "learning_rate": 0.00012801900237529692,
      "loss": 0.683,
      "step": 14330
    },
    {
      "epoch": 6.81,
      "learning_rate": 0.00012782897862232778,
      "loss": 0.6865,
      "step": 14340
    },
    {
      "epoch": 6.82,
      "learning_rate": 0.00012763895486935867,
      "loss": 0.6959,
      "step": 14350
    },
    {
      "epoch": 6.82,
      "learning_rate": 0.00012744893111638956,
      "loss": 0.6781,
      "step": 14360
    },
    {
      "epoch": 6.83,
      "learning_rate": 0.00012725890736342042,
      "loss": 0.6846,
      "step": 14370
    },
    {
      "epoch": 6.83,
      "learning_rate": 0.0001270688836104513,
      "loss": 0.6839,
      "step": 14380
    },
    {
      "epoch": 6.84,
      "learning_rate": 0.0001268788598574822,
      "loss": 0.6815,
      "step": 14390
    },
    {
      "epoch": 6.84,
      "learning_rate": 0.0001266888361045131,
      "loss": 0.6899,
      "step": 14400
    },
    {
      "epoch": 6.85,
      "learning_rate": 0.00012649881235154395,
      "loss": 0.6789,
      "step": 14410
    },
    {
      "epoch": 6.85,
      "learning_rate": 0.0001263087885985748,
      "loss": 0.7033,
      "step": 14420
    },
    {
      "epoch": 6.86,
      "learning_rate": 0.0001261187648456057,
      "loss": 0.688,
      "step": 14430
    },
    {
      "epoch": 6.86,
      "learning_rate": 0.0001259287410926366,
      "loss": 0.6858,
      "step": 14440
    },
    {
      "epoch": 6.86,
      "learning_rate": 0.00012573871733966748,
      "loss": 0.6788,
      "step": 14450
    },
    {
      "epoch": 6.87,
      "learning_rate": 0.00012554869358669834,
      "loss": 0.6879,
      "step": 14460
    },
    {
      "epoch": 6.87,
      "learning_rate": 0.0001253586698337292,
      "loss": 0.6858,
      "step": 14470
    },
    {
      "epoch": 6.88,
      "learning_rate": 0.00012516864608076012,
      "loss": 0.6842,
      "step": 14480
    },
    {
      "epoch": 6.88,
      "learning_rate": 0.00012497862232779098,
      "loss": 0.6908,
      "step": 14490
    },
    {
      "epoch": 6.89,
      "learning_rate": 0.00012478859857482187,
      "loss": 0.6911,
      "step": 14500
    },
    {
      "epoch": 6.89,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6982399225234985,
      "eval_runtime": 0.5118,
      "eval_samples_per_second": 1703.701,
      "eval_steps_per_second": 13.676,
      "step": 14500
    },
    {
      "epoch": 6.89,
      "learning_rate": 0.00012459857482185273,
      "loss": 0.6872,
      "step": 14510
    },
    {
      "epoch": 6.9,
      "learning_rate": 0.0001244085510688836,
      "loss": 0.6839,
      "step": 14520
    },
    {
      "epoch": 6.9,
      "learning_rate": 0.0001242185273159145,
      "loss": 0.6752,
      "step": 14530
    },
    {
      "epoch": 6.91,
      "learning_rate": 0.00012402850356294537,
      "loss": 0.6825,
      "step": 14540
    },
    {
      "epoch": 6.91,
      "learning_rate": 0.00012383847980997626,
      "loss": 0.6816,
      "step": 14550
    },
    {
      "epoch": 6.92,
      "learning_rate": 0.00012364845605700712,
      "loss": 0.6958,
      "step": 14560
    },
    {
      "epoch": 6.92,
      "learning_rate": 0.000123458432304038,
      "loss": 0.6793,
      "step": 14570
    },
    {
      "epoch": 6.93,
      "learning_rate": 0.0001232684085510689,
      "loss": 0.6729,
      "step": 14580
    },
    {
      "epoch": 6.93,
      "learning_rate": 0.00012307838479809976,
      "loss": 0.6862,
      "step": 14590
    },
    {
      "epoch": 6.94,
      "learning_rate": 0.00012288836104513065,
      "loss": 0.6882,
      "step": 14600
    },
    {
      "epoch": 6.94,
      "learning_rate": 0.00012269833729216154,
      "loss": 0.6939,
      "step": 14610
    },
    {
      "epoch": 6.95,
      "learning_rate": 0.0001225083135391924,
      "loss": 0.683,
      "step": 14620
    },
    {
      "epoch": 6.95,
      "learning_rate": 0.0001223182897862233,
      "loss": 0.6788,
      "step": 14630
    },
    {
      "epoch": 6.95,
      "learning_rate": 0.00012212826603325415,
      "loss": 0.6921,
      "step": 14640
    },
    {
      "epoch": 6.96,
      "learning_rate": 0.00012193824228028504,
      "loss": 0.6951,
      "step": 14650
    },
    {
      "epoch": 6.96,
      "learning_rate": 0.00012174821852731593,
      "loss": 0.6895,
      "step": 14660
    },
    {
      "epoch": 6.97,
      "learning_rate": 0.0001215581947743468,
      "loss": 0.6873,
      "step": 14670
    },
    {
      "epoch": 6.97,
      "learning_rate": 0.00012136817102137768,
      "loss": 0.6842,
      "step": 14680
    },
    {
      "epoch": 6.98,
      "learning_rate": 0.00012117814726840855,
      "loss": 0.6772,
      "step": 14690
    },
    {
      "epoch": 6.98,
      "learning_rate": 0.00012098812351543944,
      "loss": 0.6945,
      "step": 14700
    },
    {
      "epoch": 6.99,
      "learning_rate": 0.00012079809976247032,
      "loss": 0.6842,
      "step": 14710
    },
    {
      "epoch": 6.99,
      "learning_rate": 0.00012060807600950119,
      "loss": 0.6919,
      "step": 14720
    },
    {
      "epoch": 7.0,
      "learning_rate": 0.00012041805225653207,
      "loss": 0.6773,
      "step": 14730
    },
    {
      "epoch": 7.0,
      "learning_rate": 0.00012022802850356296,
      "loss": 0.6817,
      "step": 14740
    },
    {
      "epoch": 7.01,
      "learning_rate": 0.00012003800475059383,
      "loss": 0.6908,
      "step": 14750
    },
    {
      "epoch": 7.01,
      "learning_rate": 0.0001198479809976247,
      "loss": 0.683,
      "step": 14760
    },
    {
      "epoch": 7.02,
      "learning_rate": 0.00011965795724465558,
      "loss": 0.6773,
      "step": 14770
    },
    {
      "epoch": 7.02,
      "learning_rate": 0.00011946793349168646,
      "loss": 0.6918,
      "step": 14780
    },
    {
      "epoch": 7.03,
      "learning_rate": 0.00011927790973871736,
      "loss": 0.6781,
      "step": 14790
    },
    {
      "epoch": 7.03,
      "learning_rate": 0.00011908788598574822,
      "loss": 0.6769,
      "step": 14800
    },
    {
      "epoch": 7.04,
      "learning_rate": 0.0001188978622327791,
      "loss": 0.6897,
      "step": 14810
    },
    {
      "epoch": 7.04,
      "learning_rate": 0.00011870783847980997,
      "loss": 0.6864,
      "step": 14820
    },
    {
      "epoch": 7.05,
      "learning_rate": 0.00011851781472684087,
      "loss": 0.6838,
      "step": 14830
    },
    {
      "epoch": 7.05,
      "learning_rate": 0.00011832779097387175,
      "loss": 0.68,
      "step": 14840
    },
    {
      "epoch": 7.05,
      "learning_rate": 0.00011813776722090262,
      "loss": 0.6951,
      "step": 14850
    },
    {
      "epoch": 7.06,
      "learning_rate": 0.00011794774346793349,
      "loss": 0.6917,
      "step": 14860
    },
    {
      "epoch": 7.06,
      "learning_rate": 0.00011775771971496436,
      "loss": 0.6993,
      "step": 14870
    },
    {
      "epoch": 7.07,
      "learning_rate": 0.00011756769596199526,
      "loss": 0.6996,
      "step": 14880
    },
    {
      "epoch": 7.07,
      "learning_rate": 0.00011737767220902614,
      "loss": 0.6955,
      "step": 14890
    },
    {
      "epoch": 7.08,
      "learning_rate": 0.00011718764845605701,
      "loss": 0.691,
      "step": 14900
    },
    {
      "epoch": 7.08,
      "learning_rate": 0.00011699762470308789,
      "loss": 0.6924,
      "step": 14910
    },
    {
      "epoch": 7.09,
      "learning_rate": 0.00011680760095011878,
      "loss": 0.6944,
      "step": 14920
    },
    {
      "epoch": 7.09,
      "learning_rate": 0.00011661757719714965,
      "loss": 0.6821,
      "step": 14930
    },
    {
      "epoch": 7.1,
      "learning_rate": 0.00011642755344418053,
      "loss": 0.6904,
      "step": 14940
    },
    {
      "epoch": 7.1,
      "learning_rate": 0.0001162375296912114,
      "loss": 0.6944,
      "step": 14950
    },
    {
      "epoch": 7.11,
      "learning_rate": 0.00011604750593824229,
      "loss": 0.677,
      "step": 14960
    },
    {
      "epoch": 7.11,
      "learning_rate": 0.00011585748218527317,
      "loss": 0.6831,
      "step": 14970
    },
    {
      "epoch": 7.12,
      "learning_rate": 0.00011566745843230404,
      "loss": 0.6998,
      "step": 14980
    },
    {
      "epoch": 7.12,
      "learning_rate": 0.00011547743467933492,
      "loss": 0.6751,
      "step": 14990
    },
    {
      "epoch": 7.13,
      "learning_rate": 0.00011528741092636579,
      "loss": 0.6915,
      "step": 15000
    },
    {
      "epoch": 7.13,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7052797079086304,
      "eval_runtime": 0.4982,
      "eval_samples_per_second": 1750.166,
      "eval_steps_per_second": 14.049,
      "step": 15000
    },
    {
      "epoch": 7.13,
      "learning_rate": 0.00011509738717339668,
      "loss": 0.6889,
      "step": 15010
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.00011490736342042756,
      "loss": 0.6903,
      "step": 15020
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.00011471733966745843,
      "loss": 0.6914,
      "step": 15030
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.00011452731591448931,
      "loss": 0.687,
      "step": 15040
    },
    {
      "epoch": 7.15,
      "learning_rate": 0.00011433729216152021,
      "loss": 0.6854,
      "step": 15050
    },
    {
      "epoch": 7.15,
      "learning_rate": 0.00011414726840855107,
      "loss": 0.6816,
      "step": 15060
    },
    {
      "epoch": 7.16,
      "learning_rate": 0.00011395724465558195,
      "loss": 0.6826,
      "step": 15070
    },
    {
      "epoch": 7.16,
      "learning_rate": 0.00011376722090261282,
      "loss": 0.6908,
      "step": 15080
    },
    {
      "epoch": 7.17,
      "learning_rate": 0.00011357719714964372,
      "loss": 0.6922,
      "step": 15090
    },
    {
      "epoch": 7.17,
      "learning_rate": 0.0001133871733966746,
      "loss": 0.6922,
      "step": 15100
    },
    {
      "epoch": 7.18,
      "learning_rate": 0.00011319714964370547,
      "loss": 0.6825,
      "step": 15110
    },
    {
      "epoch": 7.18,
      "learning_rate": 0.00011300712589073634,
      "loss": 0.6886,
      "step": 15120
    },
    {
      "epoch": 7.19,
      "learning_rate": 0.00011281710213776721,
      "loss": 0.6866,
      "step": 15130
    },
    {
      "epoch": 7.19,
      "learning_rate": 0.00011262707838479811,
      "loss": 0.6838,
      "step": 15140
    },
    {
      "epoch": 7.2,
      "learning_rate": 0.00011243705463182899,
      "loss": 0.6805,
      "step": 15150
    },
    {
      "epoch": 7.2,
      "learning_rate": 0.00011224703087885986,
      "loss": 0.6827,
      "step": 15160
    },
    {
      "epoch": 7.21,
      "learning_rate": 0.00011205700712589074,
      "loss": 0.6969,
      "step": 15170
    },
    {
      "epoch": 7.21,
      "learning_rate": 0.00011186698337292163,
      "loss": 0.7006,
      "step": 15180
    },
    {
      "epoch": 7.22,
      "learning_rate": 0.0001116769596199525,
      "loss": 0.6993,
      "step": 15190
    },
    {
      "epoch": 7.22,
      "learning_rate": 0.00011148693586698338,
      "loss": 0.683,
      "step": 15200
    },
    {
      "epoch": 7.23,
      "learning_rate": 0.00011129691211401425,
      "loss": 0.68,
      "step": 15210
    },
    {
      "epoch": 7.23,
      "learning_rate": 0.00011110688836104513,
      "loss": 0.6976,
      "step": 15220
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.00011091686460807602,
      "loss": 0.6948,
      "step": 15230
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.0001107268408551069,
      "loss": 0.6854,
      "step": 15240
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.00011053681710213777,
      "loss": 0.6822,
      "step": 15250
    },
    {
      "epoch": 7.25,
      "learning_rate": 0.00011034679334916864,
      "loss": 0.6865,
      "step": 15260
    },
    {
      "epoch": 7.25,
      "learning_rate": 0.00011015676959619953,
      "loss": 0.6739,
      "step": 15270
    },
    {
      "epoch": 7.26,
      "learning_rate": 0.00010996674584323041,
      "loss": 0.6819,
      "step": 15280
    },
    {
      "epoch": 7.26,
      "learning_rate": 0.00010977672209026128,
      "loss": 0.6879,
      "step": 15290
    },
    {
      "epoch": 7.27,
      "learning_rate": 0.00010958669833729216,
      "loss": 0.6914,
      "step": 15300
    },
    {
      "epoch": 7.27,
      "learning_rate": 0.00010939667458432306,
      "loss": 0.687,
      "step": 15310
    },
    {
      "epoch": 7.28,
      "learning_rate": 0.00010920665083135392,
      "loss": 0.6792,
      "step": 15320
    },
    {
      "epoch": 7.28,
      "learning_rate": 0.0001090166270783848,
      "loss": 0.6842,
      "step": 15330
    },
    {
      "epoch": 7.29,
      "learning_rate": 0.00010882660332541567,
      "loss": 0.6847,
      "step": 15340
    },
    {
      "epoch": 7.29,
      "learning_rate": 0.00010863657957244655,
      "loss": 0.6911,
      "step": 15350
    },
    {
      "epoch": 7.3,
      "learning_rate": 0.00010844655581947745,
      "loss": 0.6913,
      "step": 15360
    },
    {
      "epoch": 7.3,
      "learning_rate": 0.00010825653206650833,
      "loss": 0.6914,
      "step": 15370
    },
    {
      "epoch": 7.31,
      "learning_rate": 0.00010806650831353919,
      "loss": 0.6977,
      "step": 15380
    },
    {
      "epoch": 7.31,
      "learning_rate": 0.00010787648456057006,
      "loss": 0.6903,
      "step": 15390
    },
    {
      "epoch": 7.32,
      "learning_rate": 0.00010768646080760097,
      "loss": 0.6807,
      "step": 15400
    },
    {
      "epoch": 7.32,
      "learning_rate": 0.00010749643705463184,
      "loss": 0.6985,
      "step": 15410
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.00010730641330166272,
      "loss": 0.6889,
      "step": 15420
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.00010711638954869359,
      "loss": 0.684,
      "step": 15430
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.00010692636579572448,
      "loss": 0.699,
      "step": 15440
    },
    {
      "epoch": 7.34,
      "learning_rate": 0.00010673634204275535,
      "loss": 0.6921,
      "step": 15450
    },
    {
      "epoch": 7.34,
      "learning_rate": 0.00010654631828978623,
      "loss": 0.6938,
      "step": 15460
    },
    {
      "epoch": 7.35,
      "learning_rate": 0.0001063562945368171,
      "loss": 0.677,
      "step": 15470
    },
    {
      "epoch": 7.35,
      "learning_rate": 0.00010616627078384798,
      "loss": 0.689,
      "step": 15480
    },
    {
      "epoch": 7.36,
      "learning_rate": 0.00010597624703087887,
      "loss": 0.6846,
      "step": 15490
    },
    {
      "epoch": 7.36,
      "learning_rate": 0.00010578622327790974,
      "loss": 0.692,
      "step": 15500
    },
    {
      "epoch": 7.36,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7191968560218811,
      "eval_runtime": 0.5034,
      "eval_samples_per_second": 1732.216,
      "eval_steps_per_second": 13.905,
      "step": 15500
    },
    {
      "epoch": 7.37,
      "learning_rate": 0.00010559619952494062,
      "loss": 0.6923,
      "step": 15510
    },
    {
      "epoch": 7.37,
      "learning_rate": 0.0001054061757719715,
      "loss": 0.6909,
      "step": 15520
    },
    {
      "epoch": 7.38,
      "learning_rate": 0.00010521615201900238,
      "loss": 0.6912,
      "step": 15530
    },
    {
      "epoch": 7.38,
      "learning_rate": 0.00010502612826603326,
      "loss": 0.689,
      "step": 15540
    },
    {
      "epoch": 7.39,
      "learning_rate": 0.00010483610451306413,
      "loss": 0.6902,
      "step": 15550
    },
    {
      "epoch": 7.39,
      "learning_rate": 0.00010464608076009501,
      "loss": 0.6904,
      "step": 15560
    },
    {
      "epoch": 7.4,
      "learning_rate": 0.00010445605700712588,
      "loss": 0.6815,
      "step": 15570
    },
    {
      "epoch": 7.4,
      "learning_rate": 0.00010426603325415679,
      "loss": 0.685,
      "step": 15580
    },
    {
      "epoch": 7.41,
      "learning_rate": 0.00010407600950118765,
      "loss": 0.6901,
      "step": 15590
    },
    {
      "epoch": 7.41,
      "learning_rate": 0.00010388598574821852,
      "loss": 0.6895,
      "step": 15600
    },
    {
      "epoch": 7.42,
      "learning_rate": 0.0001036959619952494,
      "loss": 0.6775,
      "step": 15610
    },
    {
      "epoch": 7.42,
      "learning_rate": 0.0001035059382422803,
      "loss": 0.686,
      "step": 15620
    },
    {
      "epoch": 7.43,
      "learning_rate": 0.00010331591448931118,
      "loss": 0.6983,
      "step": 15630
    },
    {
      "epoch": 7.43,
      "learning_rate": 0.00010312589073634205,
      "loss": 0.6847,
      "step": 15640
    },
    {
      "epoch": 7.43,
      "learning_rate": 0.00010293586698337291,
      "loss": 0.6937,
      "step": 15650
    },
    {
      "epoch": 7.44,
      "learning_rate": 0.00010276484560570072,
      "loss": 0.6843,
      "step": 15660
    },
    {
      "epoch": 7.44,
      "learning_rate": 0.00010257482185273159,
      "loss": 0.6913,
      "step": 15670
    },
    {
      "epoch": 7.45,
      "learning_rate": 0.00010238479809976247,
      "loss": 0.6857,
      "step": 15680
    },
    {
      "epoch": 7.45,
      "learning_rate": 0.00010219477434679337,
      "loss": 0.6866,
      "step": 15690
    },
    {
      "epoch": 7.46,
      "learning_rate": 0.00010200475059382424,
      "loss": 0.6817,
      "step": 15700
    },
    {
      "epoch": 7.46,
      "learning_rate": 0.0001018147268408551,
      "loss": 0.6896,
      "step": 15710
    },
    {
      "epoch": 7.47,
      "learning_rate": 0.00010162470308788598,
      "loss": 0.6921,
      "step": 15720
    },
    {
      "epoch": 7.47,
      "learning_rate": 0.00010143467933491686,
      "loss": 0.6861,
      "step": 15730
    },
    {
      "epoch": 7.48,
      "learning_rate": 0.00010124465558194776,
      "loss": 0.6892,
      "step": 15740
    },
    {
      "epoch": 7.48,
      "learning_rate": 0.00010105463182897863,
      "loss": 0.6852,
      "step": 15750
    },
    {
      "epoch": 7.49,
      "learning_rate": 0.00010086460807600951,
      "loss": 0.6912,
      "step": 15760
    },
    {
      "epoch": 7.49,
      "learning_rate": 0.00010067458432304037,
      "loss": 0.6976,
      "step": 15770
    },
    {
      "epoch": 7.5,
      "learning_rate": 0.00010050356294536817,
      "loss": 0.6881,
      "step": 15780
    },
    {
      "epoch": 7.5,
      "learning_rate": 0.00010031353919239905,
      "loss": 0.693,
      "step": 15790
    },
    {
      "epoch": 7.51,
      "learning_rate": 0.00010012351543942992,
      "loss": 0.6912,
      "step": 15800
    },
    {
      "epoch": 7.51,
      "learning_rate": 9.993349168646081e-05,
      "loss": 0.6896,
      "step": 15810
    },
    {
      "epoch": 7.52,
      "learning_rate": 9.97434679334917e-05,
      "loss": 0.6828,
      "step": 15820
    },
    {
      "epoch": 7.52,
      "learning_rate": 9.955344418052256e-05,
      "loss": 0.6859,
      "step": 15830
    },
    {
      "epoch": 7.52,
      "learning_rate": 9.936342042755344e-05,
      "loss": 0.6866,
      "step": 15840
    },
    {
      "epoch": 7.53,
      "learning_rate": 9.917339667458433e-05,
      "loss": 0.6632,
      "step": 15850
    },
    {
      "epoch": 7.53,
      "learning_rate": 9.89833729216152e-05,
      "loss": 0.7038,
      "step": 15860
    },
    {
      "epoch": 7.54,
      "learning_rate": 9.879334916864609e-05,
      "loss": 0.6811,
      "step": 15870
    },
    {
      "epoch": 7.54,
      "learning_rate": 9.860332541567697e-05,
      "loss": 0.6728,
      "step": 15880
    },
    {
      "epoch": 7.55,
      "learning_rate": 9.841330166270784e-05,
      "loss": 0.7003,
      "step": 15890
    },
    {
      "epoch": 7.55,
      "learning_rate": 9.822327790973872e-05,
      "loss": 0.6634,
      "step": 15900
    },
    {
      "epoch": 7.56,
      "learning_rate": 9.80332541567696e-05,
      "loss": 0.6854,
      "step": 15910
    },
    {
      "epoch": 7.56,
      "learning_rate": 9.784323040380048e-05,
      "loss": 0.6949,
      "step": 15920
    },
    {
      "epoch": 7.57,
      "learning_rate": 9.765320665083137e-05,
      "loss": 0.6842,
      "step": 15930
    },
    {
      "epoch": 7.57,
      "learning_rate": 9.746318289786223e-05,
      "loss": 0.6919,
      "step": 15940
    },
    {
      "epoch": 7.58,
      "learning_rate": 9.727315914489311e-05,
      "loss": 0.6868,
      "step": 15950
    },
    {
      "epoch": 7.58,
      "learning_rate": 9.7083135391924e-05,
      "loss": 0.6862,
      "step": 15960
    },
    {
      "epoch": 7.59,
      "learning_rate": 9.689311163895487e-05,
      "loss": 0.6875,
      "step": 15970
    },
    {
      "epoch": 7.59,
      "learning_rate": 9.670308788598576e-05,
      "loss": 0.6917,
      "step": 15980
    },
    {
      "epoch": 7.6,
      "learning_rate": 9.651306413301664e-05,
      "loss": 0.6846,
      "step": 15990
    },
    {
      "epoch": 7.6,
      "learning_rate": 9.632304038004751e-05,
      "loss": 0.6878,
      "step": 16000
    },
    {
      "epoch": 7.6,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.703770637512207,
      "eval_runtime": 0.4972,
      "eval_samples_per_second": 1753.993,
      "eval_steps_per_second": 14.08,
      "step": 16000
    },
    {
      "epoch": 7.61,
      "learning_rate": 9.613301662707839e-05,
      "loss": 0.6701,
      "step": 16010
    },
    {
      "epoch": 7.61,
      "learning_rate": 9.594299287410927e-05,
      "loss": 0.6898,
      "step": 16020
    },
    {
      "epoch": 7.62,
      "learning_rate": 9.575296912114015e-05,
      "loss": 0.6754,
      "step": 16030
    },
    {
      "epoch": 7.62,
      "learning_rate": 9.556294536817102e-05,
      "loss": 0.6907,
      "step": 16040
    },
    {
      "epoch": 7.62,
      "learning_rate": 9.53729216152019e-05,
      "loss": 0.6722,
      "step": 16050
    },
    {
      "epoch": 7.63,
      "learning_rate": 9.518289786223278e-05,
      "loss": 0.6746,
      "step": 16060
    },
    {
      "epoch": 7.63,
      "learning_rate": 9.499287410926366e-05,
      "loss": 0.6917,
      "step": 16070
    },
    {
      "epoch": 7.64,
      "learning_rate": 9.480285035629454e-05,
      "loss": 0.6919,
      "step": 16080
    },
    {
      "epoch": 7.64,
      "learning_rate": 9.461282660332543e-05,
      "loss": 0.6892,
      "step": 16090
    },
    {
      "epoch": 7.65,
      "learning_rate": 9.442280285035629e-05,
      "loss": 0.6738,
      "step": 16100
    },
    {
      "epoch": 7.65,
      "learning_rate": 9.423277909738718e-05,
      "loss": 0.6877,
      "step": 16110
    },
    {
      "epoch": 7.66,
      "learning_rate": 9.404275534441805e-05,
      "loss": 0.678,
      "step": 16120
    },
    {
      "epoch": 7.66,
      "learning_rate": 9.385273159144894e-05,
      "loss": 0.6864,
      "step": 16130
    },
    {
      "epoch": 7.67,
      "learning_rate": 9.366270783847982e-05,
      "loss": 0.6683,
      "step": 16140
    },
    {
      "epoch": 7.67,
      "learning_rate": 9.34726840855107e-05,
      "loss": 0.6849,
      "step": 16150
    },
    {
      "epoch": 7.68,
      "learning_rate": 9.328266033254157e-05,
      "loss": 0.6817,
      "step": 16160
    },
    {
      "epoch": 7.68,
      "learning_rate": 9.309263657957246e-05,
      "loss": 0.6858,
      "step": 16170
    },
    {
      "epoch": 7.69,
      "learning_rate": 9.290261282660333e-05,
      "loss": 0.6934,
      "step": 16180
    },
    {
      "epoch": 7.69,
      "learning_rate": 9.271258907363421e-05,
      "loss": 0.6702,
      "step": 16190
    },
    {
      "epoch": 7.7,
      "learning_rate": 9.252256532066508e-05,
      "loss": 0.6868,
      "step": 16200
    },
    {
      "epoch": 7.7,
      "learning_rate": 9.233254156769596e-05,
      "loss": 0.6811,
      "step": 16210
    },
    {
      "epoch": 7.71,
      "learning_rate": 9.214251781472685e-05,
      "loss": 0.6751,
      "step": 16220
    },
    {
      "epoch": 7.71,
      "learning_rate": 9.195249406175772e-05,
      "loss": 0.6875,
      "step": 16230
    },
    {
      "epoch": 7.71,
      "learning_rate": 9.176247030878861e-05,
      "loss": 0.6783,
      "step": 16240
    },
    {
      "epoch": 7.72,
      "learning_rate": 9.157244655581949e-05,
      "loss": 0.6904,
      "step": 16250
    },
    {
      "epoch": 7.72,
      "learning_rate": 9.138242280285036e-05,
      "loss": 0.6953,
      "step": 16260
    },
    {
      "epoch": 7.73,
      "learning_rate": 9.119239904988124e-05,
      "loss": 0.694,
      "step": 16270
    },
    {
      "epoch": 7.73,
      "learning_rate": 9.100237529691213e-05,
      "loss": 0.6935,
      "step": 16280
    },
    {
      "epoch": 7.74,
      "learning_rate": 9.0812351543943e-05,
      "loss": 0.6857,
      "step": 16290
    },
    {
      "epoch": 7.74,
      "learning_rate": 9.062232779097388e-05,
      "loss": 0.698,
      "step": 16300
    },
    {
      "epoch": 7.75,
      "learning_rate": 9.043230403800475e-05,
      "loss": 0.685,
      "step": 16310
    },
    {
      "epoch": 7.75,
      "learning_rate": 9.024228028503563e-05,
      "loss": 0.6896,
      "step": 16320
    },
    {
      "epoch": 7.76,
      "learning_rate": 9.005225653206652e-05,
      "loss": 0.6931,
      "step": 16330
    },
    {
      "epoch": 7.76,
      "learning_rate": 8.986223277909739e-05,
      "loss": 0.6761,
      "step": 16340
    },
    {
      "epoch": 7.77,
      "learning_rate": 8.967220902612828e-05,
      "loss": 0.6909,
      "step": 16350
    },
    {
      "epoch": 7.77,
      "learning_rate": 8.948218527315914e-05,
      "loss": 0.6863,
      "step": 16360
    },
    {
      "epoch": 7.78,
      "learning_rate": 8.929216152019003e-05,
      "loss": 0.6844,
      "step": 16370
    },
    {
      "epoch": 7.78,
      "learning_rate": 8.91021377672209e-05,
      "loss": 0.6985,
      "step": 16380
    },
    {
      "epoch": 7.79,
      "learning_rate": 8.89121140142518e-05,
      "loss": 0.6689,
      "step": 16390
    },
    {
      "epoch": 7.79,
      "learning_rate": 8.872209026128267e-05,
      "loss": 0.6962,
      "step": 16400
    },
    {
      "epoch": 7.8,
      "learning_rate": 8.853206650831354e-05,
      "loss": 0.6821,
      "step": 16410
    },
    {
      "epoch": 7.8,
      "learning_rate": 8.834204275534442e-05,
      "loss": 0.6855,
      "step": 16420
    },
    {
      "epoch": 7.81,
      "learning_rate": 8.81520190023753e-05,
      "loss": 0.6831,
      "step": 16430
    },
    {
      "epoch": 7.81,
      "learning_rate": 8.796199524940618e-05,
      "loss": 0.6894,
      "step": 16440
    },
    {
      "epoch": 7.81,
      "learning_rate": 8.777197149643706e-05,
      "loss": 0.6869,
      "step": 16450
    },
    {
      "epoch": 7.82,
      "learning_rate": 8.758194774346793e-05,
      "loss": 0.6944,
      "step": 16460
    },
    {
      "epoch": 7.82,
      "learning_rate": 8.739192399049881e-05,
      "loss": 0.6906,
      "step": 16470
    },
    {
      "epoch": 7.83,
      "learning_rate": 8.72019002375297e-05,
      "loss": 0.6933,
      "step": 16480
    },
    {
      "epoch": 7.83,
      "learning_rate": 8.701187648456057e-05,
      "loss": 0.6896,
      "step": 16490
    },
    {
      "epoch": 7.84,
      "learning_rate": 8.682185273159146e-05,
      "loss": 0.6909,
      "step": 16500
    },
    {
      "epoch": 7.84,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7054230570793152,
      "eval_runtime": 0.498,
      "eval_samples_per_second": 1751.128,
      "eval_steps_per_second": 14.057,
      "step": 16500
    },
    {
      "epoch": 7.84,
      "learning_rate": 8.663182897862234e-05,
      "loss": 0.6914,
      "step": 16510
    },
    {
      "epoch": 7.85,
      "learning_rate": 8.644180522565321e-05,
      "loss": 0.6916,
      "step": 16520
    },
    {
      "epoch": 7.85,
      "learning_rate": 8.625178147268409e-05,
      "loss": 0.6823,
      "step": 16530
    },
    {
      "epoch": 7.86,
      "learning_rate": 8.606175771971496e-05,
      "loss": 0.6894,
      "step": 16540
    },
    {
      "epoch": 7.86,
      "learning_rate": 8.587173396674585e-05,
      "loss": 0.6919,
      "step": 16550
    },
    {
      "epoch": 7.87,
      "learning_rate": 8.568171021377673e-05,
      "loss": 0.6835,
      "step": 16560
    },
    {
      "epoch": 7.87,
      "learning_rate": 8.54916864608076e-05,
      "loss": 0.6854,
      "step": 16570
    },
    {
      "epoch": 7.88,
      "learning_rate": 8.530166270783848e-05,
      "loss": 0.6921,
      "step": 16580
    },
    {
      "epoch": 7.88,
      "learning_rate": 8.511163895486937e-05,
      "loss": 0.6817,
      "step": 16590
    },
    {
      "epoch": 7.89,
      "learning_rate": 8.492161520190024e-05,
      "loss": 0.6891,
      "step": 16600
    },
    {
      "epoch": 7.89,
      "learning_rate": 8.473159144893113e-05,
      "loss": 0.6764,
      "step": 16610
    },
    {
      "epoch": 7.9,
      "learning_rate": 8.454156769596199e-05,
      "loss": 0.6891,
      "step": 16620
    },
    {
      "epoch": 7.9,
      "learning_rate": 8.435154394299288e-05,
      "loss": 0.6934,
      "step": 16630
    },
    {
      "epoch": 7.9,
      "learning_rate": 8.416152019002376e-05,
      "loss": 0.6926,
      "step": 16640
    },
    {
      "epoch": 7.91,
      "learning_rate": 8.397149643705463e-05,
      "loss": 0.6911,
      "step": 16650
    },
    {
      "epoch": 7.91,
      "learning_rate": 8.378147268408552e-05,
      "loss": 0.6832,
      "step": 16660
    },
    {
      "epoch": 7.92,
      "learning_rate": 8.35914489311164e-05,
      "loss": 0.6877,
      "step": 16670
    },
    {
      "epoch": 7.92,
      "learning_rate": 8.340142517814727e-05,
      "loss": 0.6801,
      "step": 16680
    },
    {
      "epoch": 7.93,
      "learning_rate": 8.321140142517815e-05,
      "loss": 0.6866,
      "step": 16690
    },
    {
      "epoch": 7.93,
      "learning_rate": 8.302137767220903e-05,
      "loss": 0.6845,
      "step": 16700
    },
    {
      "epoch": 7.94,
      "learning_rate": 8.283135391923991e-05,
      "loss": 0.699,
      "step": 16710
    },
    {
      "epoch": 7.94,
      "learning_rate": 8.264133016627079e-05,
      "loss": 0.6859,
      "step": 16720
    },
    {
      "epoch": 7.95,
      "learning_rate": 8.245130641330166e-05,
      "loss": 0.6892,
      "step": 16730
    },
    {
      "epoch": 7.95,
      "learning_rate": 8.226128266033255e-05,
      "loss": 0.6902,
      "step": 16740
    },
    {
      "epoch": 7.96,
      "learning_rate": 8.207125890736342e-05,
      "loss": 0.6871,
      "step": 16750
    },
    {
      "epoch": 7.96,
      "learning_rate": 8.18812351543943e-05,
      "loss": 0.6878,
      "step": 16760
    },
    {
      "epoch": 7.97,
      "learning_rate": 8.169121140142519e-05,
      "loss": 0.6817,
      "step": 16770
    },
    {
      "epoch": 7.97,
      "learning_rate": 8.150118764845605e-05,
      "loss": 0.6841,
      "step": 16780
    },
    {
      "epoch": 7.98,
      "learning_rate": 8.131116389548694e-05,
      "loss": 0.6748,
      "step": 16790
    },
    {
      "epoch": 7.98,
      "learning_rate": 8.112114014251781e-05,
      "loss": 0.6879,
      "step": 16800
    },
    {
      "epoch": 7.99,
      "learning_rate": 8.09311163895487e-05,
      "loss": 0.6662,
      "step": 16810
    },
    {
      "epoch": 7.99,
      "learning_rate": 8.074109263657958e-05,
      "loss": 0.6963,
      "step": 16820
    },
    {
      "epoch": 8.0,
      "learning_rate": 8.055106888361045e-05,
      "loss": 0.6852,
      "step": 16830
    },
    {
      "epoch": 8.0,
      "learning_rate": 8.036104513064133e-05,
      "loss": 0.6796,
      "step": 16840
    },
    {
      "epoch": 8.0,
      "learning_rate": 8.017102137767222e-05,
      "loss": 0.6854,
      "step": 16850
    },
    {
      "epoch": 8.01,
      "learning_rate": 7.998099762470309e-05,
      "loss": 0.6881,
      "step": 16860
    },
    {
      "epoch": 8.01,
      "learning_rate": 7.979097387173398e-05,
      "loss": 0.6937,
      "step": 16870
    },
    {
      "epoch": 8.02,
      "learning_rate": 7.960095011876484e-05,
      "loss": 0.6804,
      "step": 16880
    },
    {
      "epoch": 8.02,
      "learning_rate": 7.941092636579572e-05,
      "loss": 0.6956,
      "step": 16890
    },
    {
      "epoch": 8.03,
      "learning_rate": 7.922090261282661e-05,
      "loss": 0.6856,
      "step": 16900
    },
    {
      "epoch": 8.03,
      "learning_rate": 7.903087885985748e-05,
      "loss": 0.6879,
      "step": 16910
    },
    {
      "epoch": 8.04,
      "learning_rate": 7.884085510688837e-05,
      "loss": 0.6972,
      "step": 16920
    },
    {
      "epoch": 8.04,
      "learning_rate": 7.865083135391925e-05,
      "loss": 0.6784,
      "step": 16930
    },
    {
      "epoch": 8.05,
      "learning_rate": 7.846080760095012e-05,
      "loss": 0.6884,
      "step": 16940
    },
    {
      "epoch": 8.05,
      "learning_rate": 7.8270783847981e-05,
      "loss": 0.6921,
      "step": 16950
    },
    {
      "epoch": 8.06,
      "learning_rate": 7.808076009501189e-05,
      "loss": 0.6877,
      "step": 16960
    },
    {
      "epoch": 8.06,
      "learning_rate": 7.789073634204276e-05,
      "loss": 0.6924,
      "step": 16970
    },
    {
      "epoch": 8.07,
      "learning_rate": 7.770071258907365e-05,
      "loss": 0.689,
      "step": 16980
    },
    {
      "epoch": 8.07,
      "learning_rate": 7.751068883610451e-05,
      "loss": 0.6947,
      "step": 16990
    },
    {
      "epoch": 8.08,
      "learning_rate": 7.732066508313539e-05,
      "loss": 0.6856,
      "step": 17000
    },
    {
      "epoch": 8.08,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7139713168144226,
      "eval_runtime": 0.5052,
      "eval_samples_per_second": 1726.214,
      "eval_steps_per_second": 13.857,
      "step": 17000
    },
    {
      "epoch": 8.08,
      "learning_rate": 7.713064133016628e-05,
      "loss": 0.6858,
      "step": 17010
    },
    {
      "epoch": 8.09,
      "learning_rate": 7.694061757719715e-05,
      "loss": 0.6756,
      "step": 17020
    },
    {
      "epoch": 8.09,
      "learning_rate": 7.675059382422804e-05,
      "loss": 0.7036,
      "step": 17030
    },
    {
      "epoch": 8.1,
      "learning_rate": 7.656057007125891e-05,
      "loss": 0.68,
      "step": 17040
    },
    {
      "epoch": 8.1,
      "learning_rate": 7.637054631828979e-05,
      "loss": 0.674,
      "step": 17050
    },
    {
      "epoch": 8.1,
      "learning_rate": 7.618052256532067e-05,
      "loss": 0.686,
      "step": 17060
    },
    {
      "epoch": 8.11,
      "learning_rate": 7.599049881235155e-05,
      "loss": 0.6767,
      "step": 17070
    },
    {
      "epoch": 8.11,
      "learning_rate": 7.580047505938243e-05,
      "loss": 0.6913,
      "step": 17080
    },
    {
      "epoch": 8.12,
      "learning_rate": 7.56104513064133e-05,
      "loss": 0.6873,
      "step": 17090
    },
    {
      "epoch": 8.12,
      "learning_rate": 7.542042755344418e-05,
      "loss": 0.6829,
      "step": 17100
    },
    {
      "epoch": 8.13,
      "learning_rate": 7.523040380047506e-05,
      "loss": 0.7042,
      "step": 17110
    },
    {
      "epoch": 8.13,
      "learning_rate": 7.504038004750594e-05,
      "loss": 0.6858,
      "step": 17120
    },
    {
      "epoch": 8.14,
      "learning_rate": 7.485035629453682e-05,
      "loss": 0.6941,
      "step": 17130
    },
    {
      "epoch": 8.14,
      "learning_rate": 7.466033254156771e-05,
      "loss": 0.6863,
      "step": 17140
    },
    {
      "epoch": 8.15,
      "learning_rate": 7.447030878859857e-05,
      "loss": 0.6872,
      "step": 17150
    },
    {
      "epoch": 8.15,
      "learning_rate": 7.428028503562946e-05,
      "loss": 0.6901,
      "step": 17160
    },
    {
      "epoch": 8.16,
      "learning_rate": 7.409026128266033e-05,
      "loss": 0.6752,
      "step": 17170
    },
    {
      "epoch": 8.16,
      "learning_rate": 7.390023752969122e-05,
      "loss": 0.6962,
      "step": 17180
    },
    {
      "epoch": 8.17,
      "learning_rate": 7.37102137767221e-05,
      "loss": 0.6791,
      "step": 17190
    },
    {
      "epoch": 8.17,
      "learning_rate": 7.352019002375297e-05,
      "loss": 0.679,
      "step": 17200
    },
    {
      "epoch": 8.18,
      "learning_rate": 7.333016627078385e-05,
      "loss": 0.6851,
      "step": 17210
    },
    {
      "epoch": 8.18,
      "learning_rate": 7.314014251781472e-05,
      "loss": 0.6797,
      "step": 17220
    },
    {
      "epoch": 8.19,
      "learning_rate": 7.295011876484561e-05,
      "loss": 0.6838,
      "step": 17230
    },
    {
      "epoch": 8.19,
      "learning_rate": 7.276009501187649e-05,
      "loss": 0.6833,
      "step": 17240
    },
    {
      "epoch": 8.19,
      "learning_rate": 7.257007125890736e-05,
      "loss": 0.679,
      "step": 17250
    },
    {
      "epoch": 8.2,
      "learning_rate": 7.238004750593824e-05,
      "loss": 0.7004,
      "step": 17260
    },
    {
      "epoch": 8.2,
      "learning_rate": 7.219002375296913e-05,
      "loss": 0.6807,
      "step": 17270
    },
    {
      "epoch": 8.21,
      "learning_rate": 7.2e-05,
      "loss": 0.6792,
      "step": 17280
    },
    {
      "epoch": 8.21,
      "learning_rate": 7.180997624703089e-05,
      "loss": 0.6865,
      "step": 17290
    },
    {
      "epoch": 8.22,
      "learning_rate": 7.161995249406177e-05,
      "loss": 0.6893,
      "step": 17300
    },
    {
      "epoch": 8.22,
      "learning_rate": 7.142992874109264e-05,
      "loss": 0.688,
      "step": 17310
    },
    {
      "epoch": 8.23,
      "learning_rate": 7.123990498812352e-05,
      "loss": 0.6991,
      "step": 17320
    },
    {
      "epoch": 8.23,
      "learning_rate": 7.10498812351544e-05,
      "loss": 0.6927,
      "step": 17330
    },
    {
      "epoch": 8.24,
      "learning_rate": 7.085985748218528e-05,
      "loss": 0.6828,
      "step": 17340
    },
    {
      "epoch": 8.24,
      "learning_rate": 7.066983372921616e-05,
      "loss": 0.6856,
      "step": 17350
    },
    {
      "epoch": 8.25,
      "learning_rate": 7.047980997624703e-05,
      "loss": 0.6795,
      "step": 17360
    },
    {
      "epoch": 8.25,
      "learning_rate": 7.02897862232779e-05,
      "loss": 0.6823,
      "step": 17370
    },
    {
      "epoch": 8.26,
      "learning_rate": 7.00997624703088e-05,
      "loss": 0.7108,
      "step": 17380
    },
    {
      "epoch": 8.26,
      "learning_rate": 6.990973871733967e-05,
      "loss": 0.6894,
      "step": 17390
    },
    {
      "epoch": 8.27,
      "learning_rate": 6.971971496437056e-05,
      "loss": 0.6749,
      "step": 17400
    },
    {
      "epoch": 8.27,
      "learning_rate": 6.952969121140142e-05,
      "loss": 0.6896,
      "step": 17410
    },
    {
      "epoch": 8.28,
      "learning_rate": 6.933966745843231e-05,
      "loss": 0.6749,
      "step": 17420
    },
    {
      "epoch": 8.28,
      "learning_rate": 6.914964370546318e-05,
      "loss": 0.69,
      "step": 17430
    },
    {
      "epoch": 8.29,
      "learning_rate": 6.895961995249407e-05,
      "loss": 0.6865,
      "step": 17440
    },
    {
      "epoch": 8.29,
      "learning_rate": 6.876959619952495e-05,
      "loss": 0.6935,
      "step": 17450
    },
    {
      "epoch": 8.29,
      "learning_rate": 6.857957244655582e-05,
      "loss": 0.7009,
      "step": 17460
    },
    {
      "epoch": 8.3,
      "learning_rate": 6.83895486935867e-05,
      "loss": 0.677,
      "step": 17470
    },
    {
      "epoch": 8.3,
      "learning_rate": 6.819952494061757e-05,
      "loss": 0.6764,
      "step": 17480
    },
    {
      "epoch": 8.31,
      "learning_rate": 6.800950118764846e-05,
      "loss": 0.6985,
      "step": 17490
    },
    {
      "epoch": 8.31,
      "learning_rate": 6.781947743467934e-05,
      "loss": 0.6913,
      "step": 17500
    },
    {
      "epoch": 8.31,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7028853297233582,
      "eval_runtime": 0.4899,
      "eval_samples_per_second": 1779.893,
      "eval_steps_per_second": 14.288,
      "step": 17500
    },
    {
      "epoch": 8.32,
      "learning_rate": 6.762945368171021e-05,
      "loss": 0.6915,
      "step": 17510
    },
    {
      "epoch": 8.32,
      "learning_rate": 6.743942992874109e-05,
      "loss": 0.6917,
      "step": 17520
    },
    {
      "epoch": 8.33,
      "learning_rate": 6.724940617577198e-05,
      "loss": 0.6909,
      "step": 17530
    },
    {
      "epoch": 8.33,
      "learning_rate": 6.705938242280285e-05,
      "loss": 0.6777,
      "step": 17540
    },
    {
      "epoch": 8.34,
      "learning_rate": 6.686935866983374e-05,
      "loss": 0.6899,
      "step": 17550
    },
    {
      "epoch": 8.34,
      "learning_rate": 6.667933491686462e-05,
      "loss": 0.6911,
      "step": 17560
    },
    {
      "epoch": 8.35,
      "learning_rate": 6.648931116389548e-05,
      "loss": 0.701,
      "step": 17570
    },
    {
      "epoch": 8.35,
      "learning_rate": 6.629928741092637e-05,
      "loss": 0.6978,
      "step": 17580
    },
    {
      "epoch": 8.36,
      "learning_rate": 6.610926365795724e-05,
      "loss": 0.6782,
      "step": 17590
    },
    {
      "epoch": 8.36,
      "learning_rate": 6.591923990498813e-05,
      "loss": 0.6931,
      "step": 17600
    },
    {
      "epoch": 8.37,
      "learning_rate": 6.5729216152019e-05,
      "loss": 0.6889,
      "step": 17610
    },
    {
      "epoch": 8.37,
      "learning_rate": 6.553919239904988e-05,
      "loss": 0.6892,
      "step": 17620
    },
    {
      "epoch": 8.38,
      "learning_rate": 6.534916864608076e-05,
      "loss": 0.6852,
      "step": 17630
    },
    {
      "epoch": 8.38,
      "learning_rate": 6.515914489311165e-05,
      "loss": 0.6786,
      "step": 17640
    },
    {
      "epoch": 8.38,
      "learning_rate": 6.496912114014252e-05,
      "loss": 0.6782,
      "step": 17650
    },
    {
      "epoch": 8.39,
      "learning_rate": 6.477909738717341e-05,
      "loss": 0.6869,
      "step": 17660
    },
    {
      "epoch": 8.39,
      "learning_rate": 6.458907363420427e-05,
      "loss": 0.6807,
      "step": 17670
    },
    {
      "epoch": 8.4,
      "learning_rate": 6.439904988123516e-05,
      "loss": 0.6834,
      "step": 17680
    },
    {
      "epoch": 8.4,
      "learning_rate": 6.420902612826604e-05,
      "loss": 0.6902,
      "step": 17690
    },
    {
      "epoch": 8.41,
      "learning_rate": 6.401900237529691e-05,
      "loss": 0.6822,
      "step": 17700
    },
    {
      "epoch": 8.41,
      "learning_rate": 6.38289786223278e-05,
      "loss": 0.685,
      "step": 17710
    },
    {
      "epoch": 8.42,
      "learning_rate": 6.363895486935867e-05,
      "loss": 0.6832,
      "step": 17720
    },
    {
      "epoch": 8.42,
      "learning_rate": 6.344893111638955e-05,
      "loss": 0.6819,
      "step": 17730
    },
    {
      "epoch": 8.43,
      "learning_rate": 6.325890736342043e-05,
      "loss": 0.6943,
      "step": 17740
    },
    {
      "epoch": 8.43,
      "learning_rate": 6.306888361045131e-05,
      "loss": 0.6789,
      "step": 17750
    },
    {
      "epoch": 8.44,
      "learning_rate": 6.287885985748219e-05,
      "loss": 0.6937,
      "step": 17760
    },
    {
      "epoch": 8.44,
      "learning_rate": 6.268883610451306e-05,
      "loss": 0.6827,
      "step": 17770
    },
    {
      "epoch": 8.45,
      "learning_rate": 6.249881235154394e-05,
      "loss": 0.6802,
      "step": 17780
    },
    {
      "epoch": 8.45,
      "learning_rate": 6.230878859857483e-05,
      "loss": 0.6958,
      "step": 17790
    },
    {
      "epoch": 8.46,
      "learning_rate": 6.21187648456057e-05,
      "loss": 0.6798,
      "step": 17800
    },
    {
      "epoch": 8.46,
      "learning_rate": 6.192874109263658e-05,
      "loss": 0.6723,
      "step": 17810
    },
    {
      "epoch": 8.47,
      "learning_rate": 6.173871733966747e-05,
      "loss": 0.7003,
      "step": 17820
    },
    {
      "epoch": 8.47,
      "learning_rate": 6.154869358669833e-05,
      "loss": 0.6947,
      "step": 17830
    },
    {
      "epoch": 8.48,
      "learning_rate": 6.135866983372922e-05,
      "loss": 0.6892,
      "step": 17840
    },
    {
      "epoch": 8.48,
      "learning_rate": 6.11686460807601e-05,
      "loss": 0.6867,
      "step": 17850
    },
    {
      "epoch": 8.48,
      "learning_rate": 6.097862232779098e-05,
      "loss": 0.6896,
      "step": 17860
    },
    {
      "epoch": 8.49,
      "learning_rate": 6.078859857482185e-05,
      "loss": 0.6906,
      "step": 17870
    },
    {
      "epoch": 8.49,
      "learning_rate": 6.059857482185274e-05,
      "loss": 0.6866,
      "step": 17880
    },
    {
      "epoch": 8.5,
      "learning_rate": 6.0408551068883615e-05,
      "loss": 0.6926,
      "step": 17890
    },
    {
      "epoch": 8.5,
      "learning_rate": 6.02185273159145e-05,
      "loss": 0.6709,
      "step": 17900
    },
    {
      "epoch": 8.51,
      "learning_rate": 6.002850356294537e-05,
      "loss": 0.6865,
      "step": 17910
    },
    {
      "epoch": 8.51,
      "learning_rate": 5.983847980997625e-05,
      "loss": 0.6719,
      "step": 17920
    },
    {
      "epoch": 8.52,
      "learning_rate": 5.964845605700713e-05,
      "loss": 0.6844,
      "step": 17930
    },
    {
      "epoch": 8.52,
      "learning_rate": 5.9458432304038005e-05,
      "loss": 0.689,
      "step": 17940
    },
    {
      "epoch": 8.53,
      "learning_rate": 5.926840855106889e-05,
      "loss": 0.6823,
      "step": 17950
    },
    {
      "epoch": 8.53,
      "learning_rate": 5.907838479809976e-05,
      "loss": 0.6813,
      "step": 17960
    },
    {
      "epoch": 8.54,
      "learning_rate": 5.8888361045130644e-05,
      "loss": 0.701,
      "step": 17970
    },
    {
      "epoch": 8.54,
      "learning_rate": 5.869833729216152e-05,
      "loss": 0.6776,
      "step": 17980
    },
    {
      "epoch": 8.55,
      "learning_rate": 5.850831353919241e-05,
      "loss": 0.6772,
      "step": 17990
    },
    {
      "epoch": 8.55,
      "learning_rate": 5.8318289786223277e-05,
      "loss": 0.6919,
      "step": 18000
    },
    {
      "epoch": 8.55,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.71357262134552,
      "eval_runtime": 0.4859,
      "eval_samples_per_second": 1794.468,
      "eval_steps_per_second": 14.405,
      "step": 18000
    },
    {
      "epoch": 8.56,
      "learning_rate": 5.8128266033254165e-05,
      "loss": 0.6972,
      "step": 18010
    },
    {
      "epoch": 8.56,
      "learning_rate": 5.793824228028504e-05,
      "loss": 0.69,
      "step": 18020
    },
    {
      "epoch": 8.57,
      "learning_rate": 5.774821852731592e-05,
      "loss": 0.6837,
      "step": 18030
    },
    {
      "epoch": 8.57,
      "learning_rate": 5.75581947743468e-05,
      "loss": 0.6932,
      "step": 18040
    },
    {
      "epoch": 8.57,
      "learning_rate": 5.736817102137767e-05,
      "loss": 0.6811,
      "step": 18050
    },
    {
      "epoch": 8.58,
      "learning_rate": 5.7178147268408555e-05,
      "loss": 0.6857,
      "step": 18060
    },
    {
      "epoch": 8.58,
      "learning_rate": 5.698812351543943e-05,
      "loss": 0.693,
      "step": 18070
    },
    {
      "epoch": 8.59,
      "learning_rate": 5.679809976247031e-05,
      "loss": 0.6835,
      "step": 18080
    },
    {
      "epoch": 8.59,
      "learning_rate": 5.660807600950119e-05,
      "loss": 0.6813,
      "step": 18090
    },
    {
      "epoch": 8.6,
      "learning_rate": 5.641805225653207e-05,
      "loss": 0.7004,
      "step": 18100
    },
    {
      "epoch": 8.6,
      "learning_rate": 5.6228028503562945e-05,
      "loss": 0.6909,
      "step": 18110
    },
    {
      "epoch": 8.61,
      "learning_rate": 5.6038004750593834e-05,
      "loss": 0.6742,
      "step": 18120
    },
    {
      "epoch": 8.61,
      "learning_rate": 5.58479809976247e-05,
      "loss": 0.6923,
      "step": 18130
    },
    {
      "epoch": 8.62,
      "learning_rate": 5.565795724465559e-05,
      "loss": 0.6825,
      "step": 18140
    },
    {
      "epoch": 8.62,
      "learning_rate": 5.5467933491686466e-05,
      "loss": 0.6844,
      "step": 18150
    },
    {
      "epoch": 8.63,
      "learning_rate": 5.5277909738717335e-05,
      "loss": 0.7041,
      "step": 18160
    },
    {
      "epoch": 8.63,
      "learning_rate": 5.508788598574822e-05,
      "loss": 0.6921,
      "step": 18170
    },
    {
      "epoch": 8.64,
      "learning_rate": 5.48978622327791e-05,
      "loss": 0.6944,
      "step": 18180
    },
    {
      "epoch": 8.64,
      "learning_rate": 5.470783847980998e-05,
      "loss": 0.6856,
      "step": 18190
    },
    {
      "epoch": 8.65,
      "learning_rate": 5.4517814726840856e-05,
      "loss": 0.6941,
      "step": 18200
    },
    {
      "epoch": 8.65,
      "learning_rate": 5.432779097387174e-05,
      "loss": 0.6824,
      "step": 18210
    },
    {
      "epoch": 8.66,
      "learning_rate": 5.413776722090261e-05,
      "loss": 0.6824,
      "step": 18220
    },
    {
      "epoch": 8.66,
      "learning_rate": 5.3947743467933495e-05,
      "loss": 0.6899,
      "step": 18230
    },
    {
      "epoch": 8.67,
      "learning_rate": 5.375771971496437e-05,
      "loss": 0.6847,
      "step": 18240
    },
    {
      "epoch": 8.67,
      "learning_rate": 5.356769596199526e-05,
      "loss": 0.6907,
      "step": 18250
    },
    {
      "epoch": 8.67,
      "learning_rate": 5.337767220902613e-05,
      "loss": 0.6944,
      "step": 18260
    },
    {
      "epoch": 8.68,
      "learning_rate": 5.3187648456057e-05,
      "loss": 0.6806,
      "step": 18270
    },
    {
      "epoch": 8.68,
      "learning_rate": 5.299762470308789e-05,
      "loss": 0.6979,
      "step": 18280
    },
    {
      "epoch": 8.69,
      "learning_rate": 5.280760095011876e-05,
      "loss": 0.6843,
      "step": 18290
    },
    {
      "epoch": 8.69,
      "learning_rate": 5.261757719714965e-05,
      "loss": 0.6835,
      "step": 18300
    },
    {
      "epoch": 8.7,
      "learning_rate": 5.2427553444180524e-05,
      "loss": 0.6977,
      "step": 18310
    },
    {
      "epoch": 8.7,
      "learning_rate": 5.2237529691211406e-05,
      "loss": 0.6845,
      "step": 18320
    },
    {
      "epoch": 8.71,
      "learning_rate": 5.204750593824228e-05,
      "loss": 0.6852,
      "step": 18330
    },
    {
      "epoch": 8.71,
      "learning_rate": 5.1857482185273163e-05,
      "loss": 0.6922,
      "step": 18340
    },
    {
      "epoch": 8.72,
      "learning_rate": 5.166745843230404e-05,
      "loss": 0.6913,
      "step": 18350
    },
    {
      "epoch": 8.72,
      "learning_rate": 5.147743467933492e-05,
      "loss": 0.6873,
      "step": 18360
    },
    {
      "epoch": 8.73,
      "learning_rate": 5.1287410926365796e-05,
      "loss": 0.6883,
      "step": 18370
    },
    {
      "epoch": 8.73,
      "learning_rate": 5.1097387173396685e-05,
      "loss": 0.687,
      "step": 18380
    },
    {
      "epoch": 8.74,
      "learning_rate": 5.090736342042755e-05,
      "loss": 0.6909,
      "step": 18390
    },
    {
      "epoch": 8.74,
      "learning_rate": 5.071733966745843e-05,
      "loss": 0.6894,
      "step": 18400
    },
    {
      "epoch": 8.75,
      "learning_rate": 5.052731591448932e-05,
      "loss": 0.6832,
      "step": 18410
    },
    {
      "epoch": 8.75,
      "learning_rate": 5.0337292161520186e-05,
      "loss": 0.6866,
      "step": 18420
    },
    {
      "epoch": 8.76,
      "learning_rate": 5.0147268408551074e-05,
      "loss": 0.6916,
      "step": 18430
    },
    {
      "epoch": 8.76,
      "learning_rate": 4.995724465558195e-05,
      "loss": 0.6966,
      "step": 18440
    },
    {
      "epoch": 8.76,
      "learning_rate": 4.9767220902612825e-05,
      "loss": 0.6853,
      "step": 18450
    },
    {
      "epoch": 8.77,
      "learning_rate": 4.957719714964371e-05,
      "loss": 0.6897,
      "step": 18460
    },
    {
      "epoch": 8.77,
      "learning_rate": 4.938717339667458e-05,
      "loss": 0.6935,
      "step": 18470
    },
    {
      "epoch": 8.78,
      "learning_rate": 4.9197149643705464e-05,
      "loss": 0.6937,
      "step": 18480
    },
    {
      "epoch": 8.78,
      "learning_rate": 4.9007125890736346e-05,
      "loss": 0.6821,
      "step": 18490
    },
    {
      "epoch": 8.79,
      "learning_rate": 4.881710213776722e-05,
      "loss": 0.6859,
      "step": 18500
    },
    {
      "epoch": 8.79,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7031792998313904,
      "eval_runtime": 0.4865,
      "eval_samples_per_second": 1792.357,
      "eval_steps_per_second": 14.388,
      "step": 18500
    },
    {
      "epoch": 8.79,
      "learning_rate": 4.8627078384798103e-05,
      "loss": 0.6892,
      "step": 18510
    },
    {
      "epoch": 8.8,
      "learning_rate": 4.843705463182898e-05,
      "loss": 0.7018,
      "step": 18520
    },
    {
      "epoch": 8.8,
      "learning_rate": 4.824703087885986e-05,
      "loss": 0.6839,
      "step": 18530
    },
    {
      "epoch": 8.81,
      "learning_rate": 4.805700712589074e-05,
      "loss": 0.6809,
      "step": 18540
    },
    {
      "epoch": 8.81,
      "learning_rate": 4.786698337292162e-05,
      "loss": 0.69,
      "step": 18550
    },
    {
      "epoch": 8.82,
      "learning_rate": 4.767695961995249e-05,
      "loss": 0.6792,
      "step": 18560
    },
    {
      "epoch": 8.82,
      "learning_rate": 4.7486935866983375e-05,
      "loss": 0.6888,
      "step": 18570
    },
    {
      "epoch": 8.83,
      "learning_rate": 4.729691211401425e-05,
      "loss": 0.6814,
      "step": 18580
    },
    {
      "epoch": 8.83,
      "learning_rate": 4.710688836104513e-05,
      "loss": 0.6855,
      "step": 18590
    },
    {
      "epoch": 8.84,
      "learning_rate": 4.691686460807601e-05,
      "loss": 0.7032,
      "step": 18600
    },
    {
      "epoch": 8.84,
      "learning_rate": 4.672684085510689e-05,
      "loss": 0.6964,
      "step": 18610
    },
    {
      "epoch": 8.85,
      "learning_rate": 4.653681710213777e-05,
      "loss": 0.6903,
      "step": 18620
    },
    {
      "epoch": 8.85,
      "learning_rate": 4.634679334916865e-05,
      "loss": 0.676,
      "step": 18630
    },
    {
      "epoch": 8.86,
      "learning_rate": 4.615676959619953e-05,
      "loss": 0.6838,
      "step": 18640
    },
    {
      "epoch": 8.86,
      "learning_rate": 4.596674584323041e-05,
      "loss": 0.6968,
      "step": 18650
    },
    {
      "epoch": 8.86,
      "learning_rate": 4.5776722090261286e-05,
      "loss": 0.6897,
      "step": 18660
    },
    {
      "epoch": 8.87,
      "learning_rate": 4.558669833729217e-05,
      "loss": 0.7033,
      "step": 18670
    },
    {
      "epoch": 8.87,
      "learning_rate": 4.5396674584323043e-05,
      "loss": 0.6808,
      "step": 18680
    },
    {
      "epoch": 8.88,
      "learning_rate": 4.520665083135392e-05,
      "loss": 0.6875,
      "step": 18690
    },
    {
      "epoch": 8.88,
      "learning_rate": 4.50166270783848e-05,
      "loss": 0.6886,
      "step": 18700
    },
    {
      "epoch": 8.89,
      "learning_rate": 4.4826603325415676e-05,
      "loss": 0.6696,
      "step": 18710
    },
    {
      "epoch": 8.89,
      "learning_rate": 4.463657957244656e-05,
      "loss": 0.6742,
      "step": 18720
    },
    {
      "epoch": 8.9,
      "learning_rate": 4.444655581947744e-05,
      "loss": 0.6873,
      "step": 18730
    },
    {
      "epoch": 8.9,
      "learning_rate": 4.4256532066508315e-05,
      "loss": 0.6716,
      "step": 18740
    },
    {
      "epoch": 8.91,
      "learning_rate": 4.40665083135392e-05,
      "loss": 0.6866,
      "step": 18750
    },
    {
      "epoch": 8.91,
      "learning_rate": 4.387648456057007e-05,
      "loss": 0.7002,
      "step": 18760
    },
    {
      "epoch": 8.92,
      "learning_rate": 4.3686460807600955e-05,
      "loss": 0.6792,
      "step": 18770
    },
    {
      "epoch": 8.92,
      "learning_rate": 4.3496437054631837e-05,
      "loss": 0.6872,
      "step": 18780
    },
    {
      "epoch": 8.93,
      "learning_rate": 4.3306413301662705e-05,
      "loss": 0.6675,
      "step": 18790
    },
    {
      "epoch": 8.93,
      "learning_rate": 4.311638954869359e-05,
      "loss": 0.6749,
      "step": 18800
    },
    {
      "epoch": 8.94,
      "learning_rate": 4.292636579572447e-05,
      "loss": 0.6862,
      "step": 18810
    },
    {
      "epoch": 8.94,
      "learning_rate": 4.2736342042755344e-05,
      "loss": 0.6825,
      "step": 18820
    },
    {
      "epoch": 8.95,
      "learning_rate": 4.2546318289786226e-05,
      "loss": 0.6944,
      "step": 18830
    },
    {
      "epoch": 8.95,
      "learning_rate": 4.23562945368171e-05,
      "loss": 0.6729,
      "step": 18840
    },
    {
      "epoch": 8.95,
      "learning_rate": 4.2166270783847984e-05,
      "loss": 0.6739,
      "step": 18850
    },
    {
      "epoch": 8.96,
      "learning_rate": 4.1976247030878866e-05,
      "loss": 0.673,
      "step": 18860
    },
    {
      "epoch": 8.96,
      "learning_rate": 4.178622327790974e-05,
      "loss": 0.6829,
      "step": 18870
    },
    {
      "epoch": 8.97,
      "learning_rate": 4.159619952494062e-05,
      "loss": 0.6899,
      "step": 18880
    },
    {
      "epoch": 8.97,
      "learning_rate": 4.14061757719715e-05,
      "loss": 0.6761,
      "step": 18890
    },
    {
      "epoch": 8.98,
      "learning_rate": 4.121615201900238e-05,
      "loss": 0.6778,
      "step": 18900
    },
    {
      "epoch": 8.98,
      "learning_rate": 4.1026128266033255e-05,
      "loss": 0.6778,
      "step": 18910
    },
    {
      "epoch": 8.99,
      "learning_rate": 4.083610451306413e-05,
      "loss": 0.7014,
      "step": 18920
    },
    {
      "epoch": 8.99,
      "learning_rate": 4.064608076009501e-05,
      "loss": 0.6884,
      "step": 18930
    },
    {
      "epoch": 9.0,
      "learning_rate": 4.0456057007125895e-05,
      "loss": 0.6797,
      "step": 18940
    },
    {
      "epoch": 9.0,
      "learning_rate": 4.026603325415677e-05,
      "loss": 0.6914,
      "step": 18950
    },
    {
      "epoch": 9.01,
      "learning_rate": 4.007600950118765e-05,
      "loss": 0.6897,
      "step": 18960
    },
    {
      "epoch": 9.01,
      "learning_rate": 3.988598574821853e-05,
      "loss": 0.6912,
      "step": 18970
    },
    {
      "epoch": 9.02,
      "learning_rate": 3.969596199524941e-05,
      "loss": 0.6827,
      "step": 18980
    },
    {
      "epoch": 9.02,
      "learning_rate": 3.950593824228029e-05,
      "loss": 0.6894,
      "step": 18990
    },
    {
      "epoch": 9.03,
      "learning_rate": 3.9315914489311166e-05,
      "loss": 0.6852,
      "step": 19000
    },
    {
      "epoch": 9.03,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7121268510818481,
      "eval_runtime": 0.4884,
      "eval_samples_per_second": 1785.418,
      "eval_steps_per_second": 14.332,
      "step": 19000
    },
    {
      "epoch": 9.03,
      "learning_rate": 3.912589073634205e-05,
      "loss": 0.6907,
      "step": 19010
    },
    {
      "epoch": 9.04,
      "learning_rate": 3.8935866983372924e-05,
      "loss": 0.6824,
      "step": 19020
    },
    {
      "epoch": 9.04,
      "learning_rate": 3.87458432304038e-05,
      "loss": 0.6822,
      "step": 19030
    },
    {
      "epoch": 9.05,
      "learning_rate": 3.855581947743468e-05,
      "loss": 0.686,
      "step": 19040
    },
    {
      "epoch": 9.05,
      "learning_rate": 3.8365795724465556e-05,
      "loss": 0.6908,
      "step": 19050
    },
    {
      "epoch": 9.05,
      "learning_rate": 3.817577197149644e-05,
      "loss": 0.688,
      "step": 19060
    },
    {
      "epoch": 9.06,
      "learning_rate": 3.798574821852732e-05,
      "loss": 0.6733,
      "step": 19070
    },
    {
      "epoch": 9.06,
      "learning_rate": 3.7795724465558195e-05,
      "loss": 0.7054,
      "step": 19080
    },
    {
      "epoch": 9.07,
      "learning_rate": 3.760570071258908e-05,
      "loss": 0.6783,
      "step": 19090
    },
    {
      "epoch": 9.07,
      "learning_rate": 3.741567695961995e-05,
      "loss": 0.7009,
      "step": 19100
    },
    {
      "epoch": 9.08,
      "learning_rate": 3.7225653206650835e-05,
      "loss": 0.6864,
      "step": 19110
    },
    {
      "epoch": 9.08,
      "learning_rate": 3.703562945368172e-05,
      "loss": 0.6886,
      "step": 19120
    },
    {
      "epoch": 9.09,
      "learning_rate": 3.684560570071259e-05,
      "loss": 0.6839,
      "step": 19130
    },
    {
      "epoch": 9.09,
      "learning_rate": 3.665558194774347e-05,
      "loss": 0.6832,
      "step": 19140
    },
    {
      "epoch": 9.1,
      "learning_rate": 3.646555819477435e-05,
      "loss": 0.6873,
      "step": 19150
    },
    {
      "epoch": 9.1,
      "learning_rate": 3.6275534441805224e-05,
      "loss": 0.6899,
      "step": 19160
    },
    {
      "epoch": 9.11,
      "learning_rate": 3.6085510688836106e-05,
      "loss": 0.6827,
      "step": 19170
    },
    {
      "epoch": 9.11,
      "learning_rate": 3.589548693586698e-05,
      "loss": 0.6857,
      "step": 19180
    },
    {
      "epoch": 9.12,
      "learning_rate": 3.5705463182897864e-05,
      "loss": 0.6943,
      "step": 19190
    },
    {
      "epoch": 9.12,
      "learning_rate": 3.5515439429928746e-05,
      "loss": 0.7021,
      "step": 19200
    },
    {
      "epoch": 9.13,
      "learning_rate": 3.532541567695962e-05,
      "loss": 0.6963,
      "step": 19210
    },
    {
      "epoch": 9.13,
      "learning_rate": 3.51353919239905e-05,
      "loss": 0.6888,
      "step": 19220
    },
    {
      "epoch": 9.14,
      "learning_rate": 3.494536817102138e-05,
      "loss": 0.6856,
      "step": 19230
    },
    {
      "epoch": 9.14,
      "learning_rate": 3.475534441805226e-05,
      "loss": 0.6938,
      "step": 19240
    },
    {
      "epoch": 9.14,
      "learning_rate": 3.456532066508314e-05,
      "loss": 0.686,
      "step": 19250
    },
    {
      "epoch": 9.15,
      "learning_rate": 3.437529691211401e-05,
      "loss": 0.6774,
      "step": 19260
    },
    {
      "epoch": 9.15,
      "learning_rate": 3.418527315914489e-05,
      "loss": 0.6905,
      "step": 19270
    },
    {
      "epoch": 9.16,
      "learning_rate": 3.3995249406175775e-05,
      "loss": 0.6666,
      "step": 19280
    },
    {
      "epoch": 9.16,
      "learning_rate": 3.380522565320665e-05,
      "loss": 0.6678,
      "step": 19290
    },
    {
      "epoch": 9.17,
      "learning_rate": 3.361520190023753e-05,
      "loss": 0.7018,
      "step": 19300
    },
    {
      "epoch": 9.17,
      "learning_rate": 3.342517814726841e-05,
      "loss": 0.6981,
      "step": 19310
    },
    {
      "epoch": 9.18,
      "learning_rate": 3.323515439429929e-05,
      "loss": 0.6981,
      "step": 19320
    },
    {
      "epoch": 9.18,
      "learning_rate": 3.304513064133017e-05,
      "loss": 0.6844,
      "step": 19330
    },
    {
      "epoch": 9.19,
      "learning_rate": 3.2855106888361046e-05,
      "loss": 0.6756,
      "step": 19340
    },
    {
      "epoch": 9.19,
      "learning_rate": 3.266508313539193e-05,
      "loss": 0.6817,
      "step": 19350
    },
    {
      "epoch": 9.2,
      "learning_rate": 3.2475059382422804e-05,
      "loss": 0.6888,
      "step": 19360
    },
    {
      "epoch": 9.2,
      "learning_rate": 3.2285035629453686e-05,
      "loss": 0.6954,
      "step": 19370
    },
    {
      "epoch": 9.21,
      "learning_rate": 3.209501187648456e-05,
      "loss": 0.6897,
      "step": 19380
    },
    {
      "epoch": 9.21,
      "learning_rate": 3.1904988123515436e-05,
      "loss": 0.693,
      "step": 19390
    },
    {
      "epoch": 9.22,
      "learning_rate": 3.171496437054632e-05,
      "loss": 0.692,
      "step": 19400
    },
    {
      "epoch": 9.22,
      "learning_rate": 3.15249406175772e-05,
      "loss": 0.6807,
      "step": 19410
    },
    {
      "epoch": 9.23,
      "learning_rate": 3.1334916864608075e-05,
      "loss": 0.6821,
      "step": 19420
    },
    {
      "epoch": 9.23,
      "learning_rate": 3.114489311163896e-05,
      "loss": 0.6911,
      "step": 19430
    },
    {
      "epoch": 9.24,
      "learning_rate": 3.095486935866983e-05,
      "loss": 0.6845,
      "step": 19440
    },
    {
      "epoch": 9.24,
      "learning_rate": 3.0764845605700715e-05,
      "loss": 0.6848,
      "step": 19450
    },
    {
      "epoch": 9.24,
      "learning_rate": 3.05748218527316e-05,
      "loss": 0.6827,
      "step": 19460
    },
    {
      "epoch": 9.25,
      "learning_rate": 3.0384798099762475e-05,
      "loss": 0.6795,
      "step": 19470
    },
    {
      "epoch": 9.25,
      "learning_rate": 3.0194774346793354e-05,
      "loss": 0.6912,
      "step": 19480
    },
    {
      "epoch": 9.26,
      "learning_rate": 3.0004750593824226e-05,
      "loss": 0.6785,
      "step": 19490
    },
    {
      "epoch": 9.26,
      "learning_rate": 2.9814726840855104e-05,
      "loss": 0.6974,
      "step": 19500
    },
    {
      "epoch": 9.26,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7101059556007385,
      "eval_runtime": 0.4862,
      "eval_samples_per_second": 1793.499,
      "eval_steps_per_second": 14.397,
      "step": 19500
    },
    {
      "epoch": 9.27,
      "learning_rate": 2.9624703087885986e-05,
      "loss": 0.6858,
      "step": 19510
    },
    {
      "epoch": 9.27,
      "learning_rate": 2.9434679334916865e-05,
      "loss": 0.6892,
      "step": 19520
    },
    {
      "epoch": 9.28,
      "learning_rate": 2.9244655581947744e-05,
      "loss": 0.6852,
      "step": 19530
    },
    {
      "epoch": 9.28,
      "learning_rate": 2.9054631828978622e-05,
      "loss": 0.6844,
      "step": 19540
    },
    {
      "epoch": 9.29,
      "learning_rate": 2.8864608076009504e-05,
      "loss": 0.6836,
      "step": 19550
    },
    {
      "epoch": 9.29,
      "learning_rate": 2.8674584323040383e-05,
      "loss": 0.6878,
      "step": 19560
    },
    {
      "epoch": 9.3,
      "learning_rate": 2.848456057007126e-05,
      "loss": 0.695,
      "step": 19570
    },
    {
      "epoch": 9.3,
      "learning_rate": 2.829453681710214e-05,
      "loss": 0.6804,
      "step": 19580
    },
    {
      "epoch": 9.31,
      "learning_rate": 2.810451306413302e-05,
      "loss": 0.6851,
      "step": 19590
    },
    {
      "epoch": 9.31,
      "learning_rate": 2.79144893111639e-05,
      "loss": 0.6805,
      "step": 19600
    },
    {
      "epoch": 9.32,
      "learning_rate": 2.7724465558194773e-05,
      "loss": 0.6967,
      "step": 19610
    },
    {
      "epoch": 9.32,
      "learning_rate": 2.753444180522565e-05,
      "loss": 0.6808,
      "step": 19620
    },
    {
      "epoch": 9.33,
      "learning_rate": 2.7344418052256533e-05,
      "loss": 0.6804,
      "step": 19630
    },
    {
      "epoch": 9.33,
      "learning_rate": 2.7154394299287412e-05,
      "loss": 0.671,
      "step": 19640
    },
    {
      "epoch": 9.33,
      "learning_rate": 2.696437054631829e-05,
      "loss": 0.6835,
      "step": 19650
    },
    {
      "epoch": 9.34,
      "learning_rate": 2.677434679334917e-05,
      "loss": 0.6841,
      "step": 19660
    },
    {
      "epoch": 9.34,
      "learning_rate": 2.6584323040380048e-05,
      "loss": 0.6881,
      "step": 19670
    },
    {
      "epoch": 9.35,
      "learning_rate": 2.639429928741093e-05,
      "loss": 0.6944,
      "step": 19680
    },
    {
      "epoch": 9.35,
      "learning_rate": 2.620427553444181e-05,
      "loss": 0.6968,
      "step": 19690
    },
    {
      "epoch": 9.36,
      "learning_rate": 2.6014251781472687e-05,
      "loss": 0.6767,
      "step": 19700
    },
    {
      "epoch": 9.36,
      "learning_rate": 2.5824228028503566e-05,
      "loss": 0.6947,
      "step": 19710
    },
    {
      "epoch": 9.37,
      "learning_rate": 2.563420427553444e-05,
      "loss": 0.678,
      "step": 19720
    },
    {
      "epoch": 9.37,
      "learning_rate": 2.544418052256532e-05,
      "loss": 0.6815,
      "step": 19730
    },
    {
      "epoch": 9.38,
      "learning_rate": 2.5254156769596198e-05,
      "loss": 0.6895,
      "step": 19740
    },
    {
      "epoch": 9.38,
      "learning_rate": 2.5064133016627077e-05,
      "loss": 0.682,
      "step": 19750
    },
    {
      "epoch": 9.39,
      "learning_rate": 2.487410926365796e-05,
      "loss": 0.6905,
      "step": 19760
    },
    {
      "epoch": 9.39,
      "learning_rate": 2.4684085510688838e-05,
      "loss": 0.6869,
      "step": 19770
    },
    {
      "epoch": 9.4,
      "learning_rate": 2.4494061757719716e-05,
      "loss": 0.6772,
      "step": 19780
    },
    {
      "epoch": 9.4,
      "learning_rate": 2.4304038004750595e-05,
      "loss": 0.6885,
      "step": 19790
    },
    {
      "epoch": 9.41,
      "learning_rate": 2.4114014251781473e-05,
      "loss": 0.689,
      "step": 19800
    },
    {
      "epoch": 9.41,
      "learning_rate": 2.3923990498812352e-05,
      "loss": 0.6813,
      "step": 19810
    },
    {
      "epoch": 9.42,
      "learning_rate": 2.373396674584323e-05,
      "loss": 0.6878,
      "step": 19820
    },
    {
      "epoch": 9.42,
      "learning_rate": 2.354394299287411e-05,
      "loss": 0.6922,
      "step": 19830
    },
    {
      "epoch": 9.43,
      "learning_rate": 2.3353919239904988e-05,
      "loss": 0.6867,
      "step": 19840
    },
    {
      "epoch": 9.43,
      "learning_rate": 2.316389548693587e-05,
      "loss": 0.6842,
      "step": 19850
    },
    {
      "epoch": 9.43,
      "learning_rate": 2.297387173396675e-05,
      "loss": 0.7026,
      "step": 19860
    },
    {
      "epoch": 9.44,
      "learning_rate": 2.2783847980997624e-05,
      "loss": 0.6841,
      "step": 19870
    },
    {
      "epoch": 9.44,
      "learning_rate": 2.2593824228028502e-05,
      "loss": 0.6837,
      "step": 19880
    },
    {
      "epoch": 9.45,
      "learning_rate": 2.2403800475059384e-05,
      "loss": 0.6899,
      "step": 19890
    },
    {
      "epoch": 9.45,
      "learning_rate": 2.2213776722090263e-05,
      "loss": 0.6755,
      "step": 19900
    },
    {
      "epoch": 9.46,
      "learning_rate": 2.2023752969121142e-05,
      "loss": 0.6931,
      "step": 19910
    },
    {
      "epoch": 9.46,
      "learning_rate": 2.183372921615202e-05,
      "loss": 0.6863,
      "step": 19920
    },
    {
      "epoch": 9.47,
      "learning_rate": 2.16437054631829e-05,
      "loss": 0.6826,
      "step": 19930
    },
    {
      "epoch": 9.47,
      "learning_rate": 2.1453681710213778e-05,
      "loss": 0.6892,
      "step": 19940
    },
    {
      "epoch": 9.48,
      "learning_rate": 2.1263657957244656e-05,
      "loss": 0.6806,
      "step": 19950
    },
    {
      "epoch": 9.48,
      "learning_rate": 2.1073634204275535e-05,
      "loss": 0.6863,
      "step": 19960
    },
    {
      "epoch": 9.49,
      "learning_rate": 2.0883610451306413e-05,
      "loss": 0.6942,
      "step": 19970
    },
    {
      "epoch": 9.49,
      "learning_rate": 2.0693586698337295e-05,
      "loss": 0.6874,
      "step": 19980
    },
    {
      "epoch": 9.5,
      "learning_rate": 2.050356294536817e-05,
      "loss": 0.6865,
      "step": 19990
    },
    {
      "epoch": 9.5,
      "learning_rate": 2.031353919239905e-05,
      "loss": 0.686,
      "step": 20000
    },
    {
      "epoch": 9.5,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.70921790599823,
      "eval_runtime": 0.4864,
      "eval_samples_per_second": 1792.832,
      "eval_steps_per_second": 14.392,
      "step": 20000
    },
    {
      "epoch": 9.51,
      "learning_rate": 2.0123515439429928e-05,
      "loss": 0.6853,
      "step": 20010
    },
    {
      "epoch": 9.51,
      "learning_rate": 1.993349168646081e-05,
      "loss": 0.6797,
      "step": 20020
    },
    {
      "epoch": 9.52,
      "learning_rate": 1.974346793349169e-05,
      "loss": 0.6862,
      "step": 20030
    },
    {
      "epoch": 9.52,
      "learning_rate": 1.9553444180522564e-05,
      "loss": 0.6801,
      "step": 20040
    },
    {
      "epoch": 9.52,
      "learning_rate": 1.9363420427553446e-05,
      "loss": 0.6911,
      "step": 20050
    },
    {
      "epoch": 9.53,
      "learning_rate": 1.9173396674584325e-05,
      "loss": 0.6765,
      "step": 20060
    },
    {
      "epoch": 9.53,
      "learning_rate": 1.8983372921615203e-05,
      "loss": 0.6985,
      "step": 20070
    },
    {
      "epoch": 9.54,
      "learning_rate": 1.8793349168646082e-05,
      "loss": 0.6877,
      "step": 20080
    },
    {
      "epoch": 9.54,
      "learning_rate": 1.860332541567696e-05,
      "loss": 0.6869,
      "step": 20090
    },
    {
      "epoch": 9.55,
      "learning_rate": 1.841330166270784e-05,
      "loss": 0.6804,
      "step": 20100
    },
    {
      "epoch": 9.55,
      "learning_rate": 1.8223277909738718e-05,
      "loss": 0.6713,
      "step": 20110
    },
    {
      "epoch": 9.56,
      "learning_rate": 1.8033254156769596e-05,
      "loss": 0.6838,
      "step": 20120
    },
    {
      "epoch": 9.56,
      "learning_rate": 1.7843230403800475e-05,
      "loss": 0.6818,
      "step": 20130
    },
    {
      "epoch": 9.57,
      "learning_rate": 1.7653206650831357e-05,
      "loss": 0.6811,
      "step": 20140
    },
    {
      "epoch": 9.57,
      "learning_rate": 1.7463182897862236e-05,
      "loss": 0.6732,
      "step": 20150
    },
    {
      "epoch": 9.58,
      "learning_rate": 1.727315914489311e-05,
      "loss": 0.682,
      "step": 20160
    },
    {
      "epoch": 9.58,
      "learning_rate": 1.708313539192399e-05,
      "loss": 0.6821,
      "step": 20170
    },
    {
      "epoch": 9.59,
      "learning_rate": 1.689311163895487e-05,
      "loss": 0.6684,
      "step": 20180
    },
    {
      "epoch": 9.59,
      "learning_rate": 1.670308788598575e-05,
      "loss": 0.6884,
      "step": 20190
    },
    {
      "epoch": 9.6,
      "learning_rate": 1.651306413301663e-05,
      "loss": 0.6863,
      "step": 20200
    },
    {
      "epoch": 9.6,
      "learning_rate": 1.6323040380047507e-05,
      "loss": 0.6979,
      "step": 20210
    },
    {
      "epoch": 9.61,
      "learning_rate": 1.6133016627078386e-05,
      "loss": 0.6908,
      "step": 20220
    },
    {
      "epoch": 9.61,
      "learning_rate": 1.5942992874109265e-05,
      "loss": 0.6864,
      "step": 20230
    },
    {
      "epoch": 9.62,
      "learning_rate": 1.5752969121140143e-05,
      "loss": 0.6796,
      "step": 20240
    },
    {
      "epoch": 9.62,
      "learning_rate": 1.5562945368171022e-05,
      "loss": 0.6914,
      "step": 20250
    },
    {
      "epoch": 9.62,
      "learning_rate": 1.53729216152019e-05,
      "loss": 0.6774,
      "step": 20260
    },
    {
      "epoch": 9.63,
      "learning_rate": 1.518289786223278e-05,
      "loss": 0.6913,
      "step": 20270
    },
    {
      "epoch": 9.63,
      "learning_rate": 1.4992874109263658e-05,
      "loss": 0.6961,
      "step": 20280
    },
    {
      "epoch": 9.64,
      "learning_rate": 1.4802850356294536e-05,
      "loss": 0.69,
      "step": 20290
    },
    {
      "epoch": 9.64,
      "learning_rate": 1.4612826603325417e-05,
      "loss": 0.6979,
      "step": 20300
    },
    {
      "epoch": 9.65,
      "learning_rate": 1.4422802850356295e-05,
      "loss": 0.6878,
      "step": 20310
    },
    {
      "epoch": 9.65,
      "learning_rate": 1.4232779097387176e-05,
      "loss": 0.6855,
      "step": 20320
    },
    {
      "epoch": 9.66,
      "learning_rate": 1.4042755344418054e-05,
      "loss": 0.6887,
      "step": 20330
    },
    {
      "epoch": 9.66,
      "learning_rate": 1.3852731591448931e-05,
      "loss": 0.6934,
      "step": 20340
    },
    {
      "epoch": 9.67,
      "learning_rate": 1.366270783847981e-05,
      "loss": 0.6839,
      "step": 20350
    },
    {
      "epoch": 9.67,
      "learning_rate": 1.347268408551069e-05,
      "loss": 0.6809,
      "step": 20360
    },
    {
      "epoch": 9.68,
      "learning_rate": 1.3282660332541569e-05,
      "loss": 0.6868,
      "step": 20370
    },
    {
      "epoch": 9.68,
      "learning_rate": 1.3092636579572447e-05,
      "loss": 0.6893,
      "step": 20380
    },
    {
      "epoch": 9.69,
      "learning_rate": 1.2902612826603324e-05,
      "loss": 0.6848,
      "step": 20390
    },
    {
      "epoch": 9.69,
      "learning_rate": 1.2712589073634205e-05,
      "loss": 0.6688,
      "step": 20400
    },
    {
      "epoch": 9.7,
      "learning_rate": 1.2522565320665083e-05,
      "loss": 0.6775,
      "step": 20410
    },
    {
      "epoch": 9.7,
      "learning_rate": 1.2332541567695962e-05,
      "loss": 0.6956,
      "step": 20420
    },
    {
      "epoch": 9.71,
      "learning_rate": 1.2142517814726842e-05,
      "loss": 0.676,
      "step": 20430
    },
    {
      "epoch": 9.71,
      "learning_rate": 1.195249406175772e-05,
      "loss": 0.6759,
      "step": 20440
    },
    {
      "epoch": 9.71,
      "learning_rate": 1.17624703087886e-05,
      "loss": 0.6826,
      "step": 20450
    },
    {
      "epoch": 9.72,
      "learning_rate": 1.1572446555819478e-05,
      "loss": 0.6776,
      "step": 20460
    },
    {
      "epoch": 9.72,
      "learning_rate": 1.1382422802850357e-05,
      "loss": 0.6864,
      "step": 20470
    },
    {
      "epoch": 9.73,
      "learning_rate": 1.1192399049881235e-05,
      "loss": 0.6985,
      "step": 20480
    },
    {
      "epoch": 9.73,
      "learning_rate": 1.1002375296912116e-05,
      "loss": 0.6705,
      "step": 20490
    },
    {
      "epoch": 9.74,
      "learning_rate": 1.0812351543942993e-05,
      "loss": 0.6806,
      "step": 20500
    },
    {
      "epoch": 9.74,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7134332060813904,
      "eval_runtime": 0.4907,
      "eval_samples_per_second": 1777.035,
      "eval_steps_per_second": 14.265,
      "step": 20500
    },
    {
      "epoch": 9.74,
      "learning_rate": 1.0622327790973873e-05,
      "loss": 0.6686,
      "step": 20510
    },
    {
      "epoch": 9.75,
      "learning_rate": 1.043230403800475e-05,
      "loss": 0.678,
      "step": 20520
    },
    {
      "epoch": 9.75,
      "learning_rate": 1.024228028503563e-05,
      "loss": 0.6935,
      "step": 20530
    },
    {
      "epoch": 9.76,
      "learning_rate": 1.0052256532066509e-05,
      "loss": 0.689,
      "step": 20540
    },
    {
      "epoch": 9.76,
      "learning_rate": 9.862232779097387e-06,
      "loss": 0.6962,
      "step": 20550
    },
    {
      "epoch": 9.77,
      "learning_rate": 9.672209026128266e-06,
      "loss": 0.6785,
      "step": 20560
    },
    {
      "epoch": 9.77,
      "learning_rate": 9.482185273159146e-06,
      "loss": 0.6938,
      "step": 20570
    },
    {
      "epoch": 9.78,
      "learning_rate": 9.292161520190023e-06,
      "loss": 0.6772,
      "step": 20580
    },
    {
      "epoch": 9.78,
      "learning_rate": 9.102137767220904e-06,
      "loss": 0.6668,
      "step": 20590
    },
    {
      "epoch": 9.79,
      "learning_rate": 8.912114014251782e-06,
      "loss": 0.673,
      "step": 20600
    },
    {
      "epoch": 9.79,
      "learning_rate": 8.722090261282661e-06,
      "loss": 0.6671,
      "step": 20610
    },
    {
      "epoch": 9.8,
      "learning_rate": 8.53206650831354e-06,
      "loss": 0.6801,
      "step": 20620
    },
    {
      "epoch": 9.8,
      "learning_rate": 8.342042755344418e-06,
      "loss": 0.6891,
      "step": 20630
    },
    {
      "epoch": 9.81,
      "learning_rate": 8.152019002375297e-06,
      "loss": 0.6938,
      "step": 20640
    },
    {
      "epoch": 9.81,
      "learning_rate": 7.961995249406175e-06,
      "loss": 0.6832,
      "step": 20650
    },
    {
      "epoch": 9.81,
      "learning_rate": 7.771971496437056e-06,
      "loss": 0.6848,
      "step": 20660
    },
    {
      "epoch": 9.82,
      "learning_rate": 7.5819477434679335e-06,
      "loss": 0.6898,
      "step": 20670
    },
    {
      "epoch": 9.82,
      "learning_rate": 7.391923990498813e-06,
      "loss": 0.7,
      "step": 20680
    },
    {
      "epoch": 9.83,
      "learning_rate": 7.201900237529692e-06,
      "loss": 0.6841,
      "step": 20690
    },
    {
      "epoch": 9.83,
      "learning_rate": 7.01187648456057e-06,
      "loss": 0.6882,
      "step": 20700
    },
    {
      "epoch": 9.84,
      "learning_rate": 6.82185273159145e-06,
      "loss": 0.687,
      "step": 20710
    },
    {
      "epoch": 9.84,
      "learning_rate": 6.631828978622328e-06,
      "loss": 0.6948,
      "step": 20720
    },
    {
      "epoch": 9.85,
      "learning_rate": 6.441805225653207e-06,
      "loss": 0.6879,
      "step": 20730
    },
    {
      "epoch": 9.85,
      "learning_rate": 6.2517814726840855e-06,
      "loss": 0.694,
      "step": 20740
    },
    {
      "epoch": 9.86,
      "learning_rate": 6.061757719714964e-06,
      "loss": 0.6981,
      "step": 20750
    },
    {
      "epoch": 9.86,
      "learning_rate": 5.871733966745843e-06,
      "loss": 0.6965,
      "step": 20760
    },
    {
      "epoch": 9.87,
      "learning_rate": 5.681710213776722e-06,
      "loss": 0.6914,
      "step": 20770
    },
    {
      "epoch": 9.87,
      "learning_rate": 5.491686460807601e-06,
      "loss": 0.6893,
      "step": 20780
    },
    {
      "epoch": 9.88,
      "learning_rate": 5.3016627078384795e-06,
      "loss": 0.6848,
      "step": 20790
    },
    {
      "epoch": 9.88,
      "learning_rate": 5.111638954869359e-06,
      "loss": 0.6885,
      "step": 20800
    },
    {
      "epoch": 9.89,
      "learning_rate": 4.921615201900238e-06,
      "loss": 0.6852,
      "step": 20810
    },
    {
      "epoch": 9.89,
      "learning_rate": 4.731591448931116e-06,
      "loss": 0.6866,
      "step": 20820
    },
    {
      "epoch": 9.9,
      "learning_rate": 4.541567695961996e-06,
      "loss": 0.6919,
      "step": 20830
    },
    {
      "epoch": 9.9,
      "learning_rate": 4.351543942992874e-06,
      "loss": 0.6847,
      "step": 20840
    },
    {
      "epoch": 9.9,
      "learning_rate": 4.161520190023753e-06,
      "loss": 0.676,
      "step": 20850
    },
    {
      "epoch": 9.91,
      "learning_rate": 3.9714964370546325e-06,
      "loss": 0.6884,
      "step": 20860
    },
    {
      "epoch": 9.91,
      "learning_rate": 3.781472684085511e-06,
      "loss": 0.6927,
      "step": 20870
    },
    {
      "epoch": 9.92,
      "learning_rate": 3.5914489311163897e-06,
      "loss": 0.6877,
      "step": 20880
    },
    {
      "epoch": 9.92,
      "learning_rate": 3.4014251781472688e-06,
      "loss": 0.6846,
      "step": 20890
    },
    {
      "epoch": 9.93,
      "learning_rate": 3.2114014251781474e-06,
      "loss": 0.7192,
      "step": 20900
    },
    {
      "epoch": 9.93,
      "learning_rate": 3.021377672209026e-06,
      "loss": 0.6955,
      "step": 20910
    },
    {
      "epoch": 9.94,
      "learning_rate": 2.831353919239905e-06,
      "loss": 0.6826,
      "step": 20920
    },
    {
      "epoch": 9.94,
      "learning_rate": 2.641330166270784e-06,
      "loss": 0.6912,
      "step": 20930
    },
    {
      "epoch": 9.95,
      "learning_rate": 2.4513064133016627e-06,
      "loss": 0.6926,
      "step": 20940
    },
    {
      "epoch": 9.95,
      "learning_rate": 2.261282660332542e-06,
      "loss": 0.6868,
      "step": 20950
    },
    {
      "epoch": 9.96,
      "learning_rate": 2.0712589073634204e-06,
      "loss": 0.6877,
      "step": 20960
    },
    {
      "epoch": 9.96,
      "learning_rate": 1.8812351543942995e-06,
      "loss": 0.6978,
      "step": 20970
    },
    {
      "epoch": 9.97,
      "learning_rate": 1.6912114014251783e-06,
      "loss": 0.6852,
      "step": 20980
    },
    {
      "epoch": 9.97,
      "learning_rate": 1.5011876484560572e-06,
      "loss": 0.6799,
      "step": 20990
    },
    {
      "epoch": 9.98,
      "learning_rate": 1.311163895486936e-06,
      "loss": 0.6875,
      "step": 21000
    },
    {
      "epoch": 9.98,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7107852101325989,
      "eval_runtime": 0.4884,
      "eval_samples_per_second": 1785.468,
      "eval_steps_per_second": 14.333,
      "step": 21000
    },
    {
      "epoch": 9.98,
      "learning_rate": 1.1211401425178148e-06,
      "loss": 0.6912,
      "step": 21010
    },
    {
      "epoch": 9.99,
      "learning_rate": 9.311163895486936e-07,
      "loss": 0.6913,
      "step": 21020
    },
    {
      "epoch": 9.99,
      "learning_rate": 7.410926365795725e-07,
      "loss": 0.6772,
      "step": 21030
    },
    {
      "epoch": 10.0,
      "learning_rate": 5.510688836104513e-07,
      "loss": 0.6823,
      "step": 21040
    },
    {
      "epoch": 10.0,
      "learning_rate": 3.610451306413302e-07,
      "loss": 0.6858,
      "step": 21050
    },
    {
      "epoch": 10.0,
      "step": 21050,
      "total_flos": 4.475948005653504e+16,
      "train_loss": 0.6839622354394184,
      "train_runtime": 1185.7288,
      "train_samples_per_second": 567.997,
      "train_steps_per_second": 17.753
    }
  ],
  "logging_steps": 10,
  "max_steps": 21050,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 4.475948005653504e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
