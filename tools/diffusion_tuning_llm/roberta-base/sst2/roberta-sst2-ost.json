{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 21050,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 0.0003998099762470309,
      "loss": 0.6967,
      "step": 10
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00039963895486935867,
      "loss": 0.6841,
      "step": 20
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0003995059382422803,
      "loss": 0.6122,
      "step": 30
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0003993349168646081,
      "loss": 0.4781,
      "step": 40
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.00039914489311163894,
      "loss": 0.4296,
      "step": 50
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0003989548693586699,
      "loss": 0.4404,
      "step": 60
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0003987648456057007,
      "loss": 0.4016,
      "step": 70
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0003985748218527316,
      "loss": 0.4156,
      "step": 80
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0003983847980997625,
      "loss": 0.3244,
      "step": 90
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00039819477434679333,
      "loss": 0.3912,
      "step": 100
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00039800475059382427,
      "loss": 0.4466,
      "step": 110
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00039781472684085516,
      "loss": 0.4595,
      "step": 120
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0003976437054631829,
      "loss": 0.3423,
      "step": 130
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00039745368171021376,
      "loss": 0.4089,
      "step": 140
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0003972636579572447,
      "loss": 0.4291,
      "step": 150
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0003970736342042756,
      "loss": 0.3511,
      "step": 160
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0003968836104513064,
      "loss": 0.356,
      "step": 170
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0003966935866983373,
      "loss": 0.3146,
      "step": 180
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0003965035629453682,
      "loss": 0.4522,
      "step": 190
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0003963135391923991,
      "loss": 0.3781,
      "step": 200
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00039612351543943,
      "loss": 0.3715,
      "step": 210
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0003959334916864608,
      "loss": 0.4186,
      "step": 220
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0003957434679334917,
      "loss": 0.3993,
      "step": 230
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0003955534441805226,
      "loss": 0.3696,
      "step": 240
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0003953634204275535,
      "loss": 0.364,
      "step": 250
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00039517339667458437,
      "loss": 0.4201,
      "step": 260
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00039500237529691213,
      "loss": 0.3417,
      "step": 270
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.000394812351543943,
      "loss": 0.4023,
      "step": 280
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00039462232779097385,
      "loss": 0.363,
      "step": 290
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0003944323040380048,
      "loss": 0.275,
      "step": 300
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0003942422802850357,
      "loss": 0.3219,
      "step": 310
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0003940522565320665,
      "loss": 0.3982,
      "step": 320
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0003938622327790974,
      "loss": 0.376,
      "step": 330
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0003936722090261283,
      "loss": 0.4419,
      "step": 340
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0003934821852731592,
      "loss": 0.3885,
      "step": 350
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0003932921615201901,
      "loss": 0.4215,
      "step": 360
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0003931021377672209,
      "loss": 0.3279,
      "step": 370
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0003929121140142518,
      "loss": 0.3909,
      "step": 380
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0003927220902612827,
      "loss": 0.4159,
      "step": 390
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0003925320665083136,
      "loss": 0.4557,
      "step": 400
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00039234204275534446,
      "loss": 0.2785,
      "step": 410
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0003921520190023753,
      "loss": 0.4193,
      "step": 420
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0003919619952494062,
      "loss": 0.3367,
      "step": 430
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0003917719714964371,
      "loss": 0.3329,
      "step": 440
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00039158194774346796,
      "loss": 0.3892,
      "step": 450
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00039139192399049885,
      "loss": 0.3516,
      "step": 460
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0003912019002375297,
      "loss": 0.3101,
      "step": 470
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0003910118764845606,
      "loss": 0.2971,
      "step": 480
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00039082185273159147,
      "loss": 0.429,
      "step": 490
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00039063182897862235,
      "loss": 0.3484,
      "step": 500
    },
    {
      "epoch": 0.24,
      "eval_accuracy": 0.9174311926605505,
      "eval_loss": 0.23723137378692627,
      "eval_runtime": 0.49,
      "eval_samples_per_second": 1779.613,
      "eval_steps_per_second": 14.286,
      "step": 500
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00039044180522565324,
      "loss": 0.4344,
      "step": 510
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0003902517814726841,
      "loss": 0.4294,
      "step": 520
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00039006175771971497,
      "loss": 0.4077,
      "step": 530
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00038987173396674586,
      "loss": 0.3545,
      "step": 540
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00038968171021377674,
      "loss": 0.3724,
      "step": 550
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00038949168646080763,
      "loss": 0.3124,
      "step": 560
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00038930166270783847,
      "loss": 0.3489,
      "step": 570
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00038911163895486936,
      "loss": 0.3976,
      "step": 580
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00038892161520190024,
      "loss": 0.4043,
      "step": 590
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00038873159144893113,
      "loss": 0.3785,
      "step": 600
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.000388541567695962,
      "loss": 0.4272,
      "step": 610
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0003883515439429929,
      "loss": 0.3669,
      "step": 620
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00038816152019002375,
      "loss": 0.4772,
      "step": 630
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00038797149643705463,
      "loss": 0.43,
      "step": 640
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0003877814726840855,
      "loss": 0.3688,
      "step": 650
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0003875914489311164,
      "loss": 0.3945,
      "step": 660
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0003874014251781473,
      "loss": 0.3697,
      "step": 670
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00038721140142517814,
      "loss": 0.329,
      "step": 680
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.000387021377672209,
      "loss": 0.381,
      "step": 690
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0003868313539192399,
      "loss": 0.4292,
      "step": 700
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0003866413301662708,
      "loss": 0.3981,
      "step": 710
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0003864513064133017,
      "loss": 0.4692,
      "step": 720
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0003862612826603325,
      "loss": 0.3693,
      "step": 730
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00038607125890736347,
      "loss": 0.3936,
      "step": 740
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00038588123515439436,
      "loss": 0.4058,
      "step": 750
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0003856912114014252,
      "loss": 0.3757,
      "step": 760
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0003855011876484561,
      "loss": 0.4136,
      "step": 770
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0003853111638954869,
      "loss": 0.4433,
      "step": 780
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00038512114014251786,
      "loss": 0.4078,
      "step": 790
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00038493111638954875,
      "loss": 0.398,
      "step": 800
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0003847410926365796,
      "loss": 0.4984,
      "step": 810
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00038455106888361047,
      "loss": 0.4384,
      "step": 820
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0003843610451306413,
      "loss": 0.4692,
      "step": 830
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00038417102137767225,
      "loss": 0.4774,
      "step": 840
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00038398099762470314,
      "loss": 0.4799,
      "step": 850
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00038379097387173397,
      "loss": 0.4316,
      "step": 860
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00038360095011876486,
      "loss": 0.3915,
      "step": 870
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00038341092636579575,
      "loss": 0.4542,
      "step": 880
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00038322090261282664,
      "loss": 0.4485,
      "step": 890
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0003830308788598575,
      "loss": 0.4673,
      "step": 900
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00038284085510688836,
      "loss": 0.435,
      "step": 910
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00038265083135391925,
      "loss": 0.4336,
      "step": 920
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00038246080760095014,
      "loss": 0.4521,
      "step": 930
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00038227078384798103,
      "loss": 0.4225,
      "step": 940
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0003820807600950119,
      "loss": 0.4566,
      "step": 950
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00038189073634204275,
      "loss": 0.4564,
      "step": 960
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00038170071258907364,
      "loss": 0.4257,
      "step": 970
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00038151068883610453,
      "loss": 0.4289,
      "step": 980
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0003813206650831354,
      "loss": 0.3691,
      "step": 990
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0003811306413301663,
      "loss": 0.4322,
      "step": 1000
    },
    {
      "epoch": 0.48,
      "eval_accuracy": 0.8509174311926605,
      "eval_loss": 0.38551753759384155,
      "eval_runtime": 0.5023,
      "eval_samples_per_second": 1736.116,
      "eval_steps_per_second": 13.937,
      "step": 1000
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0003809406175771972,
      "loss": 0.4465,
      "step": 1010
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00038075059382422803,
      "loss": 0.3885,
      "step": 1020
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00038057957244655585,
      "loss": 0.5179,
      "step": 1030
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00038038954869358673,
      "loss": 0.6284,
      "step": 1040
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0003801995249406176,
      "loss": 0.6726,
      "step": 1050
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00038000950118764846,
      "loss": 0.4571,
      "step": 1060
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00037981947743467935,
      "loss": 0.5415,
      "step": 1070
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00037962945368171024,
      "loss": 0.5655,
      "step": 1080
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0003794394299287411,
      "loss": 0.5262,
      "step": 1090
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.000379249406175772,
      "loss": 0.601,
      "step": 1100
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00037905938242280285,
      "loss": 0.6483,
      "step": 1110
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00037886935866983374,
      "loss": 0.6789,
      "step": 1120
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0003786793349168646,
      "loss": 0.6968,
      "step": 1130
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0003784893111638955,
      "loss": 0.6948,
      "step": 1140
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0003782992874109264,
      "loss": 0.7009,
      "step": 1150
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00037810926365795724,
      "loss": 0.6898,
      "step": 1160
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0003779192399049881,
      "loss": 0.6971,
      "step": 1170
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.000377729216152019,
      "loss": 0.6928,
      "step": 1180
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0003775391923990499,
      "loss": 0.6874,
      "step": 1190
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0003773491686460808,
      "loss": 0.7186,
      "step": 1200
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0003771591448931116,
      "loss": 0.6673,
      "step": 1210
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0003769691211401425,
      "loss": 0.6993,
      "step": 1220
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0003767790973871734,
      "loss": 0.6888,
      "step": 1230
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0003765890736342043,
      "loss": 0.6971,
      "step": 1240
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0003763990498812352,
      "loss": 0.6874,
      "step": 1250
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00037620902612826607,
      "loss": 0.6949,
      "step": 1260
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0003760190023752969,
      "loss": 0.6865,
      "step": 1270
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0003758289786223278,
      "loss": 0.6955,
      "step": 1280
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0003756389548693587,
      "loss": 0.6737,
      "step": 1290
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00037544893111638957,
      "loss": 0.6708,
      "step": 1300
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00037525890736342046,
      "loss": 0.6782,
      "step": 1310
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0003750688836104513,
      "loss": 0.6939,
      "step": 1320
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00037487885985748224,
      "loss": 0.6802,
      "step": 1330
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00037468883610451307,
      "loss": 0.6916,
      "step": 1340
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00037449881235154396,
      "loss": 0.6991,
      "step": 1350
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00037430878859857485,
      "loss": 0.6867,
      "step": 1360
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0003741187648456057,
      "loss": 0.6881,
      "step": 1370
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00037392874109263663,
      "loss": 0.6901,
      "step": 1380
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00037373871733966746,
      "loss": 0.6853,
      "step": 1390
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00037354869358669835,
      "loss": 0.6941,
      "step": 1400
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00037335866983372924,
      "loss": 0.6955,
      "step": 1410
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0003731686460807601,
      "loss": 0.6966,
      "step": 1420
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.000372978622327791,
      "loss": 0.6926,
      "step": 1430
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0003727885985748219,
      "loss": 0.6945,
      "step": 1440
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00037259857482185274,
      "loss": 0.698,
      "step": 1450
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00037240855106888363,
      "loss": 0.6915,
      "step": 1460
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00037221852731591446,
      "loss": 0.6887,
      "step": 1470
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0003720285035629454,
      "loss": 0.6778,
      "step": 1480
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0003718384798099763,
      "loss": 0.6921,
      "step": 1490
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00037164845605700713,
      "loss": 0.6765,
      "step": 1500
    },
    {
      "epoch": 0.71,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7170499563217163,
      "eval_runtime": 0.4897,
      "eval_samples_per_second": 1780.536,
      "eval_steps_per_second": 14.293,
      "step": 1500
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.000371458432304038,
      "loss": 0.6871,
      "step": 1510
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00037126840855106885,
      "loss": 0.6933,
      "step": 1520
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0003710783847980998,
      "loss": 0.6907,
      "step": 1530
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0003708883610451307,
      "loss": 0.696,
      "step": 1540
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0003706983372921615,
      "loss": 0.6861,
      "step": 1550
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0003705083135391924,
      "loss": 0.6968,
      "step": 1560
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0003703182897862233,
      "loss": 0.6927,
      "step": 1570
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0003701282660332542,
      "loss": 0.6893,
      "step": 1580
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0003699382422802851,
      "loss": 0.6967,
      "step": 1590
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0003697482185273159,
      "loss": 0.6892,
      "step": 1600
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0003695581947743468,
      "loss": 0.6938,
      "step": 1610
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0003693681710213777,
      "loss": 0.6907,
      "step": 1620
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0003691781472684086,
      "loss": 0.698,
      "step": 1630
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00036898812351543947,
      "loss": 0.6917,
      "step": 1640
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0003687980997624703,
      "loss": 0.6923,
      "step": 1650
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0003686080760095012,
      "loss": 0.6904,
      "step": 1660
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0003684180522565321,
      "loss": 0.6674,
      "step": 1670
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00036822802850356297,
      "loss": 0.7129,
      "step": 1680
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00036803800475059386,
      "loss": 0.6947,
      "step": 1690
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00036784798099762474,
      "loss": 0.6941,
      "step": 1700
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0003676579572446556,
      "loss": 0.6972,
      "step": 1710
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00036746793349168647,
      "loss": 0.6799,
      "step": 1720
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00036727790973871736,
      "loss": 0.6915,
      "step": 1730
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00036708788598574824,
      "loss": 0.6932,
      "step": 1740
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00036689786223277913,
      "loss": 0.6952,
      "step": 1750
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00036670783847980997,
      "loss": 0.6913,
      "step": 1760
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00036651781472684086,
      "loss": 0.6904,
      "step": 1770
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00036632779097387175,
      "loss": 0.68,
      "step": 1780
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00036613776722090263,
      "loss": 0.6788,
      "step": 1790
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0003659477434679335,
      "loss": 0.6843,
      "step": 1800
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00036575771971496436,
      "loss": 0.6927,
      "step": 1810
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00036556769596199525,
      "loss": 0.6921,
      "step": 1820
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0003653776722090262,
      "loss": 0.6898,
      "step": 1830
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.000365187648456057,
      "loss": 0.6997,
      "step": 1840
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0003649976247030879,
      "loss": 0.689,
      "step": 1850
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00036480760095011875,
      "loss": 0.6943,
      "step": 1860
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00036461757719714964,
      "loss": 0.6882,
      "step": 1870
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0003644275534441806,
      "loss": 0.6913,
      "step": 1880
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0003642375296912114,
      "loss": 0.6887,
      "step": 1890
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0003640475059382423,
      "loss": 0.6942,
      "step": 1900
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00036385748218527314,
      "loss": 0.6907,
      "step": 1910
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0003636674584323041,
      "loss": 0.6865,
      "step": 1920
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00036347743467933497,
      "loss": 0.6794,
      "step": 1930
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0003632874109263658,
      "loss": 0.6695,
      "step": 1940
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0003630973871733967,
      "loss": 0.6883,
      "step": 1950
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0003629073634204276,
      "loss": 0.69,
      "step": 1960
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00036271733966745847,
      "loss": 0.6886,
      "step": 1970
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00036252731591448936,
      "loss": 0.6919,
      "step": 1980
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0003623372921615202,
      "loss": 0.6837,
      "step": 1990
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0003621472684085511,
      "loss": 0.6787,
      "step": 2000
    },
    {
      "epoch": 0.95,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7132601737976074,
      "eval_runtime": 0.5602,
      "eval_samples_per_second": 1556.485,
      "eval_steps_per_second": 12.495,
      "step": 2000
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00036195724465558197,
      "loss": 0.6929,
      "step": 2010
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00036176722090261286,
      "loss": 0.6951,
      "step": 2020
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00036157719714964375,
      "loss": 0.6898,
      "step": 2030
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0003613871733966746,
      "loss": 0.694,
      "step": 2040
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00036119714964370547,
      "loss": 0.6995,
      "step": 2050
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00036100712589073636,
      "loss": 0.691,
      "step": 2060
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00036081710213776725,
      "loss": 0.6932,
      "step": 2070
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00036062707838479814,
      "loss": 0.6983,
      "step": 2080
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.000360437054631829,
      "loss": 0.6943,
      "step": 2090
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00036024703087885986,
      "loss": 0.693,
      "step": 2100
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00036005700712589075,
      "loss": 0.6956,
      "step": 2110
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00035986698337292164,
      "loss": 0.6975,
      "step": 2120
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00035967695961995253,
      "loss": 0.7007,
      "step": 2130
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0003594869358669834,
      "loss": 0.6902,
      "step": 2140
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00035929691211401425,
      "loss": 0.6986,
      "step": 2150
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00035910688836104514,
      "loss": 0.6935,
      "step": 2160
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00035891686460807603,
      "loss": 0.6896,
      "step": 2170
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0003587268408551069,
      "loss": 0.6856,
      "step": 2180
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0003585368171021378,
      "loss": 0.6776,
      "step": 2190
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00035834679334916864,
      "loss": 0.6927,
      "step": 2200
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00035815676959619953,
      "loss": 0.6934,
      "step": 2210
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0003579667458432304,
      "loss": 0.6841,
      "step": 2220
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0003577767220902613,
      "loss": 0.6965,
      "step": 2230
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0003575866983372922,
      "loss": 0.6781,
      "step": 2240
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00035739667458432303,
      "loss": 0.6912,
      "step": 2250
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0003572066508313539,
      "loss": 0.6996,
      "step": 2260
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0003570166270783848,
      "loss": 0.696,
      "step": 2270
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0003568266033254157,
      "loss": 0.6899,
      "step": 2280
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0003566365795724466,
      "loss": 0.6818,
      "step": 2290
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0003564465558194774,
      "loss": 0.6921,
      "step": 2300
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0003562565320665083,
      "loss": 0.6922,
      "step": 2310
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00035606650831353925,
      "loss": 0.6921,
      "step": 2320
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0003558764845605701,
      "loss": 0.6856,
      "step": 2330
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.000355686460807601,
      "loss": 0.6935,
      "step": 2340
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0003554964370546318,
      "loss": 0.6865,
      "step": 2350
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0003553064133016627,
      "loss": 0.6799,
      "step": 2360
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00035511638954869364,
      "loss": 0.6995,
      "step": 2370
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0003549263657957245,
      "loss": 0.6837,
      "step": 2380
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00035473634204275537,
      "loss": 0.6849,
      "step": 2390
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00035454631828978625,
      "loss": 0.6994,
      "step": 2400
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0003543562945368171,
      "loss": 0.6978,
      "step": 2410
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00035416627078384803,
      "loss": 0.6931,
      "step": 2420
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00035397624703087887,
      "loss": 0.6903,
      "step": 2430
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00035378622327790976,
      "loss": 0.689,
      "step": 2440
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00035359619952494064,
      "loss": 0.6855,
      "step": 2450
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0003534061757719715,
      "loss": 0.6903,
      "step": 2460
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0003532161520190024,
      "loss": 0.7,
      "step": 2470
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00035302612826603326,
      "loss": 0.6838,
      "step": 2480
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00035283610451306415,
      "loss": 0.6932,
      "step": 2490
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00035264608076009503,
      "loss": 0.6888,
      "step": 2500
    },
    {
      "epoch": 1.19,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6986296772956848,
      "eval_runtime": 0.4907,
      "eval_samples_per_second": 1776.978,
      "eval_steps_per_second": 14.265,
      "step": 2500
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00035245605700712587,
      "loss": 0.6852,
      "step": 2510
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0003522660332541568,
      "loss": 0.6921,
      "step": 2520
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0003520760095011877,
      "loss": 0.6908,
      "step": 2530
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00035188598574821853,
      "loss": 0.6875,
      "step": 2540
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0003516959619952494,
      "loss": 0.6739,
      "step": 2550
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0003515059382422803,
      "loss": 0.6989,
      "step": 2560
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0003513159144893112,
      "loss": 0.6925,
      "step": 2570
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0003511258907363421,
      "loss": 0.6964,
      "step": 2580
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0003509358669833729,
      "loss": 0.6964,
      "step": 2590
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0003507458432304038,
      "loss": 0.6952,
      "step": 2600
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0003505558194774347,
      "loss": 0.6836,
      "step": 2610
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0003503657957244656,
      "loss": 0.6945,
      "step": 2620
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0003501757719714965,
      "loss": 0.6902,
      "step": 2630
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0003499857482185273,
      "loss": 0.6925,
      "step": 2640
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0003497957244655582,
      "loss": 0.6996,
      "step": 2650
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0003496057007125891,
      "loss": 0.6875,
      "step": 2660
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00034941567695962,
      "loss": 0.6939,
      "step": 2670
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00034922565320665087,
      "loss": 0.6921,
      "step": 2680
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0003490356294536817,
      "loss": 0.6869,
      "step": 2690
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0003488456057007126,
      "loss": 0.6873,
      "step": 2700
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0003486555819477435,
      "loss": 0.6785,
      "step": 2710
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00034846555819477437,
      "loss": 0.6815,
      "step": 2720
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00034827553444180526,
      "loss": 0.6855,
      "step": 2730
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0003480855106888361,
      "loss": 0.6915,
      "step": 2740
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.000347895486935867,
      "loss": 0.6902,
      "step": 2750
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00034770546318289787,
      "loss": 0.6852,
      "step": 2760
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00034751543942992876,
      "loss": 0.6963,
      "step": 2770
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00034732541567695965,
      "loss": 0.6898,
      "step": 2780
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0003471353919239905,
      "loss": 0.6954,
      "step": 2790
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00034694536817102137,
      "loss": 0.6897,
      "step": 2800
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00034675534441805226,
      "loss": 0.682,
      "step": 2810
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00034656532066508315,
      "loss": 0.6891,
      "step": 2820
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00034637529691211404,
      "loss": 0.695,
      "step": 2830
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00034618527315914493,
      "loss": 0.6957,
      "step": 2840
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00034599524940617576,
      "loss": 0.6909,
      "step": 2850
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00034580522565320665,
      "loss": 0.6828,
      "step": 2860
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00034561520190023754,
      "loss": 0.6777,
      "step": 2870
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00034542517814726843,
      "loss": 0.687,
      "step": 2880
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0003452351543942993,
      "loss": 0.6924,
      "step": 2890
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00034504513064133015,
      "loss": 0.691,
      "step": 2900
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0003448551068883611,
      "loss": 0.6884,
      "step": 2910
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00034466508313539193,
      "loss": 0.6886,
      "step": 2920
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0003444750593824228,
      "loss": 0.6907,
      "step": 2930
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0003442850356294537,
      "loss": 0.683,
      "step": 2940
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00034409501187648454,
      "loss": 0.6807,
      "step": 2950
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0003439049881235155,
      "loss": 0.6859,
      "step": 2960
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0003437149643705464,
      "loss": 0.6857,
      "step": 2970
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0003435249406175772,
      "loss": 0.683,
      "step": 2980
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0003433349168646081,
      "loss": 0.6723,
      "step": 2990
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00034314489311163893,
      "loss": 0.6822,
      "step": 3000
    },
    {
      "epoch": 1.43,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7070357203483582,
      "eval_runtime": 0.5486,
      "eval_samples_per_second": 1589.425,
      "eval_steps_per_second": 12.759,
      "step": 3000
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0003429548693586699,
      "loss": 0.6907,
      "step": 3010
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00034276484560570076,
      "loss": 0.6942,
      "step": 3020
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003425748218527316,
      "loss": 0.6993,
      "step": 3030
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0003423847980997625,
      "loss": 0.6856,
      "step": 3040
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0003421947743467933,
      "loss": 0.6922,
      "step": 3050
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00034200475059382426,
      "loss": 0.6915,
      "step": 3060
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00034181472684085515,
      "loss": 0.6927,
      "step": 3070
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.000341624703087886,
      "loss": 0.6786,
      "step": 3080
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0003414346793349169,
      "loss": 0.6903,
      "step": 3090
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00034124465558194777,
      "loss": 0.6959,
      "step": 3100
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00034105463182897865,
      "loss": 0.6917,
      "step": 3110
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00034086460807600954,
      "loss": 0.6938,
      "step": 3120
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0003406745843230404,
      "loss": 0.6791,
      "step": 3130
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00034048456057007127,
      "loss": 0.6718,
      "step": 3140
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00034029453681710215,
      "loss": 0.6947,
      "step": 3150
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00034010451306413304,
      "loss": 0.6785,
      "step": 3160
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00033991448931116393,
      "loss": 0.6887,
      "step": 3170
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00033972446555819477,
      "loss": 0.6882,
      "step": 3180
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00033953444180522566,
      "loss": 0.6872,
      "step": 3190
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00033934441805225654,
      "loss": 0.6901,
      "step": 3200
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00033915439429928743,
      "loss": 0.6876,
      "step": 3210
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0003389643705463183,
      "loss": 0.6732,
      "step": 3220
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0003387743467933492,
      "loss": 0.6924,
      "step": 3230
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00033858432304038005,
      "loss": 0.6823,
      "step": 3240
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00033839429928741093,
      "loss": 0.6861,
      "step": 3250
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0003382042755344418,
      "loss": 0.6893,
      "step": 3260
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0003380142517814727,
      "loss": 0.6971,
      "step": 3270
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0003378242280285036,
      "loss": 0.6852,
      "step": 3280
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00033763420427553444,
      "loss": 0.6923,
      "step": 3290
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0003374441805225653,
      "loss": 0.6918,
      "step": 3300
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0003372541567695962,
      "loss": 0.681,
      "step": 3310
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0003370641330166271,
      "loss": 0.6921,
      "step": 3320
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.000336874109263658,
      "loss": 0.6857,
      "step": 3330
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0003366840855106888,
      "loss": 0.6993,
      "step": 3340
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0003364940617577197,
      "loss": 0.695,
      "step": 3350
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0003363040380047506,
      "loss": 0.6864,
      "step": 3360
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0003361140142517815,
      "loss": 0.6883,
      "step": 3370
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0003359239904988124,
      "loss": 0.6913,
      "step": 3380
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0003357339667458432,
      "loss": 0.6944,
      "step": 3390
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0003355439429928741,
      "loss": 0.6881,
      "step": 3400
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00033535391923990505,
      "loss": 0.6907,
      "step": 3410
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0003351638954869359,
      "loss": 0.681,
      "step": 3420
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00033497387173396677,
      "loss": 0.6818,
      "step": 3430
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0003347838479809976,
      "loss": 0.6934,
      "step": 3440
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0003345938242280285,
      "loss": 0.6884,
      "step": 3450
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00033440380047505944,
      "loss": 0.6935,
      "step": 3460
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00033421377672209027,
      "loss": 0.6868,
      "step": 3470
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00033402375296912116,
      "loss": 0.6867,
      "step": 3480
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.000333833729216152,
      "loss": 0.6899,
      "step": 3490
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0003336437054631829,
      "loss": 0.6899,
      "step": 3500
    },
    {
      "epoch": 1.66,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6936180591583252,
      "eval_runtime": 0.5293,
      "eval_samples_per_second": 1647.393,
      "eval_steps_per_second": 13.224,
      "step": 3500
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0003334536817102138,
      "loss": 0.6858,
      "step": 3510
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00033326365795724466,
      "loss": 0.7202,
      "step": 3520
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00033307363420427555,
      "loss": 0.6858,
      "step": 3530
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00033288361045130644,
      "loss": 0.6817,
      "step": 3540
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00033269358669833733,
      "loss": 0.6922,
      "step": 3550
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0003325035629453682,
      "loss": 0.6967,
      "step": 3560
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00033231353919239905,
      "loss": 0.6907,
      "step": 3570
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00033212351543942994,
      "loss": 0.6871,
      "step": 3580
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00033193349168646083,
      "loss": 0.6855,
      "step": 3590
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0003317434679334917,
      "loss": 0.6751,
      "step": 3600
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0003315534441805226,
      "loss": 0.6875,
      "step": 3610
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00033136342042755344,
      "loss": 0.6977,
      "step": 3620
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00033117339667458433,
      "loss": 0.6987,
      "step": 3630
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0003309833729216152,
      "loss": 0.6797,
      "step": 3640
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0003307933491686461,
      "loss": 0.687,
      "step": 3650
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.000330603325415677,
      "loss": 0.6817,
      "step": 3660
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0003304133016627079,
      "loss": 0.6841,
      "step": 3670
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0003302232779097387,
      "loss": 0.6901,
      "step": 3680
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0003300332541567696,
      "loss": 0.6785,
      "step": 3690
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0003298432304038005,
      "loss": 0.7077,
      "step": 3700
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0003296532066508314,
      "loss": 0.6832,
      "step": 3710
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0003294631828978623,
      "loss": 0.6927,
      "step": 3720
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0003292731591448931,
      "loss": 0.6998,
      "step": 3730
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.000329083135391924,
      "loss": 0.6862,
      "step": 3740
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0003288931116389549,
      "loss": 0.692,
      "step": 3750
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0003287030878859858,
      "loss": 0.695,
      "step": 3760
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00032851306413301666,
      "loss": 0.6847,
      "step": 3770
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0003283230403800475,
      "loss": 0.6839,
      "step": 3780
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0003281330166270784,
      "loss": 0.6979,
      "step": 3790
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0003279429928741093,
      "loss": 0.6824,
      "step": 3800
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.00032775296912114016,
      "loss": 0.6971,
      "step": 3810
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.00032756294536817105,
      "loss": 0.6965,
      "step": 3820
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0003273729216152019,
      "loss": 0.6946,
      "step": 3830
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0003271828978622328,
      "loss": 0.6955,
      "step": 3840
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.00032699287410926367,
      "loss": 0.6846,
      "step": 3850
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.00032680285035629455,
      "loss": 0.6824,
      "step": 3860
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00032661282660332544,
      "loss": 0.6943,
      "step": 3870
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0003264228028503563,
      "loss": 0.6861,
      "step": 3880
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00032623277909738717,
      "loss": 0.6974,
      "step": 3890
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0003260427553444181,
      "loss": 0.6875,
      "step": 3900
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00032585273159144894,
      "loss": 0.6824,
      "step": 3910
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00032566270783847983,
      "loss": 0.6958,
      "step": 3920
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0003254726840855107,
      "loss": 0.6675,
      "step": 3930
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00032528266033254156,
      "loss": 0.6862,
      "step": 3940
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0003250926365795725,
      "loss": 0.6866,
      "step": 3950
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00032490261282660333,
      "loss": 0.6914,
      "step": 3960
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0003247125890736342,
      "loss": 0.6822,
      "step": 3970
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0003245225653206651,
      "loss": 0.6641,
      "step": 3980
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00032433254156769595,
      "loss": 0.6999,
      "step": 3990
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0003241425178147269,
      "loss": 0.6895,
      "step": 4000
    },
    {
      "epoch": 1.9,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6967941522598267,
      "eval_runtime": 0.4983,
      "eval_samples_per_second": 1749.91,
      "eval_steps_per_second": 14.047,
      "step": 4000
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0003239524940617577,
      "loss": 0.6912,
      "step": 4010
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0003237624703087886,
      "loss": 0.6841,
      "step": 4020
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0003235724465558195,
      "loss": 0.6551,
      "step": 4030
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00032338242280285034,
      "loss": 0.711,
      "step": 4040
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0003231923990498813,
      "loss": 0.698,
      "step": 4050
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0003230023752969121,
      "loss": 0.6922,
      "step": 4060
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.000322812351543943,
      "loss": 0.6828,
      "step": 4070
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0003226223277909739,
      "loss": 0.6753,
      "step": 4080
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0003224323040380047,
      "loss": 0.694,
      "step": 4090
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00032224228028503567,
      "loss": 0.6893,
      "step": 4100
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00032205225653206656,
      "loss": 0.6894,
      "step": 4110
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0003218622327790974,
      "loss": 0.6823,
      "step": 4120
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0003216722090261283,
      "loss": 0.6998,
      "step": 4130
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0003214821852731591,
      "loss": 0.6921,
      "step": 4140
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.00032129216152019006,
      "loss": 0.6834,
      "step": 4150
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00032110213776722095,
      "loss": 0.6922,
      "step": 4160
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0003209121140142518,
      "loss": 0.6848,
      "step": 4170
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00032072209026128267,
      "loss": 0.7017,
      "step": 4180
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00032053206650831356,
      "loss": 0.6942,
      "step": 4190
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00032034204275534445,
      "loss": 0.6887,
      "step": 4200
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00032015201900237534,
      "loss": 0.692,
      "step": 4210
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00031996199524940617,
      "loss": 0.6811,
      "step": 4220
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.00031977197149643706,
      "loss": 0.6943,
      "step": 4230
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.00031958194774346795,
      "loss": 0.693,
      "step": 4240
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.00031939192399049884,
      "loss": 0.6919,
      "step": 4250
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0003192019002375297,
      "loss": 0.6949,
      "step": 4260
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00031901187648456056,
      "loss": 0.6846,
      "step": 4270
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00031882185273159145,
      "loss": 0.6826,
      "step": 4280
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.00031865083135391927,
      "loss": 0.6883,
      "step": 4290
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.00031846080760095015,
      "loss": 0.6696,
      "step": 4300
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.000318270783847981,
      "loss": 0.7111,
      "step": 4310
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0003180807600950119,
      "loss": 0.682,
      "step": 4320
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.00031789073634204277,
      "loss": 0.6966,
      "step": 4330
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.00031770071258907366,
      "loss": 0.6777,
      "step": 4340
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00031751068883610454,
      "loss": 0.6886,
      "step": 4350
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00031732066508313543,
      "loss": 0.6844,
      "step": 4360
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.00031713064133016627,
      "loss": 0.6807,
      "step": 4370
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.00031694061757719716,
      "loss": 0.6854,
      "step": 4380
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.00031675059382422805,
      "loss": 0.6891,
      "step": 4390
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.00031656057007125893,
      "loss": 0.6905,
      "step": 4400
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0003163705463182898,
      "loss": 0.678,
      "step": 4410
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.00031618052256532066,
      "loss": 0.6798,
      "step": 4420
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.00031599049881235155,
      "loss": 0.6763,
      "step": 4430
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00031580047505938244,
      "loss": 0.6947,
      "step": 4440
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0003156104513064133,
      "loss": 0.6955,
      "step": 4450
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.0003154204275534442,
      "loss": 0.6823,
      "step": 4460
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00031523040380047505,
      "loss": 0.6751,
      "step": 4470
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00031504038004750594,
      "loss": 0.6842,
      "step": 4480
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0003148503562945369,
      "loss": 0.6934,
      "step": 4490
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0003146603325415677,
      "loss": 0.6907,
      "step": 4500
    },
    {
      "epoch": 2.14,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6955846548080444,
      "eval_runtime": 0.4996,
      "eval_samples_per_second": 1745.339,
      "eval_steps_per_second": 14.011,
      "step": 4500
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0003144703087885986,
      "loss": 0.6864,
      "step": 4510
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00031428028503562944,
      "loss": 0.6875,
      "step": 4520
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0003140902612826603,
      "loss": 0.6909,
      "step": 4530
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00031390023752969127,
      "loss": 0.6873,
      "step": 4540
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0003137102137767221,
      "loss": 0.6889,
      "step": 4550
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.000313520190023753,
      "loss": 0.6897,
      "step": 4560
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0003133301662707838,
      "loss": 0.6974,
      "step": 4570
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0003131401425178147,
      "loss": 0.6849,
      "step": 4580
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.00031295011876484566,
      "loss": 0.6936,
      "step": 4590
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0003127600950118765,
      "loss": 0.6864,
      "step": 4600
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0003125700712589074,
      "loss": 0.6976,
      "step": 4610
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00031238004750593827,
      "loss": 0.6931,
      "step": 4620
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0003121900237529691,
      "loss": 0.7034,
      "step": 4630
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.00031200000000000005,
      "loss": 0.6779,
      "step": 4640
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0003118099762470309,
      "loss": 0.6875,
      "step": 4650
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00031161995249406177,
      "loss": 0.6841,
      "step": 4660
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00031142992874109266,
      "loss": 0.6838,
      "step": 4670
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0003112399049881235,
      "loss": 0.6811,
      "step": 4680
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.00031104988123515444,
      "loss": 0.6879,
      "step": 4690
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.00031085985748218527,
      "loss": 0.693,
      "step": 4700
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00031066983372921616,
      "loss": 0.6869,
      "step": 4710
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00031047980997624705,
      "loss": 0.6752,
      "step": 4720
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0003102897862232779,
      "loss": 0.7051,
      "step": 4730
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00031009976247030883,
      "loss": 0.683,
      "step": 4740
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0003099097387173397,
      "loss": 0.6948,
      "step": 4750
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00030971971496437055,
      "loss": 0.6928,
      "step": 4760
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00030952969121140144,
      "loss": 0.6711,
      "step": 4770
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00030933966745843233,
      "loss": 0.691,
      "step": 4780
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0003091496437054632,
      "loss": 0.6952,
      "step": 4790
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0003089596199524941,
      "loss": 0.696,
      "step": 4800
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00030876959619952494,
      "loss": 0.6979,
      "step": 4810
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00030857957244655583,
      "loss": 0.6812,
      "step": 4820
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0003083895486935867,
      "loss": 0.6811,
      "step": 4830
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0003081995249406176,
      "loss": 0.6883,
      "step": 4840
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0003080095011876485,
      "loss": 0.6756,
      "step": 4850
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.00030781947743467933,
      "loss": 0.6921,
      "step": 4860
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0003076294536817102,
      "loss": 0.6721,
      "step": 4870
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0003074394299287411,
      "loss": 0.6876,
      "step": 4880
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.000307249406175772,
      "loss": 0.6835,
      "step": 4890
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0003070593824228029,
      "loss": 0.673,
      "step": 4900
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0003068693586698337,
      "loss": 0.6815,
      "step": 4910
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0003066793349168646,
      "loss": 0.6832,
      "step": 4920
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0003064893111638955,
      "loss": 0.6879,
      "step": 4930
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0003062992874109264,
      "loss": 0.6848,
      "step": 4940
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0003061092636579573,
      "loss": 0.6946,
      "step": 4950
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0003059192399049881,
      "loss": 0.6971,
      "step": 4960
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.000305729216152019,
      "loss": 0.688,
      "step": 4970
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0003055391923990499,
      "loss": 0.6836,
      "step": 4980
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0003053491686460808,
      "loss": 0.6918,
      "step": 4990
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.00030515914489311167,
      "loss": 0.6814,
      "step": 5000
    },
    {
      "epoch": 2.38,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7029054760932922,
      "eval_runtime": 0.4995,
      "eval_samples_per_second": 1745.707,
      "eval_steps_per_second": 14.014,
      "step": 5000
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0003049691211401425,
      "loss": 0.7012,
      "step": 5010
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0003047790973871734,
      "loss": 0.6859,
      "step": 5020
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0003045890736342043,
      "loss": 0.6827,
      "step": 5030
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00030439904988123517,
      "loss": 0.689,
      "step": 5040
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00030420902612826606,
      "loss": 0.687,
      "step": 5050
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00030401900237529694,
      "loss": 0.6854,
      "step": 5060
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0003038289786223278,
      "loss": 0.6831,
      "step": 5070
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.00030363895486935867,
      "loss": 0.6932,
      "step": 5080
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.00030344893111638956,
      "loss": 0.7062,
      "step": 5090
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.00030325890736342045,
      "loss": 0.6904,
      "step": 5100
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00030306888361045133,
      "loss": 0.686,
      "step": 5110
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00030287885985748217,
      "loss": 0.695,
      "step": 5120
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0003026888361045131,
      "loss": 0.6723,
      "step": 5130
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.00030249881235154395,
      "loss": 0.7007,
      "step": 5140
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00030230878859857483,
      "loss": 0.6999,
      "step": 5150
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0003021187648456057,
      "loss": 0.6826,
      "step": 5160
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00030192874109263656,
      "loss": 0.6834,
      "step": 5170
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0003017387173396675,
      "loss": 0.7049,
      "step": 5180
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0003015486935866984,
      "loss": 0.6968,
      "step": 5190
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0003013586698337292,
      "loss": 0.6919,
      "step": 5200
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0003011686460807601,
      "loss": 0.6886,
      "step": 5210
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00030097862232779095,
      "loss": 0.6989,
      "step": 5220
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0003007885985748219,
      "loss": 0.689,
      "step": 5230
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0003005985748218528,
      "loss": 0.6937,
      "step": 5240
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0003004085510688836,
      "loss": 0.6929,
      "step": 5250
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0003002185273159145,
      "loss": 0.6934,
      "step": 5260
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.00030002850356294534,
      "loss": 0.6862,
      "step": 5270
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0002998384798099763,
      "loss": 0.6924,
      "step": 5280
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00029964845605700717,
      "loss": 0.6801,
      "step": 5290
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.000299458432304038,
      "loss": 0.6927,
      "step": 5300
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0002992684085510689,
      "loss": 0.6862,
      "step": 5310
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0002990783847980998,
      "loss": 0.6926,
      "step": 5320
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.00029888836104513067,
      "loss": 0.6788,
      "step": 5330
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00029869833729216156,
      "loss": 0.6936,
      "step": 5340
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0002985083135391924,
      "loss": 0.6942,
      "step": 5350
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0002983182897862233,
      "loss": 0.685,
      "step": 5360
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.00029812826603325417,
      "loss": 0.6765,
      "step": 5370
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00029793824228028506,
      "loss": 0.7012,
      "step": 5380
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00029774821852731595,
      "loss": 0.6968,
      "step": 5390
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0002975581947743468,
      "loss": 0.6961,
      "step": 5400
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00029736817102137767,
      "loss": 0.6953,
      "step": 5410
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00029717814726840856,
      "loss": 0.6846,
      "step": 5420
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00029698812351543945,
      "loss": 0.673,
      "step": 5430
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00029679809976247034,
      "loss": 0.7057,
      "step": 5440
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00029660807600950123,
      "loss": 0.6839,
      "step": 5450
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00029641805225653206,
      "loss": 0.6851,
      "step": 5460
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00029622802850356295,
      "loss": 0.6989,
      "step": 5470
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00029603800475059384,
      "loss": 0.672,
      "step": 5480
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00029584798099762473,
      "loss": 0.6881,
      "step": 5490
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0002956579572446556,
      "loss": 0.6939,
      "step": 5500
    },
    {
      "epoch": 2.61,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6963786482810974,
      "eval_runtime": 0.499,
      "eval_samples_per_second": 1747.613,
      "eval_steps_per_second": 14.029,
      "step": 5500
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.00029546793349168645,
      "loss": 0.6846,
      "step": 5510
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.00029527790973871734,
      "loss": 0.6854,
      "step": 5520
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.00029508788598574823,
      "loss": 0.6845,
      "step": 5530
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0002948978622327791,
      "loss": 0.7056,
      "step": 5540
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00029470783847981,
      "loss": 0.6748,
      "step": 5550
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00029451781472684084,
      "loss": 0.6893,
      "step": 5560
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.00029432779097387173,
      "loss": 0.6849,
      "step": 5570
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0002941377672209026,
      "loss": 0.6957,
      "step": 5580
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0002939477434679335,
      "loss": 0.6898,
      "step": 5590
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0002937577197149644,
      "loss": 0.6962,
      "step": 5600
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00029356769596199523,
      "loss": 0.6966,
      "step": 5610
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0002933776722090261,
      "loss": 0.6875,
      "step": 5620
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00029318764845605706,
      "loss": 0.6888,
      "step": 5630
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0002929976247030879,
      "loss": 0.696,
      "step": 5640
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0002928076009501188,
      "loss": 0.6954,
      "step": 5650
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0002926175771971496,
      "loss": 0.6904,
      "step": 5660
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0002924275534441805,
      "loss": 0.6937,
      "step": 5670
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.00029223752969121145,
      "loss": 0.6831,
      "step": 5680
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0002920475059382423,
      "loss": 0.6784,
      "step": 5690
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0002918574821852732,
      "loss": 0.6768,
      "step": 5700
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.000291667458432304,
      "loss": 0.6952,
      "step": 5710
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0002914774346793349,
      "loss": 0.6862,
      "step": 5720
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.00029128741092636584,
      "loss": 0.6948,
      "step": 5730
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0002910973871733967,
      "loss": 0.6866,
      "step": 5740
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00029090736342042757,
      "loss": 0.6861,
      "step": 5750
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00029071733966745845,
      "loss": 0.6968,
      "step": 5760
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00029052731591448934,
      "loss": 0.6829,
      "step": 5770
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00029033729216152023,
      "loss": 0.6857,
      "step": 5780
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.000290166270783848,
      "loss": 0.69,
      "step": 5790
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0002899762470308789,
      "loss": 0.6923,
      "step": 5800
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0002897862232779097,
      "loss": 0.6734,
      "step": 5810
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00028959619952494066,
      "loss": 0.6889,
      "step": 5820
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0002894061757719715,
      "loss": 0.689,
      "step": 5830
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0002892161520190024,
      "loss": 0.6922,
      "step": 5840
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.00028902612826603327,
      "loss": 0.6801,
      "step": 5850
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0002888361045130641,
      "loss": 0.7041,
      "step": 5860
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.00028864608076009505,
      "loss": 0.6949,
      "step": 5870
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.00028845605700712594,
      "loss": 0.6959,
      "step": 5880
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0002882660332541568,
      "loss": 0.7017,
      "step": 5890
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.00028807600950118766,
      "loss": 0.6986,
      "step": 5900
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0002878859857482185,
      "loss": 0.6744,
      "step": 5910
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00028769596199524944,
      "loss": 0.7031,
      "step": 5920
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00028750593824228033,
      "loss": 0.6802,
      "step": 5930
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00028731591448931116,
      "loss": 0.695,
      "step": 5940
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00028712589073634205,
      "loss": 0.6811,
      "step": 5950
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00028693586698337294,
      "loss": 0.6961,
      "step": 5960
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00028674584323040383,
      "loss": 0.6882,
      "step": 5970
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0002865558194774347,
      "loss": 0.6912,
      "step": 5980
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00028636579572446555,
      "loss": 0.688,
      "step": 5990
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00028617577197149644,
      "loss": 0.6873,
      "step": 6000
    },
    {
      "epoch": 2.85,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6954765915870667,
      "eval_runtime": 0.5006,
      "eval_samples_per_second": 1742.018,
      "eval_steps_per_second": 13.984,
      "step": 6000
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.00028598574821852733,
      "loss": 0.6921,
      "step": 6010
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0002857957244655582,
      "loss": 0.689,
      "step": 6020
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0002856057007125891,
      "loss": 0.6951,
      "step": 6030
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00028541567695961994,
      "loss": 0.6899,
      "step": 6040
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00028522565320665083,
      "loss": 0.6851,
      "step": 6050
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.0002850356294536817,
      "loss": 0.6925,
      "step": 6060
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.0002848456057007126,
      "loss": 0.692,
      "step": 6070
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0002846555819477435,
      "loss": 0.6901,
      "step": 6080
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.00028446555819477433,
      "loss": 0.6824,
      "step": 6090
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0002842755344418052,
      "loss": 0.6837,
      "step": 6100
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0002840855106888361,
      "loss": 0.6939,
      "step": 6110
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.000283895486935867,
      "loss": 0.6764,
      "step": 6120
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0002837054631828979,
      "loss": 0.6802,
      "step": 6130
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0002835154394299288,
      "loss": 0.6875,
      "step": 6140
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0002833254156769596,
      "loss": 0.6908,
      "step": 6150
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.0002831353919239905,
      "loss": 0.7024,
      "step": 6160
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.0002829453681710214,
      "loss": 0.6903,
      "step": 6170
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0002827553444180523,
      "loss": 0.6921,
      "step": 6180
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00028256532066508317,
      "loss": 0.6998,
      "step": 6190
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.000282375296912114,
      "loss": 0.6913,
      "step": 6200
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0002821852731591449,
      "loss": 0.6912,
      "step": 6210
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0002819952494061758,
      "loss": 0.6887,
      "step": 6220
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00028180522565320667,
      "loss": 0.694,
      "step": 6230
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00028161520190023756,
      "loss": 0.6874,
      "step": 6240
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0002814251781472684,
      "loss": 0.6979,
      "step": 6250
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0002812351543942993,
      "loss": 0.6911,
      "step": 6260
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.0002810451306413302,
      "loss": 0.7011,
      "step": 6270
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00028085510688836106,
      "loss": 0.6849,
      "step": 6280
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.00028066508313539195,
      "loss": 0.673,
      "step": 6290
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0002804750593824228,
      "loss": 0.7035,
      "step": 6300
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00028028503562945367,
      "loss": 0.6762,
      "step": 6310
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.0002800950118764846,
      "loss": 0.6946,
      "step": 6320
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.00027990498812351545,
      "loss": 0.6822,
      "step": 6330
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.00027971496437054634,
      "loss": 0.6853,
      "step": 6340
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00027952494061757717,
      "loss": 0.6887,
      "step": 6350
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.0002793349168646081,
      "loss": 0.6957,
      "step": 6360
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.000279144893111639,
      "loss": 0.7021,
      "step": 6370
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00027895486935866984,
      "loss": 0.6998,
      "step": 6380
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.0002787648456057007,
      "loss": 0.6891,
      "step": 6390
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.0002785748218527316,
      "loss": 0.6861,
      "step": 6400
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0002783847980997625,
      "loss": 0.6762,
      "step": 6410
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0002781947743467934,
      "loss": 0.6878,
      "step": 6420
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0002780047505938242,
      "loss": 0.7112,
      "step": 6430
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.0002778147268408551,
      "loss": 0.6884,
      "step": 6440
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.000277624703087886,
      "loss": 0.6858,
      "step": 6450
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0002774346793349169,
      "loss": 0.6863,
      "step": 6460
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0002772446555819478,
      "loss": 0.7011,
      "step": 6470
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.0002770546318289786,
      "loss": 0.6996,
      "step": 6480
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.0002768646080760095,
      "loss": 0.6903,
      "step": 6490
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.0002766745843230404,
      "loss": 0.6912,
      "step": 6500
    },
    {
      "epoch": 3.09,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6965824961662292,
      "eval_runtime": 0.5126,
      "eval_samples_per_second": 1701.153,
      "eval_steps_per_second": 13.656,
      "step": 6500
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.0002764845605700713,
      "loss": 0.6865,
      "step": 6510
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00027629453681710217,
      "loss": 0.6885,
      "step": 6520
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.000276104513064133,
      "loss": 0.6774,
      "step": 6530
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.0002759144893111639,
      "loss": 0.683,
      "step": 6540
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.0002757244655581948,
      "loss": 0.6893,
      "step": 6550
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00027553444180522567,
      "loss": 0.6978,
      "step": 6560
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00027534441805225656,
      "loss": 0.6783,
      "step": 6570
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00027515439429928745,
      "loss": 0.6876,
      "step": 6580
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.0002749643705463183,
      "loss": 0.6859,
      "step": 6590
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.0002747743467933492,
      "loss": 0.6851,
      "step": 6600
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00027458432304038006,
      "loss": 0.6975,
      "step": 6610
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00027439429928741095,
      "loss": 0.6902,
      "step": 6620
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00027420427553444184,
      "loss": 0.692,
      "step": 6630
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.0002740142517814727,
      "loss": 0.6904,
      "step": 6640
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00027382422802850356,
      "loss": 0.6995,
      "step": 6650
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00027363420427553445,
      "loss": 0.6842,
      "step": 6660
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.00027344418052256534,
      "loss": 0.6731,
      "step": 6670
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.00027325415676959623,
      "loss": 0.6886,
      "step": 6680
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00027306413301662706,
      "loss": 0.6721,
      "step": 6690
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00027287410926365795,
      "loss": 0.6856,
      "step": 6700
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.0002726840855106889,
      "loss": 0.6975,
      "step": 6710
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00027249406175771973,
      "loss": 0.6987,
      "step": 6720
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.0002723040380047506,
      "loss": 0.6835,
      "step": 6730
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00027211401425178145,
      "loss": 0.6976,
      "step": 6740
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.00027192399049881234,
      "loss": 0.7037,
      "step": 6750
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.0002717339667458433,
      "loss": 0.6953,
      "step": 6760
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.0002715439429928741,
      "loss": 0.694,
      "step": 6770
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.000271353919239905,
      "loss": 0.6949,
      "step": 6780
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00027116389548693584,
      "loss": 0.6832,
      "step": 6790
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00027097387173396673,
      "loss": 0.6931,
      "step": 6800
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.0002707838479809977,
      "loss": 0.6776,
      "step": 6810
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.0002705938242280285,
      "loss": 0.6858,
      "step": 6820
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.0002704038004750594,
      "loss": 0.7104,
      "step": 6830
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.0002702137767220903,
      "loss": 0.6914,
      "step": 6840
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.0002700237529691211,
      "loss": 0.6923,
      "step": 6850
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.00026983372921615207,
      "loss": 0.6985,
      "step": 6860
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0002696437054631829,
      "loss": 0.6805,
      "step": 6870
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.0002694536817102138,
      "loss": 0.7191,
      "step": 6880
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.0002692636579572447,
      "loss": 0.6922,
      "step": 6890
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.0002690736342042755,
      "loss": 0.7271,
      "step": 6900
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.00026888361045130645,
      "loss": 0.7027,
      "step": 6910
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.0002686935866983373,
      "loss": 0.6846,
      "step": 6920
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.0002685035629453682,
      "loss": 0.6898,
      "step": 6930
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00026831353919239907,
      "loss": 0.7025,
      "step": 6940
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00026812351543942996,
      "loss": 0.7009,
      "step": 6950
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.00026793349168646084,
      "loss": 0.6916,
      "step": 6960
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.00026774346793349173,
      "loss": 0.7007,
      "step": 6970
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00026755344418052257,
      "loss": 0.6919,
      "step": 6980
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00026736342042755346,
      "loss": 0.6879,
      "step": 6990
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00026717339667458435,
      "loss": 0.6929,
      "step": 7000
    },
    {
      "epoch": 3.33,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6963299512863159,
      "eval_runtime": 0.4984,
      "eval_samples_per_second": 1749.603,
      "eval_steps_per_second": 14.045,
      "step": 7000
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00026698337292161523,
      "loss": 0.6885,
      "step": 7010
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.0002667933491686461,
      "loss": 0.686,
      "step": 7020
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00026660332541567696,
      "loss": 0.6952,
      "step": 7030
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00026641330166270785,
      "loss": 0.6816,
      "step": 7040
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00026622327790973874,
      "loss": 0.7004,
      "step": 7050
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.0002660332541567696,
      "loss": 0.7103,
      "step": 7060
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.0002658432304038005,
      "loss": 0.6946,
      "step": 7070
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00026565320665083135,
      "loss": 0.6953,
      "step": 7080
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.00026546318289786224,
      "loss": 0.6946,
      "step": 7090
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.0002652731591448931,
      "loss": 0.6898,
      "step": 7100
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.000265083135391924,
      "loss": 0.687,
      "step": 7110
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0002648931116389549,
      "loss": 0.6876,
      "step": 7120
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00026470308788598574,
      "loss": 0.6849,
      "step": 7130
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.0002645130641330166,
      "loss": 0.699,
      "step": 7140
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.0002643230403800475,
      "loss": 0.6887,
      "step": 7150
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.0002641330166270784,
      "loss": 0.6912,
      "step": 7160
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.0002639429928741093,
      "loss": 0.6816,
      "step": 7170
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.0002637529691211401,
      "loss": 0.6881,
      "step": 7180
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.000263562945368171,
      "loss": 0.686,
      "step": 7190
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00026339192399049883,
      "loss": 0.6849,
      "step": 7200
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0002632019002375297,
      "loss": 0.6936,
      "step": 7210
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0002630118764845606,
      "loss": 0.6864,
      "step": 7220
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00026282185273159144,
      "loss": 0.6976,
      "step": 7230
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.00026263182897862233,
      "loss": 0.6889,
      "step": 7240
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0002624418052256532,
      "loss": 0.6895,
      "step": 7250
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.0002622517814726841,
      "loss": 0.6931,
      "step": 7260
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.000262061757719715,
      "loss": 0.6913,
      "step": 7270
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00026187173396674583,
      "loss": 0.6926,
      "step": 7280
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.0002616817102137767,
      "loss": 0.6769,
      "step": 7290
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.0002614916864608076,
      "loss": 0.6947,
      "step": 7300
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.0002613016627078385,
      "loss": 0.6865,
      "step": 7310
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0002611116389548694,
      "loss": 0.6738,
      "step": 7320
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0002609216152019002,
      "loss": 0.6986,
      "step": 7330
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0002607315914489311,
      "loss": 0.7035,
      "step": 7340
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.000260541567695962,
      "loss": 0.6907,
      "step": 7350
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.0002603515439429929,
      "loss": 0.6887,
      "step": 7360
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.0002601615201900238,
      "loss": 0.6829,
      "step": 7370
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.0002599714964370546,
      "loss": 0.6963,
      "step": 7380
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.0002597814726840855,
      "loss": 0.6932,
      "step": 7390
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00025959144893111645,
      "loss": 0.6769,
      "step": 7400
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.0002594014251781473,
      "loss": 0.6872,
      "step": 7410
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00025921140142517817,
      "loss": 0.6958,
      "step": 7420
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.000259021377672209,
      "loss": 0.6876,
      "step": 7430
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.0002588313539192399,
      "loss": 0.6885,
      "step": 7440
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00025864133016627083,
      "loss": 0.6911,
      "step": 7450
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00025845130641330167,
      "loss": 0.6772,
      "step": 7460
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00025826128266033256,
      "loss": 0.6833,
      "step": 7470
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.0002580712589073634,
      "loss": 0.6877,
      "step": 7480
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.0002578812351543943,
      "loss": 0.6838,
      "step": 7490
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.0002576912114014252,
      "loss": 0.6929,
      "step": 7500
    },
    {
      "epoch": 3.56,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6982220411300659,
      "eval_runtime": 0.5013,
      "eval_samples_per_second": 1739.356,
      "eval_steps_per_second": 13.963,
      "step": 7500
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00025750118764845606,
      "loss": 0.6946,
      "step": 7510
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00025731116389548695,
      "loss": 0.6794,
      "step": 7520
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00025712114014251784,
      "loss": 0.6847,
      "step": 7530
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00025693111638954867,
      "loss": 0.6774,
      "step": 7540
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.0002567410926365796,
      "loss": 0.7037,
      "step": 7550
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.00025655106888361045,
      "loss": 0.6937,
      "step": 7560
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00025636104513064134,
      "loss": 0.6773,
      "step": 7570
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.0002561710213776722,
      "loss": 0.6972,
      "step": 7580
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.0002559809976247031,
      "loss": 0.6998,
      "step": 7590
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.000255790973871734,
      "loss": 0.691,
      "step": 7600
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00025560095011876484,
      "loss": 0.6952,
      "step": 7610
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00025541092636579573,
      "loss": 0.6906,
      "step": 7620
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.0002552209026128266,
      "loss": 0.6712,
      "step": 7630
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.0002550308788598575,
      "loss": 0.692,
      "step": 7640
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.0002548408551068884,
      "loss": 0.6925,
      "step": 7650
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.0002546508313539193,
      "loss": 0.6884,
      "step": 7660
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.0002544608076009501,
      "loss": 0.6816,
      "step": 7670
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.000254270783847981,
      "loss": 0.6886,
      "step": 7680
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.0002540807600950119,
      "loss": 0.6676,
      "step": 7690
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.0002538907363420428,
      "loss": 0.6767,
      "step": 7700
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00025370071258907367,
      "loss": 0.6868,
      "step": 7710
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.0002535106888361045,
      "loss": 0.6849,
      "step": 7720
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.0002533206650831354,
      "loss": 0.6858,
      "step": 7730
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0002531306413301663,
      "loss": 0.6856,
      "step": 7740
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0002529406175771972,
      "loss": 0.6881,
      "step": 7750
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00025275059382422806,
      "loss": 0.6901,
      "step": 7760
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.0002525605700712589,
      "loss": 0.6943,
      "step": 7770
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.0002523705463182898,
      "loss": 0.6863,
      "step": 7780
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.0002521805225653207,
      "loss": 0.6884,
      "step": 7790
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00025199049881235156,
      "loss": 0.6851,
      "step": 7800
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00025180047505938245,
      "loss": 0.691,
      "step": 7810
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.0002516104513064133,
      "loss": 0.6902,
      "step": 7820
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.0002514204275534442,
      "loss": 0.6899,
      "step": 7830
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00025123040380047506,
      "loss": 0.6829,
      "step": 7840
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00025104038004750595,
      "loss": 0.6804,
      "step": 7850
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00025085035629453684,
      "loss": 0.696,
      "step": 7860
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.0002506603325415677,
      "loss": 0.7044,
      "step": 7870
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00025047030878859856,
      "loss": 0.6834,
      "step": 7880
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00025028028503562945,
      "loss": 0.6955,
      "step": 7890
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00025009026128266034,
      "loss": 0.6879,
      "step": 7900
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00024990023752969123,
      "loss": 0.6866,
      "step": 7910
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.0002497102137767221,
      "loss": 0.6811,
      "step": 7920
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00024952019002375295,
      "loss": 0.6853,
      "step": 7930
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.0002493301662707839,
      "loss": 0.6914,
      "step": 7940
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00024914014251781473,
      "loss": 0.6966,
      "step": 7950
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.0002489501187648456,
      "loss": 0.6975,
      "step": 7960
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.0002487600950118765,
      "loss": 0.6952,
      "step": 7970
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00024857007125890734,
      "loss": 0.6855,
      "step": 7980
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0002483800475059383,
      "loss": 0.6954,
      "step": 7990
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0002481900237529691,
      "loss": 0.6945,
      "step": 8000
    },
    {
      "epoch": 3.8,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6980092525482178,
      "eval_runtime": 0.4993,
      "eval_samples_per_second": 1746.376,
      "eval_steps_per_second": 14.019,
      "step": 8000
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.000248,
      "loss": 0.6884,
      "step": 8010
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.0002478099762470309,
      "loss": 0.6879,
      "step": 8020
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00024761995249406173,
      "loss": 0.6865,
      "step": 8030
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.0002474299287410927,
      "loss": 0.6927,
      "step": 8040
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.0002472399049881235,
      "loss": 0.6914,
      "step": 8050
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.0002470498812351544,
      "loss": 0.6762,
      "step": 8060
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.0002468598574821853,
      "loss": 0.6935,
      "step": 8070
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.0002466698337292161,
      "loss": 0.6869,
      "step": 8080
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00024647980997624707,
      "loss": 0.6864,
      "step": 8090
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.00024628978622327796,
      "loss": 0.6891,
      "step": 8100
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0002460997624703088,
      "loss": 0.6906,
      "step": 8110
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.0002459097387173397,
      "loss": 0.6944,
      "step": 8120
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.0002457197149643705,
      "loss": 0.6876,
      "step": 8130
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00024552969121140146,
      "loss": 0.6914,
      "step": 8140
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00024533966745843235,
      "loss": 0.6914,
      "step": 8150
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.0002451496437054632,
      "loss": 0.6899,
      "step": 8160
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00024495961995249407,
      "loss": 0.6843,
      "step": 8170
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00024476959619952496,
      "loss": 0.6796,
      "step": 8180
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00024457957244655585,
      "loss": 0.6836,
      "step": 8190
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00024438954869358674,
      "loss": 0.7005,
      "step": 8200
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00024419952494061757,
      "loss": 0.6878,
      "step": 8210
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00024400950118764846,
      "loss": 0.6975,
      "step": 8220
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00024381947743467937,
      "loss": 0.6925,
      "step": 8230
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.0002436294536817102,
      "loss": 0.6808,
      "step": 8240
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00024343942992874112,
      "loss": 0.6947,
      "step": 8250
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00024324940617577196,
      "loss": 0.6715,
      "step": 8260
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00024305938242280285,
      "loss": 0.6891,
      "step": 8270
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00024286935866983376,
      "loss": 0.6869,
      "step": 8280
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.0002426793349168646,
      "loss": 0.6869,
      "step": 8290
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00024248931116389551,
      "loss": 0.6764,
      "step": 8300
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00024229928741092635,
      "loss": 0.6745,
      "step": 8310
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00024210926365795727,
      "loss": 0.6977,
      "step": 8320
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00024191923990498815,
      "loss": 0.6899,
      "step": 8330
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.000241729216152019,
      "loss": 0.6778,
      "step": 8340
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.0002415391923990499,
      "loss": 0.6742,
      "step": 8350
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.0002413491686460808,
      "loss": 0.6787,
      "step": 8360
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00024115914489311165,
      "loss": 0.7079,
      "step": 8370
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00024096912114014254,
      "loss": 0.694,
      "step": 8380
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00024077909738717338,
      "loss": 0.6972,
      "step": 8390
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.0002405890736342043,
      "loss": 0.6969,
      "step": 8400
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00024039904988123518,
      "loss": 0.6954,
      "step": 8410
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00024020902612826604,
      "loss": 0.6674,
      "step": 8420
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00024001900237529693,
      "loss": 0.6857,
      "step": 8430
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.0002398289786223278,
      "loss": 0.698,
      "step": 8440
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00023963895486935868,
      "loss": 0.6898,
      "step": 8450
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00023944893111638957,
      "loss": 0.6899,
      "step": 8460
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00023925890736342043,
      "loss": 0.6867,
      "step": 8470
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00023906888361045132,
      "loss": 0.6955,
      "step": 8480
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.0002388788598574822,
      "loss": 0.6862,
      "step": 8490
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00023870783847981,
      "loss": 0.6908,
      "step": 8500
    },
    {
      "epoch": 4.04,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6944389939308167,
      "eval_runtime": 0.5793,
      "eval_samples_per_second": 1505.217,
      "eval_steps_per_second": 12.083,
      "step": 8500
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00023851781472684084,
      "loss": 0.6782,
      "step": 8510
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00023832779097387175,
      "loss": 0.6927,
      "step": 8520
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00023813776722090264,
      "loss": 0.679,
      "step": 8530
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.0002379477434679335,
      "loss": 0.7011,
      "step": 8540
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.0002377577197149644,
      "loss": 0.6837,
      "step": 8550
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00023756769596199525,
      "loss": 0.689,
      "step": 8560
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00023737767220902614,
      "loss": 0.686,
      "step": 8570
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00023718764845605703,
      "loss": 0.682,
      "step": 8580
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.0002369976247030879,
      "loss": 0.7048,
      "step": 8590
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00023680760095011878,
      "loss": 0.675,
      "step": 8600
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00023661757719714967,
      "loss": 0.6855,
      "step": 8610
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00023642755344418053,
      "loss": 0.6949,
      "step": 8620
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00023623752969121142,
      "loss": 0.6899,
      "step": 8630
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00023604750593824228,
      "loss": 0.6952,
      "step": 8640
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00023585748218527317,
      "loss": 0.692,
      "step": 8650
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00023566745843230406,
      "loss": 0.6851,
      "step": 8660
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00023547743467933492,
      "loss": 0.6922,
      "step": 8670
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.0002352874109263658,
      "loss": 0.6965,
      "step": 8680
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00023509738717339667,
      "loss": 0.6943,
      "step": 8690
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00023490736342042756,
      "loss": 0.6941,
      "step": 8700
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.00023471733966745845,
      "loss": 0.688,
      "step": 8710
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.0002345273159144893,
      "loss": 0.6803,
      "step": 8720
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.0002343372921615202,
      "loss": 0.698,
      "step": 8730
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.0002341472684085511,
      "loss": 0.689,
      "step": 8740
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.00023395724465558195,
      "loss": 0.6836,
      "step": 8750
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.00023376722090261284,
      "loss": 0.6839,
      "step": 8760
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.0002335771971496437,
      "loss": 0.6868,
      "step": 8770
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.0002333871733966746,
      "loss": 0.7048,
      "step": 8780
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.0002331971496437055,
      "loss": 0.6845,
      "step": 8790
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00023300712589073634,
      "loss": 0.6854,
      "step": 8800
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00023281710213776723,
      "loss": 0.6946,
      "step": 8810
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.0002326270783847981,
      "loss": 0.7005,
      "step": 8820
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00023243705463182898,
      "loss": 0.6846,
      "step": 8830
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.0002322470308788599,
      "loss": 0.6941,
      "step": 8840
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00023205700712589073,
      "loss": 0.6978,
      "step": 8850
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00023186698337292162,
      "loss": 0.6887,
      "step": 8860
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00023167695961995253,
      "loss": 0.6821,
      "step": 8870
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00023148693586698337,
      "loss": 0.6879,
      "step": 8880
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00023129691211401428,
      "loss": 0.6878,
      "step": 8890
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00023110688836104512,
      "loss": 0.6851,
      "step": 8900
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00023091686460807603,
      "loss": 0.6971,
      "step": 8910
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00023072684085510692,
      "loss": 0.6884,
      "step": 8920
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00023053681710213776,
      "loss": 0.6882,
      "step": 8930
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00023034679334916867,
      "loss": 0.6878,
      "step": 8940
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.0002301567695961995,
      "loss": 0.6854,
      "step": 8950
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00022996674584323042,
      "loss": 0.6998,
      "step": 8960
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.0002297767220902613,
      "loss": 0.6976,
      "step": 8970
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00022958669833729215,
      "loss": 0.6871,
      "step": 8980
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00022939667458432306,
      "loss": 0.6869,
      "step": 8990
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.0002292066508313539,
      "loss": 0.6808,
      "step": 9000
    },
    {
      "epoch": 4.28,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.709884762763977,
      "eval_runtime": 0.5003,
      "eval_samples_per_second": 1742.971,
      "eval_steps_per_second": 13.992,
      "step": 9000
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00022901662707838481,
      "loss": 0.6958,
      "step": 9010
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.0002288266033254157,
      "loss": 0.6969,
      "step": 9020
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00022863657957244656,
      "loss": 0.6912,
      "step": 9030
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00022844655581947745,
      "loss": 0.6904,
      "step": 9040
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00022825653206650834,
      "loss": 0.6944,
      "step": 9050
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.0002280665083135392,
      "loss": 0.6866,
      "step": 9060
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.0002278764845605701,
      "loss": 0.702,
      "step": 9070
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00022768646080760095,
      "loss": 0.6859,
      "step": 9080
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00022749643705463184,
      "loss": 0.6989,
      "step": 9090
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00022730641330166273,
      "loss": 0.7002,
      "step": 9100
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.0002271163895486936,
      "loss": 0.7111,
      "step": 9110
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00022692636579572448,
      "loss": 0.6808,
      "step": 9120
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00022673634204275534,
      "loss": 0.6911,
      "step": 9130
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00022654631828978623,
      "loss": 0.6994,
      "step": 9140
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.00022635629453681712,
      "loss": 0.6926,
      "step": 9150
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.00022616627078384798,
      "loss": 0.6927,
      "step": 9160
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.00022597624703087887,
      "loss": 0.6736,
      "step": 9170
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.00022578622327790976,
      "loss": 0.6904,
      "step": 9180
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.00022559619952494062,
      "loss": 0.7015,
      "step": 9190
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.0002254061757719715,
      "loss": 0.6899,
      "step": 9200
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00022521615201900237,
      "loss": 0.689,
      "step": 9210
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00022502612826603326,
      "loss": 0.6926,
      "step": 9220
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00022483610451306415,
      "loss": 0.6897,
      "step": 9230
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.000224646080760095,
      "loss": 0.6845,
      "step": 9240
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.0002244560570071259,
      "loss": 0.7064,
      "step": 9250
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00022426603325415676,
      "loss": 0.6884,
      "step": 9260
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00022407600950118765,
      "loss": 0.6951,
      "step": 9270
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.00022388598574821854,
      "loss": 0.6922,
      "step": 9280
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.0002236959619952494,
      "loss": 0.6811,
      "step": 9290
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.0002235059382422803,
      "loss": 0.6815,
      "step": 9300
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.0002233159144893112,
      "loss": 0.7014,
      "step": 9310
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.00022312589073634204,
      "loss": 0.6799,
      "step": 9320
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.00022293586698337293,
      "loss": 0.6829,
      "step": 9330
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.0002227458432304038,
      "loss": 0.6899,
      "step": 9340
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.00022255581947743468,
      "loss": 0.6872,
      "step": 9350
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.0002223657957244656,
      "loss": 0.684,
      "step": 9360
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.00022217577197149643,
      "loss": 0.6766,
      "step": 9370
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.00022198574821852735,
      "loss": 0.6934,
      "step": 9380
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.00022179572446555818,
      "loss": 0.6984,
      "step": 9390
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.00022160570071258907,
      "loss": 0.6931,
      "step": 9400
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.00022141567695962,
      "loss": 0.6879,
      "step": 9410
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00022122565320665082,
      "loss": 0.6866,
      "step": 9420
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00022103562945368174,
      "loss": 0.6735,
      "step": 9430
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00022084560570071263,
      "loss": 0.6998,
      "step": 9440
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.00022065558194774346,
      "loss": 0.6998,
      "step": 9450
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.00022046555819477438,
      "loss": 0.6965,
      "step": 9460
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.0002202755344418052,
      "loss": 0.6897,
      "step": 9470
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.00022008551068883613,
      "loss": 0.6971,
      "step": 9480
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.00021989548693586702,
      "loss": 0.6853,
      "step": 9490
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.00021970546318289788,
      "loss": 0.6898,
      "step": 9500
    },
    {
      "epoch": 4.51,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7053894400596619,
      "eval_runtime": 0.5002,
      "eval_samples_per_second": 1743.455,
      "eval_steps_per_second": 13.996,
      "step": 9500
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.00021951543942992877,
      "loss": 0.6852,
      "step": 9510
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.0002193254156769596,
      "loss": 0.6829,
      "step": 9520
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.00021913539192399052,
      "loss": 0.6895,
      "step": 9530
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.0002189453681710214,
      "loss": 0.6931,
      "step": 9540
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00021875534441805227,
      "loss": 0.694,
      "step": 9550
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00021856532066508316,
      "loss": 0.6961,
      "step": 9560
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.00021837529691211404,
      "loss": 0.6925,
      "step": 9570
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.0002181852731591449,
      "loss": 0.6837,
      "step": 9580
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.0002179952494061758,
      "loss": 0.6952,
      "step": 9590
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.00021780522565320666,
      "loss": 0.6755,
      "step": 9600
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00021761520190023755,
      "loss": 0.6947,
      "step": 9610
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00021742517814726843,
      "loss": 0.6833,
      "step": 9620
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.0002172351543942993,
      "loss": 0.6936,
      "step": 9630
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.00021704513064133018,
      "loss": 0.6838,
      "step": 9640
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.00021685510688836105,
      "loss": 0.6852,
      "step": 9650
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.00021668408551068886,
      "loss": 0.6875,
      "step": 9660
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.00021649406175771972,
      "loss": 0.6877,
      "step": 9670
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.0002163040380047506,
      "loss": 0.7008,
      "step": 9680
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.0002161140142517815,
      "loss": 0.6841,
      "step": 9690
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.00021592399049881236,
      "loss": 0.6883,
      "step": 9700
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.00021573396674584325,
      "loss": 0.6869,
      "step": 9710
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.00021554394299287411,
      "loss": 0.6878,
      "step": 9720
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.000215353919239905,
      "loss": 0.6771,
      "step": 9730
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.0002151638954869359,
      "loss": 0.7066,
      "step": 9740
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.00021497387173396675,
      "loss": 0.686,
      "step": 9750
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.00021478384798099764,
      "loss": 0.6889,
      "step": 9760
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.0002145938242280285,
      "loss": 0.6892,
      "step": 9770
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.0002144038004750594,
      "loss": 0.6773,
      "step": 9780
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.00021421377672209028,
      "loss": 0.6828,
      "step": 9790
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.00021402375296912114,
      "loss": 0.6768,
      "step": 9800
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.00021383372921615203,
      "loss": 0.6734,
      "step": 9810
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.0002136437054631829,
      "loss": 0.7013,
      "step": 9820
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00021345368171021378,
      "loss": 0.6874,
      "step": 9830
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00021326365795724467,
      "loss": 0.6852,
      "step": 9840
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00021307363420427553,
      "loss": 0.6967,
      "step": 9850
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00021288361045130642,
      "loss": 0.6785,
      "step": 9860
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.0002126935866983373,
      "loss": 0.701,
      "step": 9870
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.00021250356294536817,
      "loss": 0.692,
      "step": 9880
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.00021231353919239906,
      "loss": 0.6909,
      "step": 9890
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.00021212351543942992,
      "loss": 0.6903,
      "step": 9900
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.0002119334916864608,
      "loss": 0.6883,
      "step": 9910
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.0002117434679334917,
      "loss": 0.6814,
      "step": 9920
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.00021155344418052256,
      "loss": 0.6805,
      "step": 9930
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.00021136342042755345,
      "loss": 0.7045,
      "step": 9940
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.0002111733966745843,
      "loss": 0.6898,
      "step": 9950
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.0002109833729216152,
      "loss": 0.6931,
      "step": 9960
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.00021079334916864612,
      "loss": 0.6842,
      "step": 9970
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.00021060332541567695,
      "loss": 0.6919,
      "step": 9980
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00021041330166270784,
      "loss": 0.6906,
      "step": 9990
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00021022327790973876,
      "loss": 0.6923,
      "step": 10000
    },
    {
      "epoch": 4.75,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7090224623680115,
      "eval_runtime": 0.5152,
      "eval_samples_per_second": 1692.568,
      "eval_steps_per_second": 13.587,
      "step": 10000
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.0002100332541567696,
      "loss": 0.6854,
      "step": 10010
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.0002098432304038005,
      "loss": 0.6719,
      "step": 10020
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.00020965320665083134,
      "loss": 0.6876,
      "step": 10030
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.00020946318289786223,
      "loss": 0.6758,
      "step": 10040
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.00020927315914489315,
      "loss": 0.6893,
      "step": 10050
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.00020908313539192398,
      "loss": 0.6774,
      "step": 10060
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.0002088931116389549,
      "loss": 0.6887,
      "step": 10070
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.00020870308788598573,
      "loss": 0.679,
      "step": 10080
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.00020851306413301662,
      "loss": 0.6764,
      "step": 10090
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.00020832304038004754,
      "loss": 0.6838,
      "step": 10100
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.00020813301662707837,
      "loss": 0.6992,
      "step": 10110
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.00020794299287410929,
      "loss": 0.6898,
      "step": 10120
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.00020775296912114018,
      "loss": 0.6829,
      "step": 10130
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00020756294536817104,
      "loss": 0.6944,
      "step": 10140
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00020737292161520193,
      "loss": 0.6843,
      "step": 10150
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.00020718289786223276,
      "loss": 0.682,
      "step": 10160
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.00020699287410926368,
      "loss": 0.6959,
      "step": 10170
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.00020680285035629456,
      "loss": 0.6822,
      "step": 10180
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.00020661282660332543,
      "loss": 0.684,
      "step": 10190
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.00020642280285035632,
      "loss": 0.6829,
      "step": 10200
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.00020623277909738715,
      "loss": 0.6825,
      "step": 10210
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.00020604275534441807,
      "loss": 0.6847,
      "step": 10220
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.00020585273159144895,
      "loss": 0.6803,
      "step": 10230
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.00020566270783847982,
      "loss": 0.6905,
      "step": 10240
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.0002054726840855107,
      "loss": 0.6952,
      "step": 10250
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.0002052826603325416,
      "loss": 0.6894,
      "step": 10260
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00020509263657957246,
      "loss": 0.6779,
      "step": 10270
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00020490261282660334,
      "loss": 0.6947,
      "step": 10280
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.0002047125890736342,
      "loss": 0.7062,
      "step": 10290
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.0002045225653206651,
      "loss": 0.6939,
      "step": 10300
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.00020433254156769598,
      "loss": 0.7017,
      "step": 10310
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.00020414251781472685,
      "loss": 0.6956,
      "step": 10320
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.00020395249406175773,
      "loss": 0.6833,
      "step": 10330
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.0002037624703087886,
      "loss": 0.6913,
      "step": 10340
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.00020357244655581948,
      "loss": 0.679,
      "step": 10350
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.00020338242280285037,
      "loss": 0.6913,
      "step": 10360
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.00020319239904988124,
      "loss": 0.6806,
      "step": 10370
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.00020300237529691212,
      "loss": 0.6923,
      "step": 10380
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.000202812351543943,
      "loss": 0.6687,
      "step": 10390
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.00020262232779097387,
      "loss": 0.6833,
      "step": 10400
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00020243230403800476,
      "loss": 0.6834,
      "step": 10410
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00020224228028503562,
      "loss": 0.6983,
      "step": 10420
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00020205225653206651,
      "loss": 0.6951,
      "step": 10430
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.0002018622327790974,
      "loss": 0.6904,
      "step": 10440
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.00020167220902612826,
      "loss": 0.6869,
      "step": 10450
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.00020148218527315915,
      "loss": 0.6924,
      "step": 10460
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.00020129216152019001,
      "loss": 0.6722,
      "step": 10470
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.0002011021377672209,
      "loss": 0.6787,
      "step": 10480
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.00020091211401425182,
      "loss": 0.6907,
      "step": 10490
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.00020072209026128265,
      "loss": 0.6841,
      "step": 10500
    },
    {
      "epoch": 4.99,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7024597525596619,
      "eval_runtime": 0.5007,
      "eval_samples_per_second": 1741.405,
      "eval_steps_per_second": 13.979,
      "step": 10500
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.00020053206650831354,
      "loss": 0.6914,
      "step": 10510
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.0002003420427553444,
      "loss": 0.6848,
      "step": 10520
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.0002001520190023753,
      "loss": 0.6788,
      "step": 10530
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.00019996199524940618,
      "loss": 0.6879,
      "step": 10540
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.00019977197149643707,
      "loss": 0.6906,
      "step": 10550
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.00019958194774346793,
      "loss": 0.6842,
      "step": 10560
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.00019939192399049882,
      "loss": 0.6931,
      "step": 10570
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.00019920190023752968,
      "loss": 0.6794,
      "step": 10580
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.0001990118764845606,
      "loss": 0.689,
      "step": 10590
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.00019882185273159146,
      "loss": 0.6811,
      "step": 10600
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.00019863182897862235,
      "loss": 0.6925,
      "step": 10610
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.0001984418052256532,
      "loss": 0.6798,
      "step": 10620
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.0001982517814726841,
      "loss": 0.6837,
      "step": 10630
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.000198061757719715,
      "loss": 0.6998,
      "step": 10640
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.00019787173396674585,
      "loss": 0.6809,
      "step": 10650
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.00019768171021377674,
      "loss": 0.6934,
      "step": 10660
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.0001974916864608076,
      "loss": 0.6878,
      "step": 10670
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.0001973016627078385,
      "loss": 0.6888,
      "step": 10680
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.00019711163895486938,
      "loss": 0.6984,
      "step": 10690
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.00019692161520190024,
      "loss": 0.6849,
      "step": 10700
    },
    {
      "epoch": 5.09,
      "learning_rate": 0.00019673159144893113,
      "loss": 0.687,
      "step": 10710
    },
    {
      "epoch": 5.09,
      "learning_rate": 0.00019654156769596202,
      "loss": 0.6987,
      "step": 10720
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.00019635154394299288,
      "loss": 0.6952,
      "step": 10730
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.00019616152019002377,
      "loss": 0.6883,
      "step": 10740
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.00019597149643705463,
      "loss": 0.6941,
      "step": 10750
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.00019578147268408552,
      "loss": 0.6831,
      "step": 10760
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.0001955914489311164,
      "loss": 0.6904,
      "step": 10770
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.00019540142517814727,
      "loss": 0.6814,
      "step": 10780
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.00019521140142517816,
      "loss": 0.6999,
      "step": 10790
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.00019502137767220902,
      "loss": 0.6856,
      "step": 10800
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.00019483135391923994,
      "loss": 0.6797,
      "step": 10810
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.0001946413301662708,
      "loss": 0.6919,
      "step": 10820
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.00019445130641330166,
      "loss": 0.6692,
      "step": 10830
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.00019426128266033255,
      "loss": 0.6966,
      "step": 10840
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.00019407125890736344,
      "loss": 0.6981,
      "step": 10850
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.00019388123515439433,
      "loss": 0.7031,
      "step": 10860
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.0001936912114014252,
      "loss": 0.6938,
      "step": 10870
    },
    {
      "epoch": 5.17,
      "learning_rate": 0.00019350118764845605,
      "loss": 0.6976,
      "step": 10880
    },
    {
      "epoch": 5.17,
      "learning_rate": 0.00019331116389548694,
      "loss": 0.6848,
      "step": 10890
    },
    {
      "epoch": 5.18,
      "learning_rate": 0.00019312114014251783,
      "loss": 0.6744,
      "step": 10900
    },
    {
      "epoch": 5.18,
      "learning_rate": 0.00019293111638954871,
      "loss": 0.6858,
      "step": 10910
    },
    {
      "epoch": 5.19,
      "learning_rate": 0.00019274109263657958,
      "loss": 0.6993,
      "step": 10920
    },
    {
      "epoch": 5.19,
      "learning_rate": 0.00019255106888361047,
      "loss": 0.6893,
      "step": 10930
    },
    {
      "epoch": 5.2,
      "learning_rate": 0.00019236104513064135,
      "loss": 0.6812,
      "step": 10940
    },
    {
      "epoch": 5.2,
      "learning_rate": 0.00019217102137767222,
      "loss": 0.6881,
      "step": 10950
    },
    {
      "epoch": 5.21,
      "learning_rate": 0.0001919809976247031,
      "loss": 0.6814,
      "step": 10960
    },
    {
      "epoch": 5.21,
      "learning_rate": 0.00019179097387173397,
      "loss": 0.6958,
      "step": 10970
    },
    {
      "epoch": 5.22,
      "learning_rate": 0.00019160095011876486,
      "loss": 0.6854,
      "step": 10980
    },
    {
      "epoch": 5.22,
      "learning_rate": 0.00019141092636579574,
      "loss": 0.6791,
      "step": 10990
    },
    {
      "epoch": 5.23,
      "learning_rate": 0.0001912209026128266,
      "loss": 0.6843,
      "step": 11000
    },
    {
      "epoch": 5.23,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7065922617912292,
      "eval_runtime": 0.5043,
      "eval_samples_per_second": 1729.088,
      "eval_steps_per_second": 13.88,
      "step": 11000
    },
    {
      "epoch": 5.23,
      "learning_rate": 0.0001910308788598575,
      "loss": 0.6998,
      "step": 11010
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.00019084085510688836,
      "loss": 0.6949,
      "step": 11020
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.00019065083135391924,
      "loss": 0.6998,
      "step": 11030
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.00019046080760095013,
      "loss": 0.6824,
      "step": 11040
    },
    {
      "epoch": 5.25,
      "learning_rate": 0.000190270783847981,
      "loss": 0.6909,
      "step": 11050
    },
    {
      "epoch": 5.25,
      "learning_rate": 0.00019008076009501188,
      "loss": 0.683,
      "step": 11060
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.00018989073634204277,
      "loss": 0.6854,
      "step": 11070
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.00018970071258907363,
      "loss": 0.6869,
      "step": 11080
    },
    {
      "epoch": 5.27,
      "learning_rate": 0.00018951068883610452,
      "loss": 0.6829,
      "step": 11090
    },
    {
      "epoch": 5.27,
      "learning_rate": 0.00018932066508313539,
      "loss": 0.6915,
      "step": 11100
    },
    {
      "epoch": 5.28,
      "learning_rate": 0.00018913064133016627,
      "loss": 0.6868,
      "step": 11110
    },
    {
      "epoch": 5.28,
      "learning_rate": 0.00018894061757719716,
      "loss": 0.685,
      "step": 11120
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.00018875059382422805,
      "loss": 0.6804,
      "step": 11130
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.0001885605700712589,
      "loss": 0.6999,
      "step": 11140
    },
    {
      "epoch": 5.3,
      "learning_rate": 0.00018837054631828977,
      "loss": 0.6915,
      "step": 11150
    },
    {
      "epoch": 5.3,
      "learning_rate": 0.0001881805225653207,
      "loss": 0.6901,
      "step": 11160
    },
    {
      "epoch": 5.31,
      "learning_rate": 0.00018799049881235155,
      "loss": 0.688,
      "step": 11170
    },
    {
      "epoch": 5.31,
      "learning_rate": 0.00018780047505938244,
      "loss": 0.6932,
      "step": 11180
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.0001876104513064133,
      "loss": 0.6972,
      "step": 11190
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.0001874204275534442,
      "loss": 0.6918,
      "step": 11200
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.00018723040380047508,
      "loss": 0.6864,
      "step": 11210
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.00018704038004750594,
      "loss": 0.6754,
      "step": 11220
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.00018685035629453683,
      "loss": 0.6775,
      "step": 11230
    },
    {
      "epoch": 5.34,
      "learning_rate": 0.0001866603325415677,
      "loss": 0.7002,
      "step": 11240
    },
    {
      "epoch": 5.34,
      "learning_rate": 0.00018647030878859858,
      "loss": 0.7,
      "step": 11250
    },
    {
      "epoch": 5.35,
      "learning_rate": 0.00018628028503562947,
      "loss": 0.6827,
      "step": 11260
    },
    {
      "epoch": 5.35,
      "learning_rate": 0.00018609026128266033,
      "loss": 0.6812,
      "step": 11270
    },
    {
      "epoch": 5.36,
      "learning_rate": 0.00018590023752969122,
      "loss": 0.6874,
      "step": 11280
    },
    {
      "epoch": 5.36,
      "learning_rate": 0.0001857102137767221,
      "loss": 0.6982,
      "step": 11290
    },
    {
      "epoch": 5.37,
      "learning_rate": 0.00018552019002375297,
      "loss": 0.6879,
      "step": 11300
    },
    {
      "epoch": 5.37,
      "learning_rate": 0.00018533016627078386,
      "loss": 0.694,
      "step": 11310
    },
    {
      "epoch": 5.38,
      "learning_rate": 0.00018514014251781472,
      "loss": 0.6934,
      "step": 11320
    },
    {
      "epoch": 5.38,
      "learning_rate": 0.0001849501187648456,
      "loss": 0.6772,
      "step": 11330
    },
    {
      "epoch": 5.39,
      "learning_rate": 0.0001847600950118765,
      "loss": 0.6872,
      "step": 11340
    },
    {
      "epoch": 5.39,
      "learning_rate": 0.00018457007125890736,
      "loss": 0.6823,
      "step": 11350
    },
    {
      "epoch": 5.4,
      "learning_rate": 0.00018438004750593825,
      "loss": 0.6994,
      "step": 11360
    },
    {
      "epoch": 5.4,
      "learning_rate": 0.0001841900237529691,
      "loss": 0.6945,
      "step": 11370
    },
    {
      "epoch": 5.41,
      "learning_rate": 0.00018400000000000003,
      "loss": 0.687,
      "step": 11380
    },
    {
      "epoch": 5.41,
      "learning_rate": 0.0001838099762470309,
      "loss": 0.6842,
      "step": 11390
    },
    {
      "epoch": 5.42,
      "learning_rate": 0.00018361995249406178,
      "loss": 0.7038,
      "step": 11400
    },
    {
      "epoch": 5.42,
      "learning_rate": 0.00018342992874109264,
      "loss": 0.6883,
      "step": 11410
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.00018323990498812353,
      "loss": 0.6846,
      "step": 11420
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.00018304988123515442,
      "loss": 0.6887,
      "step": 11430
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.00018285985748218528,
      "loss": 0.696,
      "step": 11440
    },
    {
      "epoch": 5.44,
      "learning_rate": 0.00018266983372921617,
      "loss": 0.6886,
      "step": 11450
    },
    {
      "epoch": 5.44,
      "learning_rate": 0.00018247980997624703,
      "loss": 0.6904,
      "step": 11460
    },
    {
      "epoch": 5.45,
      "learning_rate": 0.00018228978622327792,
      "loss": 0.6931,
      "step": 11470
    },
    {
      "epoch": 5.45,
      "learning_rate": 0.0001820997624703088,
      "loss": 0.6918,
      "step": 11480
    },
    {
      "epoch": 5.46,
      "learning_rate": 0.00018190973871733967,
      "loss": 0.6942,
      "step": 11490
    },
    {
      "epoch": 5.46,
      "learning_rate": 0.00018171971496437056,
      "loss": 0.6824,
      "step": 11500
    },
    {
      "epoch": 5.46,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6967818140983582,
      "eval_runtime": 0.5002,
      "eval_samples_per_second": 1743.324,
      "eval_steps_per_second": 13.995,
      "step": 11500
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.00018152969121140145,
      "loss": 0.6751,
      "step": 11510
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.0001813396674584323,
      "loss": 0.6824,
      "step": 11520
    },
    {
      "epoch": 5.48,
      "learning_rate": 0.0001811496437054632,
      "loss": 0.6787,
      "step": 11530
    },
    {
      "epoch": 5.48,
      "learning_rate": 0.00018095961995249406,
      "loss": 0.6795,
      "step": 11540
    },
    {
      "epoch": 5.49,
      "learning_rate": 0.00018076959619952495,
      "loss": 0.6792,
      "step": 11550
    },
    {
      "epoch": 5.49,
      "learning_rate": 0.00018057957244655584,
      "loss": 0.6834,
      "step": 11560
    },
    {
      "epoch": 5.5,
      "learning_rate": 0.0001803895486935867,
      "loss": 0.686,
      "step": 11570
    },
    {
      "epoch": 5.5,
      "learning_rate": 0.00018019952494061759,
      "loss": 0.7021,
      "step": 11580
    },
    {
      "epoch": 5.51,
      "learning_rate": 0.00018000950118764845,
      "loss": 0.6902,
      "step": 11590
    },
    {
      "epoch": 5.51,
      "learning_rate": 0.00017981947743467936,
      "loss": 0.6879,
      "step": 11600
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.00017962945368171023,
      "loss": 0.6892,
      "step": 11610
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.0001794394299287411,
      "loss": 0.6876,
      "step": 11620
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.00017924940617577198,
      "loss": 0.6902,
      "step": 11630
    },
    {
      "epoch": 5.53,
      "learning_rate": 0.00017905938242280286,
      "loss": 0.6976,
      "step": 11640
    },
    {
      "epoch": 5.53,
      "learning_rate": 0.00017886935866983375,
      "loss": 0.6887,
      "step": 11650
    },
    {
      "epoch": 5.54,
      "learning_rate": 0.00017867933491686462,
      "loss": 0.6881,
      "step": 11660
    },
    {
      "epoch": 5.54,
      "learning_rate": 0.0001785083135391924,
      "loss": 0.6965,
      "step": 11670
    },
    {
      "epoch": 5.55,
      "learning_rate": 0.0001783182897862233,
      "loss": 0.688,
      "step": 11680
    },
    {
      "epoch": 5.55,
      "learning_rate": 0.00017812826603325415,
      "loss": 0.6805,
      "step": 11690
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.00017793824228028504,
      "loss": 0.6953,
      "step": 11700
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.0001777482185273159,
      "loss": 0.6868,
      "step": 11710
    },
    {
      "epoch": 5.57,
      "learning_rate": 0.00017755819477434682,
      "loss": 0.6811,
      "step": 11720
    },
    {
      "epoch": 5.57,
      "learning_rate": 0.00017736817102137768,
      "loss": 0.6961,
      "step": 11730
    },
    {
      "epoch": 5.58,
      "learning_rate": 0.00017717814726840854,
      "loss": 0.698,
      "step": 11740
    },
    {
      "epoch": 5.58,
      "learning_rate": 0.00017698812351543943,
      "loss": 0.6904,
      "step": 11750
    },
    {
      "epoch": 5.59,
      "learning_rate": 0.00017679809976247032,
      "loss": 0.6852,
      "step": 11760
    },
    {
      "epoch": 5.59,
      "learning_rate": 0.0001766080760095012,
      "loss": 0.701,
      "step": 11770
    },
    {
      "epoch": 5.6,
      "learning_rate": 0.00017641805225653207,
      "loss": 0.6858,
      "step": 11780
    },
    {
      "epoch": 5.6,
      "learning_rate": 0.00017622802850356293,
      "loss": 0.6833,
      "step": 11790
    },
    {
      "epoch": 5.61,
      "learning_rate": 0.00017603800475059385,
      "loss": 0.6839,
      "step": 11800
    },
    {
      "epoch": 5.61,
      "learning_rate": 0.0001758479809976247,
      "loss": 0.6942,
      "step": 11810
    },
    {
      "epoch": 5.62,
      "learning_rate": 0.0001756579572446556,
      "loss": 0.6745,
      "step": 11820
    },
    {
      "epoch": 5.62,
      "learning_rate": 0.00017546793349168646,
      "loss": 0.6757,
      "step": 11830
    },
    {
      "epoch": 5.62,
      "learning_rate": 0.00017527790973871735,
      "loss": 0.6906,
      "step": 11840
    },
    {
      "epoch": 5.63,
      "learning_rate": 0.00017508788598574824,
      "loss": 0.6942,
      "step": 11850
    },
    {
      "epoch": 5.63,
      "learning_rate": 0.0001748978622327791,
      "loss": 0.698,
      "step": 11860
    },
    {
      "epoch": 5.64,
      "learning_rate": 0.00017470783847981,
      "loss": 0.6914,
      "step": 11870
    },
    {
      "epoch": 5.64,
      "learning_rate": 0.00017451781472684085,
      "loss": 0.6849,
      "step": 11880
    },
    {
      "epoch": 5.65,
      "learning_rate": 0.00017432779097387174,
      "loss": 0.6839,
      "step": 11890
    },
    {
      "epoch": 5.65,
      "learning_rate": 0.00017413776722090263,
      "loss": 0.6827,
      "step": 11900
    },
    {
      "epoch": 5.66,
      "learning_rate": 0.0001739477434679335,
      "loss": 0.6829,
      "step": 11910
    },
    {
      "epoch": 5.66,
      "learning_rate": 0.00017375771971496438,
      "loss": 0.6699,
      "step": 11920
    },
    {
      "epoch": 5.67,
      "learning_rate": 0.00017356769596199524,
      "loss": 0.6743,
      "step": 11930
    },
    {
      "epoch": 5.67,
      "learning_rate": 0.00017337767220902613,
      "loss": 0.6935,
      "step": 11940
    },
    {
      "epoch": 5.68,
      "learning_rate": 0.00017318764845605702,
      "loss": 0.6881,
      "step": 11950
    },
    {
      "epoch": 5.68,
      "learning_rate": 0.00017299762470308788,
      "loss": 0.6815,
      "step": 11960
    },
    {
      "epoch": 5.69,
      "learning_rate": 0.00017280760095011877,
      "loss": 0.6625,
      "step": 11970
    },
    {
      "epoch": 5.69,
      "learning_rate": 0.00017261757719714966,
      "loss": 0.6685,
      "step": 11980
    },
    {
      "epoch": 5.7,
      "learning_rate": 0.00017242755344418055,
      "loss": 0.7086,
      "step": 11990
    },
    {
      "epoch": 5.7,
      "learning_rate": 0.0001722375296912114,
      "loss": 0.6888,
      "step": 12000
    },
    {
      "epoch": 5.7,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6935027241706848,
      "eval_runtime": 0.5034,
      "eval_samples_per_second": 1732.3,
      "eval_steps_per_second": 13.906,
      "step": 12000
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.00017204750593824227,
      "loss": 0.701,
      "step": 12010
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.0001718574821852732,
      "loss": 0.6907,
      "step": 12020
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.00017166745843230405,
      "loss": 0.6851,
      "step": 12030
    },
    {
      "epoch": 5.72,
      "learning_rate": 0.00017147743467933494,
      "loss": 0.6989,
      "step": 12040
    },
    {
      "epoch": 5.72,
      "learning_rate": 0.0001712874109263658,
      "loss": 0.6952,
      "step": 12050
    },
    {
      "epoch": 5.73,
      "learning_rate": 0.00017109738717339666,
      "loss": 0.6816,
      "step": 12060
    },
    {
      "epoch": 5.73,
      "learning_rate": 0.00017090736342042758,
      "loss": 0.6868,
      "step": 12070
    },
    {
      "epoch": 5.74,
      "learning_rate": 0.00017071733966745844,
      "loss": 0.6939,
      "step": 12080
    },
    {
      "epoch": 5.74,
      "learning_rate": 0.00017052731591448933,
      "loss": 0.6912,
      "step": 12090
    },
    {
      "epoch": 5.75,
      "learning_rate": 0.0001703372921615202,
      "loss": 0.6844,
      "step": 12100
    },
    {
      "epoch": 5.75,
      "learning_rate": 0.00017014726840855108,
      "loss": 0.6747,
      "step": 12110
    },
    {
      "epoch": 5.76,
      "learning_rate": 0.00016995724465558197,
      "loss": 0.6891,
      "step": 12120
    },
    {
      "epoch": 5.76,
      "learning_rate": 0.00016976722090261283,
      "loss": 0.691,
      "step": 12130
    },
    {
      "epoch": 5.77,
      "learning_rate": 0.00016957719714964372,
      "loss": 0.6729,
      "step": 12140
    },
    {
      "epoch": 5.77,
      "learning_rate": 0.0001693871733966746,
      "loss": 0.7076,
      "step": 12150
    },
    {
      "epoch": 5.78,
      "learning_rate": 0.00016919714964370547,
      "loss": 0.6881,
      "step": 12160
    },
    {
      "epoch": 5.78,
      "learning_rate": 0.00016900712589073636,
      "loss": 0.6829,
      "step": 12170
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.00016881710213776722,
      "loss": 0.6721,
      "step": 12180
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.0001686270783847981,
      "loss": 0.6879,
      "step": 12190
    },
    {
      "epoch": 5.8,
      "learning_rate": 0.000168437054631829,
      "loss": 0.6705,
      "step": 12200
    },
    {
      "epoch": 5.8,
      "learning_rate": 0.00016824703087885986,
      "loss": 0.6908,
      "step": 12210
    },
    {
      "epoch": 5.81,
      "learning_rate": 0.00016805700712589075,
      "loss": 0.6863,
      "step": 12220
    },
    {
      "epoch": 5.81,
      "learning_rate": 0.0001678669833729216,
      "loss": 0.6964,
      "step": 12230
    },
    {
      "epoch": 5.81,
      "learning_rate": 0.00016767695961995252,
      "loss": 0.6894,
      "step": 12240
    },
    {
      "epoch": 5.82,
      "learning_rate": 0.00016748693586698339,
      "loss": 0.6865,
      "step": 12250
    },
    {
      "epoch": 5.82,
      "learning_rate": 0.00016729691211401425,
      "loss": 0.6885,
      "step": 12260
    },
    {
      "epoch": 5.83,
      "learning_rate": 0.00016710688836104514,
      "loss": 0.6948,
      "step": 12270
    },
    {
      "epoch": 5.83,
      "learning_rate": 0.000166916864608076,
      "loss": 0.6821,
      "step": 12280
    },
    {
      "epoch": 5.84,
      "learning_rate": 0.0001667268408551069,
      "loss": 0.679,
      "step": 12290
    },
    {
      "epoch": 5.84,
      "learning_rate": 0.00016653681710213777,
      "loss": 0.6715,
      "step": 12300
    },
    {
      "epoch": 5.85,
      "learning_rate": 0.00016634679334916866,
      "loss": 0.6789,
      "step": 12310
    },
    {
      "epoch": 5.85,
      "learning_rate": 0.00016615676959619953,
      "loss": 0.679,
      "step": 12320
    },
    {
      "epoch": 5.86,
      "learning_rate": 0.00016596674584323041,
      "loss": 0.6987,
      "step": 12330
    },
    {
      "epoch": 5.86,
      "learning_rate": 0.0001657767220902613,
      "loss": 0.7005,
      "step": 12340
    },
    {
      "epoch": 5.87,
      "learning_rate": 0.00016558669833729216,
      "loss": 0.6916,
      "step": 12350
    },
    {
      "epoch": 5.87,
      "learning_rate": 0.00016539667458432305,
      "loss": 0.6916,
      "step": 12360
    },
    {
      "epoch": 5.88,
      "learning_rate": 0.00016520665083135394,
      "loss": 0.6969,
      "step": 12370
    },
    {
      "epoch": 5.88,
      "learning_rate": 0.0001650166270783848,
      "loss": 0.7027,
      "step": 12380
    },
    {
      "epoch": 5.89,
      "learning_rate": 0.0001648266033254157,
      "loss": 0.6804,
      "step": 12390
    },
    {
      "epoch": 5.89,
      "learning_rate": 0.00016463657957244655,
      "loss": 0.6778,
      "step": 12400
    },
    {
      "epoch": 5.9,
      "learning_rate": 0.00016444655581947744,
      "loss": 0.6888,
      "step": 12410
    },
    {
      "epoch": 5.9,
      "learning_rate": 0.00016425653206650833,
      "loss": 0.6657,
      "step": 12420
    },
    {
      "epoch": 5.9,
      "learning_rate": 0.0001640665083135392,
      "loss": 0.6981,
      "step": 12430
    },
    {
      "epoch": 5.91,
      "learning_rate": 0.00016387648456057008,
      "loss": 0.6919,
      "step": 12440
    },
    {
      "epoch": 5.91,
      "learning_rate": 0.00016368646080760094,
      "loss": 0.6884,
      "step": 12450
    },
    {
      "epoch": 5.92,
      "learning_rate": 0.00016349643705463183,
      "loss": 0.6919,
      "step": 12460
    },
    {
      "epoch": 5.92,
      "learning_rate": 0.00016330641330166272,
      "loss": 0.6842,
      "step": 12470
    },
    {
      "epoch": 5.93,
      "learning_rate": 0.00016311638954869358,
      "loss": 0.6782,
      "step": 12480
    },
    {
      "epoch": 5.93,
      "learning_rate": 0.00016292636579572447,
      "loss": 0.688,
      "step": 12490
    },
    {
      "epoch": 5.94,
      "learning_rate": 0.00016273634204275536,
      "loss": 0.6931,
      "step": 12500
    },
    {
      "epoch": 5.94,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7007306218147278,
      "eval_runtime": 0.5345,
      "eval_samples_per_second": 1631.413,
      "eval_steps_per_second": 13.096,
      "step": 12500
    },
    {
      "epoch": 5.94,
      "learning_rate": 0.00016254631828978625,
      "loss": 0.6902,
      "step": 12510
    },
    {
      "epoch": 5.95,
      "learning_rate": 0.0001623562945368171,
      "loss": 0.6957,
      "step": 12520
    },
    {
      "epoch": 5.95,
      "learning_rate": 0.00016216627078384797,
      "loss": 0.6937,
      "step": 12530
    },
    {
      "epoch": 5.96,
      "learning_rate": 0.00016197624703087886,
      "loss": 0.685,
      "step": 12540
    },
    {
      "epoch": 5.96,
      "learning_rate": 0.00016178622327790975,
      "loss": 0.7045,
      "step": 12550
    },
    {
      "epoch": 5.97,
      "learning_rate": 0.00016159619952494064,
      "loss": 0.6916,
      "step": 12560
    },
    {
      "epoch": 5.97,
      "learning_rate": 0.0001614061757719715,
      "loss": 0.6879,
      "step": 12570
    },
    {
      "epoch": 5.98,
      "learning_rate": 0.00016121615201900236,
      "loss": 0.6789,
      "step": 12580
    },
    {
      "epoch": 5.98,
      "learning_rate": 0.00016102612826603328,
      "loss": 0.6789,
      "step": 12590
    },
    {
      "epoch": 5.99,
      "learning_rate": 0.00016083610451306414,
      "loss": 0.6856,
      "step": 12600
    },
    {
      "epoch": 5.99,
      "learning_rate": 0.00016064608076009503,
      "loss": 0.6916,
      "step": 12610
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.0001604560570071259,
      "loss": 0.6925,
      "step": 12620
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.00016026603325415678,
      "loss": 0.6907,
      "step": 12630
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.00016007600950118767,
      "loss": 0.6984,
      "step": 12640
    },
    {
      "epoch": 6.01,
      "learning_rate": 0.00015988598574821853,
      "loss": 0.6966,
      "step": 12650
    },
    {
      "epoch": 6.01,
      "learning_rate": 0.00015969596199524942,
      "loss": 0.6998,
      "step": 12660
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.00015950593824228028,
      "loss": 0.6862,
      "step": 12670
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.00015931591448931117,
      "loss": 0.6863,
      "step": 12680
    },
    {
      "epoch": 6.03,
      "learning_rate": 0.00015912589073634206,
      "loss": 0.6753,
      "step": 12690
    },
    {
      "epoch": 6.03,
      "learning_rate": 0.00015893586698337292,
      "loss": 0.6883,
      "step": 12700
    },
    {
      "epoch": 6.04,
      "learning_rate": 0.0001587458432304038,
      "loss": 0.6844,
      "step": 12710
    },
    {
      "epoch": 6.04,
      "learning_rate": 0.0001585558194774347,
      "loss": 0.6897,
      "step": 12720
    },
    {
      "epoch": 6.05,
      "learning_rate": 0.00015836579572446556,
      "loss": 0.6908,
      "step": 12730
    },
    {
      "epoch": 6.05,
      "learning_rate": 0.00015817577197149645,
      "loss": 0.6981,
      "step": 12740
    },
    {
      "epoch": 6.06,
      "learning_rate": 0.0001579857482185273,
      "loss": 0.6943,
      "step": 12750
    },
    {
      "epoch": 6.06,
      "learning_rate": 0.0001577957244655582,
      "loss": 0.6895,
      "step": 12760
    },
    {
      "epoch": 6.07,
      "learning_rate": 0.0001576057007125891,
      "loss": 0.6866,
      "step": 12770
    },
    {
      "epoch": 6.07,
      "learning_rate": 0.00015741567695961995,
      "loss": 0.6881,
      "step": 12780
    },
    {
      "epoch": 6.08,
      "learning_rate": 0.00015722565320665084,
      "loss": 0.6853,
      "step": 12790
    },
    {
      "epoch": 6.08,
      "learning_rate": 0.0001570356294536817,
      "loss": 0.6823,
      "step": 12800
    },
    {
      "epoch": 6.09,
      "learning_rate": 0.00015684560570071262,
      "loss": 0.6943,
      "step": 12810
    },
    {
      "epoch": 6.09,
      "learning_rate": 0.00015665558194774348,
      "loss": 0.6937,
      "step": 12820
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.00015646555819477437,
      "loss": 0.6936,
      "step": 12830
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.00015627553444180523,
      "loss": 0.6978,
      "step": 12840
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.00015608551068883612,
      "loss": 0.6891,
      "step": 12850
    },
    {
      "epoch": 6.11,
      "learning_rate": 0.000155895486935867,
      "loss": 0.678,
      "step": 12860
    },
    {
      "epoch": 6.11,
      "learning_rate": 0.00015570546318289787,
      "loss": 0.693,
      "step": 12870
    },
    {
      "epoch": 6.12,
      "learning_rate": 0.00015551543942992876,
      "loss": 0.6924,
      "step": 12880
    },
    {
      "epoch": 6.12,
      "learning_rate": 0.00015532541567695962,
      "loss": 0.6892,
      "step": 12890
    },
    {
      "epoch": 6.13,
      "learning_rate": 0.0001551353919239905,
      "loss": 0.6816,
      "step": 12900
    },
    {
      "epoch": 6.13,
      "learning_rate": 0.0001549453681710214,
      "loss": 0.6918,
      "step": 12910
    },
    {
      "epoch": 6.14,
      "learning_rate": 0.00015475534441805226,
      "loss": 0.6958,
      "step": 12920
    },
    {
      "epoch": 6.14,
      "learning_rate": 0.00015456532066508315,
      "loss": 0.6831,
      "step": 12930
    },
    {
      "epoch": 6.15,
      "learning_rate": 0.00015437529691211403,
      "loss": 0.6784,
      "step": 12940
    },
    {
      "epoch": 6.15,
      "learning_rate": 0.0001541852731591449,
      "loss": 0.6777,
      "step": 12950
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.00015399524940617578,
      "loss": 0.6749,
      "step": 12960
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.00015380522565320665,
      "loss": 0.7026,
      "step": 12970
    },
    {
      "epoch": 6.17,
      "learning_rate": 0.00015361520190023753,
      "loss": 0.6869,
      "step": 12980
    },
    {
      "epoch": 6.17,
      "learning_rate": 0.00015342517814726842,
      "loss": 0.6873,
      "step": 12990
    },
    {
      "epoch": 6.18,
      "learning_rate": 0.00015323515439429929,
      "loss": 0.6889,
      "step": 13000
    },
    {
      "epoch": 6.18,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7005178332328796,
      "eval_runtime": 0.5008,
      "eval_samples_per_second": 1741.179,
      "eval_steps_per_second": 13.977,
      "step": 13000
    },
    {
      "epoch": 6.18,
      "learning_rate": 0.00015304513064133017,
      "loss": 0.6835,
      "step": 13010
    },
    {
      "epoch": 6.19,
      "learning_rate": 0.00015285510688836104,
      "loss": 0.6797,
      "step": 13020
    },
    {
      "epoch": 6.19,
      "learning_rate": 0.00015266508313539195,
      "loss": 0.6851,
      "step": 13030
    },
    {
      "epoch": 6.19,
      "learning_rate": 0.0001524750593824228,
      "loss": 0.6951,
      "step": 13040
    },
    {
      "epoch": 6.2,
      "learning_rate": 0.00015228503562945368,
      "loss": 0.6882,
      "step": 13050
    },
    {
      "epoch": 6.2,
      "learning_rate": 0.00015209501187648456,
      "loss": 0.6928,
      "step": 13060
    },
    {
      "epoch": 6.21,
      "learning_rate": 0.00015190498812351545,
      "loss": 0.6935,
      "step": 13070
    },
    {
      "epoch": 6.21,
      "learning_rate": 0.00015171496437054634,
      "loss": 0.6929,
      "step": 13080
    },
    {
      "epoch": 6.22,
      "learning_rate": 0.0001515249406175772,
      "loss": 0.6925,
      "step": 13090
    },
    {
      "epoch": 6.22,
      "learning_rate": 0.00015133491686460806,
      "loss": 0.6918,
      "step": 13100
    },
    {
      "epoch": 6.23,
      "learning_rate": 0.00015114489311163895,
      "loss": 0.6926,
      "step": 13110
    },
    {
      "epoch": 6.23,
      "learning_rate": 0.00015095486935866984,
      "loss": 0.6843,
      "step": 13120
    },
    {
      "epoch": 6.24,
      "learning_rate": 0.00015076484560570073,
      "loss": 0.6885,
      "step": 13130
    },
    {
      "epoch": 6.24,
      "learning_rate": 0.0001505748218527316,
      "loss": 0.6684,
      "step": 13140
    },
    {
      "epoch": 6.25,
      "learning_rate": 0.00015038479809976248,
      "loss": 0.675,
      "step": 13150
    },
    {
      "epoch": 6.25,
      "learning_rate": 0.00015019477434679337,
      "loss": 0.6947,
      "step": 13160
    },
    {
      "epoch": 6.26,
      "learning_rate": 0.00015000475059382423,
      "loss": 0.6862,
      "step": 13170
    },
    {
      "epoch": 6.26,
      "learning_rate": 0.00014981472684085512,
      "loss": 0.6806,
      "step": 13180
    },
    {
      "epoch": 6.27,
      "learning_rate": 0.00014962470308788598,
      "loss": 0.6933,
      "step": 13190
    },
    {
      "epoch": 6.27,
      "learning_rate": 0.00014943467933491687,
      "loss": 0.6863,
      "step": 13200
    },
    {
      "epoch": 6.28,
      "learning_rate": 0.00014924465558194776,
      "loss": 0.6886,
      "step": 13210
    },
    {
      "epoch": 6.28,
      "learning_rate": 0.00014905463182897862,
      "loss": 0.6801,
      "step": 13220
    },
    {
      "epoch": 6.29,
      "learning_rate": 0.0001488646080760095,
      "loss": 0.6895,
      "step": 13230
    },
    {
      "epoch": 6.29,
      "learning_rate": 0.00014867458432304037,
      "loss": 0.699,
      "step": 13240
    },
    {
      "epoch": 6.29,
      "learning_rate": 0.00014848456057007126,
      "loss": 0.6886,
      "step": 13250
    },
    {
      "epoch": 6.3,
      "learning_rate": 0.00014829453681710215,
      "loss": 0.684,
      "step": 13260
    },
    {
      "epoch": 6.3,
      "learning_rate": 0.000148104513064133,
      "loss": 0.6818,
      "step": 13270
    },
    {
      "epoch": 6.31,
      "learning_rate": 0.0001479144893111639,
      "loss": 0.6813,
      "step": 13280
    },
    {
      "epoch": 6.31,
      "learning_rate": 0.0001477244655581948,
      "loss": 0.688,
      "step": 13290
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.00014753444180522568,
      "loss": 0.691,
      "step": 13300
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.00014734441805225654,
      "loss": 0.6911,
      "step": 13310
    },
    {
      "epoch": 6.33,
      "learning_rate": 0.0001471543942992874,
      "loss": 0.6937,
      "step": 13320
    },
    {
      "epoch": 6.33,
      "learning_rate": 0.0001469643705463183,
      "loss": 0.6951,
      "step": 13330
    },
    {
      "epoch": 6.34,
      "learning_rate": 0.00014677434679334918,
      "loss": 0.6845,
      "step": 13340
    },
    {
      "epoch": 6.34,
      "learning_rate": 0.00014658432304038007,
      "loss": 0.694,
      "step": 13350
    },
    {
      "epoch": 6.35,
      "learning_rate": 0.00014639429928741093,
      "loss": 0.6956,
      "step": 13360
    },
    {
      "epoch": 6.35,
      "learning_rate": 0.0001462042755344418,
      "loss": 0.6947,
      "step": 13370
    },
    {
      "epoch": 6.36,
      "learning_rate": 0.0001460142517814727,
      "loss": 0.6911,
      "step": 13380
    },
    {
      "epoch": 6.36,
      "learning_rate": 0.00014582422802850357,
      "loss": 0.6728,
      "step": 13390
    },
    {
      "epoch": 6.37,
      "learning_rate": 0.00014563420427553446,
      "loss": 0.6937,
      "step": 13400
    },
    {
      "epoch": 6.37,
      "learning_rate": 0.00014544418052256532,
      "loss": 0.7028,
      "step": 13410
    },
    {
      "epoch": 6.38,
      "learning_rate": 0.0001452541567695962,
      "loss": 0.6965,
      "step": 13420
    },
    {
      "epoch": 6.38,
      "learning_rate": 0.0001450641330166271,
      "loss": 0.6858,
      "step": 13430
    },
    {
      "epoch": 6.38,
      "learning_rate": 0.00014487410926365796,
      "loss": 0.6877,
      "step": 13440
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.00014468408551068885,
      "loss": 0.6915,
      "step": 13450
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.0001444940617577197,
      "loss": 0.6819,
      "step": 13460
    },
    {
      "epoch": 6.4,
      "learning_rate": 0.0001443040380047506,
      "loss": 0.6723,
      "step": 13470
    },
    {
      "epoch": 6.4,
      "learning_rate": 0.0001441140142517815,
      "loss": 0.6634,
      "step": 13480
    },
    {
      "epoch": 6.41,
      "learning_rate": 0.00014394299287410925,
      "loss": 0.6865,
      "step": 13490
    },
    {
      "epoch": 6.41,
      "learning_rate": 0.00014375296912114016,
      "loss": 0.7131,
      "step": 13500
    },
    {
      "epoch": 6.41,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7166675329208374,
      "eval_runtime": 0.4997,
      "eval_samples_per_second": 1744.973,
      "eval_steps_per_second": 14.008,
      "step": 13500
    },
    {
      "epoch": 6.42,
      "learning_rate": 0.00014356294536817103,
      "loss": 0.6822,
      "step": 13510
    },
    {
      "epoch": 6.42,
      "learning_rate": 0.00014337292161520191,
      "loss": 0.6924,
      "step": 13520
    },
    {
      "epoch": 6.43,
      "learning_rate": 0.00014318289786223278,
      "loss": 0.6901,
      "step": 13530
    },
    {
      "epoch": 6.43,
      "learning_rate": 0.00014299287410926367,
      "loss": 0.6903,
      "step": 13540
    },
    {
      "epoch": 6.44,
      "learning_rate": 0.00014280285035629455,
      "loss": 0.6921,
      "step": 13550
    },
    {
      "epoch": 6.44,
      "learning_rate": 0.00014261282660332542,
      "loss": 0.6817,
      "step": 13560
    },
    {
      "epoch": 6.45,
      "learning_rate": 0.0001424228028503563,
      "loss": 0.6749,
      "step": 13570
    },
    {
      "epoch": 6.45,
      "learning_rate": 0.00014223277909738717,
      "loss": 0.6876,
      "step": 13580
    },
    {
      "epoch": 6.46,
      "learning_rate": 0.00014204275534441806,
      "loss": 0.6828,
      "step": 13590
    },
    {
      "epoch": 6.46,
      "learning_rate": 0.00014185273159144894,
      "loss": 0.6758,
      "step": 13600
    },
    {
      "epoch": 6.47,
      "learning_rate": 0.0001416627078384798,
      "loss": 0.6815,
      "step": 13610
    },
    {
      "epoch": 6.47,
      "learning_rate": 0.0001414726840855107,
      "loss": 0.6886,
      "step": 13620
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.00014128266033254158,
      "loss": 0.6797,
      "step": 13630
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.00014109263657957244,
      "loss": 0.6749,
      "step": 13640
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.00014090261282660333,
      "loss": 0.6909,
      "step": 13650
    },
    {
      "epoch": 6.49,
      "learning_rate": 0.0001407125890736342,
      "loss": 0.6883,
      "step": 13660
    },
    {
      "epoch": 6.49,
      "learning_rate": 0.0001405225653206651,
      "loss": 0.6926,
      "step": 13670
    },
    {
      "epoch": 6.5,
      "learning_rate": 0.00014033254156769597,
      "loss": 0.6834,
      "step": 13680
    },
    {
      "epoch": 6.5,
      "learning_rate": 0.00014014251781472683,
      "loss": 0.6883,
      "step": 13690
    },
    {
      "epoch": 6.51,
      "learning_rate": 0.00013995249406175772,
      "loss": 0.6763,
      "step": 13700
    },
    {
      "epoch": 6.51,
      "learning_rate": 0.00013976247030878859,
      "loss": 0.6801,
      "step": 13710
    },
    {
      "epoch": 6.52,
      "learning_rate": 0.0001395724465558195,
      "loss": 0.6793,
      "step": 13720
    },
    {
      "epoch": 6.52,
      "learning_rate": 0.00013938242280285036,
      "loss": 0.6882,
      "step": 13730
    },
    {
      "epoch": 6.53,
      "learning_rate": 0.00013919239904988125,
      "loss": 0.6888,
      "step": 13740
    },
    {
      "epoch": 6.53,
      "learning_rate": 0.0001390023752969121,
      "loss": 0.6845,
      "step": 13750
    },
    {
      "epoch": 6.54,
      "learning_rate": 0.000138812351543943,
      "loss": 0.6992,
      "step": 13760
    },
    {
      "epoch": 6.54,
      "learning_rate": 0.0001386223277909739,
      "loss": 0.6865,
      "step": 13770
    },
    {
      "epoch": 6.55,
      "learning_rate": 0.00013843230403800475,
      "loss": 0.6987,
      "step": 13780
    },
    {
      "epoch": 6.55,
      "learning_rate": 0.00013824228028503564,
      "loss": 0.6934,
      "step": 13790
    },
    {
      "epoch": 6.56,
      "learning_rate": 0.0001380522565320665,
      "loss": 0.6863,
      "step": 13800
    },
    {
      "epoch": 6.56,
      "learning_rate": 0.0001378622327790974,
      "loss": 0.6908,
      "step": 13810
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.00013767220902612828,
      "loss": 0.6862,
      "step": 13820
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.00013748218527315914,
      "loss": 0.6728,
      "step": 13830
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.00013729216152019003,
      "loss": 0.682,
      "step": 13840
    },
    {
      "epoch": 6.58,
      "learning_rate": 0.00013710213776722092,
      "loss": 0.6973,
      "step": 13850
    },
    {
      "epoch": 6.58,
      "learning_rate": 0.00013691211401425178,
      "loss": 0.6957,
      "step": 13860
    },
    {
      "epoch": 6.59,
      "learning_rate": 0.00013672209026128267,
      "loss": 0.6899,
      "step": 13870
    },
    {
      "epoch": 6.59,
      "learning_rate": 0.00013653206650831353,
      "loss": 0.6913,
      "step": 13880
    },
    {
      "epoch": 6.6,
      "learning_rate": 0.00013634204275534445,
      "loss": 0.6933,
      "step": 13890
    },
    {
      "epoch": 6.6,
      "learning_rate": 0.0001361520190023753,
      "loss": 0.6921,
      "step": 13900
    },
    {
      "epoch": 6.61,
      "learning_rate": 0.00013596199524940617,
      "loss": 0.6896,
      "step": 13910
    },
    {
      "epoch": 6.61,
      "learning_rate": 0.00013577197149643706,
      "loss": 0.6935,
      "step": 13920
    },
    {
      "epoch": 6.62,
      "learning_rate": 0.00013558194774346792,
      "loss": 0.6914,
      "step": 13930
    },
    {
      "epoch": 6.62,
      "learning_rate": 0.00013539192399049884,
      "loss": 0.6924,
      "step": 13940
    },
    {
      "epoch": 6.63,
      "learning_rate": 0.0001352019002375297,
      "loss": 0.6689,
      "step": 13950
    },
    {
      "epoch": 6.63,
      "learning_rate": 0.00013501187648456056,
      "loss": 0.6817,
      "step": 13960
    },
    {
      "epoch": 6.64,
      "learning_rate": 0.00013482185273159145,
      "loss": 0.6833,
      "step": 13970
    },
    {
      "epoch": 6.64,
      "learning_rate": 0.00013463182897862234,
      "loss": 0.6861,
      "step": 13980
    },
    {
      "epoch": 6.65,
      "learning_rate": 0.00013444180522565323,
      "loss": 0.679,
      "step": 13990
    },
    {
      "epoch": 6.65,
      "learning_rate": 0.0001342517814726841,
      "loss": 0.6801,
      "step": 14000
    },
    {
      "epoch": 6.65,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7052707672119141,
      "eval_runtime": 0.4989,
      "eval_samples_per_second": 1747.821,
      "eval_steps_per_second": 14.031,
      "step": 14000
    },
    {
      "epoch": 6.66,
      "learning_rate": 0.00013406175771971498,
      "loss": 0.6883,
      "step": 14010
    },
    {
      "epoch": 6.66,
      "learning_rate": 0.00013387173396674587,
      "loss": 0.6892,
      "step": 14020
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.00013368171021377673,
      "loss": 0.6887,
      "step": 14030
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.00013349168646080762,
      "loss": 0.6789,
      "step": 14040
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.00013330166270783848,
      "loss": 0.6832,
      "step": 14050
    },
    {
      "epoch": 6.68,
      "learning_rate": 0.00013311163895486937,
      "loss": 0.6831,
      "step": 14060
    },
    {
      "epoch": 6.68,
      "learning_rate": 0.00013292161520190026,
      "loss": 0.6895,
      "step": 14070
    },
    {
      "epoch": 6.69,
      "learning_rate": 0.00013273159144893112,
      "loss": 0.6878,
      "step": 14080
    },
    {
      "epoch": 6.69,
      "learning_rate": 0.000132541567695962,
      "loss": 0.697,
      "step": 14090
    },
    {
      "epoch": 6.7,
      "learning_rate": 0.00013235154394299287,
      "loss": 0.6888,
      "step": 14100
    },
    {
      "epoch": 6.7,
      "learning_rate": 0.00013216152019002376,
      "loss": 0.6852,
      "step": 14110
    },
    {
      "epoch": 6.71,
      "learning_rate": 0.00013197149643705465,
      "loss": 0.6907,
      "step": 14120
    },
    {
      "epoch": 6.71,
      "learning_rate": 0.0001317814726840855,
      "loss": 0.687,
      "step": 14130
    },
    {
      "epoch": 6.72,
      "learning_rate": 0.0001315914489311164,
      "loss": 0.6941,
      "step": 14140
    },
    {
      "epoch": 6.72,
      "learning_rate": 0.00013140142517814726,
      "loss": 0.6941,
      "step": 14150
    },
    {
      "epoch": 6.73,
      "learning_rate": 0.00013121140142517815,
      "loss": 0.6834,
      "step": 14160
    },
    {
      "epoch": 6.73,
      "learning_rate": 0.00013102137767220904,
      "loss": 0.6943,
      "step": 14170
    },
    {
      "epoch": 6.74,
      "learning_rate": 0.0001308313539192399,
      "loss": 0.6946,
      "step": 14180
    },
    {
      "epoch": 6.74,
      "learning_rate": 0.00013064133016627079,
      "loss": 0.675,
      "step": 14190
    },
    {
      "epoch": 6.75,
      "learning_rate": 0.00013045130641330168,
      "loss": 0.6981,
      "step": 14200
    },
    {
      "epoch": 6.75,
      "learning_rate": 0.00013026128266033256,
      "loss": 0.6976,
      "step": 14210
    },
    {
      "epoch": 6.76,
      "learning_rate": 0.00013007125890736343,
      "loss": 0.6838,
      "step": 14220
    },
    {
      "epoch": 6.76,
      "learning_rate": 0.0001298812351543943,
      "loss": 0.6889,
      "step": 14230
    },
    {
      "epoch": 6.76,
      "learning_rate": 0.0001296912114014252,
      "loss": 0.6778,
      "step": 14240
    },
    {
      "epoch": 6.77,
      "learning_rate": 0.00012950118764845606,
      "loss": 0.681,
      "step": 14250
    },
    {
      "epoch": 6.77,
      "learning_rate": 0.00012931116389548695,
      "loss": 0.6867,
      "step": 14260
    },
    {
      "epoch": 6.78,
      "learning_rate": 0.00012912114014251782,
      "loss": 0.6926,
      "step": 14270
    },
    {
      "epoch": 6.78,
      "learning_rate": 0.00012893111638954868,
      "loss": 0.6958,
      "step": 14280
    },
    {
      "epoch": 6.79,
      "learning_rate": 0.0001287410926365796,
      "loss": 0.6964,
      "step": 14290
    },
    {
      "epoch": 6.79,
      "learning_rate": 0.00012855106888361045,
      "loss": 0.6959,
      "step": 14300
    },
    {
      "epoch": 6.8,
      "learning_rate": 0.00012836104513064134,
      "loss": 0.6892,
      "step": 14310
    },
    {
      "epoch": 6.8,
      "learning_rate": 0.0001281710213776722,
      "loss": 0.6919,
      "step": 14320
    },
    {
      "epoch": 6.81,
      "learning_rate": 0.0001279809976247031,
      "loss": 0.6877,
      "step": 14330
    },
    {
      "epoch": 6.81,
      "learning_rate": 0.00012779097387173398,
      "loss": 0.6871,
      "step": 14340
    },
    {
      "epoch": 6.82,
      "learning_rate": 0.00012760095011876484,
      "loss": 0.6919,
      "step": 14350
    },
    {
      "epoch": 6.82,
      "learning_rate": 0.00012741092636579573,
      "loss": 0.6825,
      "step": 14360
    },
    {
      "epoch": 6.83,
      "learning_rate": 0.00012722090261282662,
      "loss": 0.6859,
      "step": 14370
    },
    {
      "epoch": 6.83,
      "learning_rate": 0.00012703087885985748,
      "loss": 0.684,
      "step": 14380
    },
    {
      "epoch": 6.84,
      "learning_rate": 0.00012684085510688837,
      "loss": 0.6826,
      "step": 14390
    },
    {
      "epoch": 6.84,
      "learning_rate": 0.00012665083135391923,
      "loss": 0.6919,
      "step": 14400
    },
    {
      "epoch": 6.85,
      "learning_rate": 0.00012646080760095012,
      "loss": 0.6829,
      "step": 14410
    },
    {
      "epoch": 6.85,
      "learning_rate": 0.000126270783847981,
      "loss": 0.6962,
      "step": 14420
    },
    {
      "epoch": 6.86,
      "learning_rate": 0.00012608076009501187,
      "loss": 0.6919,
      "step": 14430
    },
    {
      "epoch": 6.86,
      "learning_rate": 0.00012589073634204276,
      "loss": 0.6822,
      "step": 14440
    },
    {
      "epoch": 6.86,
      "learning_rate": 0.00012570071258907362,
      "loss": 0.6766,
      "step": 14450
    },
    {
      "epoch": 6.87,
      "learning_rate": 0.00012551068883610454,
      "loss": 0.6861,
      "step": 14460
    },
    {
      "epoch": 6.87,
      "learning_rate": 0.0001253206650831354,
      "loss": 0.6833,
      "step": 14470
    },
    {
      "epoch": 6.88,
      "learning_rate": 0.00012513064133016626,
      "loss": 0.6817,
      "step": 14480
    },
    {
      "epoch": 6.88,
      "learning_rate": 0.00012494061757719715,
      "loss": 0.696,
      "step": 14490
    },
    {
      "epoch": 6.89,
      "learning_rate": 0.00012475059382422801,
      "loss": 0.6949,
      "step": 14500
    },
    {
      "epoch": 6.89,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7056963443756104,
      "eval_runtime": 0.5051,
      "eval_samples_per_second": 1726.232,
      "eval_steps_per_second": 13.857,
      "step": 14500
    },
    {
      "epoch": 6.89,
      "learning_rate": 0.00012456057007125893,
      "loss": 0.6997,
      "step": 14510
    },
    {
      "epoch": 6.9,
      "learning_rate": 0.0001243705463182898,
      "loss": 0.6831,
      "step": 14520
    },
    {
      "epoch": 6.9,
      "learning_rate": 0.00012418052256532068,
      "loss": 0.6739,
      "step": 14530
    },
    {
      "epoch": 6.91,
      "learning_rate": 0.00012399049881235154,
      "loss": 0.6886,
      "step": 14540
    },
    {
      "epoch": 6.91,
      "learning_rate": 0.00012380047505938243,
      "loss": 0.6816,
      "step": 14550
    },
    {
      "epoch": 6.92,
      "learning_rate": 0.00012361045130641332,
      "loss": 0.6978,
      "step": 14560
    },
    {
      "epoch": 6.92,
      "learning_rate": 0.00012342042755344418,
      "loss": 0.6775,
      "step": 14570
    },
    {
      "epoch": 6.93,
      "learning_rate": 0.00012323040380047507,
      "loss": 0.6731,
      "step": 14580
    },
    {
      "epoch": 6.93,
      "learning_rate": 0.00012304038004750596,
      "loss": 0.6864,
      "step": 14590
    },
    {
      "epoch": 6.94,
      "learning_rate": 0.00012285035629453682,
      "loss": 0.6895,
      "step": 14600
    },
    {
      "epoch": 6.94,
      "learning_rate": 0.0001226603325415677,
      "loss": 0.6894,
      "step": 14610
    },
    {
      "epoch": 6.95,
      "learning_rate": 0.00012247030878859857,
      "loss": 0.6798,
      "step": 14620
    },
    {
      "epoch": 6.95,
      "learning_rate": 0.00012228028503562946,
      "loss": 0.6785,
      "step": 14630
    },
    {
      "epoch": 6.95,
      "learning_rate": 0.00012209026128266035,
      "loss": 0.6842,
      "step": 14640
    },
    {
      "epoch": 6.96,
      "learning_rate": 0.00012190023752969122,
      "loss": 0.6965,
      "step": 14650
    },
    {
      "epoch": 6.96,
      "learning_rate": 0.0001217102137767221,
      "loss": 0.6956,
      "step": 14660
    },
    {
      "epoch": 6.97,
      "learning_rate": 0.00012152019002375296,
      "loss": 0.6838,
      "step": 14670
    },
    {
      "epoch": 6.97,
      "learning_rate": 0.00012133016627078386,
      "loss": 0.6838,
      "step": 14680
    },
    {
      "epoch": 6.98,
      "learning_rate": 0.00012114014251781474,
      "loss": 0.6769,
      "step": 14690
    },
    {
      "epoch": 6.98,
      "learning_rate": 0.00012095011876484561,
      "loss": 0.6957,
      "step": 14700
    },
    {
      "epoch": 6.99,
      "learning_rate": 0.00012076009501187649,
      "loss": 0.686,
      "step": 14710
    },
    {
      "epoch": 6.99,
      "learning_rate": 0.00012057007125890738,
      "loss": 0.6859,
      "step": 14720
    },
    {
      "epoch": 7.0,
      "learning_rate": 0.00012038004750593825,
      "loss": 0.6837,
      "step": 14730
    },
    {
      "epoch": 7.0,
      "learning_rate": 0.00012019002375296913,
      "loss": 0.6853,
      "step": 14740
    },
    {
      "epoch": 7.01,
      "learning_rate": 0.00012,
      "loss": 0.6879,
      "step": 14750
    },
    {
      "epoch": 7.01,
      "learning_rate": 0.00011980997624703088,
      "loss": 0.6838,
      "step": 14760
    },
    {
      "epoch": 7.02,
      "learning_rate": 0.00011961995249406177,
      "loss": 0.6842,
      "step": 14770
    },
    {
      "epoch": 7.02,
      "learning_rate": 0.00011942992874109264,
      "loss": 0.6867,
      "step": 14780
    },
    {
      "epoch": 7.03,
      "learning_rate": 0.00011923990498812352,
      "loss": 0.6788,
      "step": 14790
    },
    {
      "epoch": 7.03,
      "learning_rate": 0.00011904988123515439,
      "loss": 0.6811,
      "step": 14800
    },
    {
      "epoch": 7.04,
      "learning_rate": 0.0001188598574821853,
      "loss": 0.6887,
      "step": 14810
    },
    {
      "epoch": 7.04,
      "learning_rate": 0.00011866983372921616,
      "loss": 0.6949,
      "step": 14820
    },
    {
      "epoch": 7.05,
      "learning_rate": 0.00011847980997624703,
      "loss": 0.6835,
      "step": 14830
    },
    {
      "epoch": 7.05,
      "learning_rate": 0.00011828978622327791,
      "loss": 0.6822,
      "step": 14840
    },
    {
      "epoch": 7.05,
      "learning_rate": 0.00011809976247030878,
      "loss": 0.6971,
      "step": 14850
    },
    {
      "epoch": 7.06,
      "learning_rate": 0.00011790973871733968,
      "loss": 0.6938,
      "step": 14860
    },
    {
      "epoch": 7.06,
      "learning_rate": 0.00011771971496437055,
      "loss": 0.6994,
      "step": 14870
    },
    {
      "epoch": 7.07,
      "learning_rate": 0.00011754869358669834,
      "loss": 0.6946,
      "step": 14880
    },
    {
      "epoch": 7.07,
      "learning_rate": 0.00011735866983372922,
      "loss": 0.6909,
      "step": 14890
    },
    {
      "epoch": 7.08,
      "learning_rate": 0.0001171686460807601,
      "loss": 0.6932,
      "step": 14900
    },
    {
      "epoch": 7.08,
      "learning_rate": 0.00011697862232779097,
      "loss": 0.6901,
      "step": 14910
    },
    {
      "epoch": 7.09,
      "learning_rate": 0.00011678859857482185,
      "loss": 0.6919,
      "step": 14920
    },
    {
      "epoch": 7.09,
      "learning_rate": 0.00011659857482185275,
      "loss": 0.685,
      "step": 14930
    },
    {
      "epoch": 7.1,
      "learning_rate": 0.00011640855106888361,
      "loss": 0.6895,
      "step": 14940
    },
    {
      "epoch": 7.1,
      "learning_rate": 0.00011621852731591449,
      "loss": 0.6909,
      "step": 14950
    },
    {
      "epoch": 7.11,
      "learning_rate": 0.00011602850356294536,
      "loss": 0.6782,
      "step": 14960
    },
    {
      "epoch": 7.11,
      "learning_rate": 0.00011583847980997627,
      "loss": 0.6866,
      "step": 14970
    },
    {
      "epoch": 7.12,
      "learning_rate": 0.00011564845605700714,
      "loss": 0.6994,
      "step": 14980
    },
    {
      "epoch": 7.12,
      "learning_rate": 0.00011545843230403802,
      "loss": 0.6757,
      "step": 14990
    },
    {
      "epoch": 7.13,
      "learning_rate": 0.00011526840855106888,
      "loss": 0.6886,
      "step": 15000
    },
    {
      "epoch": 7.13,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7037448883056641,
      "eval_runtime": 0.4993,
      "eval_samples_per_second": 1746.372,
      "eval_steps_per_second": 14.019,
      "step": 15000
    },
    {
      "epoch": 7.13,
      "learning_rate": 0.00011507838479809975,
      "loss": 0.6878,
      "step": 15010
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.00011488836104513066,
      "loss": 0.6913,
      "step": 15020
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.00011469833729216153,
      "loss": 0.6887,
      "step": 15030
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.00011450831353919241,
      "loss": 0.6875,
      "step": 15040
    },
    {
      "epoch": 7.15,
      "learning_rate": 0.00011431828978622328,
      "loss": 0.6873,
      "step": 15050
    },
    {
      "epoch": 7.15,
      "learning_rate": 0.00011412826603325417,
      "loss": 0.6857,
      "step": 15060
    },
    {
      "epoch": 7.16,
      "learning_rate": 0.00011393824228028505,
      "loss": 0.6777,
      "step": 15070
    },
    {
      "epoch": 7.16,
      "learning_rate": 0.00011374821852731592,
      "loss": 0.693,
      "step": 15080
    },
    {
      "epoch": 7.17,
      "learning_rate": 0.0001135581947743468,
      "loss": 0.6922,
      "step": 15090
    },
    {
      "epoch": 7.17,
      "learning_rate": 0.00011336817102137767,
      "loss": 0.6928,
      "step": 15100
    },
    {
      "epoch": 7.18,
      "learning_rate": 0.00011317814726840856,
      "loss": 0.6826,
      "step": 15110
    },
    {
      "epoch": 7.18,
      "learning_rate": 0.00011298812351543944,
      "loss": 0.6848,
      "step": 15120
    },
    {
      "epoch": 7.19,
      "learning_rate": 0.00011279809976247031,
      "loss": 0.6874,
      "step": 15130
    },
    {
      "epoch": 7.19,
      "learning_rate": 0.00011260807600950119,
      "loss": 0.6846,
      "step": 15140
    },
    {
      "epoch": 7.2,
      "learning_rate": 0.00011241805225653208,
      "loss": 0.6826,
      "step": 15150
    },
    {
      "epoch": 7.2,
      "learning_rate": 0.00011222802850356295,
      "loss": 0.681,
      "step": 15160
    },
    {
      "epoch": 7.21,
      "learning_rate": 0.00011203800475059383,
      "loss": 0.6956,
      "step": 15170
    },
    {
      "epoch": 7.21,
      "learning_rate": 0.0001118479809976247,
      "loss": 0.7036,
      "step": 15180
    },
    {
      "epoch": 7.22,
      "learning_rate": 0.0001116579572446556,
      "loss": 0.6955,
      "step": 15190
    },
    {
      "epoch": 7.22,
      "learning_rate": 0.00011146793349168647,
      "loss": 0.6793,
      "step": 15200
    },
    {
      "epoch": 7.23,
      "learning_rate": 0.00011127790973871734,
      "loss": 0.6774,
      "step": 15210
    },
    {
      "epoch": 7.23,
      "learning_rate": 0.00011108788598574822,
      "loss": 0.6989,
      "step": 15220
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.00011089786223277909,
      "loss": 0.6887,
      "step": 15230
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.00011070783847981,
      "loss": 0.6843,
      "step": 15240
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.00011051781472684087,
      "loss": 0.6954,
      "step": 15250
    },
    {
      "epoch": 7.25,
      "learning_rate": 0.00011032779097387173,
      "loss": 0.6864,
      "step": 15260
    },
    {
      "epoch": 7.25,
      "learning_rate": 0.0001101377672209026,
      "loss": 0.6776,
      "step": 15270
    },
    {
      "epoch": 7.26,
      "learning_rate": 0.00010994774346793351,
      "loss": 0.682,
      "step": 15280
    },
    {
      "epoch": 7.26,
      "learning_rate": 0.00010975771971496438,
      "loss": 0.6871,
      "step": 15290
    },
    {
      "epoch": 7.27,
      "learning_rate": 0.00010956769596199526,
      "loss": 0.6889,
      "step": 15300
    },
    {
      "epoch": 7.27,
      "learning_rate": 0.00010937767220902613,
      "loss": 0.6839,
      "step": 15310
    },
    {
      "epoch": 7.28,
      "learning_rate": 0.00010918764845605702,
      "loss": 0.6814,
      "step": 15320
    },
    {
      "epoch": 7.28,
      "learning_rate": 0.0001089976247030879,
      "loss": 0.6851,
      "step": 15330
    },
    {
      "epoch": 7.29,
      "learning_rate": 0.00010880760095011877,
      "loss": 0.6902,
      "step": 15340
    },
    {
      "epoch": 7.29,
      "learning_rate": 0.00010861757719714965,
      "loss": 0.6859,
      "step": 15350
    },
    {
      "epoch": 7.3,
      "learning_rate": 0.00010842755344418052,
      "loss": 0.7028,
      "step": 15360
    },
    {
      "epoch": 7.3,
      "learning_rate": 0.00010823752969121141,
      "loss": 0.6907,
      "step": 15370
    },
    {
      "epoch": 7.31,
      "learning_rate": 0.00010804750593824229,
      "loss": 0.6959,
      "step": 15380
    },
    {
      "epoch": 7.31,
      "learning_rate": 0.00010785748218527316,
      "loss": 0.6905,
      "step": 15390
    },
    {
      "epoch": 7.32,
      "learning_rate": 0.00010766745843230404,
      "loss": 0.6817,
      "step": 15400
    },
    {
      "epoch": 7.32,
      "learning_rate": 0.00010747743467933493,
      "loss": 0.694,
      "step": 15410
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.0001072874109263658,
      "loss": 0.6852,
      "step": 15420
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.00010709738717339668,
      "loss": 0.6867,
      "step": 15430
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.00010690736342042755,
      "loss": 0.7002,
      "step": 15440
    },
    {
      "epoch": 7.34,
      "learning_rate": 0.00010671733966745843,
      "loss": 0.6868,
      "step": 15450
    },
    {
      "epoch": 7.34,
      "learning_rate": 0.00010652731591448932,
      "loss": 0.6957,
      "step": 15460
    },
    {
      "epoch": 7.35,
      "learning_rate": 0.00010633729216152019,
      "loss": 0.6798,
      "step": 15470
    },
    {
      "epoch": 7.35,
      "learning_rate": 0.00010614726840855107,
      "loss": 0.6863,
      "step": 15480
    },
    {
      "epoch": 7.36,
      "learning_rate": 0.00010595724465558194,
      "loss": 0.6798,
      "step": 15490
    },
    {
      "epoch": 7.36,
      "learning_rate": 0.00010576722090261284,
      "loss": 0.6893,
      "step": 15500
    },
    {
      "epoch": 7.36,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7092441916465759,
      "eval_runtime": 0.4953,
      "eval_samples_per_second": 1760.512,
      "eval_steps_per_second": 14.133,
      "step": 15500
    },
    {
      "epoch": 7.37,
      "learning_rate": 0.00010557719714964372,
      "loss": 0.6892,
      "step": 15510
    },
    {
      "epoch": 7.37,
      "learning_rate": 0.00010538717339667458,
      "loss": 0.6976,
      "step": 15520
    },
    {
      "epoch": 7.38,
      "learning_rate": 0.00010519714964370546,
      "loss": 0.6921,
      "step": 15530
    },
    {
      "epoch": 7.38,
      "learning_rate": 0.00010500712589073636,
      "loss": 0.6897,
      "step": 15540
    },
    {
      "epoch": 7.39,
      "learning_rate": 0.00010481710213776723,
      "loss": 0.6897,
      "step": 15550
    },
    {
      "epoch": 7.39,
      "learning_rate": 0.00010462707838479811,
      "loss": 0.687,
      "step": 15560
    },
    {
      "epoch": 7.4,
      "learning_rate": 0.00010443705463182898,
      "loss": 0.6838,
      "step": 15570
    },
    {
      "epoch": 7.4,
      "learning_rate": 0.00010424703087885985,
      "loss": 0.6846,
      "step": 15580
    },
    {
      "epoch": 7.41,
      "learning_rate": 0.00010405700712589075,
      "loss": 0.6906,
      "step": 15590
    },
    {
      "epoch": 7.41,
      "learning_rate": 0.00010386698337292162,
      "loss": 0.6919,
      "step": 15600
    },
    {
      "epoch": 7.42,
      "learning_rate": 0.0001036769596199525,
      "loss": 0.6775,
      "step": 15610
    },
    {
      "epoch": 7.42,
      "learning_rate": 0.00010348693586698337,
      "loss": 0.6858,
      "step": 15620
    },
    {
      "epoch": 7.43,
      "learning_rate": 0.00010329691211401426,
      "loss": 0.7006,
      "step": 15630
    },
    {
      "epoch": 7.43,
      "learning_rate": 0.00010310688836104514,
      "loss": 0.6831,
      "step": 15640
    },
    {
      "epoch": 7.43,
      "learning_rate": 0.00010291686460807601,
      "loss": 0.6957,
      "step": 15650
    },
    {
      "epoch": 7.44,
      "learning_rate": 0.00010272684085510689,
      "loss": 0.6842,
      "step": 15660
    },
    {
      "epoch": 7.44,
      "learning_rate": 0.00010253681710213776,
      "loss": 0.6963,
      "step": 15670
    },
    {
      "epoch": 7.45,
      "learning_rate": 0.00010234679334916865,
      "loss": 0.6871,
      "step": 15680
    },
    {
      "epoch": 7.45,
      "learning_rate": 0.00010215676959619953,
      "loss": 0.6882,
      "step": 15690
    },
    {
      "epoch": 7.46,
      "learning_rate": 0.0001019667458432304,
      "loss": 0.6834,
      "step": 15700
    },
    {
      "epoch": 7.46,
      "learning_rate": 0.00010177672209026128,
      "loss": 0.6858,
      "step": 15710
    },
    {
      "epoch": 7.47,
      "learning_rate": 0.00010158669833729218,
      "loss": 0.6869,
      "step": 15720
    },
    {
      "epoch": 7.47,
      "learning_rate": 0.00010139667458432304,
      "loss": 0.6884,
      "step": 15730
    },
    {
      "epoch": 7.48,
      "learning_rate": 0.00010120665083135392,
      "loss": 0.6952,
      "step": 15740
    },
    {
      "epoch": 7.48,
      "learning_rate": 0.00010101662707838479,
      "loss": 0.6832,
      "step": 15750
    },
    {
      "epoch": 7.49,
      "learning_rate": 0.0001008266033254157,
      "loss": 0.6871,
      "step": 15760
    },
    {
      "epoch": 7.49,
      "learning_rate": 0.00010063657957244657,
      "loss": 0.7032,
      "step": 15770
    },
    {
      "epoch": 7.5,
      "learning_rate": 0.00010044655581947745,
      "loss": 0.6889,
      "step": 15780
    },
    {
      "epoch": 7.5,
      "learning_rate": 0.00010025653206650831,
      "loss": 0.696,
      "step": 15790
    },
    {
      "epoch": 7.51,
      "learning_rate": 0.00010006650831353918,
      "loss": 0.6856,
      "step": 15800
    },
    {
      "epoch": 7.51,
      "learning_rate": 9.987648456057007e-05,
      "loss": 0.6833,
      "step": 15810
    },
    {
      "epoch": 7.52,
      "learning_rate": 9.968646080760096e-05,
      "loss": 0.6842,
      "step": 15820
    },
    {
      "epoch": 7.52,
      "learning_rate": 9.949643705463184e-05,
      "loss": 0.6859,
      "step": 15830
    },
    {
      "epoch": 7.52,
      "learning_rate": 9.930641330166271e-05,
      "loss": 0.6854,
      "step": 15840
    },
    {
      "epoch": 7.53,
      "learning_rate": 9.911638954869359e-05,
      "loss": 0.6678,
      "step": 15850
    },
    {
      "epoch": 7.53,
      "learning_rate": 9.892636579572447e-05,
      "loss": 0.7039,
      "step": 15860
    },
    {
      "epoch": 7.54,
      "learning_rate": 9.873634204275535e-05,
      "loss": 0.6787,
      "step": 15870
    },
    {
      "epoch": 7.54,
      "learning_rate": 9.854631828978624e-05,
      "loss": 0.6722,
      "step": 15880
    },
    {
      "epoch": 7.55,
      "learning_rate": 9.83562945368171e-05,
      "loss": 0.7032,
      "step": 15890
    },
    {
      "epoch": 7.55,
      "learning_rate": 9.816627078384799e-05,
      "loss": 0.6664,
      "step": 15900
    },
    {
      "epoch": 7.56,
      "learning_rate": 9.797624703087886e-05,
      "loss": 0.6825,
      "step": 15910
    },
    {
      "epoch": 7.56,
      "learning_rate": 9.778622327790974e-05,
      "loss": 0.6946,
      "step": 15920
    },
    {
      "epoch": 7.57,
      "learning_rate": 9.759619952494063e-05,
      "loss": 0.6872,
      "step": 15930
    },
    {
      "epoch": 7.57,
      "learning_rate": 9.74061757719715e-05,
      "loss": 0.6959,
      "step": 15940
    },
    {
      "epoch": 7.58,
      "learning_rate": 9.721615201900238e-05,
      "loss": 0.681,
      "step": 15950
    },
    {
      "epoch": 7.58,
      "learning_rate": 9.702612826603325e-05,
      "loss": 0.6854,
      "step": 15960
    },
    {
      "epoch": 7.59,
      "learning_rate": 9.683610451306414e-05,
      "loss": 0.6892,
      "step": 15970
    },
    {
      "epoch": 7.59,
      "learning_rate": 9.664608076009502e-05,
      "loss": 0.694,
      "step": 15980
    },
    {
      "epoch": 7.6,
      "learning_rate": 9.64560570071259e-05,
      "loss": 0.6897,
      "step": 15990
    },
    {
      "epoch": 7.6,
      "learning_rate": 9.626603325415677e-05,
      "loss": 0.6883,
      "step": 16000
    },
    {
      "epoch": 7.6,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7035393714904785,
      "eval_runtime": 0.5575,
      "eval_samples_per_second": 1564.19,
      "eval_steps_per_second": 12.557,
      "step": 16000
    },
    {
      "epoch": 7.61,
      "learning_rate": 9.607600950118766e-05,
      "loss": 0.6728,
      "step": 16010
    },
    {
      "epoch": 7.61,
      "learning_rate": 9.588598574821853e-05,
      "loss": 0.6878,
      "step": 16020
    },
    {
      "epoch": 7.62,
      "learning_rate": 9.569596199524941e-05,
      "loss": 0.6724,
      "step": 16030
    },
    {
      "epoch": 7.62,
      "learning_rate": 9.55059382422803e-05,
      "loss": 0.6912,
      "step": 16040
    },
    {
      "epoch": 7.62,
      "learning_rate": 9.531591448931116e-05,
      "loss": 0.673,
      "step": 16050
    },
    {
      "epoch": 7.63,
      "learning_rate": 9.512589073634205e-05,
      "loss": 0.6705,
      "step": 16060
    },
    {
      "epoch": 7.63,
      "learning_rate": 9.493586698337292e-05,
      "loss": 0.6923,
      "step": 16070
    },
    {
      "epoch": 7.64,
      "learning_rate": 9.474584323040381e-05,
      "loss": 0.6914,
      "step": 16080
    },
    {
      "epoch": 7.64,
      "learning_rate": 9.455581947743469e-05,
      "loss": 0.6886,
      "step": 16090
    },
    {
      "epoch": 7.65,
      "learning_rate": 9.436579572446556e-05,
      "loss": 0.674,
      "step": 16100
    },
    {
      "epoch": 7.65,
      "learning_rate": 9.417577197149644e-05,
      "loss": 0.6853,
      "step": 16110
    },
    {
      "epoch": 7.66,
      "learning_rate": 9.398574821852733e-05,
      "loss": 0.6839,
      "step": 16120
    },
    {
      "epoch": 7.66,
      "learning_rate": 9.37957244655582e-05,
      "loss": 0.6893,
      "step": 16130
    },
    {
      "epoch": 7.67,
      "learning_rate": 9.360570071258908e-05,
      "loss": 0.6732,
      "step": 16140
    },
    {
      "epoch": 7.67,
      "learning_rate": 9.341567695961995e-05,
      "loss": 0.6855,
      "step": 16150
    },
    {
      "epoch": 7.68,
      "learning_rate": 9.322565320665083e-05,
      "loss": 0.6831,
      "step": 16160
    },
    {
      "epoch": 7.68,
      "learning_rate": 9.303562945368172e-05,
      "loss": 0.6867,
      "step": 16170
    },
    {
      "epoch": 7.69,
      "learning_rate": 9.284560570071259e-05,
      "loss": 0.6869,
      "step": 16180
    },
    {
      "epoch": 7.69,
      "learning_rate": 9.265558194774348e-05,
      "loss": 0.6696,
      "step": 16190
    },
    {
      "epoch": 7.7,
      "learning_rate": 9.246555819477436e-05,
      "loss": 0.6869,
      "step": 16200
    },
    {
      "epoch": 7.7,
      "learning_rate": 9.227553444180523e-05,
      "loss": 0.6885,
      "step": 16210
    },
    {
      "epoch": 7.71,
      "learning_rate": 9.20855106888361e-05,
      "loss": 0.6788,
      "step": 16220
    },
    {
      "epoch": 7.71,
      "learning_rate": 9.1895486935867e-05,
      "loss": 0.6894,
      "step": 16230
    },
    {
      "epoch": 7.71,
      "learning_rate": 9.170546318289787e-05,
      "loss": 0.6817,
      "step": 16240
    },
    {
      "epoch": 7.72,
      "learning_rate": 9.151543942992874e-05,
      "loss": 0.6882,
      "step": 16250
    },
    {
      "epoch": 7.72,
      "learning_rate": 9.132541567695962e-05,
      "loss": 0.699,
      "step": 16260
    },
    {
      "epoch": 7.73,
      "learning_rate": 9.11353919239905e-05,
      "loss": 0.6955,
      "step": 16270
    },
    {
      "epoch": 7.73,
      "learning_rate": 9.094536817102138e-05,
      "loss": 0.6889,
      "step": 16280
    },
    {
      "epoch": 7.74,
      "learning_rate": 9.075534441805226e-05,
      "loss": 0.6875,
      "step": 16290
    },
    {
      "epoch": 7.74,
      "learning_rate": 9.056532066508315e-05,
      "loss": 0.6944,
      "step": 16300
    },
    {
      "epoch": 7.75,
      "learning_rate": 9.039429928741094e-05,
      "loss": 0.6836,
      "step": 16310
    },
    {
      "epoch": 7.75,
      "learning_rate": 9.020427553444181e-05,
      "loss": 0.6866,
      "step": 16320
    },
    {
      "epoch": 7.76,
      "learning_rate": 9.001425178147269e-05,
      "loss": 0.6972,
      "step": 16330
    },
    {
      "epoch": 7.76,
      "learning_rate": 8.982422802850356e-05,
      "loss": 0.6761,
      "step": 16340
    },
    {
      "epoch": 7.77,
      "learning_rate": 8.963420427553445e-05,
      "loss": 0.6866,
      "step": 16350
    },
    {
      "epoch": 7.77,
      "learning_rate": 8.944418052256533e-05,
      "loss": 0.683,
      "step": 16360
    },
    {
      "epoch": 7.78,
      "learning_rate": 8.92541567695962e-05,
      "loss": 0.6847,
      "step": 16370
    },
    {
      "epoch": 7.78,
      "learning_rate": 8.906413301662708e-05,
      "loss": 0.6951,
      "step": 16380
    },
    {
      "epoch": 7.79,
      "learning_rate": 8.887410926365795e-05,
      "loss": 0.6715,
      "step": 16390
    },
    {
      "epoch": 7.79,
      "learning_rate": 8.868408551068884e-05,
      "loss": 0.697,
      "step": 16400
    },
    {
      "epoch": 7.8,
      "learning_rate": 8.849406175771972e-05,
      "loss": 0.6816,
      "step": 16410
    },
    {
      "epoch": 7.8,
      "learning_rate": 8.83040380047506e-05,
      "loss": 0.6854,
      "step": 16420
    },
    {
      "epoch": 7.81,
      "learning_rate": 8.811401425178147e-05,
      "loss": 0.6853,
      "step": 16430
    },
    {
      "epoch": 7.81,
      "learning_rate": 8.792399049881236e-05,
      "loss": 0.6911,
      "step": 16440
    },
    {
      "epoch": 7.81,
      "learning_rate": 8.773396674584323e-05,
      "loss": 0.6854,
      "step": 16450
    },
    {
      "epoch": 7.82,
      "learning_rate": 8.754394299287412e-05,
      "loss": 0.6902,
      "step": 16460
    },
    {
      "epoch": 7.82,
      "learning_rate": 8.7353919239905e-05,
      "loss": 0.6987,
      "step": 16470
    },
    {
      "epoch": 7.83,
      "learning_rate": 8.716389548693587e-05,
      "loss": 0.6983,
      "step": 16480
    },
    {
      "epoch": 7.83,
      "learning_rate": 8.697387173396675e-05,
      "loss": 0.6947,
      "step": 16490
    },
    {
      "epoch": 7.84,
      "learning_rate": 8.678384798099762e-05,
      "loss": 0.6939,
      "step": 16500
    },
    {
      "epoch": 7.84,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7037633657455444,
      "eval_runtime": 0.5095,
      "eval_samples_per_second": 1711.445,
      "eval_steps_per_second": 13.739,
      "step": 16500
    },
    {
      "epoch": 7.84,
      "learning_rate": 8.659382422802851e-05,
      "loss": 0.6943,
      "step": 16510
    },
    {
      "epoch": 7.85,
      "learning_rate": 8.640380047505938e-05,
      "loss": 0.6847,
      "step": 16520
    },
    {
      "epoch": 7.85,
      "learning_rate": 8.621377672209027e-05,
      "loss": 0.6816,
      "step": 16530
    },
    {
      "epoch": 7.86,
      "learning_rate": 8.602375296912114e-05,
      "loss": 0.6895,
      "step": 16540
    },
    {
      "epoch": 7.86,
      "learning_rate": 8.583372921615202e-05,
      "loss": 0.6923,
      "step": 16550
    },
    {
      "epoch": 7.87,
      "learning_rate": 8.56437054631829e-05,
      "loss": 0.6805,
      "step": 16560
    },
    {
      "epoch": 7.87,
      "learning_rate": 8.545368171021379e-05,
      "loss": 0.6869,
      "step": 16570
    },
    {
      "epoch": 7.88,
      "learning_rate": 8.526365795724466e-05,
      "loss": 0.6959,
      "step": 16580
    },
    {
      "epoch": 7.88,
      "learning_rate": 8.507363420427554e-05,
      "loss": 0.6797,
      "step": 16590
    },
    {
      "epoch": 7.89,
      "learning_rate": 8.488361045130641e-05,
      "loss": 0.6894,
      "step": 16600
    },
    {
      "epoch": 7.89,
      "learning_rate": 8.46935866983373e-05,
      "loss": 0.6782,
      "step": 16610
    },
    {
      "epoch": 7.9,
      "learning_rate": 8.450356294536818e-05,
      "loss": 0.6938,
      "step": 16620
    },
    {
      "epoch": 7.9,
      "learning_rate": 8.431353919239905e-05,
      "loss": 0.6979,
      "step": 16630
    },
    {
      "epoch": 7.9,
      "learning_rate": 8.412351543942993e-05,
      "loss": 0.6959,
      "step": 16640
    },
    {
      "epoch": 7.91,
      "learning_rate": 8.39334916864608e-05,
      "loss": 0.6912,
      "step": 16650
    },
    {
      "epoch": 7.91,
      "learning_rate": 8.374346793349169e-05,
      "loss": 0.6825,
      "step": 16660
    },
    {
      "epoch": 7.92,
      "learning_rate": 8.355344418052257e-05,
      "loss": 0.6921,
      "step": 16670
    },
    {
      "epoch": 7.92,
      "learning_rate": 8.336342042755346e-05,
      "loss": 0.6758,
      "step": 16680
    },
    {
      "epoch": 7.93,
      "learning_rate": 8.317339667458433e-05,
      "loss": 0.6858,
      "step": 16690
    },
    {
      "epoch": 7.93,
      "learning_rate": 8.298337292161521e-05,
      "loss": 0.6878,
      "step": 16700
    },
    {
      "epoch": 7.94,
      "learning_rate": 8.279334916864608e-05,
      "loss": 0.7002,
      "step": 16710
    },
    {
      "epoch": 7.94,
      "learning_rate": 8.260332541567697e-05,
      "loss": 0.6884,
      "step": 16720
    },
    {
      "epoch": 7.95,
      "learning_rate": 8.241330166270785e-05,
      "loss": 0.6928,
      "step": 16730
    },
    {
      "epoch": 7.95,
      "learning_rate": 8.222327790973872e-05,
      "loss": 0.6947,
      "step": 16740
    },
    {
      "epoch": 7.96,
      "learning_rate": 8.20332541567696e-05,
      "loss": 0.6889,
      "step": 16750
    },
    {
      "epoch": 7.96,
      "learning_rate": 8.184323040380047e-05,
      "loss": 0.6846,
      "step": 16760
    },
    {
      "epoch": 7.97,
      "learning_rate": 8.165320665083136e-05,
      "loss": 0.6813,
      "step": 16770
    },
    {
      "epoch": 7.97,
      "learning_rate": 8.146318289786224e-05,
      "loss": 0.6854,
      "step": 16780
    },
    {
      "epoch": 7.98,
      "learning_rate": 8.127315914489312e-05,
      "loss": 0.6751,
      "step": 16790
    },
    {
      "epoch": 7.98,
      "learning_rate": 8.108313539192399e-05,
      "loss": 0.6869,
      "step": 16800
    },
    {
      "epoch": 7.99,
      "learning_rate": 8.089311163895488e-05,
      "loss": 0.6692,
      "step": 16810
    },
    {
      "epoch": 7.99,
      "learning_rate": 8.070308788598575e-05,
      "loss": 0.6963,
      "step": 16820
    },
    {
      "epoch": 8.0,
      "learning_rate": 8.051306413301664e-05,
      "loss": 0.6834,
      "step": 16830
    },
    {
      "epoch": 8.0,
      "learning_rate": 8.032304038004751e-05,
      "loss": 0.6797,
      "step": 16840
    },
    {
      "epoch": 8.0,
      "learning_rate": 8.013301662707839e-05,
      "loss": 0.6836,
      "step": 16850
    },
    {
      "epoch": 8.01,
      "learning_rate": 7.994299287410927e-05,
      "loss": 0.6829,
      "step": 16860
    },
    {
      "epoch": 8.01,
      "learning_rate": 7.975296912114014e-05,
      "loss": 0.6955,
      "step": 16870
    },
    {
      "epoch": 8.02,
      "learning_rate": 7.956294536817103e-05,
      "loss": 0.681,
      "step": 16880
    },
    {
      "epoch": 8.02,
      "learning_rate": 7.93729216152019e-05,
      "loss": 0.6936,
      "step": 16890
    },
    {
      "epoch": 8.03,
      "learning_rate": 7.918289786223278e-05,
      "loss": 0.6873,
      "step": 16900
    },
    {
      "epoch": 8.03,
      "learning_rate": 7.899287410926365e-05,
      "loss": 0.6875,
      "step": 16910
    },
    {
      "epoch": 8.04,
      "learning_rate": 7.880285035629454e-05,
      "loss": 0.6942,
      "step": 16920
    },
    {
      "epoch": 8.04,
      "learning_rate": 7.861282660332542e-05,
      "loss": 0.6813,
      "step": 16930
    },
    {
      "epoch": 8.05,
      "learning_rate": 7.842280285035631e-05,
      "loss": 0.6915,
      "step": 16940
    },
    {
      "epoch": 8.05,
      "learning_rate": 7.823277909738718e-05,
      "loss": 0.6888,
      "step": 16950
    },
    {
      "epoch": 8.06,
      "learning_rate": 7.804275534441806e-05,
      "loss": 0.688,
      "step": 16960
    },
    {
      "epoch": 8.06,
      "learning_rate": 7.785273159144893e-05,
      "loss": 0.6869,
      "step": 16970
    },
    {
      "epoch": 8.07,
      "learning_rate": 7.766270783847981e-05,
      "loss": 0.6899,
      "step": 16980
    },
    {
      "epoch": 8.07,
      "learning_rate": 7.74726840855107e-05,
      "loss": 0.6902,
      "step": 16990
    },
    {
      "epoch": 8.08,
      "learning_rate": 7.728266033254157e-05,
      "loss": 0.6861,
      "step": 17000
    },
    {
      "epoch": 8.08,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7003576755523682,
      "eval_runtime": 0.597,
      "eval_samples_per_second": 1460.538,
      "eval_steps_per_second": 11.724,
      "step": 17000
    },
    {
      "epoch": 8.08,
      "learning_rate": 7.709263657957245e-05,
      "loss": 0.688,
      "step": 17010
    },
    {
      "epoch": 8.09,
      "learning_rate": 7.690261282660332e-05,
      "loss": 0.6748,
      "step": 17020
    },
    {
      "epoch": 8.09,
      "learning_rate": 7.671258907363421e-05,
      "loss": 0.7022,
      "step": 17030
    },
    {
      "epoch": 8.1,
      "learning_rate": 7.652256532066509e-05,
      "loss": 0.6826,
      "step": 17040
    },
    {
      "epoch": 8.1,
      "learning_rate": 7.633254156769598e-05,
      "loss": 0.6671,
      "step": 17050
    },
    {
      "epoch": 8.1,
      "learning_rate": 7.614251781472684e-05,
      "loss": 0.692,
      "step": 17060
    },
    {
      "epoch": 8.11,
      "learning_rate": 7.595249406175773e-05,
      "loss": 0.6814,
      "step": 17070
    },
    {
      "epoch": 8.11,
      "learning_rate": 7.57624703087886e-05,
      "loss": 0.6944,
      "step": 17080
    },
    {
      "epoch": 8.12,
      "learning_rate": 7.557244655581948e-05,
      "loss": 0.6903,
      "step": 17090
    },
    {
      "epoch": 8.12,
      "learning_rate": 7.538242280285037e-05,
      "loss": 0.6829,
      "step": 17100
    },
    {
      "epoch": 8.13,
      "learning_rate": 7.519239904988124e-05,
      "loss": 0.6981,
      "step": 17110
    },
    {
      "epoch": 8.13,
      "learning_rate": 7.500237529691212e-05,
      "loss": 0.6811,
      "step": 17120
    },
    {
      "epoch": 8.14,
      "learning_rate": 7.481235154394299e-05,
      "loss": 0.6996,
      "step": 17130
    },
    {
      "epoch": 8.14,
      "learning_rate": 7.462232779097388e-05,
      "loss": 0.6846,
      "step": 17140
    },
    {
      "epoch": 8.15,
      "learning_rate": 7.443230403800476e-05,
      "loss": 0.6807,
      "step": 17150
    },
    {
      "epoch": 8.15,
      "learning_rate": 7.424228028503563e-05,
      "loss": 0.6928,
      "step": 17160
    },
    {
      "epoch": 8.16,
      "learning_rate": 7.40522565320665e-05,
      "loss": 0.6753,
      "step": 17170
    },
    {
      "epoch": 8.16,
      "learning_rate": 7.38622327790974e-05,
      "loss": 0.7019,
      "step": 17180
    },
    {
      "epoch": 8.17,
      "learning_rate": 7.367220902612827e-05,
      "loss": 0.6799,
      "step": 17190
    },
    {
      "epoch": 8.17,
      "learning_rate": 7.348218527315915e-05,
      "loss": 0.6838,
      "step": 17200
    },
    {
      "epoch": 8.18,
      "learning_rate": 7.329216152019003e-05,
      "loss": 0.6817,
      "step": 17210
    },
    {
      "epoch": 8.18,
      "learning_rate": 7.31021377672209e-05,
      "loss": 0.6804,
      "step": 17220
    },
    {
      "epoch": 8.19,
      "learning_rate": 7.291211401425178e-05,
      "loss": 0.6851,
      "step": 17230
    },
    {
      "epoch": 8.19,
      "learning_rate": 7.272209026128266e-05,
      "loss": 0.6812,
      "step": 17240
    },
    {
      "epoch": 8.19,
      "learning_rate": 7.253206650831355e-05,
      "loss": 0.681,
      "step": 17250
    },
    {
      "epoch": 8.2,
      "learning_rate": 7.234204275534442e-05,
      "loss": 0.7043,
      "step": 17260
    },
    {
      "epoch": 8.2,
      "learning_rate": 7.21520190023753e-05,
      "loss": 0.6809,
      "step": 17270
    },
    {
      "epoch": 8.21,
      "learning_rate": 7.196199524940617e-05,
      "loss": 0.6865,
      "step": 17280
    },
    {
      "epoch": 8.21,
      "learning_rate": 7.177197149643706e-05,
      "loss": 0.6859,
      "step": 17290
    },
    {
      "epoch": 8.22,
      "learning_rate": 7.158194774346794e-05,
      "loss": 0.6883,
      "step": 17300
    },
    {
      "epoch": 8.22,
      "learning_rate": 7.139192399049883e-05,
      "loss": 0.6898,
      "step": 17310
    },
    {
      "epoch": 8.23,
      "learning_rate": 7.120190023752969e-05,
      "loss": 0.6961,
      "step": 17320
    },
    {
      "epoch": 8.23,
      "learning_rate": 7.101187648456056e-05,
      "loss": 0.6945,
      "step": 17330
    },
    {
      "epoch": 8.24,
      "learning_rate": 7.082185273159145e-05,
      "loss": 0.6853,
      "step": 17340
    },
    {
      "epoch": 8.24,
      "learning_rate": 7.063182897862233e-05,
      "loss": 0.678,
      "step": 17350
    },
    {
      "epoch": 8.25,
      "learning_rate": 7.044180522565322e-05,
      "loss": 0.6787,
      "step": 17360
    },
    {
      "epoch": 8.25,
      "learning_rate": 7.025178147268409e-05,
      "loss": 0.6847,
      "step": 17370
    },
    {
      "epoch": 8.26,
      "learning_rate": 7.006175771971497e-05,
      "loss": 0.7026,
      "step": 17380
    },
    {
      "epoch": 8.26,
      "learning_rate": 6.987173396674584e-05,
      "loss": 0.6855,
      "step": 17390
    },
    {
      "epoch": 8.27,
      "learning_rate": 6.968171021377673e-05,
      "loss": 0.671,
      "step": 17400
    },
    {
      "epoch": 8.27,
      "learning_rate": 6.94916864608076e-05,
      "loss": 0.6881,
      "step": 17410
    },
    {
      "epoch": 8.28,
      "learning_rate": 6.930166270783848e-05,
      "loss": 0.6784,
      "step": 17420
    },
    {
      "epoch": 8.28,
      "learning_rate": 6.911163895486936e-05,
      "loss": 0.6851,
      "step": 17430
    },
    {
      "epoch": 8.29,
      "learning_rate": 6.892161520190023e-05,
      "loss": 0.6839,
      "step": 17440
    },
    {
      "epoch": 8.29,
      "learning_rate": 6.873159144893112e-05,
      "loss": 0.6935,
      "step": 17450
    },
    {
      "epoch": 8.29,
      "learning_rate": 6.8541567695962e-05,
      "loss": 0.6987,
      "step": 17460
    },
    {
      "epoch": 8.3,
      "learning_rate": 6.835154394299289e-05,
      "loss": 0.6786,
      "step": 17470
    },
    {
      "epoch": 8.3,
      "learning_rate": 6.816152019002375e-05,
      "loss": 0.6832,
      "step": 17480
    },
    {
      "epoch": 8.31,
      "learning_rate": 6.797149643705464e-05,
      "loss": 0.698,
      "step": 17490
    },
    {
      "epoch": 8.31,
      "learning_rate": 6.778147268408551e-05,
      "loss": 0.6905,
      "step": 17500
    },
    {
      "epoch": 8.31,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.698903501033783,
      "eval_runtime": 0.5026,
      "eval_samples_per_second": 1734.908,
      "eval_steps_per_second": 13.927,
      "step": 17500
    },
    {
      "epoch": 8.32,
      "learning_rate": 6.75914489311164e-05,
      "loss": 0.6945,
      "step": 17510
    },
    {
      "epoch": 8.32,
      "learning_rate": 6.740142517814727e-05,
      "loss": 0.6939,
      "step": 17520
    },
    {
      "epoch": 8.33,
      "learning_rate": 6.721140142517815e-05,
      "loss": 0.6902,
      "step": 17530
    },
    {
      "epoch": 8.33,
      "learning_rate": 6.702137767220903e-05,
      "loss": 0.6757,
      "step": 17540
    },
    {
      "epoch": 8.34,
      "learning_rate": 6.68313539192399e-05,
      "loss": 0.6872,
      "step": 17550
    },
    {
      "epoch": 8.34,
      "learning_rate": 6.664133016627079e-05,
      "loss": 0.69,
      "step": 17560
    },
    {
      "epoch": 8.35,
      "learning_rate": 6.645130641330166e-05,
      "loss": 0.6949,
      "step": 17570
    },
    {
      "epoch": 8.35,
      "learning_rate": 6.626128266033254e-05,
      "loss": 0.6888,
      "step": 17580
    },
    {
      "epoch": 8.36,
      "learning_rate": 6.607125890736341e-05,
      "loss": 0.6818,
      "step": 17590
    },
    {
      "epoch": 8.36,
      "learning_rate": 6.58812351543943e-05,
      "loss": 0.6879,
      "step": 17600
    },
    {
      "epoch": 8.37,
      "learning_rate": 6.569121140142518e-05,
      "loss": 0.685,
      "step": 17610
    },
    {
      "epoch": 8.37,
      "learning_rate": 6.550118764845607e-05,
      "loss": 0.6853,
      "step": 17620
    },
    {
      "epoch": 8.38,
      "learning_rate": 6.531116389548694e-05,
      "loss": 0.6834,
      "step": 17630
    },
    {
      "epoch": 8.38,
      "learning_rate": 6.512114014251782e-05,
      "loss": 0.6767,
      "step": 17640
    },
    {
      "epoch": 8.38,
      "learning_rate": 6.49311163895487e-05,
      "loss": 0.6828,
      "step": 17650
    },
    {
      "epoch": 8.39,
      "learning_rate": 6.474109263657957e-05,
      "loss": 0.6877,
      "step": 17660
    },
    {
      "epoch": 8.39,
      "learning_rate": 6.455106888361046e-05,
      "loss": 0.6808,
      "step": 17670
    },
    {
      "epoch": 8.4,
      "learning_rate": 6.436104513064133e-05,
      "loss": 0.6834,
      "step": 17680
    },
    {
      "epoch": 8.4,
      "learning_rate": 6.417102137767221e-05,
      "loss": 0.6869,
      "step": 17690
    },
    {
      "epoch": 8.41,
      "learning_rate": 6.398099762470308e-05,
      "loss": 0.6755,
      "step": 17700
    },
    {
      "epoch": 8.41,
      "learning_rate": 6.379097387173397e-05,
      "loss": 0.6865,
      "step": 17710
    },
    {
      "epoch": 8.42,
      "learning_rate": 6.360095011876485e-05,
      "loss": 0.6856,
      "step": 17720
    },
    {
      "epoch": 8.42,
      "learning_rate": 6.341092636579574e-05,
      "loss": 0.6833,
      "step": 17730
    },
    {
      "epoch": 8.43,
      "learning_rate": 6.322090261282661e-05,
      "loss": 0.6966,
      "step": 17740
    },
    {
      "epoch": 8.43,
      "learning_rate": 6.303087885985749e-05,
      "loss": 0.6798,
      "step": 17750
    },
    {
      "epoch": 8.44,
      "learning_rate": 6.284085510688836e-05,
      "loss": 0.7003,
      "step": 17760
    },
    {
      "epoch": 8.44,
      "learning_rate": 6.265083135391925e-05,
      "loss": 0.6841,
      "step": 17770
    },
    {
      "epoch": 8.45,
      "learning_rate": 6.246080760095013e-05,
      "loss": 0.6784,
      "step": 17780
    },
    {
      "epoch": 8.45,
      "learning_rate": 6.2270783847981e-05,
      "loss": 0.6972,
      "step": 17790
    },
    {
      "epoch": 8.46,
      "learning_rate": 6.208076009501188e-05,
      "loss": 0.6799,
      "step": 17800
    },
    {
      "epoch": 8.46,
      "learning_rate": 6.189073634204275e-05,
      "loss": 0.6808,
      "step": 17810
    },
    {
      "epoch": 8.47,
      "learning_rate": 6.170071258907364e-05,
      "loss": 0.699,
      "step": 17820
    },
    {
      "epoch": 8.47,
      "learning_rate": 6.151068883610452e-05,
      "loss": 0.6951,
      "step": 17830
    },
    {
      "epoch": 8.48,
      "learning_rate": 6.13206650831354e-05,
      "loss": 0.6868,
      "step": 17840
    },
    {
      "epoch": 8.48,
      "learning_rate": 6.113064133016627e-05,
      "loss": 0.6896,
      "step": 17850
    },
    {
      "epoch": 8.48,
      "learning_rate": 6.0940617577197155e-05,
      "loss": 0.6852,
      "step": 17860
    },
    {
      "epoch": 8.49,
      "learning_rate": 6.075059382422803e-05,
      "loss": 0.691,
      "step": 17870
    },
    {
      "epoch": 8.49,
      "learning_rate": 6.056057007125891e-05,
      "loss": 0.6866,
      "step": 17880
    },
    {
      "epoch": 8.5,
      "learning_rate": 6.037054631828979e-05,
      "loss": 0.6912,
      "step": 17890
    },
    {
      "epoch": 8.5,
      "learning_rate": 6.018052256532066e-05,
      "loss": 0.6766,
      "step": 17900
    },
    {
      "epoch": 8.51,
      "learning_rate": 5.9990498812351545e-05,
      "loss": 0.6867,
      "step": 17910
    },
    {
      "epoch": 8.51,
      "learning_rate": 5.980047505938242e-05,
      "loss": 0.6764,
      "step": 17920
    },
    {
      "epoch": 8.52,
      "learning_rate": 5.961045130641331e-05,
      "loss": 0.6849,
      "step": 17930
    },
    {
      "epoch": 8.52,
      "learning_rate": 5.942042755344418e-05,
      "loss": 0.6875,
      "step": 17940
    },
    {
      "epoch": 8.53,
      "learning_rate": 5.9230403800475066e-05,
      "loss": 0.6858,
      "step": 17950
    },
    {
      "epoch": 8.53,
      "learning_rate": 5.904038004750594e-05,
      "loss": 0.6736,
      "step": 17960
    },
    {
      "epoch": 8.54,
      "learning_rate": 5.885035629453682e-05,
      "loss": 0.7052,
      "step": 17970
    },
    {
      "epoch": 8.54,
      "learning_rate": 5.86603325415677e-05,
      "loss": 0.681,
      "step": 17980
    },
    {
      "epoch": 8.55,
      "learning_rate": 5.847030878859858e-05,
      "loss": 0.6847,
      "step": 17990
    },
    {
      "epoch": 8.55,
      "learning_rate": 5.8280285035629456e-05,
      "loss": 0.6861,
      "step": 18000
    },
    {
      "epoch": 8.55,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7011561989784241,
      "eval_runtime": 0.5032,
      "eval_samples_per_second": 1732.774,
      "eval_steps_per_second": 13.91,
      "step": 18000
    },
    {
      "epoch": 8.56,
      "learning_rate": 5.809026128266033e-05,
      "loss": 0.6883,
      "step": 18010
    },
    {
      "epoch": 8.56,
      "learning_rate": 5.790023752969121e-05,
      "loss": 0.6876,
      "step": 18020
    },
    {
      "epoch": 8.57,
      "learning_rate": 5.771021377672209e-05,
      "loss": 0.6777,
      "step": 18030
    },
    {
      "epoch": 8.57,
      "learning_rate": 5.752019002375297e-05,
      "loss": 0.693,
      "step": 18040
    },
    {
      "epoch": 8.57,
      "learning_rate": 5.7330166270783845e-05,
      "loss": 0.6828,
      "step": 18050
    },
    {
      "epoch": 8.58,
      "learning_rate": 5.7140142517814734e-05,
      "loss": 0.6886,
      "step": 18060
    },
    {
      "epoch": 8.58,
      "learning_rate": 5.69501187648456e-05,
      "loss": 0.6878,
      "step": 18070
    },
    {
      "epoch": 8.59,
      "learning_rate": 5.676009501187649e-05,
      "loss": 0.6842,
      "step": 18080
    },
    {
      "epoch": 8.59,
      "learning_rate": 5.657007125890737e-05,
      "loss": 0.676,
      "step": 18090
    },
    {
      "epoch": 8.6,
      "learning_rate": 5.638004750593825e-05,
      "loss": 0.6977,
      "step": 18100
    },
    {
      "epoch": 8.6,
      "learning_rate": 5.6190023752969124e-05,
      "loss": 0.6899,
      "step": 18110
    },
    {
      "epoch": 8.61,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 0.6771,
      "step": 18120
    },
    {
      "epoch": 8.61,
      "learning_rate": 5.580997624703088e-05,
      "loss": 0.6899,
      "step": 18130
    },
    {
      "epoch": 8.62,
      "learning_rate": 5.5619952494061756e-05,
      "loss": 0.6852,
      "step": 18140
    },
    {
      "epoch": 8.62,
      "learning_rate": 5.542992874109264e-05,
      "loss": 0.6852,
      "step": 18150
    },
    {
      "epoch": 8.63,
      "learning_rate": 5.5239904988123514e-05,
      "loss": 0.7009,
      "step": 18160
    },
    {
      "epoch": 8.63,
      "learning_rate": 5.50498812351544e-05,
      "loss": 0.6896,
      "step": 18170
    },
    {
      "epoch": 8.64,
      "learning_rate": 5.485985748218527e-05,
      "loss": 0.6897,
      "step": 18180
    },
    {
      "epoch": 8.64,
      "learning_rate": 5.466983372921616e-05,
      "loss": 0.6868,
      "step": 18190
    },
    {
      "epoch": 8.65,
      "learning_rate": 5.447980997624703e-05,
      "loss": 0.69,
      "step": 18200
    },
    {
      "epoch": 8.65,
      "learning_rate": 5.428978622327792e-05,
      "loss": 0.6849,
      "step": 18210
    },
    {
      "epoch": 8.66,
      "learning_rate": 5.409976247030879e-05,
      "loss": 0.6829,
      "step": 18220
    },
    {
      "epoch": 8.66,
      "learning_rate": 5.3909738717339674e-05,
      "loss": 0.6874,
      "step": 18230
    },
    {
      "epoch": 8.67,
      "learning_rate": 5.371971496437055e-05,
      "loss": 0.6854,
      "step": 18240
    },
    {
      "epoch": 8.67,
      "learning_rate": 5.3529691211401425e-05,
      "loss": 0.6934,
      "step": 18250
    },
    {
      "epoch": 8.67,
      "learning_rate": 5.333966745843231e-05,
      "loss": 0.6912,
      "step": 18260
    },
    {
      "epoch": 8.68,
      "learning_rate": 5.314964370546318e-05,
      "loss": 0.6833,
      "step": 18270
    },
    {
      "epoch": 8.68,
      "learning_rate": 5.2959619952494064e-05,
      "loss": 0.6986,
      "step": 18280
    },
    {
      "epoch": 8.69,
      "learning_rate": 5.276959619952494e-05,
      "loss": 0.6858,
      "step": 18290
    },
    {
      "epoch": 8.69,
      "learning_rate": 5.257957244655583e-05,
      "loss": 0.6871,
      "step": 18300
    },
    {
      "epoch": 8.7,
      "learning_rate": 5.2389548693586696e-05,
      "loss": 0.6983,
      "step": 18310
    },
    {
      "epoch": 8.7,
      "learning_rate": 5.2199524940617585e-05,
      "loss": 0.6883,
      "step": 18320
    },
    {
      "epoch": 8.71,
      "learning_rate": 5.200950118764846e-05,
      "loss": 0.6812,
      "step": 18330
    },
    {
      "epoch": 8.71,
      "learning_rate": 5.181947743467934e-05,
      "loss": 0.6911,
      "step": 18340
    },
    {
      "epoch": 8.72,
      "learning_rate": 5.162945368171022e-05,
      "loss": 0.6935,
      "step": 18350
    },
    {
      "epoch": 8.72,
      "learning_rate": 5.143942992874109e-05,
      "loss": 0.6867,
      "step": 18360
    },
    {
      "epoch": 8.73,
      "learning_rate": 5.1249406175771975e-05,
      "loss": 0.6857,
      "step": 18370
    },
    {
      "epoch": 8.73,
      "learning_rate": 5.105938242280285e-05,
      "loss": 0.6867,
      "step": 18380
    },
    {
      "epoch": 8.74,
      "learning_rate": 5.086935866983373e-05,
      "loss": 0.6886,
      "step": 18390
    },
    {
      "epoch": 8.74,
      "learning_rate": 5.067933491686461e-05,
      "loss": 0.6897,
      "step": 18400
    },
    {
      "epoch": 8.75,
      "learning_rate": 5.048931116389549e-05,
      "loss": 0.6892,
      "step": 18410
    },
    {
      "epoch": 8.75,
      "learning_rate": 5.0299287410926365e-05,
      "loss": 0.6839,
      "step": 18420
    },
    {
      "epoch": 8.76,
      "learning_rate": 5.0109263657957254e-05,
      "loss": 0.6907,
      "step": 18430
    },
    {
      "epoch": 8.76,
      "learning_rate": 4.991923990498812e-05,
      "loss": 0.6923,
      "step": 18440
    },
    {
      "epoch": 8.76,
      "learning_rate": 4.9729216152019004e-05,
      "loss": 0.6818,
      "step": 18450
    },
    {
      "epoch": 8.77,
      "learning_rate": 4.9539192399049886e-05,
      "loss": 0.6934,
      "step": 18460
    },
    {
      "epoch": 8.77,
      "learning_rate": 4.934916864608076e-05,
      "loss": 0.6954,
      "step": 18470
    },
    {
      "epoch": 8.78,
      "learning_rate": 4.915914489311164e-05,
      "loss": 0.6965,
      "step": 18480
    },
    {
      "epoch": 8.78,
      "learning_rate": 4.896912114014252e-05,
      "loss": 0.6816,
      "step": 18490
    },
    {
      "epoch": 8.79,
      "learning_rate": 4.87790973871734e-05,
      "loss": 0.6869,
      "step": 18500
    },
    {
      "epoch": 8.79,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.700119137763977,
      "eval_runtime": 0.5723,
      "eval_samples_per_second": 1523.69,
      "eval_steps_per_second": 12.231,
      "step": 18500
    },
    {
      "epoch": 8.79,
      "learning_rate": 4.858907363420428e-05,
      "loss": 0.6897,
      "step": 18510
    },
    {
      "epoch": 8.8,
      "learning_rate": 4.839904988123516e-05,
      "loss": 0.6973,
      "step": 18520
    },
    {
      "epoch": 8.8,
      "learning_rate": 4.820902612826604e-05,
      "loss": 0.6839,
      "step": 18530
    },
    {
      "epoch": 8.81,
      "learning_rate": 4.8019002375296915e-05,
      "loss": 0.6841,
      "step": 18540
    },
    {
      "epoch": 8.81,
      "learning_rate": 4.782897862232779e-05,
      "loss": 0.692,
      "step": 18550
    },
    {
      "epoch": 8.82,
      "learning_rate": 4.763895486935867e-05,
      "loss": 0.6781,
      "step": 18560
    },
    {
      "epoch": 8.82,
      "learning_rate": 4.744893111638955e-05,
      "loss": 0.6844,
      "step": 18570
    },
    {
      "epoch": 8.83,
      "learning_rate": 4.725890736342043e-05,
      "loss": 0.6881,
      "step": 18580
    },
    {
      "epoch": 8.83,
      "learning_rate": 4.706888361045131e-05,
      "loss": 0.6842,
      "step": 18590
    },
    {
      "epoch": 8.84,
      "learning_rate": 4.687885985748219e-05,
      "loss": 0.6979,
      "step": 18600
    },
    {
      "epoch": 8.84,
      "learning_rate": 4.668883610451307e-05,
      "loss": 0.6963,
      "step": 18610
    },
    {
      "epoch": 8.85,
      "learning_rate": 4.6498812351543944e-05,
      "loss": 0.6856,
      "step": 18620
    },
    {
      "epoch": 8.85,
      "learning_rate": 4.6308788598574826e-05,
      "loss": 0.6743,
      "step": 18630
    },
    {
      "epoch": 8.86,
      "learning_rate": 4.611876484560571e-05,
      "loss": 0.683,
      "step": 18640
    },
    {
      "epoch": 8.86,
      "learning_rate": 4.5928741092636577e-05,
      "loss": 0.6973,
      "step": 18650
    },
    {
      "epoch": 8.86,
      "learning_rate": 4.573871733966746e-05,
      "loss": 0.6868,
      "step": 18660
    },
    {
      "epoch": 8.87,
      "learning_rate": 4.554869358669834e-05,
      "loss": 0.6991,
      "step": 18670
    },
    {
      "epoch": 8.87,
      "learning_rate": 4.5358669833729216e-05,
      "loss": 0.6844,
      "step": 18680
    },
    {
      "epoch": 8.88,
      "learning_rate": 4.51686460807601e-05,
      "loss": 0.6844,
      "step": 18690
    },
    {
      "epoch": 8.88,
      "learning_rate": 4.497862232779097e-05,
      "loss": 0.6879,
      "step": 18700
    },
    {
      "epoch": 8.89,
      "learning_rate": 4.4788598574821855e-05,
      "loss": 0.676,
      "step": 18710
    },
    {
      "epoch": 8.89,
      "learning_rate": 4.459857482185274e-05,
      "loss": 0.677,
      "step": 18720
    },
    {
      "epoch": 8.9,
      "learning_rate": 4.440855106888361e-05,
      "loss": 0.683,
      "step": 18730
    },
    {
      "epoch": 8.9,
      "learning_rate": 4.4218527315914494e-05,
      "loss": 0.6715,
      "step": 18740
    },
    {
      "epoch": 8.91,
      "learning_rate": 4.402850356294537e-05,
      "loss": 0.685,
      "step": 18750
    },
    {
      "epoch": 8.91,
      "learning_rate": 4.383847980997625e-05,
      "loss": 0.6973,
      "step": 18760
    },
    {
      "epoch": 8.92,
      "learning_rate": 4.364845605700713e-05,
      "loss": 0.6798,
      "step": 18770
    },
    {
      "epoch": 8.92,
      "learning_rate": 4.3458432304038e-05,
      "loss": 0.6868,
      "step": 18780
    },
    {
      "epoch": 8.93,
      "learning_rate": 4.3268408551068884e-05,
      "loss": 0.6704,
      "step": 18790
    },
    {
      "epoch": 8.93,
      "learning_rate": 4.3078384798099766e-05,
      "loss": 0.677,
      "step": 18800
    },
    {
      "epoch": 8.94,
      "learning_rate": 4.288836104513064e-05,
      "loss": 0.6853,
      "step": 18810
    },
    {
      "epoch": 8.94,
      "learning_rate": 4.269833729216152e-05,
      "loss": 0.6869,
      "step": 18820
    },
    {
      "epoch": 8.95,
      "learning_rate": 4.25083135391924e-05,
      "loss": 0.6928,
      "step": 18830
    },
    {
      "epoch": 8.95,
      "learning_rate": 4.231828978622328e-05,
      "loss": 0.6743,
      "step": 18840
    },
    {
      "epoch": 8.95,
      "learning_rate": 4.212826603325416e-05,
      "loss": 0.6761,
      "step": 18850
    },
    {
      "epoch": 8.96,
      "learning_rate": 4.193824228028504e-05,
      "loss": 0.6751,
      "step": 18860
    },
    {
      "epoch": 8.96,
      "learning_rate": 4.174821852731592e-05,
      "loss": 0.6837,
      "step": 18870
    },
    {
      "epoch": 8.97,
      "learning_rate": 4.1558194774346795e-05,
      "loss": 0.694,
      "step": 18880
    },
    {
      "epoch": 8.97,
      "learning_rate": 4.136817102137767e-05,
      "loss": 0.6767,
      "step": 18890
    },
    {
      "epoch": 8.98,
      "learning_rate": 4.117814726840855e-05,
      "loss": 0.6791,
      "step": 18900
    },
    {
      "epoch": 8.98,
      "learning_rate": 4.098812351543943e-05,
      "loss": 0.6797,
      "step": 18910
    },
    {
      "epoch": 8.99,
      "learning_rate": 4.079809976247031e-05,
      "loss": 0.7051,
      "step": 18920
    },
    {
      "epoch": 8.99,
      "learning_rate": 4.060807600950119e-05,
      "loss": 0.6872,
      "step": 18930
    },
    {
      "epoch": 9.0,
      "learning_rate": 4.041805225653207e-05,
      "loss": 0.6783,
      "step": 18940
    },
    {
      "epoch": 9.0,
      "learning_rate": 4.022802850356295e-05,
      "loss": 0.6894,
      "step": 18950
    },
    {
      "epoch": 9.01,
      "learning_rate": 4.0038004750593824e-05,
      "loss": 0.6902,
      "step": 18960
    },
    {
      "epoch": 9.01,
      "learning_rate": 3.9847980997624706e-05,
      "loss": 0.6994,
      "step": 18970
    },
    {
      "epoch": 9.02,
      "learning_rate": 3.965795724465559e-05,
      "loss": 0.6816,
      "step": 18980
    },
    {
      "epoch": 9.02,
      "learning_rate": 3.9467933491686463e-05,
      "loss": 0.69,
      "step": 18990
    },
    {
      "epoch": 9.03,
      "learning_rate": 3.927790973871734e-05,
      "loss": 0.6883,
      "step": 19000
    },
    {
      "epoch": 9.03,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7037398219108582,
      "eval_runtime": 0.5343,
      "eval_samples_per_second": 1632.172,
      "eval_steps_per_second": 13.102,
      "step": 19000
    },
    {
      "epoch": 9.03,
      "learning_rate": 3.908788598574822e-05,
      "loss": 0.6961,
      "step": 19010
    },
    {
      "epoch": 9.04,
      "learning_rate": 3.8897862232779096e-05,
      "loss": 0.6768,
      "step": 19020
    },
    {
      "epoch": 9.04,
      "learning_rate": 3.870783847980998e-05,
      "loss": 0.6788,
      "step": 19030
    },
    {
      "epoch": 9.05,
      "learning_rate": 3.851781472684085e-05,
      "loss": 0.686,
      "step": 19040
    },
    {
      "epoch": 9.05,
      "learning_rate": 3.8327790973871735e-05,
      "loss": 0.6936,
      "step": 19050
    },
    {
      "epoch": 9.05,
      "learning_rate": 3.813776722090262e-05,
      "loss": 0.6878,
      "step": 19060
    },
    {
      "epoch": 9.06,
      "learning_rate": 3.794774346793349e-05,
      "loss": 0.6814,
      "step": 19070
    },
    {
      "epoch": 9.06,
      "learning_rate": 3.7757719714964374e-05,
      "loss": 0.7004,
      "step": 19080
    },
    {
      "epoch": 9.07,
      "learning_rate": 3.756769596199525e-05,
      "loss": 0.6818,
      "step": 19090
    },
    {
      "epoch": 9.07,
      "learning_rate": 3.737767220902613e-05,
      "loss": 0.6914,
      "step": 19100
    },
    {
      "epoch": 9.08,
      "learning_rate": 3.7187648456057014e-05,
      "loss": 0.6905,
      "step": 19110
    },
    {
      "epoch": 9.08,
      "learning_rate": 3.699762470308788e-05,
      "loss": 0.6957,
      "step": 19120
    },
    {
      "epoch": 9.09,
      "learning_rate": 3.6807600950118764e-05,
      "loss": 0.6827,
      "step": 19130
    },
    {
      "epoch": 9.09,
      "learning_rate": 3.6617577197149646e-05,
      "loss": 0.6836,
      "step": 19140
    },
    {
      "epoch": 9.1,
      "learning_rate": 3.642755344418052e-05,
      "loss": 0.6859,
      "step": 19150
    },
    {
      "epoch": 9.1,
      "learning_rate": 3.6237529691211403e-05,
      "loss": 0.6912,
      "step": 19160
    },
    {
      "epoch": 9.11,
      "learning_rate": 3.604750593824228e-05,
      "loss": 0.6742,
      "step": 19170
    },
    {
      "epoch": 9.11,
      "learning_rate": 3.585748218527316e-05,
      "loss": 0.6842,
      "step": 19180
    },
    {
      "epoch": 9.12,
      "learning_rate": 3.566745843230404e-05,
      "loss": 0.6925,
      "step": 19190
    },
    {
      "epoch": 9.12,
      "learning_rate": 3.547743467933492e-05,
      "loss": 0.6985,
      "step": 19200
    },
    {
      "epoch": 9.13,
      "learning_rate": 3.52874109263658e-05,
      "loss": 0.6931,
      "step": 19210
    },
    {
      "epoch": 9.13,
      "learning_rate": 3.5097387173396675e-05,
      "loss": 0.6829,
      "step": 19220
    },
    {
      "epoch": 9.14,
      "learning_rate": 3.490736342042755e-05,
      "loss": 0.6871,
      "step": 19230
    },
    {
      "epoch": 9.14,
      "learning_rate": 3.471733966745843e-05,
      "loss": 0.6917,
      "step": 19240
    },
    {
      "epoch": 9.14,
      "learning_rate": 3.452731591448931e-05,
      "loss": 0.6873,
      "step": 19250
    },
    {
      "epoch": 9.15,
      "learning_rate": 3.433729216152019e-05,
      "loss": 0.6841,
      "step": 19260
    },
    {
      "epoch": 9.15,
      "learning_rate": 3.414726840855107e-05,
      "loss": 0.6929,
      "step": 19270
    },
    {
      "epoch": 9.16,
      "learning_rate": 3.395724465558195e-05,
      "loss": 0.6719,
      "step": 19280
    },
    {
      "epoch": 9.16,
      "learning_rate": 3.376722090261283e-05,
      "loss": 0.6705,
      "step": 19290
    },
    {
      "epoch": 9.17,
      "learning_rate": 3.357719714964371e-05,
      "loss": 0.6984,
      "step": 19300
    },
    {
      "epoch": 9.17,
      "learning_rate": 3.3387173396674586e-05,
      "loss": 0.6961,
      "step": 19310
    },
    {
      "epoch": 9.18,
      "learning_rate": 3.319714964370547e-05,
      "loss": 0.6995,
      "step": 19320
    },
    {
      "epoch": 9.18,
      "learning_rate": 3.3007125890736344e-05,
      "loss": 0.6879,
      "step": 19330
    },
    {
      "epoch": 9.19,
      "learning_rate": 3.2817102137767226e-05,
      "loss": 0.6764,
      "step": 19340
    },
    {
      "epoch": 9.19,
      "learning_rate": 3.26270783847981e-05,
      "loss": 0.6871,
      "step": 19350
    },
    {
      "epoch": 9.2,
      "learning_rate": 3.2437054631828976e-05,
      "loss": 0.6938,
      "step": 19360
    },
    {
      "epoch": 9.2,
      "learning_rate": 3.224703087885986e-05,
      "loss": 0.6932,
      "step": 19370
    },
    {
      "epoch": 9.21,
      "learning_rate": 3.205700712589074e-05,
      "loss": 0.688,
      "step": 19380
    },
    {
      "epoch": 9.21,
      "learning_rate": 3.1866983372921615e-05,
      "loss": 0.6936,
      "step": 19390
    },
    {
      "epoch": 9.22,
      "learning_rate": 3.16769596199525e-05,
      "loss": 0.6919,
      "step": 19400
    },
    {
      "epoch": 9.22,
      "learning_rate": 3.148693586698337e-05,
      "loss": 0.6797,
      "step": 19410
    },
    {
      "epoch": 9.23,
      "learning_rate": 3.1296912114014255e-05,
      "loss": 0.6822,
      "step": 19420
    },
    {
      "epoch": 9.23,
      "learning_rate": 3.1106888361045137e-05,
      "loss": 0.6897,
      "step": 19430
    },
    {
      "epoch": 9.24,
      "learning_rate": 3.091686460807601e-05,
      "loss": 0.6809,
      "step": 19440
    },
    {
      "epoch": 9.24,
      "learning_rate": 3.0726840855106894e-05,
      "loss": 0.6855,
      "step": 19450
    },
    {
      "epoch": 9.24,
      "learning_rate": 3.053681710213777e-05,
      "loss": 0.6843,
      "step": 19460
    },
    {
      "epoch": 9.25,
      "learning_rate": 3.0346793349168644e-05,
      "loss": 0.6767,
      "step": 19470
    },
    {
      "epoch": 9.25,
      "learning_rate": 3.0156769596199523e-05,
      "loss": 0.6913,
      "step": 19480
    },
    {
      "epoch": 9.26,
      "learning_rate": 2.9966745843230405e-05,
      "loss": 0.6823,
      "step": 19490
    },
    {
      "epoch": 9.26,
      "learning_rate": 2.9776722090261284e-05,
      "loss": 0.6974,
      "step": 19500
    },
    {
      "epoch": 9.26,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.70308917760849,
      "eval_runtime": 0.4987,
      "eval_samples_per_second": 1748.628,
      "eval_steps_per_second": 14.037,
      "step": 19500
    },
    {
      "epoch": 9.27,
      "learning_rate": 2.9586698337292162e-05,
      "loss": 0.6879,
      "step": 19510
    },
    {
      "epoch": 9.27,
      "learning_rate": 2.939667458432304e-05,
      "loss": 0.6891,
      "step": 19520
    },
    {
      "epoch": 9.28,
      "learning_rate": 2.920665083135392e-05,
      "loss": 0.684,
      "step": 19530
    },
    {
      "epoch": 9.28,
      "learning_rate": 2.90166270783848e-05,
      "loss": 0.6846,
      "step": 19540
    },
    {
      "epoch": 9.29,
      "learning_rate": 2.882660332541568e-05,
      "loss": 0.681,
      "step": 19550
    },
    {
      "epoch": 9.29,
      "learning_rate": 2.863657957244656e-05,
      "loss": 0.6861,
      "step": 19560
    },
    {
      "epoch": 9.3,
      "learning_rate": 2.8446555819477437e-05,
      "loss": 0.6988,
      "step": 19570
    },
    {
      "epoch": 9.3,
      "learning_rate": 2.8256532066508313e-05,
      "loss": 0.6789,
      "step": 19580
    },
    {
      "epoch": 9.31,
      "learning_rate": 2.806650831353919e-05,
      "loss": 0.6869,
      "step": 19590
    },
    {
      "epoch": 9.31,
      "learning_rate": 2.787648456057007e-05,
      "loss": 0.6787,
      "step": 19600
    },
    {
      "epoch": 9.32,
      "learning_rate": 2.7686460807600952e-05,
      "loss": 0.6953,
      "step": 19610
    },
    {
      "epoch": 9.32,
      "learning_rate": 2.749643705463183e-05,
      "loss": 0.6847,
      "step": 19620
    },
    {
      "epoch": 9.33,
      "learning_rate": 2.730641330166271e-05,
      "loss": 0.6839,
      "step": 19630
    },
    {
      "epoch": 9.33,
      "learning_rate": 2.7116389548693588e-05,
      "loss": 0.6717,
      "step": 19640
    },
    {
      "epoch": 9.33,
      "learning_rate": 2.6926365795724466e-05,
      "loss": 0.6888,
      "step": 19650
    },
    {
      "epoch": 9.34,
      "learning_rate": 2.673634204275535e-05,
      "loss": 0.6885,
      "step": 19660
    },
    {
      "epoch": 9.34,
      "learning_rate": 2.6546318289786227e-05,
      "loss": 0.6866,
      "step": 19670
    },
    {
      "epoch": 9.35,
      "learning_rate": 2.6356294536817106e-05,
      "loss": 0.6916,
      "step": 19680
    },
    {
      "epoch": 9.35,
      "learning_rate": 2.6166270783847984e-05,
      "loss": 0.696,
      "step": 19690
    },
    {
      "epoch": 9.36,
      "learning_rate": 2.597624703087886e-05,
      "loss": 0.6755,
      "step": 19700
    },
    {
      "epoch": 9.36,
      "learning_rate": 2.5786223277909738e-05,
      "loss": 0.6931,
      "step": 19710
    },
    {
      "epoch": 9.37,
      "learning_rate": 2.5596199524940617e-05,
      "loss": 0.6817,
      "step": 19720
    },
    {
      "epoch": 9.37,
      "learning_rate": 2.5406175771971495e-05,
      "loss": 0.6834,
      "step": 19730
    },
    {
      "epoch": 9.38,
      "learning_rate": 2.5216152019002377e-05,
      "loss": 0.6941,
      "step": 19740
    },
    {
      "epoch": 9.38,
      "learning_rate": 2.5026128266033256e-05,
      "loss": 0.6783,
      "step": 19750
    },
    {
      "epoch": 9.39,
      "learning_rate": 2.4836104513064135e-05,
      "loss": 0.6892,
      "step": 19760
    },
    {
      "epoch": 9.39,
      "learning_rate": 2.4646080760095013e-05,
      "loss": 0.6893,
      "step": 19770
    },
    {
      "epoch": 9.4,
      "learning_rate": 2.4456057007125892e-05,
      "loss": 0.6798,
      "step": 19780
    },
    {
      "epoch": 9.4,
      "learning_rate": 2.426603325415677e-05,
      "loss": 0.6894,
      "step": 19790
    },
    {
      "epoch": 9.41,
      "learning_rate": 2.407600950118765e-05,
      "loss": 0.6868,
      "step": 19800
    },
    {
      "epoch": 9.41,
      "learning_rate": 2.3885985748218528e-05,
      "loss": 0.686,
      "step": 19810
    },
    {
      "epoch": 9.42,
      "learning_rate": 2.3695961995249406e-05,
      "loss": 0.688,
      "step": 19820
    },
    {
      "epoch": 9.42,
      "learning_rate": 2.350593824228029e-05,
      "loss": 0.691,
      "step": 19830
    },
    {
      "epoch": 9.43,
      "learning_rate": 2.3315914489311167e-05,
      "loss": 0.6874,
      "step": 19840
    },
    {
      "epoch": 9.43,
      "learning_rate": 2.3125890736342042e-05,
      "loss": 0.6839,
      "step": 19850
    },
    {
      "epoch": 9.43,
      "learning_rate": 2.293586698337292e-05,
      "loss": 0.6984,
      "step": 19860
    },
    {
      "epoch": 9.44,
      "learning_rate": 2.2745843230403803e-05,
      "loss": 0.6799,
      "step": 19870
    },
    {
      "epoch": 9.44,
      "learning_rate": 2.255581947743468e-05,
      "loss": 0.6788,
      "step": 19880
    },
    {
      "epoch": 9.45,
      "learning_rate": 2.236579572446556e-05,
      "loss": 0.6842,
      "step": 19890
    },
    {
      "epoch": 9.45,
      "learning_rate": 2.2175771971496435e-05,
      "loss": 0.6808,
      "step": 19900
    },
    {
      "epoch": 9.46,
      "learning_rate": 2.1985748218527317e-05,
      "loss": 0.6924,
      "step": 19910
    },
    {
      "epoch": 9.46,
      "learning_rate": 2.1795724465558196e-05,
      "loss": 0.6888,
      "step": 19920
    },
    {
      "epoch": 9.47,
      "learning_rate": 2.1605700712589075e-05,
      "loss": 0.6832,
      "step": 19930
    },
    {
      "epoch": 9.47,
      "learning_rate": 2.1415676959619953e-05,
      "loss": 0.6926,
      "step": 19940
    },
    {
      "epoch": 9.48,
      "learning_rate": 2.1225653206650832e-05,
      "loss": 0.6884,
      "step": 19950
    },
    {
      "epoch": 9.48,
      "learning_rate": 2.103562945368171e-05,
      "loss": 0.6827,
      "step": 19960
    },
    {
      "epoch": 9.49,
      "learning_rate": 2.084560570071259e-05,
      "loss": 0.6883,
      "step": 19970
    },
    {
      "epoch": 9.49,
      "learning_rate": 2.0655581947743468e-05,
      "loss": 0.6896,
      "step": 19980
    },
    {
      "epoch": 9.5,
      "learning_rate": 2.0465558194774346e-05,
      "loss": 0.6866,
      "step": 19990
    },
    {
      "epoch": 9.5,
      "learning_rate": 2.027553444180523e-05,
      "loss": 0.6805,
      "step": 20000
    },
    {
      "epoch": 9.5,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7013779282569885,
      "eval_runtime": 0.498,
      "eval_samples_per_second": 1751.075,
      "eval_steps_per_second": 14.057,
      "step": 20000
    },
    {
      "epoch": 9.51,
      "learning_rate": 2.0085510688836107e-05,
      "loss": 0.6839,
      "step": 20010
    },
    {
      "epoch": 9.51,
      "learning_rate": 1.9895486935866982e-05,
      "loss": 0.679,
      "step": 20020
    },
    {
      "epoch": 9.52,
      "learning_rate": 1.970546318289786e-05,
      "loss": 0.6821,
      "step": 20030
    },
    {
      "epoch": 9.52,
      "learning_rate": 1.9515439429928743e-05,
      "loss": 0.6807,
      "step": 20040
    },
    {
      "epoch": 9.52,
      "learning_rate": 1.932541567695962e-05,
      "loss": 0.6904,
      "step": 20050
    },
    {
      "epoch": 9.53,
      "learning_rate": 1.91353919239905e-05,
      "loss": 0.6792,
      "step": 20060
    },
    {
      "epoch": 9.53,
      "learning_rate": 1.894536817102138e-05,
      "loss": 0.6964,
      "step": 20070
    },
    {
      "epoch": 9.54,
      "learning_rate": 1.8755344418052257e-05,
      "loss": 0.6858,
      "step": 20080
    },
    {
      "epoch": 9.54,
      "learning_rate": 1.8565320665083136e-05,
      "loss": 0.6885,
      "step": 20090
    },
    {
      "epoch": 9.55,
      "learning_rate": 1.8375296912114015e-05,
      "loss": 0.6818,
      "step": 20100
    },
    {
      "epoch": 9.55,
      "learning_rate": 1.8185273159144893e-05,
      "loss": 0.674,
      "step": 20110
    },
    {
      "epoch": 9.56,
      "learning_rate": 1.7995249406175775e-05,
      "loss": 0.6823,
      "step": 20120
    },
    {
      "epoch": 9.56,
      "learning_rate": 1.7805225653206654e-05,
      "loss": 0.6823,
      "step": 20130
    },
    {
      "epoch": 9.57,
      "learning_rate": 1.761520190023753e-05,
      "loss": 0.6772,
      "step": 20140
    },
    {
      "epoch": 9.57,
      "learning_rate": 1.7425178147268408e-05,
      "loss": 0.677,
      "step": 20150
    },
    {
      "epoch": 9.58,
      "learning_rate": 1.723515439429929e-05,
      "loss": 0.681,
      "step": 20160
    },
    {
      "epoch": 9.58,
      "learning_rate": 1.704513064133017e-05,
      "loss": 0.6836,
      "step": 20170
    },
    {
      "epoch": 9.59,
      "learning_rate": 1.6855106888361047e-05,
      "loss": 0.6709,
      "step": 20180
    },
    {
      "epoch": 9.59,
      "learning_rate": 1.6665083135391922e-05,
      "loss": 0.6895,
      "step": 20190
    },
    {
      "epoch": 9.6,
      "learning_rate": 1.6475059382422804e-05,
      "loss": 0.6874,
      "step": 20200
    },
    {
      "epoch": 9.6,
      "learning_rate": 1.6285035629453683e-05,
      "loss": 0.6961,
      "step": 20210
    },
    {
      "epoch": 9.61,
      "learning_rate": 1.609501187648456e-05,
      "loss": 0.6924,
      "step": 20220
    },
    {
      "epoch": 9.61,
      "learning_rate": 1.590498812351544e-05,
      "loss": 0.6825,
      "step": 20230
    },
    {
      "epoch": 9.62,
      "learning_rate": 1.571496437054632e-05,
      "loss": 0.6805,
      "step": 20240
    },
    {
      "epoch": 9.62,
      "learning_rate": 1.5524940617577198e-05,
      "loss": 0.6907,
      "step": 20250
    },
    {
      "epoch": 9.62,
      "learning_rate": 1.5334916864608076e-05,
      "loss": 0.6787,
      "step": 20260
    },
    {
      "epoch": 9.63,
      "learning_rate": 1.5144893111638955e-05,
      "loss": 0.6919,
      "step": 20270
    },
    {
      "epoch": 9.63,
      "learning_rate": 1.4954869358669835e-05,
      "loss": 0.6906,
      "step": 20280
    },
    {
      "epoch": 9.64,
      "learning_rate": 1.4764845605700714e-05,
      "loss": 0.6934,
      "step": 20290
    },
    {
      "epoch": 9.64,
      "learning_rate": 1.4574821852731594e-05,
      "loss": 0.699,
      "step": 20300
    },
    {
      "epoch": 9.65,
      "learning_rate": 1.438479809976247e-05,
      "loss": 0.6826,
      "step": 20310
    },
    {
      "epoch": 9.65,
      "learning_rate": 1.419477434679335e-05,
      "loss": 0.684,
      "step": 20320
    },
    {
      "epoch": 9.66,
      "learning_rate": 1.4004750593824228e-05,
      "loss": 0.6868,
      "step": 20330
    },
    {
      "epoch": 9.66,
      "learning_rate": 1.3814726840855109e-05,
      "loss": 0.696,
      "step": 20340
    },
    {
      "epoch": 9.67,
      "learning_rate": 1.3624703087885987e-05,
      "loss": 0.6817,
      "step": 20350
    },
    {
      "epoch": 9.67,
      "learning_rate": 1.3434679334916866e-05,
      "loss": 0.6766,
      "step": 20360
    },
    {
      "epoch": 9.68,
      "learning_rate": 1.3244655581947743e-05,
      "loss": 0.6858,
      "step": 20370
    },
    {
      "epoch": 9.68,
      "learning_rate": 1.3054631828978623e-05,
      "loss": 0.6922,
      "step": 20380
    },
    {
      "epoch": 9.69,
      "learning_rate": 1.2864608076009502e-05,
      "loss": 0.6814,
      "step": 20390
    },
    {
      "epoch": 9.69,
      "learning_rate": 1.267458432304038e-05,
      "loss": 0.6724,
      "step": 20400
    },
    {
      "epoch": 9.7,
      "learning_rate": 1.2484560570071259e-05,
      "loss": 0.6805,
      "step": 20410
    },
    {
      "epoch": 9.7,
      "learning_rate": 1.2294536817102138e-05,
      "loss": 0.6949,
      "step": 20420
    },
    {
      "epoch": 9.71,
      "learning_rate": 1.2104513064133018e-05,
      "loss": 0.6821,
      "step": 20430
    },
    {
      "epoch": 9.71,
      "learning_rate": 1.1914489311163895e-05,
      "loss": 0.6755,
      "step": 20440
    },
    {
      "epoch": 9.71,
      "learning_rate": 1.1724465558194775e-05,
      "loss": 0.6863,
      "step": 20450
    },
    {
      "epoch": 9.72,
      "learning_rate": 1.1534441805225654e-05,
      "loss": 0.6791,
      "step": 20460
    },
    {
      "epoch": 9.72,
      "learning_rate": 1.1344418052256532e-05,
      "loss": 0.6901,
      "step": 20470
    },
    {
      "epoch": 9.73,
      "learning_rate": 1.1154394299287411e-05,
      "loss": 0.6979,
      "step": 20480
    },
    {
      "epoch": 9.73,
      "learning_rate": 1.0964370546318291e-05,
      "loss": 0.6722,
      "step": 20490
    },
    {
      "epoch": 9.74,
      "learning_rate": 1.0774346793349168e-05,
      "loss": 0.6784,
      "step": 20500
    },
    {
      "epoch": 9.74,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7039822936058044,
      "eval_runtime": 0.4982,
      "eval_samples_per_second": 1750.244,
      "eval_steps_per_second": 14.05,
      "step": 20500
    },
    {
      "epoch": 9.74,
      "learning_rate": 1.0584323040380049e-05,
      "loss": 0.6709,
      "step": 20510
    },
    {
      "epoch": 9.75,
      "learning_rate": 1.0394299287410927e-05,
      "loss": 0.6831,
      "step": 20520
    },
    {
      "epoch": 9.75,
      "learning_rate": 1.0204275534441806e-05,
      "loss": 0.6956,
      "step": 20530
    },
    {
      "epoch": 9.76,
      "learning_rate": 1.0014251781472684e-05,
      "loss": 0.6899,
      "step": 20540
    },
    {
      "epoch": 9.76,
      "learning_rate": 9.824228028503565e-06,
      "loss": 0.6957,
      "step": 20550
    },
    {
      "epoch": 9.77,
      "learning_rate": 9.634204275534442e-06,
      "loss": 0.6829,
      "step": 20560
    },
    {
      "epoch": 9.77,
      "learning_rate": 9.444180522565322e-06,
      "loss": 0.6904,
      "step": 20570
    },
    {
      "epoch": 9.78,
      "learning_rate": 9.2541567695962e-06,
      "loss": 0.676,
      "step": 20580
    },
    {
      "epoch": 9.78,
      "learning_rate": 9.06413301662708e-06,
      "loss": 0.6725,
      "step": 20590
    },
    {
      "epoch": 9.79,
      "learning_rate": 8.874109263657958e-06,
      "loss": 0.6749,
      "step": 20600
    },
    {
      "epoch": 9.79,
      "learning_rate": 8.684085510688837e-06,
      "loss": 0.6707,
      "step": 20610
    },
    {
      "epoch": 9.8,
      "learning_rate": 8.494061757719715e-06,
      "loss": 0.6857,
      "step": 20620
    },
    {
      "epoch": 9.8,
      "learning_rate": 8.304038004750594e-06,
      "loss": 0.6877,
      "step": 20630
    },
    {
      "epoch": 9.81,
      "learning_rate": 8.114014251781472e-06,
      "loss": 0.6938,
      "step": 20640
    },
    {
      "epoch": 9.81,
      "learning_rate": 7.923990498812351e-06,
      "loss": 0.6841,
      "step": 20650
    },
    {
      "epoch": 9.81,
      "learning_rate": 7.733966745843231e-06,
      "loss": 0.6862,
      "step": 20660
    },
    {
      "epoch": 9.82,
      "learning_rate": 7.543942992874109e-06,
      "loss": 0.691,
      "step": 20670
    },
    {
      "epoch": 9.82,
      "learning_rate": 7.353919239904989e-06,
      "loss": 0.7013,
      "step": 20680
    },
    {
      "epoch": 9.83,
      "learning_rate": 7.163895486935867e-06,
      "loss": 0.6811,
      "step": 20690
    },
    {
      "epoch": 9.83,
      "learning_rate": 6.973871733966746e-06,
      "loss": 0.6891,
      "step": 20700
    },
    {
      "epoch": 9.84,
      "learning_rate": 6.7838479809976245e-06,
      "loss": 0.6859,
      "step": 20710
    },
    {
      "epoch": 9.84,
      "learning_rate": 6.593824228028504e-06,
      "loss": 0.6931,
      "step": 20720
    },
    {
      "epoch": 9.85,
      "learning_rate": 6.403800475059382e-06,
      "loss": 0.6892,
      "step": 20730
    },
    {
      "epoch": 9.85,
      "learning_rate": 6.213776722090261e-06,
      "loss": 0.6977,
      "step": 20740
    },
    {
      "epoch": 9.86,
      "learning_rate": 6.02375296912114e-06,
      "loss": 0.6989,
      "step": 20750
    },
    {
      "epoch": 9.86,
      "learning_rate": 5.833729216152019e-06,
      "loss": 0.6928,
      "step": 20760
    },
    {
      "epoch": 9.87,
      "learning_rate": 5.643705463182898e-06,
      "loss": 0.6945,
      "step": 20770
    },
    {
      "epoch": 9.87,
      "learning_rate": 5.453681710213777e-06,
      "loss": 0.6877,
      "step": 20780
    },
    {
      "epoch": 9.88,
      "learning_rate": 5.263657957244656e-06,
      "loss": 0.6837,
      "step": 20790
    },
    {
      "epoch": 9.88,
      "learning_rate": 5.073634204275535e-06,
      "loss": 0.6936,
      "step": 20800
    },
    {
      "epoch": 9.89,
      "learning_rate": 4.883610451306413e-06,
      "loss": 0.6827,
      "step": 20810
    },
    {
      "epoch": 9.89,
      "learning_rate": 4.693586698337293e-06,
      "loss": 0.6902,
      "step": 20820
    },
    {
      "epoch": 9.9,
      "learning_rate": 4.5035629453681715e-06,
      "loss": 0.6943,
      "step": 20830
    },
    {
      "epoch": 9.9,
      "learning_rate": 4.31353919239905e-06,
      "loss": 0.6872,
      "step": 20840
    },
    {
      "epoch": 9.9,
      "learning_rate": 4.1235154394299296e-06,
      "loss": 0.675,
      "step": 20850
    },
    {
      "epoch": 9.91,
      "learning_rate": 3.933491686460808e-06,
      "loss": 0.6866,
      "step": 20860
    },
    {
      "epoch": 9.91,
      "learning_rate": 3.7434679334916864e-06,
      "loss": 0.6893,
      "step": 20870
    },
    {
      "epoch": 9.92,
      "learning_rate": 3.553444180522565e-06,
      "loss": 0.6867,
      "step": 20880
    },
    {
      "epoch": 9.92,
      "learning_rate": 3.3634204275534445e-06,
      "loss": 0.6818,
      "step": 20890
    },
    {
      "epoch": 9.93,
      "learning_rate": 3.173396674584323e-06,
      "loss": 0.7123,
      "step": 20900
    },
    {
      "epoch": 9.93,
      "learning_rate": 2.983372921615202e-06,
      "loss": 0.6984,
      "step": 20910
    },
    {
      "epoch": 9.94,
      "learning_rate": 2.793349168646081e-06,
      "loss": 0.6851,
      "step": 20920
    },
    {
      "epoch": 9.94,
      "learning_rate": 2.60332541567696e-06,
      "loss": 0.6987,
      "step": 20930
    },
    {
      "epoch": 9.95,
      "learning_rate": 2.413301662707839e-06,
      "loss": 0.6924,
      "step": 20940
    },
    {
      "epoch": 9.95,
      "learning_rate": 2.2232779097387175e-06,
      "loss": 0.6852,
      "step": 20950
    },
    {
      "epoch": 9.96,
      "learning_rate": 2.033254156769596e-06,
      "loss": 0.6837,
      "step": 20960
    },
    {
      "epoch": 9.96,
      "learning_rate": 1.8432304038004752e-06,
      "loss": 0.6972,
      "step": 20970
    },
    {
      "epoch": 9.97,
      "learning_rate": 1.653206650831354e-06,
      "loss": 0.6831,
      "step": 20980
    },
    {
      "epoch": 9.97,
      "learning_rate": 1.4631828978622329e-06,
      "loss": 0.677,
      "step": 20990
    },
    {
      "epoch": 9.98,
      "learning_rate": 1.2731591448931117e-06,
      "loss": 0.6855,
      "step": 21000
    },
    {
      "epoch": 9.98,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7033109068870544,
      "eval_runtime": 0.5008,
      "eval_samples_per_second": 1741.301,
      "eval_steps_per_second": 13.978,
      "step": 21000
    },
    {
      "epoch": 9.98,
      "learning_rate": 1.0831353919239906e-06,
      "loss": 0.6932,
      "step": 21010
    },
    {
      "epoch": 9.99,
      "learning_rate": 8.931116389548694e-07,
      "loss": 0.6926,
      "step": 21020
    },
    {
      "epoch": 9.99,
      "learning_rate": 7.030878859857482e-07,
      "loss": 0.6807,
      "step": 21030
    },
    {
      "epoch": 10.0,
      "learning_rate": 5.130641330166272e-07,
      "loss": 0.681,
      "step": 21040
    },
    {
      "epoch": 10.0,
      "learning_rate": 3.2304038004750596e-07,
      "loss": 0.6829,
      "step": 21050
    },
    {
      "epoch": 10.0,
      "step": 21050,
      "total_flos": 4.475948005653504e+16,
      "train_loss": 0.6741501155545196,
      "train_runtime": 1320.5136,
      "train_samples_per_second": 510.021,
      "train_steps_per_second": 15.941
    }
  ],
  "logging_steps": 10,
  "max_steps": 21050,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 4.475948005653504e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
