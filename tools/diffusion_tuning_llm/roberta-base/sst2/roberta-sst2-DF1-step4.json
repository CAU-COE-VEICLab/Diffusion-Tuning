{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 21050,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 0.00019993349168646082,
      "loss": 0.2198,
      "step": 10
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.00019983847980997626,
      "loss": 0.293,
      "step": 20
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0001997434679334917,
      "loss": 0.266,
      "step": 30
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.00019966745843230405,
      "loss": 0.203,
      "step": 40
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.00019957244655581947,
      "loss": 0.1518,
      "step": 50
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00019947743467933494,
      "loss": 0.2539,
      "step": 60
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00019938242280285036,
      "loss": 0.2804,
      "step": 70
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0001992874109263658,
      "loss": 0.2753,
      "step": 80
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00019919239904988125,
      "loss": 0.2252,
      "step": 90
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00019909738717339666,
      "loss": 0.2422,
      "step": 100
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00019900237529691214,
      "loss": 0.3171,
      "step": 110
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00019890736342042758,
      "loss": 0.22,
      "step": 120
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.000198812351543943,
      "loss": 0.2843,
      "step": 130
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00019871733966745844,
      "loss": 0.2793,
      "step": 140
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00019862232779097389,
      "loss": 0.2747,
      "step": 150
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00019852731591448933,
      "loss": 0.2594,
      "step": 160
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00019843230403800477,
      "loss": 0.2263,
      "step": 170
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0001983372921615202,
      "loss": 0.2593,
      "step": 180
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00019824228028503564,
      "loss": 0.2545,
      "step": 190
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00019814726840855108,
      "loss": 0.2379,
      "step": 200
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00019805225653206652,
      "loss": 0.2095,
      "step": 210
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00019795724465558197,
      "loss": 0.2918,
      "step": 220
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0001978622327790974,
      "loss": 0.2359,
      "step": 230
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00019776722090261283,
      "loss": 0.2183,
      "step": 240
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00019767220902612828,
      "loss": 0.2059,
      "step": 250
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00019757719714964372,
      "loss": 0.2326,
      "step": 260
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00019748218527315916,
      "loss": 0.2717,
      "step": 270
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00019739667458432305,
      "loss": 0.2568,
      "step": 280
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0001973016627078385,
      "loss": 0.2708,
      "step": 290
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00019720665083135393,
      "loss": 0.2251,
      "step": 300
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00019711163895486938,
      "loss": 0.2193,
      "step": 310
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0001970166270783848,
      "loss": 0.2639,
      "step": 320
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00019692161520190024,
      "loss": 0.3005,
      "step": 330
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00019682660332541568,
      "loss": 0.247,
      "step": 340
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00019673159144893113,
      "loss": 0.2819,
      "step": 350
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00019663657957244657,
      "loss": 0.267,
      "step": 360
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00019654156769596202,
      "loss": 0.2323,
      "step": 370
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00019644655581947743,
      "loss": 0.2736,
      "step": 380
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00019635154394299288,
      "loss": 0.256,
      "step": 390
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00019625653206650832,
      "loss": 0.3455,
      "step": 400
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00019616152019002377,
      "loss": 0.2409,
      "step": 410
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0001960665083135392,
      "loss": 0.2571,
      "step": 420
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00019597149643705463,
      "loss": 0.2424,
      "step": 430
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00019587648456057007,
      "loss": 0.3065,
      "step": 440
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00019578147268408552,
      "loss": 0.2386,
      "step": 450
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00019568646080760096,
      "loss": 0.2497,
      "step": 460
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0001955914489311164,
      "loss": 0.2904,
      "step": 470
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00019549643705463182,
      "loss": 0.3073,
      "step": 480
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00019540142517814727,
      "loss": 0.3857,
      "step": 490
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00019531591448931118,
      "loss": 0.2928,
      "step": 500
    },
    {
      "epoch": 0.24,
      "eval_accuracy": 0.8669724770642202,
      "eval_loss": 0.3705439567565918,
      "eval_runtime": 0.5042,
      "eval_samples_per_second": 1729.575,
      "eval_steps_per_second": 13.884,
      "step": 500
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00019522090261282662,
      "loss": 0.2766,
      "step": 510
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00019512589073634204,
      "loss": 0.2931,
      "step": 520
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00019503087885985748,
      "loss": 0.2523,
      "step": 530
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00019493586698337293,
      "loss": 0.27,
      "step": 540
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00019484085510688837,
      "loss": 0.1853,
      "step": 550
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00019474584323040382,
      "loss": 0.3105,
      "step": 560
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00019465083135391923,
      "loss": 0.33,
      "step": 570
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00019455581947743468,
      "loss": 0.208,
      "step": 580
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00019446080760095012,
      "loss": 0.2353,
      "step": 590
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00019436579572446557,
      "loss": 0.3306,
      "step": 600
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.000194270783847981,
      "loss": 0.3227,
      "step": 610
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00019417577197149646,
      "loss": 0.2696,
      "step": 620
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00019408076009501187,
      "loss": 0.2567,
      "step": 630
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00019398574821852732,
      "loss": 0.3167,
      "step": 640
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00019389073634204276,
      "loss": 0.3143,
      "step": 650
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0001937957244655582,
      "loss": 0.2422,
      "step": 660
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00019370071258907365,
      "loss": 0.2281,
      "step": 670
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00019360570071258907,
      "loss": 0.3185,
      "step": 680
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0001935106888361045,
      "loss": 0.258,
      "step": 690
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.00019341567695961996,
      "loss": 0.2984,
      "step": 700
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0001933206650831354,
      "loss": 0.3098,
      "step": 710
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00019322565320665085,
      "loss": 0.3237,
      "step": 720
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00019313064133016626,
      "loss": 0.2865,
      "step": 730
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.00019303562945368173,
      "loss": 0.3286,
      "step": 740
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00019294061757719718,
      "loss": 0.2784,
      "step": 750
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0001928456057007126,
      "loss": 0.2224,
      "step": 760
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00019275059382422804,
      "loss": 0.3098,
      "step": 770
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.00019265558194774346,
      "loss": 0.3431,
      "step": 780
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00019256057007125893,
      "loss": 0.3039,
      "step": 790
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00019246555819477437,
      "loss": 0.2572,
      "step": 800
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0001923705463182898,
      "loss": 0.2496,
      "step": 810
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00019227553444180524,
      "loss": 0.3036,
      "step": 820
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00019218052256532065,
      "loss": 0.3627,
      "step": 830
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00019208551068883612,
      "loss": 0.3234,
      "step": 840
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00019199049881235157,
      "loss": 0.259,
      "step": 850
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00019189548693586699,
      "loss": 0.3001,
      "step": 860
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00019180047505938243,
      "loss": 0.2494,
      "step": 870
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019170546318289787,
      "loss": 0.3282,
      "step": 880
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.00019161045130641332,
      "loss": 0.4214,
      "step": 890
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019151543942992876,
      "loss": 0.308,
      "step": 900
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00019142042755344418,
      "loss": 0.2754,
      "step": 910
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019132541567695962,
      "loss": 0.3096,
      "step": 920
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00019123040380047507,
      "loss": 0.2997,
      "step": 930
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019113539192399051,
      "loss": 0.2926,
      "step": 940
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00019104038004750596,
      "loss": 0.3592,
      "step": 950
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019094536817102138,
      "loss": 0.2779,
      "step": 960
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00019085035629453682,
      "loss": 0.2307,
      "step": 970
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00019075534441805226,
      "loss": 0.2934,
      "step": 980
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0001906603325415677,
      "loss": 0.2925,
      "step": 990
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019056532066508315,
      "loss": 0.3387,
      "step": 1000
    },
    {
      "epoch": 0.48,
      "eval_accuracy": 0.819954128440367,
      "eval_loss": 0.46326762437820435,
      "eval_runtime": 0.4993,
      "eval_samples_per_second": 1746.507,
      "eval_steps_per_second": 14.02,
      "step": 1000
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0001904703087885986,
      "loss": 0.2558,
      "step": 1010
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00019037529691211401,
      "loss": 0.3134,
      "step": 1020
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00019028028503562946,
      "loss": 0.3345,
      "step": 1030
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0001901852731591449,
      "loss": 0.3484,
      "step": 1040
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00019009026128266035,
      "loss": 0.3611,
      "step": 1050
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0001899952494061758,
      "loss": 0.3131,
      "step": 1060
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0001899002375296912,
      "loss": 0.2571,
      "step": 1070
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00018980522565320665,
      "loss": 0.3639,
      "step": 1080
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0001897102137767221,
      "loss": 0.2699,
      "step": 1090
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00018961520190023754,
      "loss": 0.2719,
      "step": 1100
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.000189520190023753,
      "loss": 0.3478,
      "step": 1110
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0001894251781472684,
      "loss": 0.401,
      "step": 1120
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.00018933016627078385,
      "loss": 0.3556,
      "step": 1130
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0001892351543942993,
      "loss": 0.3887,
      "step": 1140
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00018914014251781474,
      "loss": 0.3645,
      "step": 1150
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00018904513064133018,
      "loss": 0.329,
      "step": 1160
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0001889501187648456,
      "loss": 0.2843,
      "step": 1170
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00018885510688836104,
      "loss": 0.3621,
      "step": 1180
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00018876009501187652,
      "loss": 0.3582,
      "step": 1190
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00018866508313539193,
      "loss": 0.2746,
      "step": 1200
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.00018857007125890738,
      "loss": 0.362,
      "step": 1210
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0001884750593824228,
      "loss": 0.3484,
      "step": 1220
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.00018838004750593824,
      "loss": 0.3017,
      "step": 1230
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0001882850356294537,
      "loss": 0.3655,
      "step": 1240
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00018819002375296913,
      "loss": 0.3652,
      "step": 1250
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00018809501187648457,
      "loss": 0.3534,
      "step": 1260
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.000188,
      "loss": 0.2916,
      "step": 1270
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00018790498812351543,
      "loss": 0.3598,
      "step": 1280
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0001878099762470309,
      "loss": 0.3367,
      "step": 1290
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018771496437054632,
      "loss": 0.2933,
      "step": 1300
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00018761995249406177,
      "loss": 0.3394,
      "step": 1310
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0001875249406175772,
      "loss": 0.285,
      "step": 1320
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00018742992874109266,
      "loss": 0.3262,
      "step": 1330
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0001873349168646081,
      "loss": 0.3196,
      "step": 1340
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00018723990498812352,
      "loss": 0.3138,
      "step": 1350
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00018714489311163896,
      "loss": 0.2815,
      "step": 1360
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0001870498812351544,
      "loss": 0.2969,
      "step": 1370
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00018695486935866985,
      "loss": 0.3103,
      "step": 1380
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0001868598574821853,
      "loss": 0.3377,
      "step": 1390
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0001867648456057007,
      "loss": 0.3549,
      "step": 1400
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00018666983372921616,
      "loss": 0.3189,
      "step": 1410
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0001865748218527316,
      "loss": 0.2895,
      "step": 1420
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00018647980997624705,
      "loss": 0.2212,
      "step": 1430
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0001863847980997625,
      "loss": 0.3264,
      "step": 1440
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018628978622327793,
      "loss": 0.3551,
      "step": 1450
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00018619477434679335,
      "loss": 0.3085,
      "step": 1460
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0001860997624703088,
      "loss": 0.2965,
      "step": 1470
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00018600475059382424,
      "loss": 0.3123,
      "step": 1480
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00018590973871733968,
      "loss": 0.2804,
      "step": 1490
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00018581472684085513,
      "loss": 0.3395,
      "step": 1500
    },
    {
      "epoch": 0.71,
      "eval_accuracy": 0.8279816513761468,
      "eval_loss": 0.47130510210990906,
      "eval_runtime": 0.5659,
      "eval_samples_per_second": 1540.911,
      "eval_steps_per_second": 12.37,
      "step": 1500
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00018571971496437055,
      "loss": 0.3222,
      "step": 1510
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.000185624703087886,
      "loss": 0.2785,
      "step": 1520
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00018552969121140143,
      "loss": 0.3036,
      "step": 1530
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00018543467933491688,
      "loss": 0.3175,
      "step": 1540
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00018533966745843232,
      "loss": 0.2798,
      "step": 1550
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.00018524465558194774,
      "loss": 0.393,
      "step": 1560
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00018514964370546319,
      "loss": 0.2772,
      "step": 1570
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00018505463182897863,
      "loss": 0.3683,
      "step": 1580
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00018495961995249407,
      "loss": 0.3142,
      "step": 1590
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00018486460807600952,
      "loss": 0.3385,
      "step": 1600
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.00018476959619952494,
      "loss": 0.2538,
      "step": 1610
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00018467458432304038,
      "loss": 0.2708,
      "step": 1620
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00018457957244655582,
      "loss": 0.4076,
      "step": 1630
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.00018448456057007127,
      "loss": 0.2945,
      "step": 1640
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0001843895486935867,
      "loss": 0.3285,
      "step": 1650
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00018429453681710213,
      "loss": 0.3103,
      "step": 1660
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00018419952494061758,
      "loss": 0.3713,
      "step": 1670
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00018410451306413302,
      "loss": 0.3297,
      "step": 1680
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.00018400950118764846,
      "loss": 0.3754,
      "step": 1690
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0001839144893111639,
      "loss": 0.3895,
      "step": 1700
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00018381947743467935,
      "loss": 0.4185,
      "step": 1710
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00018372446555819477,
      "loss": 0.436,
      "step": 1720
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00018362945368171024,
      "loss": 0.625,
      "step": 1730
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00018354394299287412,
      "loss": 0.5237,
      "step": 1740
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00018344893111638957,
      "loss": 0.5304,
      "step": 1750
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00018335391923990498,
      "loss": 0.4667,
      "step": 1760
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00018325890736342043,
      "loss": 0.4836,
      "step": 1770
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00018316389548693587,
      "loss": 0.4078,
      "step": 1780
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00018306888361045132,
      "loss": 0.4476,
      "step": 1790
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00018297387173396676,
      "loss": 0.4777,
      "step": 1800
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00018287885985748218,
      "loss": 0.4617,
      "step": 1810
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00018278384798099762,
      "loss": 0.3124,
      "step": 1820
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0001826888361045131,
      "loss": 0.3514,
      "step": 1830
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0001825938242280285,
      "loss": 0.3663,
      "step": 1840
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00018249881235154396,
      "loss": 0.4098,
      "step": 1850
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00018240380047505937,
      "loss": 0.3867,
      "step": 1860
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.00018230878859857482,
      "loss": 0.4086,
      "step": 1870
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0001822137767220903,
      "loss": 0.3868,
      "step": 1880
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0001821187648456057,
      "loss": 0.4007,
      "step": 1890
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.00018202375296912115,
      "loss": 0.3164,
      "step": 1900
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00018192874109263657,
      "loss": 0.381,
      "step": 1910
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00018183372921615204,
      "loss": 0.4681,
      "step": 1920
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00018173871733966748,
      "loss": 0.3812,
      "step": 1930
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0001816437054631829,
      "loss": 0.3927,
      "step": 1940
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00018154869358669835,
      "loss": 0.3854,
      "step": 1950
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0001814536817102138,
      "loss": 0.4046,
      "step": 1960
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00018135866983372924,
      "loss": 0.39,
      "step": 1970
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00018126365795724468,
      "loss": 0.433,
      "step": 1980
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0001811686460807601,
      "loss": 0.4473,
      "step": 1990
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00018107363420427554,
      "loss": 0.4422,
      "step": 2000
    },
    {
      "epoch": 0.95,
      "eval_accuracy": 0.7740825688073395,
      "eval_loss": 0.5408520698547363,
      "eval_runtime": 0.5002,
      "eval_samples_per_second": 1743.465,
      "eval_steps_per_second": 13.996,
      "step": 2000
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00018097862232779099,
      "loss": 0.5214,
      "step": 2010
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00018088361045130643,
      "loss": 0.5509,
      "step": 2020
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.00018078859857482187,
      "loss": 0.5254,
      "step": 2030
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0001806935866983373,
      "loss": 0.4614,
      "step": 2040
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00018059857482185274,
      "loss": 0.8778,
      "step": 2050
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00018050356294536818,
      "loss": 0.8238,
      "step": 2060
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00018040855106888362,
      "loss": 0.4647,
      "step": 2070
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00018031353919239907,
      "loss": 0.4208,
      "step": 2080
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0001802185273159145,
      "loss": 0.4509,
      "step": 2090
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00018012351543942993,
      "loss": 0.4309,
      "step": 2100
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00018002850356294538,
      "loss": 0.4348,
      "step": 2110
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00017993349168646082,
      "loss": 0.3859,
      "step": 2120
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00017983847980997626,
      "loss": 0.3161,
      "step": 2130
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0001797434679334917,
      "loss": 0.382,
      "step": 2140
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00017964845605700713,
      "loss": 0.4329,
      "step": 2150
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00017955344418052257,
      "loss": 0.3329,
      "step": 2160
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00017945843230403801,
      "loss": 0.4286,
      "step": 2170
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00017936342042755346,
      "loss": 0.3275,
      "step": 2180
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0001792684085510689,
      "loss": 0.3567,
      "step": 2190
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00017917339667458432,
      "loss": 0.3127,
      "step": 2200
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00017907838479809977,
      "loss": 0.4466,
      "step": 2210
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0001789833729216152,
      "loss": 0.3894,
      "step": 2220
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00017888836104513065,
      "loss": 0.4149,
      "step": 2230
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0001787933491686461,
      "loss": 0.4134,
      "step": 2240
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00017869833729216152,
      "loss": 0.3978,
      "step": 2250
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00017860332541567696,
      "loss": 0.3996,
      "step": 2260
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0001785083135391924,
      "loss": 0.3423,
      "step": 2270
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00017841330166270785,
      "loss": 0.3638,
      "step": 2280
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0001783182897862233,
      "loss": 0.299,
      "step": 2290
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0001782232779097387,
      "loss": 0.5053,
      "step": 2300
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00017812826603325415,
      "loss": 0.48,
      "step": 2310
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.00017803325415676963,
      "loss": 0.3947,
      "step": 2320
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00017793824228028504,
      "loss": 0.4584,
      "step": 2330
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00017785273159144892,
      "loss": 0.2961,
      "step": 2340
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00017775771971496437,
      "loss": 0.3174,
      "step": 2350
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0001776627078384798,
      "loss": 0.351,
      "step": 2360
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.00017756769596199526,
      "loss": 0.3998,
      "step": 2370
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0001774726840855107,
      "loss": 0.3557,
      "step": 2380
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00017737767220902615,
      "loss": 0.3232,
      "step": 2390
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00017728266033254156,
      "loss": 0.2862,
      "step": 2400
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.000177187648456057,
      "loss": 0.2731,
      "step": 2410
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00017710213776722092,
      "loss": 0.3969,
      "step": 2420
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00017700712589073636,
      "loss": 0.3932,
      "step": 2430
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00017691211401425178,
      "loss": 0.3878,
      "step": 2440
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.00017681710213776722,
      "loss": 0.4394,
      "step": 2450
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00017672209026128267,
      "loss": 0.3645,
      "step": 2460
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0001766270783847981,
      "loss": 0.4609,
      "step": 2470
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00017653206650831356,
      "loss": 0.3239,
      "step": 2480
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00017643705463182897,
      "loss": 0.3776,
      "step": 2490
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00017634204275534442,
      "loss": 0.4756,
      "step": 2500
    },
    {
      "epoch": 1.19,
      "eval_accuracy": 0.8451834862385321,
      "eval_loss": 0.45196840167045593,
      "eval_runtime": 0.4991,
      "eval_samples_per_second": 1747.255,
      "eval_steps_per_second": 14.026,
      "step": 2500
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0001762470308788599,
      "loss": 0.3777,
      "step": 2510
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0001761520190023753,
      "loss": 0.2983,
      "step": 2520
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00017605700712589075,
      "loss": 0.3888,
      "step": 2530
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00017596199524940617,
      "loss": 0.4195,
      "step": 2540
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0001758669833729216,
      "loss": 0.3559,
      "step": 2550
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00017577197149643708,
      "loss": 0.4501,
      "step": 2560
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0001756769596199525,
      "loss": 0.3848,
      "step": 2570
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00017558194774346795,
      "loss": 0.4947,
      "step": 2580
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00017548693586698336,
      "loss": 0.4734,
      "step": 2590
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0001753919239904988,
      "loss": 0.5093,
      "step": 2600
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00017529691211401428,
      "loss": 0.4134,
      "step": 2610
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0001752019002375297,
      "loss": 0.4259,
      "step": 2620
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00017510688836104514,
      "loss": 0.4706,
      "step": 2630
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00017501187648456058,
      "loss": 0.4376,
      "step": 2640
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.000174916864608076,
      "loss": 0.3904,
      "step": 2650
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00017482185273159147,
      "loss": 0.3624,
      "step": 2660
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0001747268408551069,
      "loss": 0.385,
      "step": 2670
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00017463182897862234,
      "loss": 0.4866,
      "step": 2680
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00017453681710213778,
      "loss": 0.489,
      "step": 2690
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0001744418052256532,
      "loss": 0.4734,
      "step": 2700
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00017434679334916867,
      "loss": 0.4411,
      "step": 2710
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00017425178147268409,
      "loss": 0.3899,
      "step": 2720
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00017415676959619953,
      "loss": 0.4684,
      "step": 2730
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0001740712589073634,
      "loss": 0.4988,
      "step": 2740
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00017397624703087888,
      "loss": 0.4845,
      "step": 2750
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00017388123515439433,
      "loss": 0.4305,
      "step": 2760
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00017378622327790974,
      "loss": 0.3606,
      "step": 2770
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0001736912114014252,
      "loss": 0.4708,
      "step": 2780
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0001735961995249406,
      "loss": 0.5678,
      "step": 2790
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00017350118764845608,
      "loss": 0.5205,
      "step": 2800
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.00017340617577197152,
      "loss": 0.4711,
      "step": 2810
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00017331116389548694,
      "loss": 0.4906,
      "step": 2820
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00017321615201900238,
      "loss": 0.4601,
      "step": 2830
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0001731211401425178,
      "loss": 0.628,
      "step": 2840
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00017302612826603327,
      "loss": 0.577,
      "step": 2850
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00017293111638954872,
      "loss": 0.5209,
      "step": 2860
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00017283610451306413,
      "loss": 0.4568,
      "step": 2870
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00017274109263657958,
      "loss": 0.457,
      "step": 2880
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00017264608076009502,
      "loss": 0.4816,
      "step": 2890
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.00017255106888361047,
      "loss": 0.481,
      "step": 2900
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0001724560570071259,
      "loss": 0.4866,
      "step": 2910
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00017236104513064133,
      "loss": 0.4688,
      "step": 2920
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00017226603325415677,
      "loss": 0.4763,
      "step": 2930
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00017217102137767222,
      "loss": 0.4634,
      "step": 2940
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.00017207600950118766,
      "loss": 0.4639,
      "step": 2950
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0001719809976247031,
      "loss": 0.4046,
      "step": 2960
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00017188598574821852,
      "loss": 0.4529,
      "step": 2970
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00017179097387173397,
      "loss": 0.4936,
      "step": 2980
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0001716959619952494,
      "loss": 0.4782,
      "step": 2990
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00017160095011876486,
      "loss": 0.5143,
      "step": 3000
    },
    {
      "epoch": 1.43,
      "eval_accuracy": 0.7385321100917431,
      "eval_loss": 0.5266287922859192,
      "eval_runtime": 0.5012,
      "eval_samples_per_second": 1739.748,
      "eval_steps_per_second": 13.966,
      "step": 3000
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0001715059382422803,
      "loss": 0.6201,
      "step": 3010
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00017141092636579575,
      "loss": 0.5603,
      "step": 3020
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00017131591448931116,
      "loss": 0.5658,
      "step": 3030
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0001712209026128266,
      "loss": 0.6011,
      "step": 3040
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00017112589073634205,
      "loss": 0.6316,
      "step": 3050
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0001710308788598575,
      "loss": 0.6337,
      "step": 3060
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00017093586698337294,
      "loss": 0.6697,
      "step": 3070
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00017084085510688836,
      "loss": 0.6496,
      "step": 3080
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0001707458432304038,
      "loss": 0.6905,
      "step": 3090
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00017065083135391925,
      "loss": 0.6896,
      "step": 3100
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0001705558194774347,
      "loss": 0.6923,
      "step": 3110
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00017046080760095014,
      "loss": 0.7053,
      "step": 3120
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00017036579572446555,
      "loss": 0.6897,
      "step": 3130
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.000170270783847981,
      "loss": 0.68,
      "step": 3140
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00017017577197149647,
      "loss": 0.7105,
      "step": 3150
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00017008076009501189,
      "loss": 0.6923,
      "step": 3160
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00016998574821852733,
      "loss": 0.6916,
      "step": 3170
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00016989073634204275,
      "loss": 0.6891,
      "step": 3180
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0001697957244655582,
      "loss": 0.6983,
      "step": 3190
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00016970071258907366,
      "loss": 0.6969,
      "step": 3200
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00016960570071258908,
      "loss": 0.6887,
      "step": 3210
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00016951068883610453,
      "loss": 0.6676,
      "step": 3220
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.00016941567695961994,
      "loss": 0.6954,
      "step": 3230
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0001693206650831354,
      "loss": 0.6894,
      "step": 3240
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00016922565320665086,
      "loss": 0.6838,
      "step": 3250
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00016913064133016628,
      "loss": 0.6922,
      "step": 3260
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.00016903562945368172,
      "loss": 0.69,
      "step": 3270
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00016894061757719714,
      "loss": 0.6877,
      "step": 3280
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00016884560570071258,
      "loss": 0.6955,
      "step": 3290
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00016875059382422805,
      "loss": 0.6956,
      "step": 3300
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00016865558194774347,
      "loss": 0.6837,
      "step": 3310
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00016856057007125891,
      "loss": 0.6907,
      "step": 3320
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.00016846555819477436,
      "loss": 0.6893,
      "step": 3330
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0001683705463182898,
      "loss": 0.6991,
      "step": 3340
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.00016827553444180525,
      "loss": 0.6942,
      "step": 3350
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00016818052256532067,
      "loss": 0.6853,
      "step": 3360
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0001680855106888361,
      "loss": 0.698,
      "step": 3370
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00016799049881235155,
      "loss": 0.6964,
      "step": 3380
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.000167895486935867,
      "loss": 0.699,
      "step": 3390
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00016780047505938244,
      "loss": 0.687,
      "step": 3400
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00016770546318289786,
      "loss": 0.6885,
      "step": 3410
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0001676104513064133,
      "loss": 0.6876,
      "step": 3420
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00016751543942992875,
      "loss": 0.6821,
      "step": 3430
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0001674204275534442,
      "loss": 0.6897,
      "step": 3440
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016732541567695964,
      "loss": 0.6913,
      "step": 3450
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00016723040380047508,
      "loss": 0.6934,
      "step": 3460
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0001671353919239905,
      "loss": 0.6845,
      "step": 3470
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00016704038004750594,
      "loss": 0.6839,
      "step": 3480
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0001669453681710214,
      "loss": 0.6898,
      "step": 3490
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00016685035629453683,
      "loss": 0.6935,
      "step": 3500
    },
    {
      "epoch": 1.66,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.69452965259552,
      "eval_runtime": 0.5002,
      "eval_samples_per_second": 1743.351,
      "eval_steps_per_second": 13.995,
      "step": 3500
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00016675534441805228,
      "loss": 0.6818,
      "step": 3510
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0001666603325415677,
      "loss": 0.7138,
      "step": 3520
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00016656532066508314,
      "loss": 0.6887,
      "step": 3530
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00016647030878859858,
      "loss": 0.6868,
      "step": 3540
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00016637529691211403,
      "loss": 0.7038,
      "step": 3550
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00016628028503562947,
      "loss": 0.6991,
      "step": 3560
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0001661852731591449,
      "loss": 0.693,
      "step": 3570
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00016609026128266033,
      "loss": 0.698,
      "step": 3580
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00016599524940617578,
      "loss": 0.6801,
      "step": 3590
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00016590023752969122,
      "loss": 0.6756,
      "step": 3600
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00016580522565320667,
      "loss": 0.6912,
      "step": 3610
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00016571021377672208,
      "loss": 0.6949,
      "step": 3620
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00016561520190023753,
      "loss": 0.6909,
      "step": 3630
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00016552019002375297,
      "loss": 0.6783,
      "step": 3640
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00016542517814726842,
      "loss": 0.6855,
      "step": 3650
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00016533016627078386,
      "loss": 0.6832,
      "step": 3660
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.00016523515439429928,
      "loss": 0.6812,
      "step": 3670
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00016514014251781472,
      "loss": 0.6887,
      "step": 3680
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00016504513064133017,
      "loss": 0.6797,
      "step": 3690
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0001649501187648456,
      "loss": 0.7103,
      "step": 3700
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00016485510688836106,
      "loss": 0.6789,
      "step": 3710
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0001647600950118765,
      "loss": 0.6912,
      "step": 3720
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.00016466508313539192,
      "loss": 0.7023,
      "step": 3730
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0001645700712589074,
      "loss": 0.682,
      "step": 3740
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0001644750593824228,
      "loss": 0.6936,
      "step": 3750
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.00016438004750593825,
      "loss": 0.6945,
      "step": 3760
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0001642850356294537,
      "loss": 0.6859,
      "step": 3770
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0001641900237529691,
      "loss": 0.6825,
      "step": 3780
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.00016409501187648458,
      "loss": 0.6871,
      "step": 3790
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.000164,
      "loss": 0.6588,
      "step": 3800
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.00016390498812351545,
      "loss": 0.6802,
      "step": 3810
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0001638099762470309,
      "loss": 0.6924,
      "step": 3820
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0001637149643705463,
      "loss": 0.6955,
      "step": 3830
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.00016361995249406178,
      "loss": 0.6982,
      "step": 3840
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.00016352494061757722,
      "loss": 0.6899,
      "step": 3850
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.00016342992874109264,
      "loss": 0.6859,
      "step": 3860
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00016333491686460809,
      "loss": 0.697,
      "step": 3870
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0001632399049881235,
      "loss": 0.6895,
      "step": 3880
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00016314489311163897,
      "loss": 0.6955,
      "step": 3890
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00016304988123515442,
      "loss": 0.6826,
      "step": 3900
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00016295486935866984,
      "loss": 0.6871,
      "step": 3910
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00016285985748218528,
      "loss": 0.6921,
      "step": 3920
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0001627648456057007,
      "loss": 0.6713,
      "step": 3930
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00016266983372921617,
      "loss": 0.6872,
      "step": 3940
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00016257482185273161,
      "loss": 0.6873,
      "step": 3950
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00016247980997624703,
      "loss": 0.6927,
      "step": 3960
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00016238479809976248,
      "loss": 0.6796,
      "step": 3970
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00016228978622327792,
      "loss": 0.6734,
      "step": 3980
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00016219477434679336,
      "loss": 0.7064,
      "step": 3990
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0001620997624703088,
      "loss": 0.6882,
      "step": 4000
    },
    {
      "epoch": 1.9,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6931264400482178,
      "eval_runtime": 0.5011,
      "eval_samples_per_second": 1740.128,
      "eval_steps_per_second": 13.969,
      "step": 4000
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00016200475059382423,
      "loss": 0.6979,
      "step": 4010
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00016190973871733967,
      "loss": 0.6851,
      "step": 4020
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00016181472684085511,
      "loss": 0.6618,
      "step": 4030
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00016171971496437056,
      "loss": 0.7006,
      "step": 4040
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.000161624703087886,
      "loss": 0.6911,
      "step": 4050
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00016152969121140142,
      "loss": 0.686,
      "step": 4060
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00016143467933491687,
      "loss": 0.6864,
      "step": 4070
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0001613396674584323,
      "loss": 0.6738,
      "step": 4080
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.00016124465558194775,
      "loss": 0.6902,
      "step": 4090
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0001611496437054632,
      "loss": 0.6904,
      "step": 4100
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00016105463182897862,
      "loss": 0.6848,
      "step": 4110
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00016095961995249406,
      "loss": 0.6844,
      "step": 4120
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0001608646080760095,
      "loss": 0.7033,
      "step": 4130
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.00016076959619952495,
      "loss": 0.6837,
      "step": 4140
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0001606745843230404,
      "loss": 0.6787,
      "step": 4150
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00016057957244655584,
      "loss": 0.6909,
      "step": 4160
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00016048456057007125,
      "loss": 0.6857,
      "step": 4170
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0001603895486935867,
      "loss": 0.6931,
      "step": 4180
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00016029453681710214,
      "loss": 0.6975,
      "step": 4190
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0001601995249406176,
      "loss": 0.6865,
      "step": 4200
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00016010451306413303,
      "loss": 0.6877,
      "step": 4210
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00016000950118764845,
      "loss": 0.6811,
      "step": 4220
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0001599144893111639,
      "loss": 0.688,
      "step": 4230
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.00015981947743467934,
      "loss": 0.6893,
      "step": 4240
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.00015972446555819478,
      "loss": 0.6879,
      "step": 4250
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.00015962945368171023,
      "loss": 0.6915,
      "step": 4260
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00015953444180522564,
      "loss": 0.6813,
      "step": 4270
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0001594394299287411,
      "loss": 0.6818,
      "step": 4280
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.00015934441805225656,
      "loss": 0.6926,
      "step": 4290
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.00015924940617577198,
      "loss": 0.6746,
      "step": 4300
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.00015915439429928742,
      "loss": 0.7005,
      "step": 4310
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.00015905938242280284,
      "loss": 0.6813,
      "step": 4320
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0001589643705463183,
      "loss": 0.695,
      "step": 4330
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.00015886935866983376,
      "loss": 0.6805,
      "step": 4340
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00015877434679334917,
      "loss": 0.6989,
      "step": 4350
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.00015867933491686462,
      "loss": 0.677,
      "step": 4360
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.00015858432304038003,
      "loss": 0.6759,
      "step": 4370
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0001584893111638955,
      "loss": 0.6854,
      "step": 4380
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.00015839429928741095,
      "loss": 0.6879,
      "step": 4390
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.00015829928741092637,
      "loss": 0.6863,
      "step": 4400
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0001582042755344418,
      "loss": 0.6804,
      "step": 4410
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.00015810926365795726,
      "loss": 0.6857,
      "step": 4420
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0001580142517814727,
      "loss": 0.6795,
      "step": 4430
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00015791923990498815,
      "loss": 0.6925,
      "step": 4440
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.00015782422802850356,
      "loss": 0.6909,
      "step": 4450
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.000157729216152019,
      "loss": 0.6817,
      "step": 4460
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00015763420427553445,
      "loss": 0.6763,
      "step": 4470
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0001575391923990499,
      "loss": 0.6875,
      "step": 4480
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00015744418052256534,
      "loss": 0.6926,
      "step": 4490
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.00015734916864608076,
      "loss": 0.6887,
      "step": 4500
    },
    {
      "epoch": 2.14,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6962016820907593,
      "eval_runtime": 0.5023,
      "eval_samples_per_second": 1735.994,
      "eval_steps_per_second": 13.936,
      "step": 4500
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0001572541567695962,
      "loss": 0.689,
      "step": 4510
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00015715914489311165,
      "loss": 0.6915,
      "step": 4520
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0001570641330166271,
      "loss": 0.6894,
      "step": 4530
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00015696912114014253,
      "loss": 0.6869,
      "step": 4540
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.00015687410926365798,
      "loss": 0.6974,
      "step": 4550
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0001567790973871734,
      "loss": 0.695,
      "step": 4560
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.00015668408551068884,
      "loss": 0.6952,
      "step": 4570
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.00015658907363420429,
      "loss": 0.6906,
      "step": 4580
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.00015649406175771973,
      "loss": 0.6952,
      "step": 4590
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00015639904988123517,
      "loss": 0.6862,
      "step": 4600
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0001563040380047506,
      "loss": 0.6979,
      "step": 4610
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.00015620902612826604,
      "loss": 0.6981,
      "step": 4620
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.00015611401425178148,
      "loss": 0.6925,
      "step": 4630
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.00015601900237529692,
      "loss": 0.6739,
      "step": 4640
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00015592399049881237,
      "loss": 0.6841,
      "step": 4650
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00015582897862232779,
      "loss": 0.697,
      "step": 4660
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00015573396674584323,
      "loss": 0.6727,
      "step": 4670
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.00015563895486935868,
      "loss": 0.6907,
      "step": 4680
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.00015554394299287412,
      "loss": 0.6909,
      "step": 4690
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.00015544893111638956,
      "loss": 0.6876,
      "step": 4700
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00015535391923990498,
      "loss": 0.6885,
      "step": 4710
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.00015525890736342043,
      "loss": 0.6733,
      "step": 4720
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0001551638954869359,
      "loss": 0.6988,
      "step": 4730
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.00015506888361045131,
      "loss": 0.6795,
      "step": 4740
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00015497387173396676,
      "loss": 0.6983,
      "step": 4750
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.00015487885985748218,
      "loss": 0.6886,
      "step": 4760
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.00015478384798099762,
      "loss": 0.6706,
      "step": 4770
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0001546888361045131,
      "loss": 0.6993,
      "step": 4780
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0001545938242280285,
      "loss": 0.6952,
      "step": 4790
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.00015449881235154395,
      "loss": 0.6919,
      "step": 4800
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00015440380047505937,
      "loss": 0.6953,
      "step": 4810
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.00015430878859857482,
      "loss": 0.688,
      "step": 4820
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0001542137767220903,
      "loss": 0.6743,
      "step": 4830
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0001541187648456057,
      "loss": 0.6886,
      "step": 4840
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.00015402375296912115,
      "loss": 0.6811,
      "step": 4850
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0001539287410926366,
      "loss": 0.6884,
      "step": 4860
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.000153833729216152,
      "loss": 0.6727,
      "step": 4870
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.00015373871733966748,
      "loss": 0.6857,
      "step": 4880
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0001536437054631829,
      "loss": 0.6886,
      "step": 4890
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.00015354869358669834,
      "loss": 0.6688,
      "step": 4900
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0001534536817102138,
      "loss": 0.6839,
      "step": 4910
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0001533586698337292,
      "loss": 0.6831,
      "step": 4920
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.00015326365795724468,
      "loss": 0.6898,
      "step": 4930
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0001531686460807601,
      "loss": 0.686,
      "step": 4940
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.00015307363420427554,
      "loss": 0.6899,
      "step": 4950
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00015297862232779098,
      "loss": 0.6927,
      "step": 4960
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00015288361045130643,
      "loss": 0.689,
      "step": 4970
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.00015278859857482187,
      "loss": 0.6899,
      "step": 4980
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.00015269358669833732,
      "loss": 0.6934,
      "step": 4990
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.00015259857482185273,
      "loss": 0.6867,
      "step": 5000
    },
    {
      "epoch": 2.38,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7046144604682922,
      "eval_runtime": 0.5031,
      "eval_samples_per_second": 1733.355,
      "eval_steps_per_second": 13.915,
      "step": 5000
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.00015250356294536818,
      "loss": 0.699,
      "step": 5010
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.00015240855106888362,
      "loss": 0.6842,
      "step": 5020
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00015231353919239907,
      "loss": 0.6803,
      "step": 5030
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0001522185273159145,
      "loss": 0.6848,
      "step": 5040
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00015212351543942993,
      "loss": 0.6922,
      "step": 5050
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.00015202850356294537,
      "loss": 0.6878,
      "step": 5060
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.00015193349168646082,
      "loss": 0.6809,
      "step": 5070
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.00015183847980997626,
      "loss": 0.6858,
      "step": 5080
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0001517434679334917,
      "loss": 0.7001,
      "step": 5090
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.00015164845605700712,
      "loss": 0.6936,
      "step": 5100
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00015155344418052257,
      "loss": 0.6942,
      "step": 5110
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.000151458432304038,
      "loss": 0.6916,
      "step": 5120
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.00015136342042755346,
      "loss": 0.6775,
      "step": 5130
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0001512684085510689,
      "loss": 0.694,
      "step": 5140
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00015117339667458432,
      "loss": 0.6935,
      "step": 5150
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.00015107838479809976,
      "loss": 0.6851,
      "step": 5160
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0001509833729216152,
      "loss": 0.683,
      "step": 5170
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.00015088836104513065,
      "loss": 0.7092,
      "step": 5180
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0001507933491686461,
      "loss": 0.6967,
      "step": 5190
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0001506983372921615,
      "loss": 0.6861,
      "step": 5200
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00015060332541567696,
      "loss": 0.6871,
      "step": 5210
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0001505083135391924,
      "loss": 0.696,
      "step": 5220
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.00015041330166270785,
      "loss": 0.6845,
      "step": 5230
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0001503182897862233,
      "loss": 0.6933,
      "step": 5240
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.00015022327790973873,
      "loss": 0.6872,
      "step": 5250
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.00015012826603325415,
      "loss": 0.6893,
      "step": 5260
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0001500332541567696,
      "loss": 0.6845,
      "step": 5270
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00014993824228028504,
      "loss": 0.691,
      "step": 5280
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.00014984323040380049,
      "loss": 0.6763,
      "step": 5290
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.00014974821852731593,
      "loss": 0.6865,
      "step": 5300
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.00014965320665083135,
      "loss": 0.6839,
      "step": 5310
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.00014955819477434682,
      "loss": 0.6902,
      "step": 5320
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.00014946318289786224,
      "loss": 0.6845,
      "step": 5330
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00014936817102137768,
      "loss": 0.6909,
      "step": 5340
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00014927315914489312,
      "loss": 0.6898,
      "step": 5350
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.00014917814726840854,
      "loss": 0.6825,
      "step": 5360
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.000149083135391924,
      "loss": 0.6848,
      "step": 5370
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00014898812351543943,
      "loss": 0.6943,
      "step": 5380
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.00014889311163895487,
      "loss": 0.6938,
      "step": 5390
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00014879809976247032,
      "loss": 0.695,
      "step": 5400
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00014870308788598574,
      "loss": 0.6961,
      "step": 5410
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0001486080760095012,
      "loss": 0.6934,
      "step": 5420
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00014851306413301665,
      "loss": 0.6717,
      "step": 5430
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.00014841805225653207,
      "loss": 0.7115,
      "step": 5440
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00014832304038004751,
      "loss": 0.6865,
      "step": 5450
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00014822802850356293,
      "loss": 0.6857,
      "step": 5460
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0001481330166270784,
      "loss": 0.6995,
      "step": 5470
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.00014803800475059385,
      "loss": 0.6791,
      "step": 5480
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.00014794299287410926,
      "loss": 0.6897,
      "step": 5490
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0001478479809976247,
      "loss": 0.6952,
      "step": 5500
    },
    {
      "epoch": 2.61,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7046144604682922,
      "eval_runtime": 0.543,
      "eval_samples_per_second": 1605.966,
      "eval_steps_per_second": 12.892,
      "step": 5500
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.00014775296912114013,
      "loss": 0.6859,
      "step": 5510
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0001476579572446556,
      "loss": 0.6919,
      "step": 5520
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.00014756294536817104,
      "loss": 0.6796,
      "step": 5530
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.00014746793349168646,
      "loss": 0.705,
      "step": 5540
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0001473729216152019,
      "loss": 0.669,
      "step": 5550
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.00014727790973871735,
      "loss": 0.682,
      "step": 5560
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0001471828978622328,
      "loss": 0.6832,
      "step": 5570
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.00014708788598574824,
      "loss": 0.6924,
      "step": 5580
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.00014699287410926365,
      "loss": 0.692,
      "step": 5590
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0001468978622327791,
      "loss": 0.7025,
      "step": 5600
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00014680285035629454,
      "loss": 0.6807,
      "step": 5610
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00014670783847981,
      "loss": 0.6884,
      "step": 5620
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.00014661282660332543,
      "loss": 0.6867,
      "step": 5630
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.00014651781472684085,
      "loss": 0.6909,
      "step": 5640
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0001464228028503563,
      "loss": 0.6928,
      "step": 5650
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.00014632779097387174,
      "loss": 0.6836,
      "step": 5660
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.00014623277909738718,
      "loss": 0.6912,
      "step": 5670
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.00014613776722090263,
      "loss": 0.683,
      "step": 5680
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.00014604275534441807,
      "loss": 0.6831,
      "step": 5690
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0001459477434679335,
      "loss": 0.6777,
      "step": 5700
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.00014585273159144893,
      "loss": 0.6979,
      "step": 5710
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.00014575771971496438,
      "loss": 0.6917,
      "step": 5720
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.00014566270783847982,
      "loss": 0.6948,
      "step": 5730
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00014556769596199527,
      "loss": 0.6865,
      "step": 5740
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.00014547268408551068,
      "loss": 0.6843,
      "step": 5750
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00014537767220902613,
      "loss": 0.6935,
      "step": 5760
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00014528266033254157,
      "loss": 0.6793,
      "step": 5770
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00014518764845605702,
      "loss": 0.6826,
      "step": 5780
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00014509263657957246,
      "loss": 0.6927,
      "step": 5790
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00014499762470308788,
      "loss": 0.6888,
      "step": 5800
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.00014490261282660332,
      "loss": 0.6745,
      "step": 5810
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0001448076009501188,
      "loss": 0.6873,
      "step": 5820
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0001447125890736342,
      "loss": 0.6947,
      "step": 5830
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.00014461757719714966,
      "loss": 0.6846,
      "step": 5840
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.00014452256532066507,
      "loss": 0.6727,
      "step": 5850
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.00014442755344418052,
      "loss": 0.7046,
      "step": 5860
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.000144332541567696,
      "loss": 0.6939,
      "step": 5870
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0001442375296912114,
      "loss": 0.692,
      "step": 5880
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.00014414251781472685,
      "loss": 0.692,
      "step": 5890
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.00014404750593824227,
      "loss": 0.6905,
      "step": 5900
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0001439524940617577,
      "loss": 0.6783,
      "step": 5910
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00014385748218527318,
      "loss": 0.692,
      "step": 5920
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0001437624703087886,
      "loss": 0.6758,
      "step": 5930
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00014366745843230405,
      "loss": 0.6967,
      "step": 5940
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0001435724465558195,
      "loss": 0.683,
      "step": 5950
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00014347743467933493,
      "loss": 0.6921,
      "step": 5960
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00014338242280285038,
      "loss": 0.6844,
      "step": 5970
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0001432874109263658,
      "loss": 0.6905,
      "step": 5980
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00014319239904988124,
      "loss": 0.689,
      "step": 5990
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.00014309738717339668,
      "loss": 0.6848,
      "step": 6000
    },
    {
      "epoch": 2.85,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7035236954689026,
      "eval_runtime": 0.5006,
      "eval_samples_per_second": 1742.069,
      "eval_steps_per_second": 13.984,
      "step": 6000
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.00014300237529691213,
      "loss": 0.695,
      "step": 6010
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.00014290736342042757,
      "loss": 0.685,
      "step": 6020
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.000142812351543943,
      "loss": 0.6961,
      "step": 6030
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00014271733966745844,
      "loss": 0.6873,
      "step": 6040
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00014262232779097388,
      "loss": 0.6895,
      "step": 6050
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00014252731591448932,
      "loss": 0.6927,
      "step": 6060
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00014243230403800477,
      "loss": 0.6926,
      "step": 6070
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.00014233729216152019,
      "loss": 0.6889,
      "step": 6080
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.00014224228028503563,
      "loss": 0.6847,
      "step": 6090
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.00014214726840855107,
      "loss": 0.6824,
      "step": 6100
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.00014205225653206652,
      "loss": 0.6896,
      "step": 6110
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.00014195724465558196,
      "loss": 0.6652,
      "step": 6120
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0001418622327790974,
      "loss": 0.685,
      "step": 6130
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00014176722090261282,
      "loss": 0.6866,
      "step": 6140
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00014167220902612827,
      "loss": 0.6894,
      "step": 6150
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00014157719714964371,
      "loss": 0.6893,
      "step": 6160
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00014148218527315916,
      "loss": 0.6873,
      "step": 6170
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0001413871733966746,
      "loss": 0.694,
      "step": 6180
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00014129216152019002,
      "loss": 0.695,
      "step": 6190
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00014119714964370546,
      "loss": 0.695,
      "step": 6200
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0001411021377672209,
      "loss": 0.6867,
      "step": 6210
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00014100712589073635,
      "loss": 0.6889,
      "step": 6220
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0001409121140142518,
      "loss": 0.6915,
      "step": 6230
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00014081710213776721,
      "loss": 0.684,
      "step": 6240
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00014072209026128266,
      "loss": 0.6988,
      "step": 6250
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0001406270783847981,
      "loss": 0.6918,
      "step": 6260
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00014053206650831355,
      "loss": 0.6874,
      "step": 6270
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.000140437054631829,
      "loss": 0.6802,
      "step": 6280
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0001403420427553444,
      "loss": 0.6735,
      "step": 6290
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.00014024703087885985,
      "loss": 0.7044,
      "step": 6300
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00014015201900237533,
      "loss": 0.6808,
      "step": 6310
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00014005700712589074,
      "loss": 0.6951,
      "step": 6320
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0001399619952494062,
      "loss": 0.6786,
      "step": 6330
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0001398669833729216,
      "loss": 0.6855,
      "step": 6340
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00013977197149643705,
      "loss": 0.6894,
      "step": 6350
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00013967695961995252,
      "loss": 0.695,
      "step": 6360
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00013958194774346794,
      "loss": 0.6932,
      "step": 6370
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00013948693586698338,
      "loss": 0.6866,
      "step": 6380
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00013939192399049883,
      "loss": 0.6819,
      "step": 6390
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00013929691211401424,
      "loss": 0.6877,
      "step": 6400
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.00013920190023752972,
      "loss": 0.6862,
      "step": 6410
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.00013910688836104513,
      "loss": 0.6835,
      "step": 6420
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.00013901187648456058,
      "loss": 0.7098,
      "step": 6430
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.00013891686460807602,
      "loss": 0.6854,
      "step": 6440
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.00013882185273159144,
      "loss": 0.6867,
      "step": 6450
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0001387268408551069,
      "loss": 0.6847,
      "step": 6460
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.00013863182897862233,
      "loss": 0.6951,
      "step": 6470
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00013853681710213777,
      "loss": 0.6999,
      "step": 6480
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00013844180522565322,
      "loss": 0.692,
      "step": 6490
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00013834679334916863,
      "loss": 0.6907,
      "step": 6500
    },
    {
      "epoch": 3.09,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6932916045188904,
      "eval_runtime": 0.5015,
      "eval_samples_per_second": 1738.934,
      "eval_steps_per_second": 13.959,
      "step": 6500
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.0001382517814726841,
      "loss": 0.6927,
      "step": 6510
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00013815676959619955,
      "loss": 0.6849,
      "step": 6520
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00013806175771971497,
      "loss": 0.6771,
      "step": 6530
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.0001379667458432304,
      "loss": 0.6806,
      "step": 6540
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00013787173396674583,
      "loss": 0.6908,
      "step": 6550
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.0001377767220902613,
      "loss": 0.7051,
      "step": 6560
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00013768171021377674,
      "loss": 0.682,
      "step": 6570
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00013758669833729216,
      "loss": 0.6835,
      "step": 6580
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.0001374916864608076,
      "loss": 0.6803,
      "step": 6590
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00013739667458432305,
      "loss": 0.6881,
      "step": 6600
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.0001373016627078385,
      "loss": 0.6936,
      "step": 6610
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00013720665083135394,
      "loss": 0.6935,
      "step": 6620
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00013711163895486936,
      "loss": 0.6936,
      "step": 6630
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.0001370166270783848,
      "loss": 0.6931,
      "step": 6640
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00013692161520190025,
      "loss": 0.6923,
      "step": 6650
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.0001368266033254157,
      "loss": 0.6833,
      "step": 6660
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.00013673159144893113,
      "loss": 0.6689,
      "step": 6670
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.00013663657957244655,
      "loss": 0.6901,
      "step": 6680
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.000136541567695962,
      "loss": 0.6769,
      "step": 6690
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00013644655581947744,
      "loss": 0.6894,
      "step": 6700
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00013635154394299288,
      "loss": 0.694,
      "step": 6710
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00013625653206650833,
      "loss": 0.6891,
      "step": 6720
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00013616152019002375,
      "loss": 0.6802,
      "step": 6730
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.0001360665083135392,
      "loss": 0.6904,
      "step": 6740
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.00013597149643705463,
      "loss": 0.6992,
      "step": 6750
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.00013587648456057008,
      "loss": 0.6919,
      "step": 6760
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.00013578147268408552,
      "loss": 0.6927,
      "step": 6770
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.00013568646080760094,
      "loss": 0.6927,
      "step": 6780
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00013559144893111639,
      "loss": 0.6852,
      "step": 6790
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00013549643705463183,
      "loss": 0.6909,
      "step": 6800
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00013540142517814727,
      "loss": 0.7029,
      "step": 6810
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00013530641330166272,
      "loss": 0.7439,
      "step": 6820
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00013521140142517816,
      "loss": 0.7045,
      "step": 6830
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.00013511638954869358,
      "loss": 0.7019,
      "step": 6840
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.00013502137767220902,
      "loss": 0.7082,
      "step": 6850
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.00013492636579572447,
      "loss": 0.6978,
      "step": 6860
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0001348313539192399,
      "loss": 0.6958,
      "step": 6870
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.00013473634204275536,
      "loss": 0.6945,
      "step": 6880
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.00013464133016627078,
      "loss": 0.6963,
      "step": 6890
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.00013454631828978622,
      "loss": 0.701,
      "step": 6900
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.00013445130641330166,
      "loss": 0.6851,
      "step": 6910
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.0001343562945368171,
      "loss": 0.6858,
      "step": 6920
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00013426128266033255,
      "loss": 0.6869,
      "step": 6930
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00013416627078384797,
      "loss": 0.6919,
      "step": 6940
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00013407125890736344,
      "loss": 0.6949,
      "step": 6950
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.00013397624703087889,
      "loss": 0.6872,
      "step": 6960
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0001338812351543943,
      "loss": 0.6904,
      "step": 6970
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00013378622327790975,
      "loss": 0.6857,
      "step": 6980
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00013369121140142516,
      "loss": 0.6913,
      "step": 6990
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00013359619952494064,
      "loss": 0.6895,
      "step": 7000
    },
    {
      "epoch": 3.33,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.697621762752533,
      "eval_runtime": 0.5778,
      "eval_samples_per_second": 1509.232,
      "eval_steps_per_second": 12.115,
      "step": 7000
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00013350118764845608,
      "loss": 0.685,
      "step": 7010
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.0001334061757719715,
      "loss": 0.6973,
      "step": 7020
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00013331116389548694,
      "loss": 0.6865,
      "step": 7030
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00013321615201900236,
      "loss": 0.6753,
      "step": 7040
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00013312114014251783,
      "loss": 0.6892,
      "step": 7050
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00013302612826603328,
      "loss": 0.6998,
      "step": 7060
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.0001329311163895487,
      "loss": 0.6738,
      "step": 7070
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00013283610451306414,
      "loss": 0.698,
      "step": 7080
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.00013274109263657958,
      "loss": 0.6997,
      "step": 7090
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.00013264608076009503,
      "loss": 0.6935,
      "step": 7100
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.00013255106888361047,
      "loss": 0.6908,
      "step": 7110
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0001324560570071259,
      "loss": 0.689,
      "step": 7120
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00013236104513064133,
      "loss": 0.6896,
      "step": 7130
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00013226603325415678,
      "loss": 0.6943,
      "step": 7140
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00013217102137767222,
      "loss": 0.6894,
      "step": 7150
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00013207600950118767,
      "loss": 0.6952,
      "step": 7160
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.00013198099762470308,
      "loss": 0.6799,
      "step": 7170
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.00013188598574821853,
      "loss": 0.6894,
      "step": 7180
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00013179097387173397,
      "loss": 0.6866,
      "step": 7190
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00013169596199524942,
      "loss": 0.6844,
      "step": 7200
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00013160095011876486,
      "loss": 0.6909,
      "step": 7210
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0001315059382422803,
      "loss": 0.6898,
      "step": 7220
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00013141092636579572,
      "loss": 0.6902,
      "step": 7230
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.00013131591448931117,
      "loss": 0.69,
      "step": 7240
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0001312209026128266,
      "loss": 0.6934,
      "step": 7250
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00013112589073634206,
      "loss": 0.6941,
      "step": 7260
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.0001310308788598575,
      "loss": 0.6866,
      "step": 7270
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00013093586698337292,
      "loss": 0.6894,
      "step": 7280
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00013084085510688836,
      "loss": 0.6812,
      "step": 7290
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.0001307458432304038,
      "loss": 0.69,
      "step": 7300
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.00013065083135391925,
      "loss": 0.6886,
      "step": 7310
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0001305558194774347,
      "loss": 0.6692,
      "step": 7320
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0001304608076009501,
      "loss": 0.6948,
      "step": 7330
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.00013036579572446556,
      "loss": 0.7001,
      "step": 7340
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.000130270783847981,
      "loss": 0.6905,
      "step": 7350
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.00013017577197149644,
      "loss": 0.6868,
      "step": 7360
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.0001300807600950119,
      "loss": 0.6818,
      "step": 7370
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.0001299857482185273,
      "loss": 0.6955,
      "step": 7380
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00012989073634204275,
      "loss": 0.688,
      "step": 7390
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00012979572446555822,
      "loss": 0.6754,
      "step": 7400
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00012970071258907364,
      "loss": 0.6869,
      "step": 7410
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00012960570071258908,
      "loss": 0.6986,
      "step": 7420
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.0001295106888361045,
      "loss": 0.6892,
      "step": 7430
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.00012941567695961995,
      "loss": 0.6902,
      "step": 7440
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00012932066508313542,
      "loss": 0.6891,
      "step": 7450
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00012922565320665083,
      "loss": 0.6704,
      "step": 7460
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00012913064133016628,
      "loss": 0.683,
      "step": 7470
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.0001290356294536817,
      "loss": 0.6892,
      "step": 7480
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00012894061757719714,
      "loss": 0.6873,
      "step": 7490
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.0001288456057007126,
      "loss": 0.6887,
      "step": 7500
    },
    {
      "epoch": 3.56,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7013633847236633,
      "eval_runtime": 0.5634,
      "eval_samples_per_second": 1547.729,
      "eval_steps_per_second": 12.424,
      "step": 7500
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00012875059382422803,
      "loss": 0.6948,
      "step": 7510
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00012865558194774347,
      "loss": 0.6794,
      "step": 7520
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00012856057007125892,
      "loss": 0.687,
      "step": 7530
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00012846555819477434,
      "loss": 0.6809,
      "step": 7540
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.0001283705463182898,
      "loss": 0.6968,
      "step": 7550
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.00012827553444180522,
      "loss": 0.6943,
      "step": 7560
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00012818052256532067,
      "loss": 0.6823,
      "step": 7570
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.0001280855106888361,
      "loss": 0.685,
      "step": 7580
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00012799049881235156,
      "loss": 0.6924,
      "step": 7590
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.000127895486935867,
      "loss": 0.6896,
      "step": 7600
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00012780047505938242,
      "loss": 0.689,
      "step": 7610
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00012770546318289786,
      "loss": 0.6958,
      "step": 7620
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.0001276104513064133,
      "loss": 0.6732,
      "step": 7630
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.00012751543942992875,
      "loss": 0.6864,
      "step": 7640
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.0001274204275534442,
      "loss": 0.6862,
      "step": 7650
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.00012732541567695964,
      "loss": 0.6878,
      "step": 7660
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.00012723040380047506,
      "loss": 0.685,
      "step": 7670
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.0001271353919239905,
      "loss": 0.6823,
      "step": 7680
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.00012704038004750595,
      "loss": 0.6639,
      "step": 7690
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.0001269453681710214,
      "loss": 0.6745,
      "step": 7700
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00012685035629453684,
      "loss": 0.6886,
      "step": 7710
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00012675534441805225,
      "loss": 0.6865,
      "step": 7720
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.0001266603325415677,
      "loss": 0.6925,
      "step": 7730
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.00012656532066508314,
      "loss": 0.6868,
      "step": 7740
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0001264703087885986,
      "loss": 0.6885,
      "step": 7750
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00012637529691211403,
      "loss": 0.6877,
      "step": 7760
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00012628028503562945,
      "loss": 0.6975,
      "step": 7770
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.0001261852731591449,
      "loss": 0.68,
      "step": 7780
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00012609026128266034,
      "loss": 0.6889,
      "step": 7790
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00012599524940617578,
      "loss": 0.6879,
      "step": 7800
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00012590023752969123,
      "loss": 0.6918,
      "step": 7810
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00012580522565320664,
      "loss": 0.6842,
      "step": 7820
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.0001257102137767221,
      "loss": 0.6905,
      "step": 7830
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00012561520190023753,
      "loss": 0.686,
      "step": 7840
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00012552019002375298,
      "loss": 0.679,
      "step": 7850
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00012542517814726842,
      "loss": 0.6958,
      "step": 7860
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00012533016627078384,
      "loss": 0.6963,
      "step": 7870
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00012523515439429928,
      "loss": 0.6887,
      "step": 7880
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00012514014251781473,
      "loss": 0.6903,
      "step": 7890
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00012504513064133017,
      "loss": 0.6884,
      "step": 7900
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00012495011876484562,
      "loss": 0.6846,
      "step": 7910
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00012485510688836106,
      "loss": 0.6808,
      "step": 7920
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00012476009501187648,
      "loss": 0.6905,
      "step": 7930
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00012466508313539195,
      "loss": 0.6898,
      "step": 7940
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00012457007125890737,
      "loss": 0.6888,
      "step": 7950
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.0001244750593824228,
      "loss": 0.691,
      "step": 7960
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00012438004750593825,
      "loss": 0.6735,
      "step": 7970
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00012428503562945367,
      "loss": 0.6836,
      "step": 7980
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.00012419002375296914,
      "loss": 0.693,
      "step": 7990
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.00012409501187648456,
      "loss": 0.6855,
      "step": 8000
    },
    {
      "epoch": 3.8,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7015912532806396,
      "eval_runtime": 0.5558,
      "eval_samples_per_second": 1568.827,
      "eval_steps_per_second": 12.594,
      "step": 8000
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.000124,
      "loss": 0.692,
      "step": 8010
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00012390498812351545,
      "loss": 0.687,
      "step": 8020
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00012380997624703087,
      "loss": 0.6821,
      "step": 8030
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00012371496437054634,
      "loss": 0.6915,
      "step": 8040
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00012361995249406176,
      "loss": 0.6927,
      "step": 8050
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.0001235249406175772,
      "loss": 0.6782,
      "step": 8060
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00012342992874109264,
      "loss": 0.6962,
      "step": 8070
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00012333491686460806,
      "loss": 0.6881,
      "step": 8080
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00012323990498812353,
      "loss": 0.6853,
      "step": 8090
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.00012314489311163898,
      "loss": 0.6907,
      "step": 8100
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0001230498812351544,
      "loss": 0.6894,
      "step": 8110
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.00012295486935866984,
      "loss": 0.6913,
      "step": 8120
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.00012285985748218526,
      "loss": 0.6831,
      "step": 8130
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00012276484560570073,
      "loss": 0.6946,
      "step": 8140
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00012266983372921617,
      "loss": 0.6856,
      "step": 8150
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.0001225748218527316,
      "loss": 0.688,
      "step": 8160
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00012247980997624703,
      "loss": 0.6827,
      "step": 8170
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00012238479809976248,
      "loss": 0.6776,
      "step": 8180
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00012228978622327792,
      "loss": 0.685,
      "step": 8190
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00012219477434679337,
      "loss": 0.7042,
      "step": 8200
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00012209976247030878,
      "loss": 0.6868,
      "step": 8210
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00012200475059382423,
      "loss": 0.6932,
      "step": 8220
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00012190973871733969,
      "loss": 0.6863,
      "step": 8230
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.0001218147268408551,
      "loss": 0.6781,
      "step": 8240
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00012171971496437056,
      "loss": 0.6908,
      "step": 8250
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00012162470308788598,
      "loss": 0.6726,
      "step": 8260
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00012152969121140142,
      "loss": 0.6905,
      "step": 8270
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00012143467933491688,
      "loss": 0.6806,
      "step": 8280
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.0001213396674584323,
      "loss": 0.6875,
      "step": 8290
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00012124465558194776,
      "loss": 0.6731,
      "step": 8300
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00012114964370546317,
      "loss": 0.6743,
      "step": 8310
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00012105463182897863,
      "loss": 0.6909,
      "step": 8320
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00012095961995249408,
      "loss": 0.6952,
      "step": 8330
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.0001208646080760095,
      "loss": 0.6745,
      "step": 8340
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00012076959619952495,
      "loss": 0.6727,
      "step": 8350
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.0001206745843230404,
      "loss": 0.6735,
      "step": 8360
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00012057957244655583,
      "loss": 0.7036,
      "step": 8370
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00012048456057007127,
      "loss": 0.6935,
      "step": 8380
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00012038954869358669,
      "loss": 0.6952,
      "step": 8390
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00012029453681710215,
      "loss": 0.6897,
      "step": 8400
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00012019952494061759,
      "loss": 0.6915,
      "step": 8410
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00012010451306413302,
      "loss": 0.6702,
      "step": 8420
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00012000950118764847,
      "loss": 0.6808,
      "step": 8430
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.0001199144893111639,
      "loss": 0.6936,
      "step": 8440
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00011981947743467934,
      "loss": 0.6893,
      "step": 8450
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00011972446555819479,
      "loss": 0.6955,
      "step": 8460
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00011962945368171022,
      "loss": 0.6875,
      "step": 8470
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00011953444180522566,
      "loss": 0.6915,
      "step": 8480
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.0001194394299287411,
      "loss": 0.6878,
      "step": 8490
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00011934441805225654,
      "loss": 0.6877,
      "step": 8500
    },
    {
      "epoch": 4.04,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6972208023071289,
      "eval_runtime": 0.5007,
      "eval_samples_per_second": 1741.669,
      "eval_steps_per_second": 13.981,
      "step": 8500
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00011924940617577198,
      "loss": 0.6787,
      "step": 8510
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00011915439429928741,
      "loss": 0.6919,
      "step": 8520
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00011905938242280286,
      "loss": 0.6781,
      "step": 8530
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.0001189643705463183,
      "loss": 0.6952,
      "step": 8540
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.00011886935866983373,
      "loss": 0.6817,
      "step": 8550
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00011877434679334918,
      "loss": 0.6857,
      "step": 8560
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00011867933491686461,
      "loss": 0.6857,
      "step": 8570
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00011858432304038005,
      "loss": 0.6828,
      "step": 8580
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.0001184893111638955,
      "loss": 0.7012,
      "step": 8590
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00011839429928741093,
      "loss": 0.676,
      "step": 8600
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00011829928741092637,
      "loss": 0.6832,
      "step": 8610
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00011820427553444182,
      "loss": 0.6932,
      "step": 8620
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00011810926365795725,
      "loss": 0.6875,
      "step": 8630
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00011801425178147269,
      "loss": 0.6943,
      "step": 8640
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00011791923990498812,
      "loss": 0.6818,
      "step": 8650
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00011782422802850357,
      "loss": 0.6831,
      "step": 8660
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00011772921615201902,
      "loss": 0.6921,
      "step": 8670
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00011763420427553444,
      "loss": 0.6984,
      "step": 8680
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00011753919239904989,
      "loss": 0.6919,
      "step": 8690
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00011744418052256532,
      "loss": 0.6857,
      "step": 8700
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.00011734916864608076,
      "loss": 0.6816,
      "step": 8710
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.00011725415676959622,
      "loss": 0.6805,
      "step": 8720
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00011715914489311164,
      "loss": 0.6914,
      "step": 8730
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00011706413301662708,
      "loss": 0.6798,
      "step": 8740
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.00011696912114014251,
      "loss": 0.6773,
      "step": 8750
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.00011687410926365796,
      "loss": 0.6846,
      "step": 8760
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00011677909738717341,
      "loss": 0.6853,
      "step": 8770
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00011668408551068883,
      "loss": 0.7035,
      "step": 8780
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00011658907363420429,
      "loss": 0.6812,
      "step": 8790
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00011649406175771973,
      "loss": 0.6831,
      "step": 8800
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00011639904988123515,
      "loss": 0.6875,
      "step": 8810
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00011630403800475061,
      "loss": 0.6894,
      "step": 8820
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00011620902612826603,
      "loss": 0.6868,
      "step": 8830
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00011611401425178148,
      "loss": 0.699,
      "step": 8840
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00011601900237529693,
      "loss": 0.6909,
      "step": 8850
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00011592399049881235,
      "loss": 0.6914,
      "step": 8860
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.0001158289786223278,
      "loss": 0.6814,
      "step": 8870
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00011573396674584322,
      "loss": 0.6855,
      "step": 8880
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00011563895486935868,
      "loss": 0.6904,
      "step": 8890
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00011554394299287412,
      "loss": 0.6787,
      "step": 8900
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00011544893111638955,
      "loss": 0.688,
      "step": 8910
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.000115353919239905,
      "loss": 0.6872,
      "step": 8920
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00011525890736342044,
      "loss": 0.6847,
      "step": 8930
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00011516389548693587,
      "loss": 0.685,
      "step": 8940
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00011506888361045132,
      "loss": 0.684,
      "step": 8950
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00011497387173396675,
      "loss": 0.6981,
      "step": 8960
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00011487885985748219,
      "loss": 0.6905,
      "step": 8970
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00011478384798099764,
      "loss": 0.6857,
      "step": 8980
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00011468883610451307,
      "loss": 0.6738,
      "step": 8990
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00011459382422802851,
      "loss": 0.6768,
      "step": 9000
    },
    {
      "epoch": 4.28,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7346785068511963,
      "eval_runtime": 0.4996,
      "eval_samples_per_second": 1745.376,
      "eval_steps_per_second": 14.011,
      "step": 9000
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00011449881235154394,
      "loss": 0.6946,
      "step": 9010
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00011440380047505939,
      "loss": 0.696,
      "step": 9020
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00011430878859857483,
      "loss": 0.6876,
      "step": 9030
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00011421377672209026,
      "loss": 0.6874,
      "step": 9040
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00011411876484560571,
      "loss": 0.688,
      "step": 9050
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00011402375296912115,
      "loss": 0.6874,
      "step": 9060
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00011392874109263658,
      "loss": 0.7026,
      "step": 9070
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00011383372921615203,
      "loss": 0.6867,
      "step": 9080
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00011373871733966746,
      "loss": 0.6937,
      "step": 9090
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.0001136437054631829,
      "loss": 0.6926,
      "step": 9100
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00011354869358669835,
      "loss": 0.6931,
      "step": 9110
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00011345368171021378,
      "loss": 0.6859,
      "step": 9120
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00011335866983372922,
      "loss": 0.6999,
      "step": 9130
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00011326365795724465,
      "loss": 0.6919,
      "step": 9140
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.0001131686460807601,
      "loss": 0.6916,
      "step": 9150
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.00011307363420427554,
      "loss": 0.6884,
      "step": 9160
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.00011297862232779097,
      "loss": 0.673,
      "step": 9170
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.00011288361045130642,
      "loss": 0.6828,
      "step": 9180
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.00011278859857482187,
      "loss": 0.7087,
      "step": 9190
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.00011269358669833729,
      "loss": 0.6807,
      "step": 9200
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00011259857482185274,
      "loss": 0.6904,
      "step": 9210
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00011250356294536817,
      "loss": 0.6839,
      "step": 9220
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.00011240855106888361,
      "loss": 0.6952,
      "step": 9230
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.00011231353919239907,
      "loss": 0.6819,
      "step": 9240
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.00011221852731591449,
      "loss": 0.7062,
      "step": 9250
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00011212351543942993,
      "loss": 0.6858,
      "step": 9260
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.00011202850356294536,
      "loss": 0.6934,
      "step": 9270
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.0001119334916864608,
      "loss": 0.6927,
      "step": 9280
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.00011183847980997626,
      "loss": 0.6847,
      "step": 9290
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.00011174346793349168,
      "loss": 0.6849,
      "step": 9300
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.00011164845605700714,
      "loss": 0.7,
      "step": 9310
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.00011155344418052258,
      "loss": 0.6723,
      "step": 9320
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.000111458432304038,
      "loss": 0.6832,
      "step": 9330
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.00011136342042755346,
      "loss": 0.6903,
      "step": 9340
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.00011126840855106888,
      "loss": 0.6877,
      "step": 9350
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.00011117339667458433,
      "loss": 0.684,
      "step": 9360
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.00011107838479809978,
      "loss": 0.6772,
      "step": 9370
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.0001109833729216152,
      "loss": 0.6882,
      "step": 9380
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.00011088836104513065,
      "loss": 0.6994,
      "step": 9390
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.00011079334916864607,
      "loss": 0.6927,
      "step": 9400
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.00011069833729216153,
      "loss": 0.6915,
      "step": 9410
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00011060332541567697,
      "loss": 0.6832,
      "step": 9420
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.0001105083135391924,
      "loss": 0.6769,
      "step": 9430
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.00011041330166270785,
      "loss": 0.6966,
      "step": 9440
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.00011031828978622327,
      "loss": 0.7,
      "step": 9450
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.00011022327790973872,
      "loss": 0.6939,
      "step": 9460
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.00011012826603325417,
      "loss": 0.6901,
      "step": 9470
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.0001100332541567696,
      "loss": 0.6893,
      "step": 9480
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.00010993824228028504,
      "loss": 0.6858,
      "step": 9490
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.00010984323040380049,
      "loss": 0.6853,
      "step": 9500
    },
    {
      "epoch": 4.51,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7081265449523926,
      "eval_runtime": 0.4981,
      "eval_samples_per_second": 1750.491,
      "eval_steps_per_second": 14.052,
      "step": 9500
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.00010974821852731592,
      "loss": 0.682,
      "step": 9510
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.00010965320665083136,
      "loss": 0.6819,
      "step": 9520
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.0001095581947743468,
      "loss": 0.6861,
      "step": 9530
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.00010946318289786224,
      "loss": 0.6958,
      "step": 9540
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00010936817102137768,
      "loss": 0.6892,
      "step": 9550
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.00010927315914489311,
      "loss": 0.6942,
      "step": 9560
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.00010917814726840856,
      "loss": 0.6866,
      "step": 9570
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.00010908313539192399,
      "loss": 0.6779,
      "step": 9580
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.00010898812351543943,
      "loss": 0.7027,
      "step": 9590
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.00010889311163895488,
      "loss": 0.6796,
      "step": 9600
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00010879809976247031,
      "loss": 0.6881,
      "step": 9610
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.00010870308788598575,
      "loss": 0.6829,
      "step": 9620
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.0001086080760095012,
      "loss": 0.6822,
      "step": 9630
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.00010851306413301663,
      "loss": 0.6821,
      "step": 9640
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.00010841805225653207,
      "loss": 0.6916,
      "step": 9650
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.0001083230403800475,
      "loss": 0.6845,
      "step": 9660
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.00010822802850356295,
      "loss": 0.682,
      "step": 9670
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.00010813301662707839,
      "loss": 0.6908,
      "step": 9680
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.00010803800475059382,
      "loss": 0.6864,
      "step": 9690
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.00010794299287410927,
      "loss": 0.6921,
      "step": 9700
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.0001078479809976247,
      "loss": 0.6813,
      "step": 9710
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.00010775296912114014,
      "loss": 0.6829,
      "step": 9720
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.00010765795724465559,
      "loss": 0.6781,
      "step": 9730
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.00010756294536817102,
      "loss": 0.7095,
      "step": 9740
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.00010746793349168646,
      "loss": 0.6868,
      "step": 9750
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.00010737292161520192,
      "loss": 0.6844,
      "step": 9760
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.00010727790973871734,
      "loss": 0.6876,
      "step": 9770
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.0001071828978622328,
      "loss": 0.6793,
      "step": 9780
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.00010708788598574821,
      "loss": 0.6799,
      "step": 9790
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.00010699287410926366,
      "loss": 0.6739,
      "step": 9800
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.00010689786223277912,
      "loss": 0.6778,
      "step": 9810
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00010680285035629453,
      "loss": 0.6903,
      "step": 9820
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00010670783847980999,
      "loss": 0.6804,
      "step": 9830
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.00010661282660332541,
      "loss": 0.6803,
      "step": 9840
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00010651781472684085,
      "loss": 0.6981,
      "step": 9850
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.00010642280285035631,
      "loss": 0.6838,
      "step": 9860
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.00010632779097387173,
      "loss": 0.6948,
      "step": 9870
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.00010623277909738719,
      "loss": 0.6903,
      "step": 9880
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.00010613776722090263,
      "loss": 0.6883,
      "step": 9890
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.00010604275534441806,
      "loss": 0.6838,
      "step": 9900
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.0001059477434679335,
      "loss": 0.6949,
      "step": 9910
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.00010585273159144892,
      "loss": 0.682,
      "step": 9920
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.00010575771971496438,
      "loss": 0.6807,
      "step": 9930
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.00010566270783847983,
      "loss": 0.6953,
      "step": 9940
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.00010556769596199526,
      "loss": 0.6891,
      "step": 9950
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.0001054726840855107,
      "loss": 0.687,
      "step": 9960
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.00010537767220902612,
      "loss": 0.6882,
      "step": 9970
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.00010528266033254158,
      "loss": 0.6918,
      "step": 9980
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00010518764845605702,
      "loss": 0.6901,
      "step": 9990
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.00010509263657957245,
      "loss": 0.6834,
      "step": 10000
    },
    {
      "epoch": 4.75,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7037364840507507,
      "eval_runtime": 0.5784,
      "eval_samples_per_second": 1507.664,
      "eval_steps_per_second": 12.103,
      "step": 10000
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.0001049976247030879,
      "loss": 0.6833,
      "step": 10010
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.00010490261282660334,
      "loss": 0.6754,
      "step": 10020
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.00010480760095011877,
      "loss": 0.6853,
      "step": 10030
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.00010471258907363421,
      "loss": 0.6755,
      "step": 10040
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.00010461757719714965,
      "loss": 0.6928,
      "step": 10050
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.00010452256532066509,
      "loss": 0.6782,
      "step": 10060
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.00010442755344418053,
      "loss": 0.6853,
      "step": 10070
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.00010433254156769597,
      "loss": 0.6778,
      "step": 10080
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.00010423752969121141,
      "loss": 0.6804,
      "step": 10090
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.00010414251781472684,
      "loss": 0.6825,
      "step": 10100
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.00010404750593824228,
      "loss": 0.6929,
      "step": 10110
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.00010395249406175773,
      "loss": 0.6942,
      "step": 10120
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.00010385748218527316,
      "loss": 0.6907,
      "step": 10130
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.0001037624703087886,
      "loss": 0.7055,
      "step": 10140
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.00010366745843230404,
      "loss": 0.6802,
      "step": 10150
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.00010357244655581948,
      "loss": 0.6843,
      "step": 10160
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.00010347743467933492,
      "loss": 0.6945,
      "step": 10170
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.00010338242280285036,
      "loss": 0.6724,
      "step": 10180
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.0001032874109263658,
      "loss": 0.6867,
      "step": 10190
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.00010319239904988124,
      "loss": 0.6811,
      "step": 10200
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.00010309738717339667,
      "loss": 0.6832,
      "step": 10210
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.00010300237529691212,
      "loss": 0.6815,
      "step": 10220
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.00010290736342042755,
      "loss": 0.6764,
      "step": 10230
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.000102812351543943,
      "loss": 0.6948,
      "step": 10240
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.00010271733966745844,
      "loss": 0.6913,
      "step": 10250
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.00010262232779097387,
      "loss": 0.6844,
      "step": 10260
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00010252731591448931,
      "loss": 0.6726,
      "step": 10270
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00010243230403800474,
      "loss": 0.6914,
      "step": 10280
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.00010233729216152019,
      "loss": 0.6959,
      "step": 10290
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.00010224228028503565,
      "loss": 0.6855,
      "step": 10300
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.00010214726840855106,
      "loss": 0.6926,
      "step": 10310
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.00010205225653206651,
      "loss": 0.6873,
      "step": 10320
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.00010195724465558197,
      "loss": 0.6815,
      "step": 10330
    },
    {
      "epoch": 4.91,
      "learning_rate": 0.00010186223277909738,
      "loss": 0.7011,
      "step": 10340
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.00010176722090261284,
      "loss": 0.6692,
      "step": 10350
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.00010167220902612826,
      "loss": 0.69,
      "step": 10360
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.0001015771971496437,
      "loss": 0.682,
      "step": 10370
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.00010148218527315916,
      "loss": 0.6918,
      "step": 10380
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.00010138717339667458,
      "loss": 0.6737,
      "step": 10390
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.00010129216152019004,
      "loss": 0.6798,
      "step": 10400
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00010119714964370545,
      "loss": 0.6908,
      "step": 10410
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00010110213776722091,
      "loss": 0.7021,
      "step": 10420
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.00010100712589073636,
      "loss": 0.6904,
      "step": 10430
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.00010091211401425177,
      "loss": 0.6926,
      "step": 10440
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.00010081710213776723,
      "loss": 0.6825,
      "step": 10450
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.00010072209026128268,
      "loss": 0.6874,
      "step": 10460
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.00010062707838479811,
      "loss": 0.6738,
      "step": 10470
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.00010053206650831355,
      "loss": 0.6788,
      "step": 10480
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.00010043705463182897,
      "loss": 0.694,
      "step": 10490
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.00010034204275534443,
      "loss": 0.6856,
      "step": 10500
    },
    {
      "epoch": 4.99,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6994539499282837,
      "eval_runtime": 0.5007,
      "eval_samples_per_second": 1741.626,
      "eval_steps_per_second": 13.981,
      "step": 10500
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.00010024703087885987,
      "loss": 0.6862,
      "step": 10510
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.0001001520190023753,
      "loss": 0.6834,
      "step": 10520
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.00010005700712589075,
      "loss": 0.6814,
      "step": 10530
    },
    {
      "epoch": 5.01,
      "learning_rate": 9.996199524940618e-05,
      "loss": 0.6902,
      "step": 10540
    },
    {
      "epoch": 5.01,
      "learning_rate": 9.986698337292162e-05,
      "loss": 0.6922,
      "step": 10550
    },
    {
      "epoch": 5.02,
      "learning_rate": 9.977197149643705e-05,
      "loss": 0.6824,
      "step": 10560
    },
    {
      "epoch": 5.02,
      "learning_rate": 9.96769596199525e-05,
      "loss": 0.6862,
      "step": 10570
    },
    {
      "epoch": 5.03,
      "learning_rate": 9.958194774346794e-05,
      "loss": 0.6815,
      "step": 10580
    },
    {
      "epoch": 5.03,
      "learning_rate": 9.948693586698337e-05,
      "loss": 0.6874,
      "step": 10590
    },
    {
      "epoch": 5.04,
      "learning_rate": 9.939192399049882e-05,
      "loss": 0.6774,
      "step": 10600
    },
    {
      "epoch": 5.04,
      "learning_rate": 9.929691211401425e-05,
      "loss": 0.6861,
      "step": 10610
    },
    {
      "epoch": 5.05,
      "learning_rate": 9.92019002375297e-05,
      "loss": 0.6746,
      "step": 10620
    },
    {
      "epoch": 5.05,
      "learning_rate": 9.910688836104514e-05,
      "loss": 0.6861,
      "step": 10630
    },
    {
      "epoch": 5.05,
      "learning_rate": 9.901187648456057e-05,
      "loss": 0.7024,
      "step": 10640
    },
    {
      "epoch": 5.06,
      "learning_rate": 9.891686460807601e-05,
      "loss": 0.6844,
      "step": 10650
    },
    {
      "epoch": 5.06,
      "learning_rate": 9.882185273159146e-05,
      "loss": 0.6938,
      "step": 10660
    },
    {
      "epoch": 5.07,
      "learning_rate": 9.87268408551069e-05,
      "loss": 0.6897,
      "step": 10670
    },
    {
      "epoch": 5.07,
      "learning_rate": 9.863182897862233e-05,
      "loss": 0.6891,
      "step": 10680
    },
    {
      "epoch": 5.08,
      "learning_rate": 9.853681710213776e-05,
      "loss": 0.6935,
      "step": 10690
    },
    {
      "epoch": 5.08,
      "learning_rate": 9.844180522565322e-05,
      "loss": 0.6865,
      "step": 10700
    },
    {
      "epoch": 5.09,
      "learning_rate": 9.834679334916865e-05,
      "loss": 0.6824,
      "step": 10710
    },
    {
      "epoch": 5.09,
      "learning_rate": 9.82517814726841e-05,
      "loss": 0.698,
      "step": 10720
    },
    {
      "epoch": 5.1,
      "learning_rate": 9.815676959619953e-05,
      "loss": 0.6983,
      "step": 10730
    },
    {
      "epoch": 5.1,
      "learning_rate": 9.806175771971497e-05,
      "loss": 0.6875,
      "step": 10740
    },
    {
      "epoch": 5.11,
      "learning_rate": 9.796674584323041e-05,
      "loss": 0.6877,
      "step": 10750
    },
    {
      "epoch": 5.11,
      "learning_rate": 9.787173396674585e-05,
      "loss": 0.6863,
      "step": 10760
    },
    {
      "epoch": 5.12,
      "learning_rate": 9.777672209026129e-05,
      "loss": 0.6877,
      "step": 10770
    },
    {
      "epoch": 5.12,
      "learning_rate": 9.768171021377672e-05,
      "loss": 0.6825,
      "step": 10780
    },
    {
      "epoch": 5.13,
      "learning_rate": 9.758669833729217e-05,
      "loss": 0.7002,
      "step": 10790
    },
    {
      "epoch": 5.13,
      "learning_rate": 9.749168646080761e-05,
      "loss": 0.6784,
      "step": 10800
    },
    {
      "epoch": 5.14,
      "learning_rate": 9.739667458432304e-05,
      "loss": 0.6739,
      "step": 10810
    },
    {
      "epoch": 5.14,
      "learning_rate": 9.730166270783848e-05,
      "loss": 0.6901,
      "step": 10820
    },
    {
      "epoch": 5.14,
      "learning_rate": 9.720665083135393e-05,
      "loss": 0.6713,
      "step": 10830
    },
    {
      "epoch": 5.15,
      "learning_rate": 9.711163895486936e-05,
      "loss": 0.6993,
      "step": 10840
    },
    {
      "epoch": 5.15,
      "learning_rate": 9.70166270783848e-05,
      "loss": 0.6965,
      "step": 10850
    },
    {
      "epoch": 5.16,
      "learning_rate": 9.692161520190024e-05,
      "loss": 0.6888,
      "step": 10860
    },
    {
      "epoch": 5.16,
      "learning_rate": 9.682660332541568e-05,
      "loss": 0.6876,
      "step": 10870
    },
    {
      "epoch": 5.17,
      "learning_rate": 9.673159144893112e-05,
      "loss": 0.6948,
      "step": 10880
    },
    {
      "epoch": 5.17,
      "learning_rate": 9.663657957244657e-05,
      "loss": 0.6891,
      "step": 10890
    },
    {
      "epoch": 5.18,
      "learning_rate": 9.6541567695962e-05,
      "loss": 0.6786,
      "step": 10900
    },
    {
      "epoch": 5.18,
      "learning_rate": 9.644655581947743e-05,
      "loss": 0.6873,
      "step": 10910
    },
    {
      "epoch": 5.19,
      "learning_rate": 9.635154394299289e-05,
      "loss": 0.6965,
      "step": 10920
    },
    {
      "epoch": 5.19,
      "learning_rate": 9.625653206650832e-05,
      "loss": 0.6896,
      "step": 10930
    },
    {
      "epoch": 5.2,
      "learning_rate": 9.616152019002376e-05,
      "loss": 0.6793,
      "step": 10940
    },
    {
      "epoch": 5.2,
      "learning_rate": 9.60665083135392e-05,
      "loss": 0.6857,
      "step": 10950
    },
    {
      "epoch": 5.21,
      "learning_rate": 9.597149643705462e-05,
      "loss": 0.6843,
      "step": 10960
    },
    {
      "epoch": 5.21,
      "learning_rate": 9.587648456057008e-05,
      "loss": 0.6997,
      "step": 10970
    },
    {
      "epoch": 5.22,
      "learning_rate": 9.578147268408551e-05,
      "loss": 0.6849,
      "step": 10980
    },
    {
      "epoch": 5.22,
      "learning_rate": 9.568646080760096e-05,
      "loss": 0.6819,
      "step": 10990
    },
    {
      "epoch": 5.23,
      "learning_rate": 9.559144893111639e-05,
      "loss": 0.6886,
      "step": 11000
    },
    {
      "epoch": 5.23,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7059270143508911,
      "eval_runtime": 0.4968,
      "eval_samples_per_second": 1755.171,
      "eval_steps_per_second": 14.09,
      "step": 11000
    },
    {
      "epoch": 5.23,
      "learning_rate": 9.549643705463183e-05,
      "loss": 0.6932,
      "step": 11010
    },
    {
      "epoch": 5.24,
      "learning_rate": 9.540142517814728e-05,
      "loss": 0.6892,
      "step": 11020
    },
    {
      "epoch": 5.24,
      "learning_rate": 9.530641330166271e-05,
      "loss": 0.6961,
      "step": 11030
    },
    {
      "epoch": 5.24,
      "learning_rate": 9.521140142517815e-05,
      "loss": 0.6845,
      "step": 11040
    },
    {
      "epoch": 5.25,
      "learning_rate": 9.51163895486936e-05,
      "loss": 0.6867,
      "step": 11050
    },
    {
      "epoch": 5.25,
      "learning_rate": 9.502137767220903e-05,
      "loss": 0.6892,
      "step": 11060
    },
    {
      "epoch": 5.26,
      "learning_rate": 9.492636579572447e-05,
      "loss": 0.6802,
      "step": 11070
    },
    {
      "epoch": 5.26,
      "learning_rate": 9.48313539192399e-05,
      "loss": 0.6897,
      "step": 11080
    },
    {
      "epoch": 5.27,
      "learning_rate": 9.473634204275535e-05,
      "loss": 0.6806,
      "step": 11090
    },
    {
      "epoch": 5.27,
      "learning_rate": 9.464133016627079e-05,
      "loss": 0.6872,
      "step": 11100
    },
    {
      "epoch": 5.28,
      "learning_rate": 9.454631828978622e-05,
      "loss": 0.6831,
      "step": 11110
    },
    {
      "epoch": 5.28,
      "learning_rate": 9.445130641330167e-05,
      "loss": 0.6839,
      "step": 11120
    },
    {
      "epoch": 5.29,
      "learning_rate": 9.43562945368171e-05,
      "loss": 0.6775,
      "step": 11130
    },
    {
      "epoch": 5.29,
      "learning_rate": 9.426128266033256e-05,
      "loss": 0.7021,
      "step": 11140
    },
    {
      "epoch": 5.3,
      "learning_rate": 9.416627078384799e-05,
      "loss": 0.6877,
      "step": 11150
    },
    {
      "epoch": 5.3,
      "learning_rate": 9.407125890736342e-05,
      "loss": 0.6886,
      "step": 11160
    },
    {
      "epoch": 5.31,
      "learning_rate": 9.397624703087886e-05,
      "loss": 0.6915,
      "step": 11170
    },
    {
      "epoch": 5.31,
      "learning_rate": 9.38812351543943e-05,
      "loss": 0.6961,
      "step": 11180
    },
    {
      "epoch": 5.32,
      "learning_rate": 9.378622327790975e-05,
      "loss": 0.6987,
      "step": 11190
    },
    {
      "epoch": 5.32,
      "learning_rate": 9.369121140142518e-05,
      "loss": 0.6856,
      "step": 11200
    },
    {
      "epoch": 5.33,
      "learning_rate": 9.359619952494063e-05,
      "loss": 0.6843,
      "step": 11210
    },
    {
      "epoch": 5.33,
      "learning_rate": 9.350118764845606e-05,
      "loss": 0.6787,
      "step": 11220
    },
    {
      "epoch": 5.33,
      "learning_rate": 9.34061757719715e-05,
      "loss": 0.6754,
      "step": 11230
    },
    {
      "epoch": 5.34,
      "learning_rate": 9.331116389548695e-05,
      "loss": 0.6968,
      "step": 11240
    },
    {
      "epoch": 5.34,
      "learning_rate": 9.321615201900238e-05,
      "loss": 0.6951,
      "step": 11250
    },
    {
      "epoch": 5.35,
      "learning_rate": 9.312114014251782e-05,
      "loss": 0.6815,
      "step": 11260
    },
    {
      "epoch": 5.35,
      "learning_rate": 9.302612826603327e-05,
      "loss": 0.6799,
      "step": 11270
    },
    {
      "epoch": 5.36,
      "learning_rate": 9.29311163895487e-05,
      "loss": 0.6871,
      "step": 11280
    },
    {
      "epoch": 5.36,
      "learning_rate": 9.283610451306414e-05,
      "loss": 0.7024,
      "step": 11290
    },
    {
      "epoch": 5.37,
      "learning_rate": 9.274109263657957e-05,
      "loss": 0.6813,
      "step": 11300
    },
    {
      "epoch": 5.37,
      "learning_rate": 9.264608076009502e-05,
      "loss": 0.6844,
      "step": 11310
    },
    {
      "epoch": 5.38,
      "learning_rate": 9.255106888361046e-05,
      "loss": 0.6942,
      "step": 11320
    },
    {
      "epoch": 5.38,
      "learning_rate": 9.245605700712589e-05,
      "loss": 0.6809,
      "step": 11330
    },
    {
      "epoch": 5.39,
      "learning_rate": 9.236104513064134e-05,
      "loss": 0.6861,
      "step": 11340
    },
    {
      "epoch": 5.39,
      "learning_rate": 9.226603325415677e-05,
      "loss": 0.6787,
      "step": 11350
    },
    {
      "epoch": 5.4,
      "learning_rate": 9.217102137767221e-05,
      "loss": 0.6946,
      "step": 11360
    },
    {
      "epoch": 5.4,
      "learning_rate": 9.207600950118766e-05,
      "loss": 0.6906,
      "step": 11370
    },
    {
      "epoch": 5.41,
      "learning_rate": 9.198099762470309e-05,
      "loss": 0.69,
      "step": 11380
    },
    {
      "epoch": 5.41,
      "learning_rate": 9.188598574821853e-05,
      "loss": 0.681,
      "step": 11390
    },
    {
      "epoch": 5.42,
      "learning_rate": 9.179097387173398e-05,
      "loss": 0.7036,
      "step": 11400
    },
    {
      "epoch": 5.42,
      "learning_rate": 9.169596199524942e-05,
      "loss": 0.6879,
      "step": 11410
    },
    {
      "epoch": 5.43,
      "learning_rate": 9.160095011876485e-05,
      "loss": 0.688,
      "step": 11420
    },
    {
      "epoch": 5.43,
      "learning_rate": 9.150593824228028e-05,
      "loss": 0.683,
      "step": 11430
    },
    {
      "epoch": 5.43,
      "learning_rate": 9.141092636579573e-05,
      "loss": 0.6925,
      "step": 11440
    },
    {
      "epoch": 5.44,
      "learning_rate": 9.131591448931117e-05,
      "loss": 0.6936,
      "step": 11450
    },
    {
      "epoch": 5.44,
      "learning_rate": 9.122090261282661e-05,
      "loss": 0.6874,
      "step": 11460
    },
    {
      "epoch": 5.45,
      "learning_rate": 9.112589073634205e-05,
      "loss": 0.6921,
      "step": 11470
    },
    {
      "epoch": 5.45,
      "learning_rate": 9.103087885985748e-05,
      "loss": 0.6893,
      "step": 11480
    },
    {
      "epoch": 5.46,
      "learning_rate": 9.093586698337293e-05,
      "loss": 0.6925,
      "step": 11490
    },
    {
      "epoch": 5.46,
      "learning_rate": 9.084085510688836e-05,
      "loss": 0.6909,
      "step": 11500
    },
    {
      "epoch": 5.46,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.6984348297119141,
      "eval_runtime": 0.5037,
      "eval_samples_per_second": 1731.127,
      "eval_steps_per_second": 13.897,
      "step": 11500
    },
    {
      "epoch": 5.47,
      "learning_rate": 9.074584323040381e-05,
      "loss": 0.6718,
      "step": 11510
    },
    {
      "epoch": 5.47,
      "learning_rate": 9.065083135391924e-05,
      "loss": 0.6847,
      "step": 11520
    },
    {
      "epoch": 5.48,
      "learning_rate": 9.055581947743468e-05,
      "loss": 0.6788,
      "step": 11530
    },
    {
      "epoch": 5.48,
      "learning_rate": 9.046080760095013e-05,
      "loss": 0.683,
      "step": 11540
    },
    {
      "epoch": 5.49,
      "learning_rate": 9.036579572446556e-05,
      "loss": 0.6757,
      "step": 11550
    },
    {
      "epoch": 5.49,
      "learning_rate": 9.0270783847981e-05,
      "loss": 0.68,
      "step": 11560
    },
    {
      "epoch": 5.5,
      "learning_rate": 9.017577197149643e-05,
      "loss": 0.6828,
      "step": 11570
    },
    {
      "epoch": 5.5,
      "learning_rate": 9.008076009501188e-05,
      "loss": 0.7019,
      "step": 11580
    },
    {
      "epoch": 5.51,
      "learning_rate": 8.998574821852732e-05,
      "loss": 0.69,
      "step": 11590
    },
    {
      "epoch": 5.51,
      "learning_rate": 8.989073634204275e-05,
      "loss": 0.6916,
      "step": 11600
    },
    {
      "epoch": 5.52,
      "learning_rate": 8.97957244655582e-05,
      "loss": 0.6805,
      "step": 11610
    },
    {
      "epoch": 5.52,
      "learning_rate": 8.970071258907364e-05,
      "loss": 0.6861,
      "step": 11620
    },
    {
      "epoch": 5.52,
      "learning_rate": 8.960570071258907e-05,
      "loss": 0.6885,
      "step": 11630
    },
    {
      "epoch": 5.53,
      "learning_rate": 8.951068883610452e-05,
      "loss": 0.6945,
      "step": 11640
    },
    {
      "epoch": 5.53,
      "learning_rate": 8.941567695961995e-05,
      "loss": 0.6868,
      "step": 11650
    },
    {
      "epoch": 5.54,
      "learning_rate": 8.93206650831354e-05,
      "loss": 0.6859,
      "step": 11660
    },
    {
      "epoch": 5.54,
      "learning_rate": 8.922565320665084e-05,
      "loss": 0.6966,
      "step": 11670
    },
    {
      "epoch": 5.55,
      "learning_rate": 8.913064133016627e-05,
      "loss": 0.6936,
      "step": 11680
    },
    {
      "epoch": 5.55,
      "learning_rate": 8.903562945368171e-05,
      "loss": 0.6833,
      "step": 11690
    },
    {
      "epoch": 5.56,
      "learning_rate": 8.894061757719714e-05,
      "loss": 0.7029,
      "step": 11700
    },
    {
      "epoch": 5.56,
      "learning_rate": 8.88456057007126e-05,
      "loss": 0.6858,
      "step": 11710
    },
    {
      "epoch": 5.57,
      "learning_rate": 8.875059382422803e-05,
      "loss": 0.6793,
      "step": 11720
    },
    {
      "epoch": 5.57,
      "learning_rate": 8.865558194774348e-05,
      "loss": 0.6904,
      "step": 11730
    },
    {
      "epoch": 5.58,
      "learning_rate": 8.856057007125891e-05,
      "loss": 0.69,
      "step": 11740
    },
    {
      "epoch": 5.58,
      "learning_rate": 8.846555819477435e-05,
      "loss": 0.6857,
      "step": 11750
    },
    {
      "epoch": 5.59,
      "learning_rate": 8.83705463182898e-05,
      "loss": 0.6893,
      "step": 11760
    },
    {
      "epoch": 5.59,
      "learning_rate": 8.827553444180523e-05,
      "loss": 0.6973,
      "step": 11770
    },
    {
      "epoch": 5.6,
      "learning_rate": 8.818052256532067e-05,
      "loss": 0.6807,
      "step": 11780
    },
    {
      "epoch": 5.6,
      "learning_rate": 8.80855106888361e-05,
      "loss": 0.6841,
      "step": 11790
    },
    {
      "epoch": 5.61,
      "learning_rate": 8.799049881235155e-05,
      "loss": 0.683,
      "step": 11800
    },
    {
      "epoch": 5.61,
      "learning_rate": 8.789548693586699e-05,
      "loss": 0.6899,
      "step": 11810
    },
    {
      "epoch": 5.62,
      "learning_rate": 8.780047505938242e-05,
      "loss": 0.6776,
      "step": 11820
    },
    {
      "epoch": 5.62,
      "learning_rate": 8.770546318289787e-05,
      "loss": 0.6755,
      "step": 11830
    },
    {
      "epoch": 5.62,
      "learning_rate": 8.761045130641331e-05,
      "loss": 0.6945,
      "step": 11840
    },
    {
      "epoch": 5.63,
      "learning_rate": 8.751543942992874e-05,
      "loss": 0.693,
      "step": 11850
    },
    {
      "epoch": 5.63,
      "learning_rate": 8.742042755344419e-05,
      "loss": 0.6932,
      "step": 11860
    },
    {
      "epoch": 5.64,
      "learning_rate": 8.732541567695962e-05,
      "loss": 0.6868,
      "step": 11870
    },
    {
      "epoch": 5.64,
      "learning_rate": 8.723040380047508e-05,
      "loss": 0.69,
      "step": 11880
    },
    {
      "epoch": 5.65,
      "learning_rate": 8.71353919239905e-05,
      "loss": 0.6815,
      "step": 11890
    },
    {
      "epoch": 5.65,
      "learning_rate": 8.704038004750594e-05,
      "loss": 0.6839,
      "step": 11900
    },
    {
      "epoch": 5.66,
      "learning_rate": 8.694536817102138e-05,
      "loss": 0.6863,
      "step": 11910
    },
    {
      "epoch": 5.66,
      "learning_rate": 8.685035629453681e-05,
      "loss": 0.6714,
      "step": 11920
    },
    {
      "epoch": 5.67,
      "learning_rate": 8.675534441805227e-05,
      "loss": 0.6752,
      "step": 11930
    },
    {
      "epoch": 5.67,
      "learning_rate": 8.66603325415677e-05,
      "loss": 0.6843,
      "step": 11940
    },
    {
      "epoch": 5.68,
      "learning_rate": 8.656532066508313e-05,
      "loss": 0.683,
      "step": 11950
    },
    {
      "epoch": 5.68,
      "learning_rate": 8.647030878859858e-05,
      "loss": 0.6828,
      "step": 11960
    },
    {
      "epoch": 5.69,
      "learning_rate": 8.637529691211402e-05,
      "loss": 0.6659,
      "step": 11970
    },
    {
      "epoch": 5.69,
      "learning_rate": 8.628028503562947e-05,
      "loss": 0.6601,
      "step": 11980
    },
    {
      "epoch": 5.7,
      "learning_rate": 8.61852731591449e-05,
      "loss": 0.7118,
      "step": 11990
    },
    {
      "epoch": 5.7,
      "learning_rate": 8.609026128266034e-05,
      "loss": 0.6899,
      "step": 12000
    },
    {
      "epoch": 5.7,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7215842008590698,
      "eval_runtime": 0.502,
      "eval_samples_per_second": 1736.984,
      "eval_steps_per_second": 13.944,
      "step": 12000
    },
    {
      "epoch": 5.71,
      "learning_rate": 8.599524940617577e-05,
      "loss": 0.6939,
      "step": 12010
    },
    {
      "epoch": 5.71,
      "learning_rate": 8.590023752969122e-05,
      "loss": 0.6888,
      "step": 12020
    },
    {
      "epoch": 5.71,
      "learning_rate": 8.580522565320666e-05,
      "loss": 0.6826,
      "step": 12030
    },
    {
      "epoch": 5.72,
      "learning_rate": 8.571021377672209e-05,
      "loss": 0.6942,
      "step": 12040
    },
    {
      "epoch": 5.72,
      "learning_rate": 8.561520190023754e-05,
      "loss": 0.6915,
      "step": 12050
    },
    {
      "epoch": 5.73,
      "learning_rate": 8.552019002375298e-05,
      "loss": 0.6822,
      "step": 12060
    },
    {
      "epoch": 5.73,
      "learning_rate": 8.542517814726841e-05,
      "loss": 0.69,
      "step": 12070
    },
    {
      "epoch": 5.74,
      "learning_rate": 8.533016627078386e-05,
      "loss": 0.6936,
      "step": 12080
    },
    {
      "epoch": 5.74,
      "learning_rate": 8.523515439429929e-05,
      "loss": 0.6858,
      "step": 12090
    },
    {
      "epoch": 5.75,
      "learning_rate": 8.514014251781473e-05,
      "loss": 0.6883,
      "step": 12100
    },
    {
      "epoch": 5.75,
      "learning_rate": 8.504513064133017e-05,
      "loss": 0.6787,
      "step": 12110
    },
    {
      "epoch": 5.76,
      "learning_rate": 8.49501187648456e-05,
      "loss": 0.6886,
      "step": 12120
    },
    {
      "epoch": 5.76,
      "learning_rate": 8.485510688836105e-05,
      "loss": 0.6888,
      "step": 12130
    },
    {
      "epoch": 5.77,
      "learning_rate": 8.476009501187648e-05,
      "loss": 0.6685,
      "step": 12140
    },
    {
      "epoch": 5.77,
      "learning_rate": 8.466508313539193e-05,
      "loss": 0.7024,
      "step": 12150
    },
    {
      "epoch": 5.78,
      "learning_rate": 8.457007125890737e-05,
      "loss": 0.6849,
      "step": 12160
    },
    {
      "epoch": 5.78,
      "learning_rate": 8.44750593824228e-05,
      "loss": 0.6857,
      "step": 12170
    },
    {
      "epoch": 5.79,
      "learning_rate": 8.438004750593824e-05,
      "loss": 0.6759,
      "step": 12180
    },
    {
      "epoch": 5.79,
      "learning_rate": 8.428503562945369e-05,
      "loss": 0.686,
      "step": 12190
    },
    {
      "epoch": 5.8,
      "learning_rate": 8.419002375296913e-05,
      "loss": 0.6727,
      "step": 12200
    },
    {
      "epoch": 5.8,
      "learning_rate": 8.409501187648456e-05,
      "loss": 0.699,
      "step": 12210
    },
    {
      "epoch": 5.81,
      "learning_rate": 8.4e-05,
      "loss": 0.6857,
      "step": 12220
    },
    {
      "epoch": 5.81,
      "learning_rate": 8.390498812351545e-05,
      "loss": 0.6865,
      "step": 12230
    },
    {
      "epoch": 5.81,
      "learning_rate": 8.380997624703088e-05,
      "loss": 0.6823,
      "step": 12240
    },
    {
      "epoch": 5.82,
      "learning_rate": 8.371496437054633e-05,
      "loss": 0.6824,
      "step": 12250
    },
    {
      "epoch": 5.82,
      "learning_rate": 8.361995249406176e-05,
      "loss": 0.6863,
      "step": 12260
    },
    {
      "epoch": 5.83,
      "learning_rate": 8.352494061757719e-05,
      "loss": 0.6908,
      "step": 12270
    },
    {
      "epoch": 5.83,
      "learning_rate": 8.342992874109265e-05,
      "loss": 0.6872,
      "step": 12280
    },
    {
      "epoch": 5.84,
      "learning_rate": 8.333491686460808e-05,
      "loss": 0.6804,
      "step": 12290
    },
    {
      "epoch": 5.84,
      "learning_rate": 8.323990498812352e-05,
      "loss": 0.6735,
      "step": 12300
    },
    {
      "epoch": 5.85,
      "learning_rate": 8.314489311163895e-05,
      "loss": 0.6773,
      "step": 12310
    },
    {
      "epoch": 5.85,
      "learning_rate": 8.30498812351544e-05,
      "loss": 0.6828,
      "step": 12320
    },
    {
      "epoch": 5.86,
      "learning_rate": 8.295486935866984e-05,
      "loss": 0.6891,
      "step": 12330
    },
    {
      "epoch": 5.86,
      "learning_rate": 8.285985748218527e-05,
      "loss": 0.698,
      "step": 12340
    },
    {
      "epoch": 5.87,
      "learning_rate": 8.276484560570072e-05,
      "loss": 0.6908,
      "step": 12350
    },
    {
      "epoch": 5.87,
      "learning_rate": 8.266983372921615e-05,
      "loss": 0.6845,
      "step": 12360
    },
    {
      "epoch": 5.88,
      "learning_rate": 8.25748218527316e-05,
      "loss": 0.6895,
      "step": 12370
    },
    {
      "epoch": 5.88,
      "learning_rate": 8.247980997624704e-05,
      "loss": 0.6967,
      "step": 12380
    },
    {
      "epoch": 5.89,
      "learning_rate": 8.238479809976247e-05,
      "loss": 0.6831,
      "step": 12390
    },
    {
      "epoch": 5.89,
      "learning_rate": 8.228978622327791e-05,
      "loss": 0.6809,
      "step": 12400
    },
    {
      "epoch": 5.9,
      "learning_rate": 8.219477434679336e-05,
      "loss": 0.6853,
      "step": 12410
    },
    {
      "epoch": 5.9,
      "learning_rate": 8.209976247030879e-05,
      "loss": 0.6711,
      "step": 12420
    },
    {
      "epoch": 5.9,
      "learning_rate": 8.200475059382423e-05,
      "loss": 0.6924,
      "step": 12430
    },
    {
      "epoch": 5.91,
      "learning_rate": 8.190973871733966e-05,
      "loss": 0.6938,
      "step": 12440
    },
    {
      "epoch": 5.91,
      "learning_rate": 8.181472684085512e-05,
      "loss": 0.6863,
      "step": 12450
    },
    {
      "epoch": 5.92,
      "learning_rate": 8.171971496437055e-05,
      "loss": 0.6905,
      "step": 12460
    },
    {
      "epoch": 5.92,
      "learning_rate": 8.162470308788598e-05,
      "loss": 0.6841,
      "step": 12470
    },
    {
      "epoch": 5.93,
      "learning_rate": 8.152969121140143e-05,
      "loss": 0.6747,
      "step": 12480
    },
    {
      "epoch": 5.93,
      "learning_rate": 8.143467933491686e-05,
      "loss": 0.678,
      "step": 12490
    },
    {
      "epoch": 5.94,
      "learning_rate": 8.133966745843232e-05,
      "loss": 0.6893,
      "step": 12500
    },
    {
      "epoch": 5.94,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7101323008537292,
      "eval_runtime": 0.5035,
      "eval_samples_per_second": 1731.791,
      "eval_steps_per_second": 13.902,
      "step": 12500
    },
    {
      "epoch": 5.94,
      "learning_rate": 8.124465558194775e-05,
      "loss": 0.6932,
      "step": 12510
    },
    {
      "epoch": 5.95,
      "learning_rate": 8.114964370546319e-05,
      "loss": 0.697,
      "step": 12520
    },
    {
      "epoch": 5.95,
      "learning_rate": 8.105463182897862e-05,
      "loss": 0.6779,
      "step": 12530
    },
    {
      "epoch": 5.96,
      "learning_rate": 8.095961995249407e-05,
      "loss": 0.6796,
      "step": 12540
    },
    {
      "epoch": 5.96,
      "learning_rate": 8.086460807600951e-05,
      "loss": 0.6963,
      "step": 12550
    },
    {
      "epoch": 5.97,
      "learning_rate": 8.076959619952494e-05,
      "loss": 0.6893,
      "step": 12560
    },
    {
      "epoch": 5.97,
      "learning_rate": 8.067458432304039e-05,
      "loss": 0.6856,
      "step": 12570
    },
    {
      "epoch": 5.98,
      "learning_rate": 8.057957244655583e-05,
      "loss": 0.686,
      "step": 12580
    },
    {
      "epoch": 5.98,
      "learning_rate": 8.048456057007126e-05,
      "loss": 0.6856,
      "step": 12590
    },
    {
      "epoch": 5.99,
      "learning_rate": 8.03895486935867e-05,
      "loss": 0.688,
      "step": 12600
    },
    {
      "epoch": 5.99,
      "learning_rate": 8.029453681710214e-05,
      "loss": 0.6859,
      "step": 12610
    },
    {
      "epoch": 6.0,
      "learning_rate": 8.019952494061758e-05,
      "loss": 0.6812,
      "step": 12620
    },
    {
      "epoch": 6.0,
      "learning_rate": 8.010451306413303e-05,
      "loss": 0.6949,
      "step": 12630
    },
    {
      "epoch": 6.0,
      "learning_rate": 8.000950118764846e-05,
      "loss": 0.6983,
      "step": 12640
    },
    {
      "epoch": 6.01,
      "learning_rate": 7.99144893111639e-05,
      "loss": 0.696,
      "step": 12650
    },
    {
      "epoch": 6.01,
      "learning_rate": 7.981947743467933e-05,
      "loss": 0.6944,
      "step": 12660
    },
    {
      "epoch": 6.02,
      "learning_rate": 7.972446555819478e-05,
      "loss": 0.6864,
      "step": 12670
    },
    {
      "epoch": 6.02,
      "learning_rate": 7.962945368171022e-05,
      "loss": 0.6837,
      "step": 12680
    },
    {
      "epoch": 6.03,
      "learning_rate": 7.953444180522565e-05,
      "loss": 0.6742,
      "step": 12690
    },
    {
      "epoch": 6.03,
      "learning_rate": 7.94394299287411e-05,
      "loss": 0.689,
      "step": 12700
    },
    {
      "epoch": 6.04,
      "learning_rate": 7.934441805225653e-05,
      "loss": 0.6839,
      "step": 12710
    },
    {
      "epoch": 6.04,
      "learning_rate": 7.924940617577198e-05,
      "loss": 0.6793,
      "step": 12720
    },
    {
      "epoch": 6.05,
      "learning_rate": 7.915439429928742e-05,
      "loss": 0.6916,
      "step": 12730
    },
    {
      "epoch": 6.05,
      "learning_rate": 7.905938242280285e-05,
      "loss": 0.6978,
      "step": 12740
    },
    {
      "epoch": 6.06,
      "learning_rate": 7.896437054631829e-05,
      "loss": 0.6918,
      "step": 12750
    },
    {
      "epoch": 6.06,
      "learning_rate": 7.886935866983374e-05,
      "loss": 0.6903,
      "step": 12760
    },
    {
      "epoch": 6.07,
      "learning_rate": 7.877434679334918e-05,
      "loss": 0.6924,
      "step": 12770
    },
    {
      "epoch": 6.07,
      "learning_rate": 7.867933491686461e-05,
      "loss": 0.6873,
      "step": 12780
    },
    {
      "epoch": 6.08,
      "learning_rate": 7.858432304038004e-05,
      "loss": 0.6786,
      "step": 12790
    },
    {
      "epoch": 6.08,
      "learning_rate": 7.84893111638955e-05,
      "loss": 0.6821,
      "step": 12800
    },
    {
      "epoch": 6.09,
      "learning_rate": 7.839429928741093e-05,
      "loss": 0.6974,
      "step": 12810
    },
    {
      "epoch": 6.09,
      "learning_rate": 7.829928741092637e-05,
      "loss": 0.7035,
      "step": 12820
    },
    {
      "epoch": 6.1,
      "learning_rate": 7.82042755344418e-05,
      "loss": 0.6882,
      "step": 12830
    },
    {
      "epoch": 6.1,
      "learning_rate": 7.810926365795725e-05,
      "loss": 0.698,
      "step": 12840
    },
    {
      "epoch": 6.1,
      "learning_rate": 7.80142517814727e-05,
      "loss": 0.6875,
      "step": 12850
    },
    {
      "epoch": 6.11,
      "learning_rate": 7.791923990498812e-05,
      "loss": 0.6814,
      "step": 12860
    },
    {
      "epoch": 6.11,
      "learning_rate": 7.782422802850357e-05,
      "loss": 0.6942,
      "step": 12870
    },
    {
      "epoch": 6.12,
      "learning_rate": 7.7729216152019e-05,
      "loss": 0.6953,
      "step": 12880
    },
    {
      "epoch": 6.12,
      "learning_rate": 7.763420427553444e-05,
      "loss": 0.6863,
      "step": 12890
    },
    {
      "epoch": 6.13,
      "learning_rate": 7.753919239904989e-05,
      "loss": 0.6789,
      "step": 12900
    },
    {
      "epoch": 6.13,
      "learning_rate": 7.744418052256532e-05,
      "loss": 0.693,
      "step": 12910
    },
    {
      "epoch": 6.14,
      "learning_rate": 7.734916864608076e-05,
      "loss": 0.6982,
      "step": 12920
    },
    {
      "epoch": 6.14,
      "learning_rate": 7.725415676959621e-05,
      "loss": 0.683,
      "step": 12930
    },
    {
      "epoch": 6.15,
      "learning_rate": 7.715914489311164e-05,
      "loss": 0.679,
      "step": 12940
    },
    {
      "epoch": 6.15,
      "learning_rate": 7.706413301662708e-05,
      "loss": 0.6786,
      "step": 12950
    },
    {
      "epoch": 6.16,
      "learning_rate": 7.696912114014251e-05,
      "loss": 0.6753,
      "step": 12960
    },
    {
      "epoch": 6.16,
      "learning_rate": 7.687410926365796e-05,
      "loss": 0.6986,
      "step": 12970
    },
    {
      "epoch": 6.17,
      "learning_rate": 7.67790973871734e-05,
      "loss": 0.6887,
      "step": 12980
    },
    {
      "epoch": 6.17,
      "learning_rate": 7.668408551068885e-05,
      "loss": 0.6807,
      "step": 12990
    },
    {
      "epoch": 6.18,
      "learning_rate": 7.658907363420428e-05,
      "loss": 0.6911,
      "step": 13000
    },
    {
      "epoch": 6.18,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7024424076080322,
      "eval_runtime": 0.5146,
      "eval_samples_per_second": 1694.494,
      "eval_steps_per_second": 13.603,
      "step": 13000
    },
    {
      "epoch": 6.18,
      "learning_rate": 7.649406175771971e-05,
      "loss": 0.6803,
      "step": 13010
    },
    {
      "epoch": 6.19,
      "learning_rate": 7.639904988123517e-05,
      "loss": 0.6813,
      "step": 13020
    },
    {
      "epoch": 6.19,
      "learning_rate": 7.63040380047506e-05,
      "loss": 0.6754,
      "step": 13030
    },
    {
      "epoch": 6.19,
      "learning_rate": 7.620902612826604e-05,
      "loss": 0.6975,
      "step": 13040
    },
    {
      "epoch": 6.2,
      "learning_rate": 7.611401425178147e-05,
      "loss": 0.6909,
      "step": 13050
    },
    {
      "epoch": 6.2,
      "learning_rate": 7.60190023752969e-05,
      "loss": 0.6927,
      "step": 13060
    },
    {
      "epoch": 6.21,
      "learning_rate": 7.592399049881236e-05,
      "loss": 0.6941,
      "step": 13070
    },
    {
      "epoch": 6.21,
      "learning_rate": 7.58289786223278e-05,
      "loss": 0.6892,
      "step": 13080
    },
    {
      "epoch": 6.22,
      "learning_rate": 7.573396674584324e-05,
      "loss": 0.6841,
      "step": 13090
    },
    {
      "epoch": 6.22,
      "learning_rate": 7.563895486935867e-05,
      "loss": 0.6869,
      "step": 13100
    },
    {
      "epoch": 6.23,
      "learning_rate": 7.554394299287411e-05,
      "loss": 0.6866,
      "step": 13110
    },
    {
      "epoch": 6.23,
      "learning_rate": 7.544893111638956e-05,
      "loss": 0.6875,
      "step": 13120
    },
    {
      "epoch": 6.24,
      "learning_rate": 7.535391923990499e-05,
      "loss": 0.683,
      "step": 13130
    },
    {
      "epoch": 6.24,
      "learning_rate": 7.525890736342043e-05,
      "loss": 0.6728,
      "step": 13140
    },
    {
      "epoch": 6.25,
      "learning_rate": 7.516389548693588e-05,
      "loss": 0.6803,
      "step": 13150
    },
    {
      "epoch": 6.25,
      "learning_rate": 7.506888361045131e-05,
      "loss": 0.6905,
      "step": 13160
    },
    {
      "epoch": 6.26,
      "learning_rate": 7.497387173396675e-05,
      "loss": 0.6905,
      "step": 13170
    },
    {
      "epoch": 6.26,
      "learning_rate": 7.487885985748218e-05,
      "loss": 0.6853,
      "step": 13180
    },
    {
      "epoch": 6.27,
      "learning_rate": 7.478384798099763e-05,
      "loss": 0.6894,
      "step": 13190
    },
    {
      "epoch": 6.27,
      "learning_rate": 7.468883610451307e-05,
      "loss": 0.6819,
      "step": 13200
    },
    {
      "epoch": 6.28,
      "learning_rate": 7.45938242280285e-05,
      "loss": 0.6886,
      "step": 13210
    },
    {
      "epoch": 6.28,
      "learning_rate": 7.449881235154395e-05,
      "loss": 0.6829,
      "step": 13220
    },
    {
      "epoch": 6.29,
      "learning_rate": 7.440380047505938e-05,
      "loss": 0.692,
      "step": 13230
    },
    {
      "epoch": 6.29,
      "learning_rate": 7.430878859857484e-05,
      "loss": 0.6989,
      "step": 13240
    },
    {
      "epoch": 6.29,
      "learning_rate": 7.421377672209027e-05,
      "loss": 0.6869,
      "step": 13250
    },
    {
      "epoch": 6.3,
      "learning_rate": 7.41187648456057e-05,
      "loss": 0.6839,
      "step": 13260
    },
    {
      "epoch": 6.3,
      "learning_rate": 7.402375296912114e-05,
      "loss": 0.6868,
      "step": 13270
    },
    {
      "epoch": 6.31,
      "learning_rate": 7.392874109263659e-05,
      "loss": 0.6864,
      "step": 13280
    },
    {
      "epoch": 6.31,
      "learning_rate": 7.383372921615203e-05,
      "loss": 0.6936,
      "step": 13290
    },
    {
      "epoch": 6.32,
      "learning_rate": 7.373871733966746e-05,
      "loss": 0.6866,
      "step": 13300
    },
    {
      "epoch": 6.32,
      "learning_rate": 7.36437054631829e-05,
      "loss": 0.6888,
      "step": 13310
    },
    {
      "epoch": 6.33,
      "learning_rate": 7.354869358669834e-05,
      "loss": 0.69,
      "step": 13320
    },
    {
      "epoch": 6.33,
      "learning_rate": 7.345368171021378e-05,
      "loss": 0.6886,
      "step": 13330
    },
    {
      "epoch": 6.34,
      "learning_rate": 7.335866983372923e-05,
      "loss": 0.6757,
      "step": 13340
    },
    {
      "epoch": 6.34,
      "learning_rate": 7.326365795724466e-05,
      "loss": 0.6893,
      "step": 13350
    },
    {
      "epoch": 6.35,
      "learning_rate": 7.31686460807601e-05,
      "loss": 0.7005,
      "step": 13360
    },
    {
      "epoch": 6.35,
      "learning_rate": 7.307363420427555e-05,
      "loss": 0.6897,
      "step": 13370
    },
    {
      "epoch": 6.36,
      "learning_rate": 7.297862232779098e-05,
      "loss": 0.6883,
      "step": 13380
    },
    {
      "epoch": 6.36,
      "learning_rate": 7.288361045130642e-05,
      "loss": 0.6893,
      "step": 13390
    },
    {
      "epoch": 6.37,
      "learning_rate": 7.278859857482185e-05,
      "loss": 0.6887,
      "step": 13400
    },
    {
      "epoch": 6.37,
      "learning_rate": 7.26935866983373e-05,
      "loss": 0.6976,
      "step": 13410
    },
    {
      "epoch": 6.38,
      "learning_rate": 7.259857482185274e-05,
      "loss": 0.6911,
      "step": 13420
    },
    {
      "epoch": 6.38,
      "learning_rate": 7.250356294536817e-05,
      "loss": 0.6882,
      "step": 13430
    },
    {
      "epoch": 6.38,
      "learning_rate": 7.240855106888362e-05,
      "loss": 0.6907,
      "step": 13440
    },
    {
      "epoch": 6.39,
      "learning_rate": 7.231353919239905e-05,
      "loss": 0.6876,
      "step": 13450
    },
    {
      "epoch": 6.39,
      "learning_rate": 7.221852731591449e-05,
      "loss": 0.6803,
      "step": 13460
    },
    {
      "epoch": 6.4,
      "learning_rate": 7.212351543942993e-05,
      "loss": 0.6736,
      "step": 13470
    },
    {
      "epoch": 6.4,
      "learning_rate": 7.202850356294537e-05,
      "loss": 0.6651,
      "step": 13480
    },
    {
      "epoch": 6.41,
      "learning_rate": 7.193349168646081e-05,
      "loss": 0.6829,
      "step": 13490
    },
    {
      "epoch": 6.41,
      "learning_rate": 7.183847980997625e-05,
      "loss": 0.6988,
      "step": 13500
    },
    {
      "epoch": 6.41,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7107874155044556,
      "eval_runtime": 0.5596,
      "eval_samples_per_second": 1558.14,
      "eval_steps_per_second": 12.508,
      "step": 13500
    },
    {
      "epoch": 6.42,
      "learning_rate": 7.17434679334917e-05,
      "loss": 0.6748,
      "step": 13510
    },
    {
      "epoch": 6.42,
      "learning_rate": 7.164845605700713e-05,
      "loss": 0.6905,
      "step": 13520
    },
    {
      "epoch": 6.43,
      "learning_rate": 7.155344418052256e-05,
      "loss": 0.6866,
      "step": 13530
    },
    {
      "epoch": 6.43,
      "learning_rate": 7.1458432304038e-05,
      "loss": 0.6929,
      "step": 13540
    },
    {
      "epoch": 6.44,
      "learning_rate": 7.136342042755345e-05,
      "loss": 0.6915,
      "step": 13550
    },
    {
      "epoch": 6.44,
      "learning_rate": 7.12684085510689e-05,
      "loss": 0.6794,
      "step": 13560
    },
    {
      "epoch": 6.45,
      "learning_rate": 7.117339667458432e-05,
      "loss": 0.6787,
      "step": 13570
    },
    {
      "epoch": 6.45,
      "learning_rate": 7.107838479809976e-05,
      "loss": 0.6871,
      "step": 13580
    },
    {
      "epoch": 6.46,
      "learning_rate": 7.098337292161521e-05,
      "loss": 0.6887,
      "step": 13590
    },
    {
      "epoch": 6.46,
      "learning_rate": 7.088836104513064e-05,
      "loss": 0.6768,
      "step": 13600
    },
    {
      "epoch": 6.47,
      "learning_rate": 7.079334916864609e-05,
      "loss": 0.6806,
      "step": 13610
    },
    {
      "epoch": 6.47,
      "learning_rate": 7.069833729216152e-05,
      "loss": 0.6878,
      "step": 13620
    },
    {
      "epoch": 6.48,
      "learning_rate": 7.060332541567696e-05,
      "loss": 0.6799,
      "step": 13630
    },
    {
      "epoch": 6.48,
      "learning_rate": 7.050831353919241e-05,
      "loss": 0.6678,
      "step": 13640
    },
    {
      "epoch": 6.48,
      "learning_rate": 7.041330166270784e-05,
      "loss": 0.6925,
      "step": 13650
    },
    {
      "epoch": 6.49,
      "learning_rate": 7.031828978622328e-05,
      "loss": 0.6926,
      "step": 13660
    },
    {
      "epoch": 6.49,
      "learning_rate": 7.022327790973871e-05,
      "loss": 0.6927,
      "step": 13670
    },
    {
      "epoch": 6.5,
      "learning_rate": 7.012826603325416e-05,
      "loss": 0.6833,
      "step": 13680
    },
    {
      "epoch": 6.5,
      "learning_rate": 7.00332541567696e-05,
      "loss": 0.6852,
      "step": 13690
    },
    {
      "epoch": 6.51,
      "learning_rate": 6.993824228028503e-05,
      "loss": 0.668,
      "step": 13700
    },
    {
      "epoch": 6.51,
      "learning_rate": 6.984323040380048e-05,
      "loss": 0.6833,
      "step": 13710
    },
    {
      "epoch": 6.52,
      "learning_rate": 6.974821852731592e-05,
      "loss": 0.6741,
      "step": 13720
    },
    {
      "epoch": 6.52,
      "learning_rate": 6.965320665083135e-05,
      "loss": 0.6888,
      "step": 13730
    },
    {
      "epoch": 6.53,
      "learning_rate": 6.95581947743468e-05,
      "loss": 0.6947,
      "step": 13740
    },
    {
      "epoch": 6.53,
      "learning_rate": 6.946318289786223e-05,
      "loss": 0.6826,
      "step": 13750
    },
    {
      "epoch": 6.54,
      "learning_rate": 6.936817102137767e-05,
      "loss": 0.6951,
      "step": 13760
    },
    {
      "epoch": 6.54,
      "learning_rate": 6.927315914489312e-05,
      "loss": 0.6826,
      "step": 13770
    },
    {
      "epoch": 6.55,
      "learning_rate": 6.917814726840855e-05,
      "loss": 0.6916,
      "step": 13780
    },
    {
      "epoch": 6.55,
      "learning_rate": 6.908313539192399e-05,
      "loss": 0.695,
      "step": 13790
    },
    {
      "epoch": 6.56,
      "learning_rate": 6.898812351543942e-05,
      "loss": 0.6785,
      "step": 13800
    },
    {
      "epoch": 6.56,
      "learning_rate": 6.889311163895488e-05,
      "loss": 0.6899,
      "step": 13810
    },
    {
      "epoch": 6.57,
      "learning_rate": 6.879809976247031e-05,
      "loss": 0.689,
      "step": 13820
    },
    {
      "epoch": 6.57,
      "learning_rate": 6.870308788598576e-05,
      "loss": 0.684,
      "step": 13830
    },
    {
      "epoch": 6.57,
      "learning_rate": 6.860807600950119e-05,
      "loss": 0.6756,
      "step": 13840
    },
    {
      "epoch": 6.58,
      "learning_rate": 6.851306413301663e-05,
      "loss": 0.6953,
      "step": 13850
    },
    {
      "epoch": 6.58,
      "learning_rate": 6.841805225653208e-05,
      "loss": 0.6988,
      "step": 13860
    },
    {
      "epoch": 6.59,
      "learning_rate": 6.832304038004751e-05,
      "loss": 0.6848,
      "step": 13870
    },
    {
      "epoch": 6.59,
      "learning_rate": 6.822802850356295e-05,
      "loss": 0.694,
      "step": 13880
    },
    {
      "epoch": 6.6,
      "learning_rate": 6.813301662707838e-05,
      "loss": 0.701,
      "step": 13890
    },
    {
      "epoch": 6.6,
      "learning_rate": 6.803800475059383e-05,
      "loss": 0.6908,
      "step": 13900
    },
    {
      "epoch": 6.61,
      "learning_rate": 6.794299287410927e-05,
      "loss": 0.6909,
      "step": 13910
    },
    {
      "epoch": 6.61,
      "learning_rate": 6.78479809976247e-05,
      "loss": 0.6916,
      "step": 13920
    },
    {
      "epoch": 6.62,
      "learning_rate": 6.775296912114015e-05,
      "loss": 0.6875,
      "step": 13930
    },
    {
      "epoch": 6.62,
      "learning_rate": 6.765795724465559e-05,
      "loss": 0.6932,
      "step": 13940
    },
    {
      "epoch": 6.63,
      "learning_rate": 6.756294536817102e-05,
      "loss": 0.6696,
      "step": 13950
    },
    {
      "epoch": 6.63,
      "learning_rate": 6.746793349168647e-05,
      "loss": 0.6825,
      "step": 13960
    },
    {
      "epoch": 6.64,
      "learning_rate": 6.73729216152019e-05,
      "loss": 0.6846,
      "step": 13970
    },
    {
      "epoch": 6.64,
      "learning_rate": 6.727790973871734e-05,
      "loss": 0.6849,
      "step": 13980
    },
    {
      "epoch": 6.65,
      "learning_rate": 6.718289786223279e-05,
      "loss": 0.6755,
      "step": 13990
    },
    {
      "epoch": 6.65,
      "learning_rate": 6.708788598574822e-05,
      "loss": 0.6838,
      "step": 14000
    },
    {
      "epoch": 6.65,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7090135216712952,
      "eval_runtime": 0.5017,
      "eval_samples_per_second": 1738.157,
      "eval_steps_per_second": 13.953,
      "step": 14000
    },
    {
      "epoch": 6.66,
      "learning_rate": 6.699287410926366e-05,
      "loss": 0.6893,
      "step": 14010
    },
    {
      "epoch": 6.66,
      "learning_rate": 6.689786223277909e-05,
      "loss": 0.686,
      "step": 14020
    },
    {
      "epoch": 6.67,
      "learning_rate": 6.680285035629455e-05,
      "loss": 0.6906,
      "step": 14030
    },
    {
      "epoch": 6.67,
      "learning_rate": 6.670783847980998e-05,
      "loss": 0.6815,
      "step": 14040
    },
    {
      "epoch": 6.67,
      "learning_rate": 6.661282660332541e-05,
      "loss": 0.6882,
      "step": 14050
    },
    {
      "epoch": 6.68,
      "learning_rate": 6.651781472684086e-05,
      "loss": 0.6841,
      "step": 14060
    },
    {
      "epoch": 6.68,
      "learning_rate": 6.64228028503563e-05,
      "loss": 0.6843,
      "step": 14070
    },
    {
      "epoch": 6.69,
      "learning_rate": 6.632779097387174e-05,
      "loss": 0.6863,
      "step": 14080
    },
    {
      "epoch": 6.69,
      "learning_rate": 6.623277909738718e-05,
      "loss": 0.6911,
      "step": 14090
    },
    {
      "epoch": 6.7,
      "learning_rate": 6.61377672209026e-05,
      "loss": 0.6885,
      "step": 14100
    },
    {
      "epoch": 6.7,
      "learning_rate": 6.604275534441805e-05,
      "loss": 0.6815,
      "step": 14110
    },
    {
      "epoch": 6.71,
      "learning_rate": 6.59477434679335e-05,
      "loss": 0.6891,
      "step": 14120
    },
    {
      "epoch": 6.71,
      "learning_rate": 6.585273159144894e-05,
      "loss": 0.6853,
      "step": 14130
    },
    {
      "epoch": 6.72,
      "learning_rate": 6.575771971496437e-05,
      "loss": 0.6886,
      "step": 14140
    },
    {
      "epoch": 6.72,
      "learning_rate": 6.566270783847982e-05,
      "loss": 0.6952,
      "step": 14150
    },
    {
      "epoch": 6.73,
      "learning_rate": 6.556769596199526e-05,
      "loss": 0.6855,
      "step": 14160
    },
    {
      "epoch": 6.73,
      "learning_rate": 6.547268408551069e-05,
      "loss": 0.6998,
      "step": 14170
    },
    {
      "epoch": 6.74,
      "learning_rate": 6.537767220902613e-05,
      "loss": 0.6877,
      "step": 14180
    },
    {
      "epoch": 6.74,
      "learning_rate": 6.528266033254157e-05,
      "loss": 0.6796,
      "step": 14190
    },
    {
      "epoch": 6.75,
      "learning_rate": 6.518764845605701e-05,
      "loss": 0.6924,
      "step": 14200
    },
    {
      "epoch": 6.75,
      "learning_rate": 6.509263657957245e-05,
      "loss": 0.6908,
      "step": 14210
    },
    {
      "epoch": 6.76,
      "learning_rate": 6.499762470308789e-05,
      "loss": 0.6883,
      "step": 14220
    },
    {
      "epoch": 6.76,
      "learning_rate": 6.490261282660333e-05,
      "loss": 0.6858,
      "step": 14230
    },
    {
      "epoch": 6.76,
      "learning_rate": 6.480760095011876e-05,
      "loss": 0.6736,
      "step": 14240
    },
    {
      "epoch": 6.77,
      "learning_rate": 6.47125890736342e-05,
      "loss": 0.6772,
      "step": 14250
    },
    {
      "epoch": 6.77,
      "learning_rate": 6.461757719714965e-05,
      "loss": 0.6865,
      "step": 14260
    },
    {
      "epoch": 6.78,
      "learning_rate": 6.452256532066508e-05,
      "loss": 0.6918,
      "step": 14270
    },
    {
      "epoch": 6.78,
      "learning_rate": 6.442755344418052e-05,
      "loss": 0.6959,
      "step": 14280
    },
    {
      "epoch": 6.79,
      "learning_rate": 6.433254156769597e-05,
      "loss": 0.6939,
      "step": 14290
    },
    {
      "epoch": 6.79,
      "learning_rate": 6.423752969121141e-05,
      "loss": 0.6944,
      "step": 14300
    },
    {
      "epoch": 6.8,
      "learning_rate": 6.414251781472684e-05,
      "loss": 0.6861,
      "step": 14310
    },
    {
      "epoch": 6.8,
      "learning_rate": 6.404750593824227e-05,
      "loss": 0.689,
      "step": 14320
    },
    {
      "epoch": 6.81,
      "learning_rate": 6.395249406175772e-05,
      "loss": 0.6857,
      "step": 14330
    },
    {
      "epoch": 6.81,
      "learning_rate": 6.385748218527316e-05,
      "loss": 0.6833,
      "step": 14340
    },
    {
      "epoch": 6.82,
      "learning_rate": 6.376247030878861e-05,
      "loss": 0.6946,
      "step": 14350
    },
    {
      "epoch": 6.82,
      "learning_rate": 6.366745843230404e-05,
      "loss": 0.6809,
      "step": 14360
    },
    {
      "epoch": 6.83,
      "learning_rate": 6.357244655581947e-05,
      "loss": 0.6859,
      "step": 14370
    },
    {
      "epoch": 6.83,
      "learning_rate": 6.347743467933493e-05,
      "loss": 0.6837,
      "step": 14380
    },
    {
      "epoch": 6.84,
      "learning_rate": 6.338242280285036e-05,
      "loss": 0.6802,
      "step": 14390
    },
    {
      "epoch": 6.84,
      "learning_rate": 6.32874109263658e-05,
      "loss": 0.6934,
      "step": 14400
    },
    {
      "epoch": 6.85,
      "learning_rate": 6.319239904988123e-05,
      "loss": 0.6855,
      "step": 14410
    },
    {
      "epoch": 6.85,
      "learning_rate": 6.309738717339668e-05,
      "loss": 0.6937,
      "step": 14420
    },
    {
      "epoch": 6.86,
      "learning_rate": 6.300237529691212e-05,
      "loss": 0.6906,
      "step": 14430
    },
    {
      "epoch": 6.86,
      "learning_rate": 6.290736342042755e-05,
      "loss": 0.6825,
      "step": 14440
    },
    {
      "epoch": 6.86,
      "learning_rate": 6.2812351543943e-05,
      "loss": 0.6711,
      "step": 14450
    },
    {
      "epoch": 6.87,
      "learning_rate": 6.271733966745843e-05,
      "loss": 0.6867,
      "step": 14460
    },
    {
      "epoch": 6.87,
      "learning_rate": 6.262232779097387e-05,
      "loss": 0.6866,
      "step": 14470
    },
    {
      "epoch": 6.88,
      "learning_rate": 6.252731591448932e-05,
      "loss": 0.6845,
      "step": 14480
    },
    {
      "epoch": 6.88,
      "learning_rate": 6.243230403800475e-05,
      "loss": 0.6959,
      "step": 14490
    },
    {
      "epoch": 6.89,
      "learning_rate": 6.233729216152019e-05,
      "loss": 0.6921,
      "step": 14500
    },
    {
      "epoch": 6.89,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7020431756973267,
      "eval_runtime": 0.5056,
      "eval_samples_per_second": 1724.523,
      "eval_steps_per_second": 13.844,
      "step": 14500
    },
    {
      "epoch": 6.89,
      "learning_rate": 6.224228028503564e-05,
      "loss": 0.6903,
      "step": 14510
    },
    {
      "epoch": 6.9,
      "learning_rate": 6.214726840855107e-05,
      "loss": 0.6821,
      "step": 14520
    },
    {
      "epoch": 6.9,
      "learning_rate": 6.205225653206651e-05,
      "loss": 0.6809,
      "step": 14530
    },
    {
      "epoch": 6.91,
      "learning_rate": 6.195724465558194e-05,
      "loss": 0.685,
      "step": 14540
    },
    {
      "epoch": 6.91,
      "learning_rate": 6.18622327790974e-05,
      "loss": 0.6792,
      "step": 14550
    },
    {
      "epoch": 6.92,
      "learning_rate": 6.176722090261283e-05,
      "loss": 0.6933,
      "step": 14560
    },
    {
      "epoch": 6.92,
      "learning_rate": 6.167220902612826e-05,
      "loss": 0.6782,
      "step": 14570
    },
    {
      "epoch": 6.93,
      "learning_rate": 6.157719714964371e-05,
      "loss": 0.6735,
      "step": 14580
    },
    {
      "epoch": 6.93,
      "learning_rate": 6.148218527315914e-05,
      "loss": 0.6861,
      "step": 14590
    },
    {
      "epoch": 6.94,
      "learning_rate": 6.13871733966746e-05,
      "loss": 0.6836,
      "step": 14600
    },
    {
      "epoch": 6.94,
      "learning_rate": 6.129216152019003e-05,
      "loss": 0.6935,
      "step": 14610
    },
    {
      "epoch": 6.95,
      "learning_rate": 6.119714964370547e-05,
      "loss": 0.6788,
      "step": 14620
    },
    {
      "epoch": 6.95,
      "learning_rate": 6.11021377672209e-05,
      "loss": 0.6732,
      "step": 14630
    },
    {
      "epoch": 6.95,
      "learning_rate": 6.1007125890736346e-05,
      "loss": 0.6885,
      "step": 14640
    },
    {
      "epoch": 6.96,
      "learning_rate": 6.0912114014251784e-05,
      "loss": 0.6938,
      "step": 14650
    },
    {
      "epoch": 6.96,
      "learning_rate": 6.081710213776722e-05,
      "loss": 0.692,
      "step": 14660
    },
    {
      "epoch": 6.97,
      "learning_rate": 6.072209026128266e-05,
      "loss": 0.677,
      "step": 14670
    },
    {
      "epoch": 6.97,
      "learning_rate": 6.06270783847981e-05,
      "loss": 0.6827,
      "step": 14680
    },
    {
      "epoch": 6.98,
      "learning_rate": 6.053206650831355e-05,
      "loss": 0.6774,
      "step": 14690
    },
    {
      "epoch": 6.98,
      "learning_rate": 6.043705463182898e-05,
      "loss": 0.6923,
      "step": 14700
    },
    {
      "epoch": 6.99,
      "learning_rate": 6.0342042755344417e-05,
      "loss": 0.6812,
      "step": 14710
    },
    {
      "epoch": 6.99,
      "learning_rate": 6.0247030878859854e-05,
      "loss": 0.6873,
      "step": 14720
    },
    {
      "epoch": 7.0,
      "learning_rate": 6.0152019002375305e-05,
      "loss": 0.6761,
      "step": 14730
    },
    {
      "epoch": 7.0,
      "learning_rate": 6.005700712589074e-05,
      "loss": 0.6807,
      "step": 14740
    },
    {
      "epoch": 7.01,
      "learning_rate": 5.996199524940618e-05,
      "loss": 0.6941,
      "step": 14750
    },
    {
      "epoch": 7.01,
      "learning_rate": 5.986698337292161e-05,
      "loss": 0.6812,
      "step": 14760
    },
    {
      "epoch": 7.02,
      "learning_rate": 5.977197149643706e-05,
      "loss": 0.6803,
      "step": 14770
    },
    {
      "epoch": 7.02,
      "learning_rate": 5.96769596199525e-05,
      "loss": 0.6873,
      "step": 14780
    },
    {
      "epoch": 7.03,
      "learning_rate": 5.958194774346794e-05,
      "loss": 0.6796,
      "step": 14790
    },
    {
      "epoch": 7.03,
      "learning_rate": 5.9486935866983376e-05,
      "loss": 0.6782,
      "step": 14800
    },
    {
      "epoch": 7.04,
      "learning_rate": 5.939192399049881e-05,
      "loss": 0.6861,
      "step": 14810
    },
    {
      "epoch": 7.04,
      "learning_rate": 5.929691211401426e-05,
      "loss": 0.69,
      "step": 14820
    },
    {
      "epoch": 7.05,
      "learning_rate": 5.9201900237529695e-05,
      "loss": 0.6766,
      "step": 14830
    },
    {
      "epoch": 7.05,
      "learning_rate": 5.910688836104513e-05,
      "loss": 0.6793,
      "step": 14840
    },
    {
      "epoch": 7.05,
      "learning_rate": 5.901187648456057e-05,
      "loss": 0.6903,
      "step": 14850
    },
    {
      "epoch": 7.06,
      "learning_rate": 5.8916864608076015e-05,
      "loss": 0.6901,
      "step": 14860
    },
    {
      "epoch": 7.06,
      "learning_rate": 5.882185273159145e-05,
      "loss": 0.69,
      "step": 14870
    },
    {
      "epoch": 7.07,
      "learning_rate": 5.872684085510689e-05,
      "loss": 0.6905,
      "step": 14880
    },
    {
      "epoch": 7.07,
      "learning_rate": 5.863182897862233e-05,
      "loss": 0.6947,
      "step": 14890
    },
    {
      "epoch": 7.08,
      "learning_rate": 5.853681710213777e-05,
      "loss": 0.6887,
      "step": 14900
    },
    {
      "epoch": 7.08,
      "learning_rate": 5.844180522565321e-05,
      "loss": 0.6844,
      "step": 14910
    },
    {
      "epoch": 7.09,
      "learning_rate": 5.834679334916865e-05,
      "loss": 0.6944,
      "step": 14920
    },
    {
      "epoch": 7.09,
      "learning_rate": 5.8251781472684085e-05,
      "loss": 0.6823,
      "step": 14930
    },
    {
      "epoch": 7.1,
      "learning_rate": 5.815676959619952e-05,
      "loss": 0.6927,
      "step": 14940
    },
    {
      "epoch": 7.1,
      "learning_rate": 5.8061757719714974e-05,
      "loss": 0.6902,
      "step": 14950
    },
    {
      "epoch": 7.11,
      "learning_rate": 5.7966745843230405e-05,
      "loss": 0.675,
      "step": 14960
    },
    {
      "epoch": 7.11,
      "learning_rate": 5.787173396674584e-05,
      "loss": 0.6846,
      "step": 14970
    },
    {
      "epoch": 7.12,
      "learning_rate": 5.777672209026128e-05,
      "loss": 0.6983,
      "step": 14980
    },
    {
      "epoch": 7.12,
      "learning_rate": 5.768171021377673e-05,
      "loss": 0.6755,
      "step": 14990
    },
    {
      "epoch": 7.13,
      "learning_rate": 5.758669833729217e-05,
      "loss": 0.6863,
      "step": 15000
    },
    {
      "epoch": 7.13,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7046144604682922,
      "eval_runtime": 0.5015,
      "eval_samples_per_second": 1738.83,
      "eval_steps_per_second": 13.959,
      "step": 15000
    },
    {
      "epoch": 7.13,
      "learning_rate": 5.7491686460807606e-05,
      "loss": 0.6904,
      "step": 15010
    },
    {
      "epoch": 7.14,
      "learning_rate": 5.739667458432304e-05,
      "loss": 0.6881,
      "step": 15020
    },
    {
      "epoch": 7.14,
      "learning_rate": 5.7301662707838475e-05,
      "loss": 0.6935,
      "step": 15030
    },
    {
      "epoch": 7.14,
      "learning_rate": 5.7206650831353926e-05,
      "loss": 0.6912,
      "step": 15040
    },
    {
      "epoch": 7.15,
      "learning_rate": 5.7111638954869363e-05,
      "loss": 0.6897,
      "step": 15050
    },
    {
      "epoch": 7.15,
      "learning_rate": 5.70166270783848e-05,
      "loss": 0.6801,
      "step": 15060
    },
    {
      "epoch": 7.16,
      "learning_rate": 5.692161520190024e-05,
      "loss": 0.6773,
      "step": 15070
    },
    {
      "epoch": 7.16,
      "learning_rate": 5.682660332541568e-05,
      "loss": 0.6843,
      "step": 15080
    },
    {
      "epoch": 7.17,
      "learning_rate": 5.673159144893112e-05,
      "loss": 0.6891,
      "step": 15090
    },
    {
      "epoch": 7.17,
      "learning_rate": 5.663657957244656e-05,
      "loss": 0.6884,
      "step": 15100
    },
    {
      "epoch": 7.18,
      "learning_rate": 5.6541567695961996e-05,
      "loss": 0.6844,
      "step": 15110
    },
    {
      "epoch": 7.18,
      "learning_rate": 5.644655581947744e-05,
      "loss": 0.6817,
      "step": 15120
    },
    {
      "epoch": 7.19,
      "learning_rate": 5.635154394299288e-05,
      "loss": 0.6826,
      "step": 15130
    },
    {
      "epoch": 7.19,
      "learning_rate": 5.6256532066508316e-05,
      "loss": 0.6828,
      "step": 15140
    },
    {
      "epoch": 7.2,
      "learning_rate": 5.616152019002375e-05,
      "loss": 0.6844,
      "step": 15150
    },
    {
      "epoch": 7.2,
      "learning_rate": 5.606650831353919e-05,
      "loss": 0.6784,
      "step": 15160
    },
    {
      "epoch": 7.21,
      "learning_rate": 5.5971496437054635e-05,
      "loss": 0.695,
      "step": 15170
    },
    {
      "epoch": 7.21,
      "learning_rate": 5.587648456057007e-05,
      "loss": 0.6935,
      "step": 15180
    },
    {
      "epoch": 7.22,
      "learning_rate": 5.578147268408551e-05,
      "loss": 0.6928,
      "step": 15190
    },
    {
      "epoch": 7.22,
      "learning_rate": 5.568646080760095e-05,
      "loss": 0.6814,
      "step": 15200
    },
    {
      "epoch": 7.23,
      "learning_rate": 5.55914489311164e-05,
      "loss": 0.6775,
      "step": 15210
    },
    {
      "epoch": 7.23,
      "learning_rate": 5.549643705463184e-05,
      "loss": 0.7009,
      "step": 15220
    },
    {
      "epoch": 7.24,
      "learning_rate": 5.540142517814727e-05,
      "loss": 0.6967,
      "step": 15230
    },
    {
      "epoch": 7.24,
      "learning_rate": 5.5306413301662705e-05,
      "loss": 0.6852,
      "step": 15240
    },
    {
      "epoch": 7.24,
      "learning_rate": 5.5211401425178156e-05,
      "loss": 0.6929,
      "step": 15250
    },
    {
      "epoch": 7.25,
      "learning_rate": 5.5116389548693594e-05,
      "loss": 0.6863,
      "step": 15260
    },
    {
      "epoch": 7.25,
      "learning_rate": 5.502137767220903e-05,
      "loss": 0.6785,
      "step": 15270
    },
    {
      "epoch": 7.26,
      "learning_rate": 5.492636579572447e-05,
      "loss": 0.6791,
      "step": 15280
    },
    {
      "epoch": 7.26,
      "learning_rate": 5.48313539192399e-05,
      "loss": 0.6907,
      "step": 15290
    },
    {
      "epoch": 7.27,
      "learning_rate": 5.473634204275535e-05,
      "loss": 0.6874,
      "step": 15300
    },
    {
      "epoch": 7.27,
      "learning_rate": 5.464133016627079e-05,
      "loss": 0.6804,
      "step": 15310
    },
    {
      "epoch": 7.28,
      "learning_rate": 5.4546318289786227e-05,
      "loss": 0.6807,
      "step": 15320
    },
    {
      "epoch": 7.28,
      "learning_rate": 5.4451306413301664e-05,
      "loss": 0.6883,
      "step": 15330
    },
    {
      "epoch": 7.29,
      "learning_rate": 5.435629453681711e-05,
      "loss": 0.6861,
      "step": 15340
    },
    {
      "epoch": 7.29,
      "learning_rate": 5.4261282660332546e-05,
      "loss": 0.6885,
      "step": 15350
    },
    {
      "epoch": 7.3,
      "learning_rate": 5.4166270783847984e-05,
      "loss": 0.6948,
      "step": 15360
    },
    {
      "epoch": 7.3,
      "learning_rate": 5.407125890736342e-05,
      "loss": 0.6855,
      "step": 15370
    },
    {
      "epoch": 7.31,
      "learning_rate": 5.397624703087886e-05,
      "loss": 0.6987,
      "step": 15380
    },
    {
      "epoch": 7.31,
      "learning_rate": 5.3881235154394303e-05,
      "loss": 0.692,
      "step": 15390
    },
    {
      "epoch": 7.32,
      "learning_rate": 5.378622327790974e-05,
      "loss": 0.6805,
      "step": 15400
    },
    {
      "epoch": 7.32,
      "learning_rate": 5.369121140142518e-05,
      "loss": 0.6902,
      "step": 15410
    },
    {
      "epoch": 7.33,
      "learning_rate": 5.3596199524940616e-05,
      "loss": 0.6852,
      "step": 15420
    },
    {
      "epoch": 7.33,
      "learning_rate": 5.350118764845606e-05,
      "loss": 0.6865,
      "step": 15430
    },
    {
      "epoch": 7.33,
      "learning_rate": 5.34061757719715e-05,
      "loss": 0.6989,
      "step": 15440
    },
    {
      "epoch": 7.34,
      "learning_rate": 5.3311163895486936e-05,
      "loss": 0.6887,
      "step": 15450
    },
    {
      "epoch": 7.34,
      "learning_rate": 5.3216152019002374e-05,
      "loss": 0.6922,
      "step": 15460
    },
    {
      "epoch": 7.35,
      "learning_rate": 5.3121140142517825e-05,
      "loss": 0.6787,
      "step": 15470
    },
    {
      "epoch": 7.35,
      "learning_rate": 5.302612826603326e-05,
      "loss": 0.68,
      "step": 15480
    },
    {
      "epoch": 7.36,
      "learning_rate": 5.293111638954869e-05,
      "loss": 0.6788,
      "step": 15490
    },
    {
      "epoch": 7.36,
      "learning_rate": 5.283610451306413e-05,
      "loss": 0.6905,
      "step": 15500
    },
    {
      "epoch": 7.36,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7092441916465759,
      "eval_runtime": 0.4996,
      "eval_samples_per_second": 1745.228,
      "eval_steps_per_second": 14.01,
      "step": 15500
    },
    {
      "epoch": 7.37,
      "learning_rate": 5.274109263657957e-05,
      "loss": 0.6892,
      "step": 15510
    },
    {
      "epoch": 7.37,
      "learning_rate": 5.264608076009502e-05,
      "loss": 0.6904,
      "step": 15520
    },
    {
      "epoch": 7.38,
      "learning_rate": 5.255106888361046e-05,
      "loss": 0.6878,
      "step": 15530
    },
    {
      "epoch": 7.38,
      "learning_rate": 5.2456057007125895e-05,
      "loss": 0.6922,
      "step": 15540
    },
    {
      "epoch": 7.39,
      "learning_rate": 5.2361045130641326e-05,
      "loss": 0.6916,
      "step": 15550
    },
    {
      "epoch": 7.39,
      "learning_rate": 5.226603325415678e-05,
      "loss": 0.6842,
      "step": 15560
    },
    {
      "epoch": 7.4,
      "learning_rate": 5.2171021377672215e-05,
      "loss": 0.6856,
      "step": 15570
    },
    {
      "epoch": 7.4,
      "learning_rate": 5.207600950118765e-05,
      "loss": 0.6855,
      "step": 15580
    },
    {
      "epoch": 7.41,
      "learning_rate": 5.198099762470309e-05,
      "loss": 0.6901,
      "step": 15590
    },
    {
      "epoch": 7.41,
      "learning_rate": 5.1885985748218534e-05,
      "loss": 0.6889,
      "step": 15600
    },
    {
      "epoch": 7.42,
      "learning_rate": 5.179097387173397e-05,
      "loss": 0.6748,
      "step": 15610
    },
    {
      "epoch": 7.42,
      "learning_rate": 5.169596199524941e-05,
      "loss": 0.6856,
      "step": 15620
    },
    {
      "epoch": 7.43,
      "learning_rate": 5.160095011876485e-05,
      "loss": 0.6992,
      "step": 15630
    },
    {
      "epoch": 7.43,
      "learning_rate": 5.1505938242280285e-05,
      "loss": 0.6853,
      "step": 15640
    },
    {
      "epoch": 7.43,
      "learning_rate": 5.141092636579573e-05,
      "loss": 0.6983,
      "step": 15650
    },
    {
      "epoch": 7.44,
      "learning_rate": 5.131591448931117e-05,
      "loss": 0.6824,
      "step": 15660
    },
    {
      "epoch": 7.44,
      "learning_rate": 5.1220902612826604e-05,
      "loss": 0.6893,
      "step": 15670
    },
    {
      "epoch": 7.45,
      "learning_rate": 5.112589073634204e-05,
      "loss": 0.6849,
      "step": 15680
    },
    {
      "epoch": 7.45,
      "learning_rate": 5.1030878859857486e-05,
      "loss": 0.6845,
      "step": 15690
    },
    {
      "epoch": 7.46,
      "learning_rate": 5.0935866983372924e-05,
      "loss": 0.6891,
      "step": 15700
    },
    {
      "epoch": 7.46,
      "learning_rate": 5.084085510688836e-05,
      "loss": 0.689,
      "step": 15710
    },
    {
      "epoch": 7.47,
      "learning_rate": 5.07458432304038e-05,
      "loss": 0.6865,
      "step": 15720
    },
    {
      "epoch": 7.47,
      "learning_rate": 5.065083135391924e-05,
      "loss": 0.6846,
      "step": 15730
    },
    {
      "epoch": 7.48,
      "learning_rate": 5.055581947743469e-05,
      "loss": 0.6964,
      "step": 15740
    },
    {
      "epoch": 7.48,
      "learning_rate": 5.046080760095012e-05,
      "loss": 0.683,
      "step": 15750
    },
    {
      "epoch": 7.49,
      "learning_rate": 5.0365795724465556e-05,
      "loss": 0.6906,
      "step": 15760
    },
    {
      "epoch": 7.49,
      "learning_rate": 5.0270783847980994e-05,
      "loss": 0.6967,
      "step": 15770
    },
    {
      "epoch": 7.5,
      "learning_rate": 5.0175771971496445e-05,
      "loss": 0.6832,
      "step": 15780
    },
    {
      "epoch": 7.5,
      "learning_rate": 5.008076009501188e-05,
      "loss": 0.6965,
      "step": 15790
    },
    {
      "epoch": 7.51,
      "learning_rate": 4.998574821852732e-05,
      "loss": 0.6851,
      "step": 15800
    },
    {
      "epoch": 7.51,
      "learning_rate": 4.989073634204276e-05,
      "loss": 0.6875,
      "step": 15810
    },
    {
      "epoch": 7.52,
      "learning_rate": 4.9795724465558196e-05,
      "loss": 0.6829,
      "step": 15820
    },
    {
      "epoch": 7.52,
      "learning_rate": 4.970071258907364e-05,
      "loss": 0.6861,
      "step": 15830
    },
    {
      "epoch": 7.52,
      "learning_rate": 4.960570071258908e-05,
      "loss": 0.6855,
      "step": 15840
    },
    {
      "epoch": 7.53,
      "learning_rate": 4.9510688836104515e-05,
      "loss": 0.6618,
      "step": 15850
    },
    {
      "epoch": 7.53,
      "learning_rate": 4.941567695961995e-05,
      "loss": 0.7024,
      "step": 15860
    },
    {
      "epoch": 7.54,
      "learning_rate": 4.932066508313539e-05,
      "loss": 0.686,
      "step": 15870
    },
    {
      "epoch": 7.54,
      "learning_rate": 4.9225653206650835e-05,
      "loss": 0.672,
      "step": 15880
    },
    {
      "epoch": 7.55,
      "learning_rate": 4.913064133016627e-05,
      "loss": 0.6984,
      "step": 15890
    },
    {
      "epoch": 7.55,
      "learning_rate": 4.903562945368172e-05,
      "loss": 0.6594,
      "step": 15900
    },
    {
      "epoch": 7.56,
      "learning_rate": 4.894061757719715e-05,
      "loss": 0.6832,
      "step": 15910
    },
    {
      "epoch": 7.56,
      "learning_rate": 4.884560570071259e-05,
      "loss": 0.6988,
      "step": 15920
    },
    {
      "epoch": 7.57,
      "learning_rate": 4.875059382422803e-05,
      "loss": 0.6847,
      "step": 15930
    },
    {
      "epoch": 7.57,
      "learning_rate": 4.8655581947743474e-05,
      "loss": 0.693,
      "step": 15940
    },
    {
      "epoch": 7.58,
      "learning_rate": 4.856057007125891e-05,
      "loss": 0.6862,
      "step": 15950
    },
    {
      "epoch": 7.58,
      "learning_rate": 4.846555819477435e-05,
      "loss": 0.6799,
      "step": 15960
    },
    {
      "epoch": 7.59,
      "learning_rate": 4.837054631828979e-05,
      "loss": 0.6898,
      "step": 15970
    },
    {
      "epoch": 7.59,
      "learning_rate": 4.8275534441805225e-05,
      "loss": 0.6931,
      "step": 15980
    },
    {
      "epoch": 7.6,
      "learning_rate": 4.818052256532067e-05,
      "loss": 0.6861,
      "step": 15990
    },
    {
      "epoch": 7.6,
      "learning_rate": 4.808551068883611e-05,
      "loss": 0.6885,
      "step": 16000
    },
    {
      "epoch": 7.6,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7022430896759033,
      "eval_runtime": 0.4986,
      "eval_samples_per_second": 1749.012,
      "eval_steps_per_second": 14.04,
      "step": 16000
    },
    {
      "epoch": 7.61,
      "learning_rate": 4.7990498812351544e-05,
      "loss": 0.6727,
      "step": 16010
    },
    {
      "epoch": 7.61,
      "learning_rate": 4.789548693586698e-05,
      "loss": 0.6875,
      "step": 16020
    },
    {
      "epoch": 7.62,
      "learning_rate": 4.7800475059382426e-05,
      "loss": 0.6677,
      "step": 16030
    },
    {
      "epoch": 7.62,
      "learning_rate": 4.7705463182897864e-05,
      "loss": 0.6912,
      "step": 16040
    },
    {
      "epoch": 7.62,
      "learning_rate": 4.761045130641331e-05,
      "loss": 0.6723,
      "step": 16050
    },
    {
      "epoch": 7.63,
      "learning_rate": 4.7515439429928746e-05,
      "loss": 0.6716,
      "step": 16060
    },
    {
      "epoch": 7.63,
      "learning_rate": 4.7420427553444184e-05,
      "loss": 0.6915,
      "step": 16070
    },
    {
      "epoch": 7.64,
      "learning_rate": 4.732541567695962e-05,
      "loss": 0.6969,
      "step": 16080
    },
    {
      "epoch": 7.64,
      "learning_rate": 4.723040380047506e-05,
      "loss": 0.687,
      "step": 16090
    },
    {
      "epoch": 7.65,
      "learning_rate": 4.71353919239905e-05,
      "loss": 0.6744,
      "step": 16100
    },
    {
      "epoch": 7.65,
      "learning_rate": 4.704038004750594e-05,
      "loss": 0.6845,
      "step": 16110
    },
    {
      "epoch": 7.66,
      "learning_rate": 4.694536817102138e-05,
      "loss": 0.6801,
      "step": 16120
    },
    {
      "epoch": 7.66,
      "learning_rate": 4.6850356294536816e-05,
      "loss": 0.6861,
      "step": 16130
    },
    {
      "epoch": 7.67,
      "learning_rate": 4.675534441805226e-05,
      "loss": 0.6726,
      "step": 16140
    },
    {
      "epoch": 7.67,
      "learning_rate": 4.66603325415677e-05,
      "loss": 0.6805,
      "step": 16150
    },
    {
      "epoch": 7.68,
      "learning_rate": 4.656532066508314e-05,
      "loss": 0.6807,
      "step": 16160
    },
    {
      "epoch": 7.68,
      "learning_rate": 4.647030878859857e-05,
      "loss": 0.6834,
      "step": 16170
    },
    {
      "epoch": 7.69,
      "learning_rate": 4.637529691211402e-05,
      "loss": 0.6842,
      "step": 16180
    },
    {
      "epoch": 7.69,
      "learning_rate": 4.6280285035629455e-05,
      "loss": 0.6653,
      "step": 16190
    },
    {
      "epoch": 7.7,
      "learning_rate": 4.618527315914489e-05,
      "loss": 0.6897,
      "step": 16200
    },
    {
      "epoch": 7.7,
      "learning_rate": 4.609026128266034e-05,
      "loss": 0.678,
      "step": 16210
    },
    {
      "epoch": 7.71,
      "learning_rate": 4.5995249406175775e-05,
      "loss": 0.6742,
      "step": 16220
    },
    {
      "epoch": 7.71,
      "learning_rate": 4.590023752969121e-05,
      "loss": 0.6914,
      "step": 16230
    },
    {
      "epoch": 7.71,
      "learning_rate": 4.580522565320665e-05,
      "loss": 0.6744,
      "step": 16240
    },
    {
      "epoch": 7.72,
      "learning_rate": 4.5710213776722095e-05,
      "loss": 0.6876,
      "step": 16250
    },
    {
      "epoch": 7.72,
      "learning_rate": 4.561520190023753e-05,
      "loss": 0.6964,
      "step": 16260
    },
    {
      "epoch": 7.73,
      "learning_rate": 4.552019002375298e-05,
      "loss": 0.691,
      "step": 16270
    },
    {
      "epoch": 7.73,
      "learning_rate": 4.542517814726841e-05,
      "loss": 0.6928,
      "step": 16280
    },
    {
      "epoch": 7.74,
      "learning_rate": 4.533016627078385e-05,
      "loss": 0.6846,
      "step": 16290
    },
    {
      "epoch": 7.74,
      "learning_rate": 4.523515439429929e-05,
      "loss": 0.6944,
      "step": 16300
    },
    {
      "epoch": 7.75,
      "learning_rate": 4.514014251781473e-05,
      "loss": 0.6802,
      "step": 16310
    },
    {
      "epoch": 7.75,
      "learning_rate": 4.504513064133017e-05,
      "loss": 0.6907,
      "step": 16320
    },
    {
      "epoch": 7.76,
      "learning_rate": 4.49501187648456e-05,
      "loss": 0.6883,
      "step": 16330
    },
    {
      "epoch": 7.76,
      "learning_rate": 4.485510688836105e-05,
      "loss": 0.6769,
      "step": 16340
    },
    {
      "epoch": 7.77,
      "learning_rate": 4.4760095011876484e-05,
      "loss": 0.6893,
      "step": 16350
    },
    {
      "epoch": 7.77,
      "learning_rate": 4.466508313539193e-05,
      "loss": 0.6836,
      "step": 16360
    },
    {
      "epoch": 7.78,
      "learning_rate": 4.4570071258907366e-05,
      "loss": 0.6855,
      "step": 16370
    },
    {
      "epoch": 7.78,
      "learning_rate": 4.4475059382422804e-05,
      "loss": 0.7006,
      "step": 16380
    },
    {
      "epoch": 7.79,
      "learning_rate": 4.438004750593824e-05,
      "loss": 0.6662,
      "step": 16390
    },
    {
      "epoch": 7.79,
      "learning_rate": 4.4285035629453686e-05,
      "loss": 0.6966,
      "step": 16400
    },
    {
      "epoch": 7.8,
      "learning_rate": 4.4190023752969124e-05,
      "loss": 0.683,
      "step": 16410
    },
    {
      "epoch": 7.8,
      "learning_rate": 4.409501187648457e-05,
      "loss": 0.6874,
      "step": 16420
    },
    {
      "epoch": 7.81,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.6853,
      "step": 16430
    },
    {
      "epoch": 7.81,
      "learning_rate": 4.3904988123515436e-05,
      "loss": 0.6867,
      "step": 16440
    },
    {
      "epoch": 7.81,
      "learning_rate": 4.381947743467934e-05,
      "loss": 0.6874,
      "step": 16450
    },
    {
      "epoch": 7.82,
      "learning_rate": 4.3724465558194775e-05,
      "loss": 0.6916,
      "step": 16460
    },
    {
      "epoch": 7.82,
      "learning_rate": 4.362945368171021e-05,
      "loss": 0.6918,
      "step": 16470
    },
    {
      "epoch": 7.83,
      "learning_rate": 4.353444180522566e-05,
      "loss": 0.698,
      "step": 16480
    },
    {
      "epoch": 7.83,
      "learning_rate": 4.3439429928741095e-05,
      "loss": 0.6912,
      "step": 16490
    },
    {
      "epoch": 7.84,
      "learning_rate": 4.334441805225653e-05,
      "loss": 0.6907,
      "step": 16500
    },
    {
      "epoch": 7.84,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.70599365234375,
      "eval_runtime": 0.5283,
      "eval_samples_per_second": 1650.585,
      "eval_steps_per_second": 13.25,
      "step": 16500
    },
    {
      "epoch": 7.84,
      "learning_rate": 4.324940617577197e-05,
      "loss": 0.6926,
      "step": 16510
    },
    {
      "epoch": 7.85,
      "learning_rate": 4.3154394299287415e-05,
      "loss": 0.6872,
      "step": 16520
    },
    {
      "epoch": 7.85,
      "learning_rate": 4.305938242280285e-05,
      "loss": 0.6841,
      "step": 16530
    },
    {
      "epoch": 7.86,
      "learning_rate": 4.29643705463183e-05,
      "loss": 0.6875,
      "step": 16540
    },
    {
      "epoch": 7.86,
      "learning_rate": 4.2869358669833734e-05,
      "loss": 0.6937,
      "step": 16550
    },
    {
      "epoch": 7.87,
      "learning_rate": 4.2774346793349165e-05,
      "loss": 0.6816,
      "step": 16560
    },
    {
      "epoch": 7.87,
      "learning_rate": 4.267933491686461e-05,
      "loss": 0.6852,
      "step": 16570
    },
    {
      "epoch": 7.88,
      "learning_rate": 4.258432304038005e-05,
      "loss": 0.6924,
      "step": 16580
    },
    {
      "epoch": 7.88,
      "learning_rate": 4.248931116389549e-05,
      "loss": 0.6754,
      "step": 16590
    },
    {
      "epoch": 7.89,
      "learning_rate": 4.239429928741093e-05,
      "loss": 0.688,
      "step": 16600
    },
    {
      "epoch": 7.89,
      "learning_rate": 4.229928741092637e-05,
      "loss": 0.6751,
      "step": 16610
    },
    {
      "epoch": 7.9,
      "learning_rate": 4.2204275534441804e-05,
      "loss": 0.6912,
      "step": 16620
    },
    {
      "epoch": 7.9,
      "learning_rate": 4.210926365795725e-05,
      "loss": 0.6953,
      "step": 16630
    },
    {
      "epoch": 7.9,
      "learning_rate": 4.2014251781472686e-05,
      "loss": 0.6981,
      "step": 16640
    },
    {
      "epoch": 7.91,
      "learning_rate": 4.191923990498813e-05,
      "loss": 0.6876,
      "step": 16650
    },
    {
      "epoch": 7.91,
      "learning_rate": 4.182422802850356e-05,
      "loss": 0.683,
      "step": 16660
    },
    {
      "epoch": 7.92,
      "learning_rate": 4.1729216152019e-05,
      "loss": 0.6849,
      "step": 16670
    },
    {
      "epoch": 7.92,
      "learning_rate": 4.1634204275534444e-05,
      "loss": 0.6807,
      "step": 16680
    },
    {
      "epoch": 7.93,
      "learning_rate": 4.153919239904988e-05,
      "loss": 0.6894,
      "step": 16690
    },
    {
      "epoch": 7.93,
      "learning_rate": 4.1444180522565326e-05,
      "loss": 0.6897,
      "step": 16700
    },
    {
      "epoch": 7.94,
      "learning_rate": 4.134916864608076e-05,
      "loss": 0.7003,
      "step": 16710
    },
    {
      "epoch": 7.94,
      "learning_rate": 4.12541567695962e-05,
      "loss": 0.6887,
      "step": 16720
    },
    {
      "epoch": 7.95,
      "learning_rate": 4.115914489311164e-05,
      "loss": 0.6921,
      "step": 16730
    },
    {
      "epoch": 7.95,
      "learning_rate": 4.106413301662708e-05,
      "loss": 0.6895,
      "step": 16740
    },
    {
      "epoch": 7.96,
      "learning_rate": 4.096912114014252e-05,
      "loss": 0.6849,
      "step": 16750
    },
    {
      "epoch": 7.96,
      "learning_rate": 4.087410926365796e-05,
      "loss": 0.6831,
      "step": 16760
    },
    {
      "epoch": 7.97,
      "learning_rate": 4.0779097387173396e-05,
      "loss": 0.6772,
      "step": 16770
    },
    {
      "epoch": 7.97,
      "learning_rate": 4.068408551068884e-05,
      "loss": 0.6829,
      "step": 16780
    },
    {
      "epoch": 7.98,
      "learning_rate": 4.058907363420428e-05,
      "loss": 0.675,
      "step": 16790
    },
    {
      "epoch": 7.98,
      "learning_rate": 4.0494061757719715e-05,
      "loss": 0.6899,
      "step": 16800
    },
    {
      "epoch": 7.99,
      "learning_rate": 4.039904988123516e-05,
      "loss": 0.6659,
      "step": 16810
    },
    {
      "epoch": 7.99,
      "learning_rate": 4.030403800475059e-05,
      "loss": 0.6928,
      "step": 16820
    },
    {
      "epoch": 8.0,
      "learning_rate": 4.0209026128266035e-05,
      "loss": 0.6874,
      "step": 16830
    },
    {
      "epoch": 8.0,
      "learning_rate": 4.011401425178147e-05,
      "loss": 0.6769,
      "step": 16840
    },
    {
      "epoch": 8.0,
      "learning_rate": 4.001900237529692e-05,
      "loss": 0.6828,
      "step": 16850
    },
    {
      "epoch": 8.01,
      "learning_rate": 3.9923990498812355e-05,
      "loss": 0.6826,
      "step": 16860
    },
    {
      "epoch": 8.01,
      "learning_rate": 3.982897862232779e-05,
      "loss": 0.6957,
      "step": 16870
    },
    {
      "epoch": 8.02,
      "learning_rate": 3.973396674584323e-05,
      "loss": 0.6789,
      "step": 16880
    },
    {
      "epoch": 8.02,
      "learning_rate": 3.9638954869358674e-05,
      "loss": 0.6993,
      "step": 16890
    },
    {
      "epoch": 8.03,
      "learning_rate": 3.954394299287411e-05,
      "loss": 0.6877,
      "step": 16900
    },
    {
      "epoch": 8.03,
      "learning_rate": 3.944893111638955e-05,
      "loss": 0.6852,
      "step": 16910
    },
    {
      "epoch": 8.04,
      "learning_rate": 3.935391923990499e-05,
      "loss": 0.697,
      "step": 16920
    },
    {
      "epoch": 8.04,
      "learning_rate": 3.9258907363420425e-05,
      "loss": 0.6784,
      "step": 16930
    },
    {
      "epoch": 8.05,
      "learning_rate": 3.916389548693587e-05,
      "loss": 0.6898,
      "step": 16940
    },
    {
      "epoch": 8.05,
      "learning_rate": 3.906888361045131e-05,
      "loss": 0.69,
      "step": 16950
    },
    {
      "epoch": 8.06,
      "learning_rate": 3.897387173396675e-05,
      "loss": 0.6919,
      "step": 16960
    },
    {
      "epoch": 8.06,
      "learning_rate": 3.887885985748219e-05,
      "loss": 0.6845,
      "step": 16970
    },
    {
      "epoch": 8.07,
      "learning_rate": 3.8783847980997626e-05,
      "loss": 0.6855,
      "step": 16980
    },
    {
      "epoch": 8.07,
      "learning_rate": 3.8688836104513064e-05,
      "loss": 0.6856,
      "step": 16990
    },
    {
      "epoch": 8.08,
      "learning_rate": 3.859382422802851e-05,
      "loss": 0.6842,
      "step": 17000
    },
    {
      "epoch": 8.08,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7041676640510559,
      "eval_runtime": 0.5229,
      "eval_samples_per_second": 1667.61,
      "eval_steps_per_second": 13.387,
      "step": 17000
    },
    {
      "epoch": 8.08,
      "learning_rate": 3.8498812351543946e-05,
      "loss": 0.6855,
      "step": 17010
    },
    {
      "epoch": 8.09,
      "learning_rate": 3.8403800475059384e-05,
      "loss": 0.6722,
      "step": 17020
    },
    {
      "epoch": 8.09,
      "learning_rate": 3.830878859857482e-05,
      "loss": 0.6967,
      "step": 17030
    },
    {
      "epoch": 8.1,
      "learning_rate": 3.821377672209026e-05,
      "loss": 0.6812,
      "step": 17040
    },
    {
      "epoch": 8.1,
      "learning_rate": 3.81187648456057e-05,
      "loss": 0.6705,
      "step": 17050
    },
    {
      "epoch": 8.1,
      "learning_rate": 3.802375296912114e-05,
      "loss": 0.6854,
      "step": 17060
    },
    {
      "epoch": 8.11,
      "learning_rate": 3.7928741092636585e-05,
      "loss": 0.6805,
      "step": 17070
    },
    {
      "epoch": 8.11,
      "learning_rate": 3.7833729216152016e-05,
      "loss": 0.6927,
      "step": 17080
    },
    {
      "epoch": 8.12,
      "learning_rate": 3.773871733966746e-05,
      "loss": 0.6909,
      "step": 17090
    },
    {
      "epoch": 8.12,
      "learning_rate": 3.76437054631829e-05,
      "loss": 0.68,
      "step": 17100
    },
    {
      "epoch": 8.13,
      "learning_rate": 3.754869358669834e-05,
      "loss": 0.7,
      "step": 17110
    },
    {
      "epoch": 8.13,
      "learning_rate": 3.745368171021378e-05,
      "loss": 0.6809,
      "step": 17120
    },
    {
      "epoch": 8.14,
      "learning_rate": 3.735866983372922e-05,
      "loss": 0.6927,
      "step": 17130
    },
    {
      "epoch": 8.14,
      "learning_rate": 3.7263657957244656e-05,
      "loss": 0.6874,
      "step": 17140
    },
    {
      "epoch": 8.15,
      "learning_rate": 3.716864608076009e-05,
      "loss": 0.6773,
      "step": 17150
    },
    {
      "epoch": 8.15,
      "learning_rate": 3.707363420427554e-05,
      "loss": 0.6951,
      "step": 17160
    },
    {
      "epoch": 8.16,
      "learning_rate": 3.6978622327790975e-05,
      "loss": 0.6768,
      "step": 17170
    },
    {
      "epoch": 8.16,
      "learning_rate": 3.688361045130642e-05,
      "loss": 0.6954,
      "step": 17180
    },
    {
      "epoch": 8.17,
      "learning_rate": 3.678859857482185e-05,
      "loss": 0.6815,
      "step": 17190
    },
    {
      "epoch": 8.17,
      "learning_rate": 3.6693586698337295e-05,
      "loss": 0.6815,
      "step": 17200
    },
    {
      "epoch": 8.18,
      "learning_rate": 3.659857482185273e-05,
      "loss": 0.6838,
      "step": 17210
    },
    {
      "epoch": 8.18,
      "learning_rate": 3.650356294536818e-05,
      "loss": 0.6784,
      "step": 17220
    },
    {
      "epoch": 8.19,
      "learning_rate": 3.6408551068883614e-05,
      "loss": 0.6852,
      "step": 17230
    },
    {
      "epoch": 8.19,
      "learning_rate": 3.631353919239905e-05,
      "loss": 0.6803,
      "step": 17240
    },
    {
      "epoch": 8.19,
      "learning_rate": 3.621852731591449e-05,
      "loss": 0.6832,
      "step": 17250
    },
    {
      "epoch": 8.2,
      "learning_rate": 3.612351543942993e-05,
      "loss": 0.6986,
      "step": 17260
    },
    {
      "epoch": 8.2,
      "learning_rate": 3.602850356294537e-05,
      "loss": 0.6808,
      "step": 17270
    },
    {
      "epoch": 8.21,
      "learning_rate": 3.593349168646081e-05,
      "loss": 0.6837,
      "step": 17280
    },
    {
      "epoch": 8.21,
      "learning_rate": 3.583847980997625e-05,
      "loss": 0.6859,
      "step": 17290
    },
    {
      "epoch": 8.22,
      "learning_rate": 3.5743467933491685e-05,
      "loss": 0.6959,
      "step": 17300
    },
    {
      "epoch": 8.22,
      "learning_rate": 3.564845605700713e-05,
      "loss": 0.6904,
      "step": 17310
    },
    {
      "epoch": 8.23,
      "learning_rate": 3.5553444180522567e-05,
      "loss": 0.6966,
      "step": 17320
    },
    {
      "epoch": 8.23,
      "learning_rate": 3.545843230403801e-05,
      "loss": 0.6949,
      "step": 17330
    },
    {
      "epoch": 8.24,
      "learning_rate": 3.536342042755345e-05,
      "loss": 0.6831,
      "step": 17340
    },
    {
      "epoch": 8.24,
      "learning_rate": 3.5268408551068886e-05,
      "loss": 0.6807,
      "step": 17350
    },
    {
      "epoch": 8.25,
      "learning_rate": 3.5173396674584324e-05,
      "loss": 0.6797,
      "step": 17360
    },
    {
      "epoch": 8.25,
      "learning_rate": 3.507838479809976e-05,
      "loss": 0.6807,
      "step": 17370
    },
    {
      "epoch": 8.26,
      "learning_rate": 3.4983372921615206e-05,
      "loss": 0.7011,
      "step": 17380
    },
    {
      "epoch": 8.26,
      "learning_rate": 3.4888361045130643e-05,
      "loss": 0.6897,
      "step": 17390
    },
    {
      "epoch": 8.27,
      "learning_rate": 3.479334916864608e-05,
      "loss": 0.6724,
      "step": 17400
    },
    {
      "epoch": 8.27,
      "learning_rate": 3.469833729216152e-05,
      "loss": 0.6826,
      "step": 17410
    },
    {
      "epoch": 8.28,
      "learning_rate": 3.460332541567696e-05,
      "loss": 0.68,
      "step": 17420
    },
    {
      "epoch": 8.28,
      "learning_rate": 3.45083135391924e-05,
      "loss": 0.6853,
      "step": 17430
    },
    {
      "epoch": 8.29,
      "learning_rate": 3.4413301662707845e-05,
      "loss": 0.6835,
      "step": 17440
    },
    {
      "epoch": 8.29,
      "learning_rate": 3.4318289786223276e-05,
      "loss": 0.6924,
      "step": 17450
    },
    {
      "epoch": 8.29,
      "learning_rate": 3.422327790973872e-05,
      "loss": 0.6991,
      "step": 17460
    },
    {
      "epoch": 8.3,
      "learning_rate": 3.412826603325416e-05,
      "loss": 0.674,
      "step": 17470
    },
    {
      "epoch": 8.3,
      "learning_rate": 3.40332541567696e-05,
      "loss": 0.6785,
      "step": 17480
    },
    {
      "epoch": 8.31,
      "learning_rate": 3.393824228028504e-05,
      "loss": 0.6973,
      "step": 17490
    },
    {
      "epoch": 8.31,
      "learning_rate": 3.384323040380048e-05,
      "loss": 0.6884,
      "step": 17500
    },
    {
      "epoch": 8.31,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7039671540260315,
      "eval_runtime": 0.486,
      "eval_samples_per_second": 1794.319,
      "eval_steps_per_second": 14.404,
      "step": 17500
    },
    {
      "epoch": 8.32,
      "learning_rate": 3.3748218527315915e-05,
      "loss": 0.6894,
      "step": 17510
    },
    {
      "epoch": 8.32,
      "learning_rate": 3.365320665083135e-05,
      "loss": 0.6906,
      "step": 17520
    },
    {
      "epoch": 8.33,
      "learning_rate": 3.35581947743468e-05,
      "loss": 0.6837,
      "step": 17530
    },
    {
      "epoch": 8.33,
      "learning_rate": 3.3463182897862235e-05,
      "loss": 0.6799,
      "step": 17540
    },
    {
      "epoch": 8.34,
      "learning_rate": 3.336817102137767e-05,
      "loss": 0.6839,
      "step": 17550
    },
    {
      "epoch": 8.34,
      "learning_rate": 3.327315914489311e-05,
      "loss": 0.6905,
      "step": 17560
    },
    {
      "epoch": 8.35,
      "learning_rate": 3.3178147268408554e-05,
      "loss": 0.6986,
      "step": 17570
    },
    {
      "epoch": 8.35,
      "learning_rate": 3.308313539192399e-05,
      "loss": 0.6926,
      "step": 17580
    },
    {
      "epoch": 8.36,
      "learning_rate": 3.2988123515439436e-05,
      "loss": 0.678,
      "step": 17590
    },
    {
      "epoch": 8.36,
      "learning_rate": 3.2893111638954874e-05,
      "loss": 0.6918,
      "step": 17600
    },
    {
      "epoch": 8.37,
      "learning_rate": 3.2798099762470305e-05,
      "loss": 0.6875,
      "step": 17610
    },
    {
      "epoch": 8.37,
      "learning_rate": 3.270308788598575e-05,
      "loss": 0.6864,
      "step": 17620
    },
    {
      "epoch": 8.38,
      "learning_rate": 3.260807600950119e-05,
      "loss": 0.6827,
      "step": 17630
    },
    {
      "epoch": 8.38,
      "learning_rate": 3.251306413301663e-05,
      "loss": 0.6813,
      "step": 17640
    },
    {
      "epoch": 8.38,
      "learning_rate": 3.241805225653207e-05,
      "loss": 0.6761,
      "step": 17650
    },
    {
      "epoch": 8.39,
      "learning_rate": 3.2323040380047507e-05,
      "loss": 0.6801,
      "step": 17660
    },
    {
      "epoch": 8.39,
      "learning_rate": 3.2228028503562944e-05,
      "loss": 0.6811,
      "step": 17670
    },
    {
      "epoch": 8.4,
      "learning_rate": 3.213301662707839e-05,
      "loss": 0.6844,
      "step": 17680
    },
    {
      "epoch": 8.4,
      "learning_rate": 3.2038004750593826e-05,
      "loss": 0.6898,
      "step": 17690
    },
    {
      "epoch": 8.41,
      "learning_rate": 3.194299287410927e-05,
      "loss": 0.6781,
      "step": 17700
    },
    {
      "epoch": 8.41,
      "learning_rate": 3.18479809976247e-05,
      "loss": 0.6818,
      "step": 17710
    },
    {
      "epoch": 8.42,
      "learning_rate": 3.175296912114014e-05,
      "loss": 0.687,
      "step": 17720
    },
    {
      "epoch": 8.42,
      "learning_rate": 3.1657957244655583e-05,
      "loss": 0.677,
      "step": 17730
    },
    {
      "epoch": 8.43,
      "learning_rate": 3.156294536817102e-05,
      "loss": 0.6941,
      "step": 17740
    },
    {
      "epoch": 8.43,
      "learning_rate": 3.1467933491686465e-05,
      "loss": 0.6818,
      "step": 17750
    },
    {
      "epoch": 8.44,
      "learning_rate": 3.13729216152019e-05,
      "loss": 0.694,
      "step": 17760
    },
    {
      "epoch": 8.44,
      "learning_rate": 3.127790973871734e-05,
      "loss": 0.6863,
      "step": 17770
    },
    {
      "epoch": 8.45,
      "learning_rate": 3.118289786223278e-05,
      "loss": 0.68,
      "step": 17780
    },
    {
      "epoch": 8.45,
      "learning_rate": 3.108788598574822e-05,
      "loss": 0.6946,
      "step": 17790
    },
    {
      "epoch": 8.46,
      "learning_rate": 3.099287410926366e-05,
      "loss": 0.6778,
      "step": 17800
    },
    {
      "epoch": 8.46,
      "learning_rate": 3.08978622327791e-05,
      "loss": 0.675,
      "step": 17810
    },
    {
      "epoch": 8.47,
      "learning_rate": 3.0802850356294536e-05,
      "loss": 0.7045,
      "step": 17820
    },
    {
      "epoch": 8.47,
      "learning_rate": 3.070783847980997e-05,
      "loss": 0.6901,
      "step": 17830
    },
    {
      "epoch": 8.48,
      "learning_rate": 3.061282660332542e-05,
      "loss": 0.6857,
      "step": 17840
    },
    {
      "epoch": 8.48,
      "learning_rate": 3.0517814726840855e-05,
      "loss": 0.6892,
      "step": 17850
    },
    {
      "epoch": 8.48,
      "learning_rate": 3.0422802850356296e-05,
      "loss": 0.6873,
      "step": 17860
    },
    {
      "epoch": 8.49,
      "learning_rate": 3.0327790973871734e-05,
      "loss": 0.6954,
      "step": 17870
    },
    {
      "epoch": 8.49,
      "learning_rate": 3.0232779097387175e-05,
      "loss": 0.6848,
      "step": 17880
    },
    {
      "epoch": 8.5,
      "learning_rate": 3.0137767220902612e-05,
      "loss": 0.6934,
      "step": 17890
    },
    {
      "epoch": 8.5,
      "learning_rate": 3.0042755344418057e-05,
      "loss": 0.6706,
      "step": 17900
    },
    {
      "epoch": 8.51,
      "learning_rate": 2.994774346793349e-05,
      "loss": 0.6883,
      "step": 17910
    },
    {
      "epoch": 8.51,
      "learning_rate": 2.9852731591448936e-05,
      "loss": 0.6798,
      "step": 17920
    },
    {
      "epoch": 8.52,
      "learning_rate": 2.9757719714964373e-05,
      "loss": 0.6861,
      "step": 17930
    },
    {
      "epoch": 8.52,
      "learning_rate": 2.9662707838479814e-05,
      "loss": 0.6868,
      "step": 17940
    },
    {
      "epoch": 8.53,
      "learning_rate": 2.9567695961995252e-05,
      "loss": 0.6839,
      "step": 17950
    },
    {
      "epoch": 8.53,
      "learning_rate": 2.947268408551069e-05,
      "loss": 0.6737,
      "step": 17960
    },
    {
      "epoch": 8.54,
      "learning_rate": 2.937767220902613e-05,
      "loss": 0.7026,
      "step": 17970
    },
    {
      "epoch": 8.54,
      "learning_rate": 2.9282660332541568e-05,
      "loss": 0.6787,
      "step": 17980
    },
    {
      "epoch": 8.55,
      "learning_rate": 2.918764845605701e-05,
      "loss": 0.6824,
      "step": 17990
    },
    {
      "epoch": 8.55,
      "learning_rate": 2.9092636579572447e-05,
      "loss": 0.6827,
      "step": 18000
    },
    {
      "epoch": 8.55,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7108232975006104,
      "eval_runtime": 0.4883,
      "eval_samples_per_second": 1785.908,
      "eval_steps_per_second": 14.336,
      "step": 18000
    },
    {
      "epoch": 8.56,
      "learning_rate": 2.8997624703087888e-05,
      "loss": 0.692,
      "step": 18010
    },
    {
      "epoch": 8.56,
      "learning_rate": 2.8902612826603325e-05,
      "loss": 0.6888,
      "step": 18020
    },
    {
      "epoch": 8.57,
      "learning_rate": 2.880760095011877e-05,
      "loss": 0.6813,
      "step": 18030
    },
    {
      "epoch": 8.57,
      "learning_rate": 2.8712589073634204e-05,
      "loss": 0.701,
      "step": 18040
    },
    {
      "epoch": 8.57,
      "learning_rate": 2.8617577197149648e-05,
      "loss": 0.6834,
      "step": 18050
    },
    {
      "epoch": 8.58,
      "learning_rate": 2.8522565320665086e-05,
      "loss": 0.6875,
      "step": 18060
    },
    {
      "epoch": 8.58,
      "learning_rate": 2.842755344418052e-05,
      "loss": 0.6864,
      "step": 18070
    },
    {
      "epoch": 8.59,
      "learning_rate": 2.8332541567695965e-05,
      "loss": 0.6881,
      "step": 18080
    },
    {
      "epoch": 8.59,
      "learning_rate": 2.8237529691211402e-05,
      "loss": 0.678,
      "step": 18090
    },
    {
      "epoch": 8.6,
      "learning_rate": 2.8142517814726843e-05,
      "loss": 0.6971,
      "step": 18100
    },
    {
      "epoch": 8.6,
      "learning_rate": 2.804750593824228e-05,
      "loss": 0.6894,
      "step": 18110
    },
    {
      "epoch": 8.61,
      "learning_rate": 2.7952494061757722e-05,
      "loss": 0.681,
      "step": 18120
    },
    {
      "epoch": 8.61,
      "learning_rate": 2.785748218527316e-05,
      "loss": 0.6984,
      "step": 18130
    },
    {
      "epoch": 8.62,
      "learning_rate": 2.77624703087886e-05,
      "loss": 0.6831,
      "step": 18140
    },
    {
      "epoch": 8.62,
      "learning_rate": 2.7667458432304038e-05,
      "loss": 0.6859,
      "step": 18150
    },
    {
      "epoch": 8.63,
      "learning_rate": 2.7572446555819482e-05,
      "loss": 0.6983,
      "step": 18160
    },
    {
      "epoch": 8.63,
      "learning_rate": 2.7477434679334917e-05,
      "loss": 0.6825,
      "step": 18170
    },
    {
      "epoch": 8.64,
      "learning_rate": 2.7382422802850354e-05,
      "loss": 0.6905,
      "step": 18180
    },
    {
      "epoch": 8.64,
      "learning_rate": 2.72874109263658e-05,
      "loss": 0.6834,
      "step": 18190
    },
    {
      "epoch": 8.65,
      "learning_rate": 2.7192399049881233e-05,
      "loss": 0.6902,
      "step": 18200
    },
    {
      "epoch": 8.65,
      "learning_rate": 2.7097387173396677e-05,
      "loss": 0.6787,
      "step": 18210
    },
    {
      "epoch": 8.66,
      "learning_rate": 2.7002375296912115e-05,
      "loss": 0.6788,
      "step": 18220
    },
    {
      "epoch": 8.66,
      "learning_rate": 2.6907363420427556e-05,
      "loss": 0.6894,
      "step": 18230
    },
    {
      "epoch": 8.67,
      "learning_rate": 2.6812351543942994e-05,
      "loss": 0.6867,
      "step": 18240
    },
    {
      "epoch": 8.67,
      "learning_rate": 2.6717339667458435e-05,
      "loss": 0.6978,
      "step": 18250
    },
    {
      "epoch": 8.67,
      "learning_rate": 2.6622327790973872e-05,
      "loss": 0.6929,
      "step": 18260
    },
    {
      "epoch": 8.68,
      "learning_rate": 2.6527315914489313e-05,
      "loss": 0.6758,
      "step": 18270
    },
    {
      "epoch": 8.68,
      "learning_rate": 2.643230403800475e-05,
      "loss": 0.6988,
      "step": 18280
    },
    {
      "epoch": 8.69,
      "learning_rate": 2.6337292161520195e-05,
      "loss": 0.6823,
      "step": 18290
    },
    {
      "epoch": 8.69,
      "learning_rate": 2.624228028503563e-05,
      "loss": 0.6868,
      "step": 18300
    },
    {
      "epoch": 8.7,
      "learning_rate": 2.6147268408551067e-05,
      "loss": 0.6955,
      "step": 18310
    },
    {
      "epoch": 8.7,
      "learning_rate": 2.605225653206651e-05,
      "loss": 0.6869,
      "step": 18320
    },
    {
      "epoch": 8.71,
      "learning_rate": 2.5957244655581946e-05,
      "loss": 0.6785,
      "step": 18330
    },
    {
      "epoch": 8.71,
      "learning_rate": 2.586223277909739e-05,
      "loss": 0.6902,
      "step": 18340
    },
    {
      "epoch": 8.72,
      "learning_rate": 2.5767220902612828e-05,
      "loss": 0.6951,
      "step": 18350
    },
    {
      "epoch": 8.72,
      "learning_rate": 2.567220902612827e-05,
      "loss": 0.6876,
      "step": 18360
    },
    {
      "epoch": 8.73,
      "learning_rate": 2.5577197149643706e-05,
      "loss": 0.6839,
      "step": 18370
    },
    {
      "epoch": 8.73,
      "learning_rate": 2.5482185273159147e-05,
      "loss": 0.6859,
      "step": 18380
    },
    {
      "epoch": 8.74,
      "learning_rate": 2.5387173396674585e-05,
      "loss": 0.6887,
      "step": 18390
    },
    {
      "epoch": 8.74,
      "learning_rate": 2.5292161520190026e-05,
      "loss": 0.6905,
      "step": 18400
    },
    {
      "epoch": 8.75,
      "learning_rate": 2.5197149643705464e-05,
      "loss": 0.6834,
      "step": 18410
    },
    {
      "epoch": 8.75,
      "learning_rate": 2.51021377672209e-05,
      "loss": 0.6845,
      "step": 18420
    },
    {
      "epoch": 8.76,
      "learning_rate": 2.5007125890736342e-05,
      "loss": 0.6927,
      "step": 18430
    },
    {
      "epoch": 8.76,
      "learning_rate": 2.4912114014251783e-05,
      "loss": 0.691,
      "step": 18440
    },
    {
      "epoch": 8.76,
      "learning_rate": 2.4817102137767224e-05,
      "loss": 0.6867,
      "step": 18450
    },
    {
      "epoch": 8.77,
      "learning_rate": 2.4722090261282662e-05,
      "loss": 0.69,
      "step": 18460
    },
    {
      "epoch": 8.77,
      "learning_rate": 2.46270783847981e-05,
      "loss": 0.6953,
      "step": 18470
    },
    {
      "epoch": 8.78,
      "learning_rate": 2.453206650831354e-05,
      "loss": 0.6903,
      "step": 18480
    },
    {
      "epoch": 8.78,
      "learning_rate": 2.4437054631828978e-05,
      "loss": 0.6809,
      "step": 18490
    },
    {
      "epoch": 8.79,
      "learning_rate": 2.434204275534442e-05,
      "loss": 0.6822,
      "step": 18500
    },
    {
      "epoch": 8.79,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.705261766910553,
      "eval_runtime": 0.5502,
      "eval_samples_per_second": 1584.786,
      "eval_steps_per_second": 12.722,
      "step": 18500
    },
    {
      "epoch": 8.79,
      "learning_rate": 2.4247030878859857e-05,
      "loss": 0.688,
      "step": 18510
    },
    {
      "epoch": 8.8,
      "learning_rate": 2.4152019002375298e-05,
      "loss": 0.6989,
      "step": 18520
    },
    {
      "epoch": 8.8,
      "learning_rate": 2.405700712589074e-05,
      "loss": 0.6832,
      "step": 18530
    },
    {
      "epoch": 8.81,
      "learning_rate": 2.3961995249406176e-05,
      "loss": 0.6827,
      "step": 18540
    },
    {
      "epoch": 8.81,
      "learning_rate": 2.3866983372921617e-05,
      "loss": 0.6912,
      "step": 18550
    },
    {
      "epoch": 8.82,
      "learning_rate": 2.3771971496437055e-05,
      "loss": 0.6754,
      "step": 18560
    },
    {
      "epoch": 8.82,
      "learning_rate": 2.3676959619952496e-05,
      "loss": 0.6804,
      "step": 18570
    },
    {
      "epoch": 8.83,
      "learning_rate": 2.3581947743467937e-05,
      "loss": 0.682,
      "step": 18580
    },
    {
      "epoch": 8.83,
      "learning_rate": 2.348693586698337e-05,
      "loss": 0.6859,
      "step": 18590
    },
    {
      "epoch": 8.84,
      "learning_rate": 2.3391923990498812e-05,
      "loss": 0.6976,
      "step": 18600
    },
    {
      "epoch": 8.84,
      "learning_rate": 2.3296912114014253e-05,
      "loss": 0.6965,
      "step": 18610
    },
    {
      "epoch": 8.85,
      "learning_rate": 2.320190023752969e-05,
      "loss": 0.6887,
      "step": 18620
    },
    {
      "epoch": 8.85,
      "learning_rate": 2.3106888361045132e-05,
      "loss": 0.6756,
      "step": 18630
    },
    {
      "epoch": 8.86,
      "learning_rate": 2.301187648456057e-05,
      "loss": 0.6843,
      "step": 18640
    },
    {
      "epoch": 8.86,
      "learning_rate": 2.291686460807601e-05,
      "loss": 0.6937,
      "step": 18650
    },
    {
      "epoch": 8.86,
      "learning_rate": 2.282185273159145e-05,
      "loss": 0.6914,
      "step": 18660
    },
    {
      "epoch": 8.87,
      "learning_rate": 2.272684085510689e-05,
      "loss": 0.6956,
      "step": 18670
    },
    {
      "epoch": 8.87,
      "learning_rate": 2.263182897862233e-05,
      "loss": 0.6831,
      "step": 18680
    },
    {
      "epoch": 8.88,
      "learning_rate": 2.2536817102137768e-05,
      "loss": 0.6873,
      "step": 18690
    },
    {
      "epoch": 8.88,
      "learning_rate": 2.244180522565321e-05,
      "loss": 0.6922,
      "step": 18700
    },
    {
      "epoch": 8.89,
      "learning_rate": 2.2346793349168646e-05,
      "loss": 0.6666,
      "step": 18710
    },
    {
      "epoch": 8.89,
      "learning_rate": 2.2251781472684084e-05,
      "loss": 0.675,
      "step": 18720
    },
    {
      "epoch": 8.9,
      "learning_rate": 2.2156769596199525e-05,
      "loss": 0.6827,
      "step": 18730
    },
    {
      "epoch": 8.9,
      "learning_rate": 2.2061757719714966e-05,
      "loss": 0.6726,
      "step": 18740
    },
    {
      "epoch": 8.91,
      "learning_rate": 2.1966745843230404e-05,
      "loss": 0.6877,
      "step": 18750
    },
    {
      "epoch": 8.91,
      "learning_rate": 2.1871733966745845e-05,
      "loss": 0.6971,
      "step": 18760
    },
    {
      "epoch": 8.92,
      "learning_rate": 2.1776722090261286e-05,
      "loss": 0.6824,
      "step": 18770
    },
    {
      "epoch": 8.92,
      "learning_rate": 2.1681710213776723e-05,
      "loss": 0.6908,
      "step": 18780
    },
    {
      "epoch": 8.93,
      "learning_rate": 2.1586698337292164e-05,
      "loss": 0.6663,
      "step": 18790
    },
    {
      "epoch": 8.93,
      "learning_rate": 2.1491686460807602e-05,
      "loss": 0.6764,
      "step": 18800
    },
    {
      "epoch": 8.94,
      "learning_rate": 2.1396674584323043e-05,
      "loss": 0.6828,
      "step": 18810
    },
    {
      "epoch": 8.94,
      "learning_rate": 2.130166270783848e-05,
      "loss": 0.6801,
      "step": 18820
    },
    {
      "epoch": 8.95,
      "learning_rate": 2.1206650831353918e-05,
      "loss": 0.6922,
      "step": 18830
    },
    {
      "epoch": 8.95,
      "learning_rate": 2.111163895486936e-05,
      "loss": 0.6703,
      "step": 18840
    },
    {
      "epoch": 8.95,
      "learning_rate": 2.10166270783848e-05,
      "loss": 0.6783,
      "step": 18850
    },
    {
      "epoch": 8.96,
      "learning_rate": 2.0921615201900238e-05,
      "loss": 0.6718,
      "step": 18860
    },
    {
      "epoch": 8.96,
      "learning_rate": 2.082660332541568e-05,
      "loss": 0.6811,
      "step": 18870
    },
    {
      "epoch": 8.97,
      "learning_rate": 2.0731591448931116e-05,
      "loss": 0.6854,
      "step": 18880
    },
    {
      "epoch": 8.97,
      "learning_rate": 2.0636579572446557e-05,
      "loss": 0.6756,
      "step": 18890
    },
    {
      "epoch": 8.98,
      "learning_rate": 2.0541567695962e-05,
      "loss": 0.6801,
      "step": 18900
    },
    {
      "epoch": 8.98,
      "learning_rate": 2.0446555819477436e-05,
      "loss": 0.6755,
      "step": 18910
    },
    {
      "epoch": 8.99,
      "learning_rate": 2.0351543942992877e-05,
      "loss": 0.7032,
      "step": 18920
    },
    {
      "epoch": 8.99,
      "learning_rate": 2.0256532066508315e-05,
      "loss": 0.6856,
      "step": 18930
    },
    {
      "epoch": 9.0,
      "learning_rate": 2.0161520190023752e-05,
      "loss": 0.6782,
      "step": 18940
    },
    {
      "epoch": 9.0,
      "learning_rate": 2.0066508313539193e-05,
      "loss": 0.6859,
      "step": 18950
    },
    {
      "epoch": 9.01,
      "learning_rate": 1.997149643705463e-05,
      "loss": 0.6908,
      "step": 18960
    },
    {
      "epoch": 9.01,
      "learning_rate": 1.9876484560570072e-05,
      "loss": 0.6947,
      "step": 18970
    },
    {
      "epoch": 9.02,
      "learning_rate": 1.9781472684085513e-05,
      "loss": 0.6836,
      "step": 18980
    },
    {
      "epoch": 9.02,
      "learning_rate": 1.968646080760095e-05,
      "loss": 0.6865,
      "step": 18990
    },
    {
      "epoch": 9.03,
      "learning_rate": 1.959144893111639e-05,
      "loss": 0.6859,
      "step": 19000
    },
    {
      "epoch": 9.03,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7068139910697937,
      "eval_runtime": 0.4927,
      "eval_samples_per_second": 1769.778,
      "eval_steps_per_second": 14.207,
      "step": 19000
    },
    {
      "epoch": 9.03,
      "learning_rate": 1.949643705463183e-05,
      "loss": 0.6955,
      "step": 19010
    },
    {
      "epoch": 9.04,
      "learning_rate": 1.940142517814727e-05,
      "loss": 0.6817,
      "step": 19020
    },
    {
      "epoch": 9.04,
      "learning_rate": 1.930641330166271e-05,
      "loss": 0.6838,
      "step": 19030
    },
    {
      "epoch": 9.05,
      "learning_rate": 1.921140142517815e-05,
      "loss": 0.6822,
      "step": 19040
    },
    {
      "epoch": 9.05,
      "learning_rate": 1.911638954869359e-05,
      "loss": 0.6882,
      "step": 19050
    },
    {
      "epoch": 9.05,
      "learning_rate": 1.9021377672209027e-05,
      "loss": 0.6836,
      "step": 19060
    },
    {
      "epoch": 9.06,
      "learning_rate": 1.8926365795724465e-05,
      "loss": 0.6761,
      "step": 19070
    },
    {
      "epoch": 9.06,
      "learning_rate": 1.8831353919239906e-05,
      "loss": 0.7069,
      "step": 19080
    },
    {
      "epoch": 9.07,
      "learning_rate": 1.8736342042755344e-05,
      "loss": 0.6759,
      "step": 19090
    },
    {
      "epoch": 9.07,
      "learning_rate": 1.8641330166270785e-05,
      "loss": 0.693,
      "step": 19100
    },
    {
      "epoch": 9.08,
      "learning_rate": 1.8546318289786226e-05,
      "loss": 0.6867,
      "step": 19110
    },
    {
      "epoch": 9.08,
      "learning_rate": 1.8451306413301663e-05,
      "loss": 0.6848,
      "step": 19120
    },
    {
      "epoch": 9.09,
      "learning_rate": 1.8356294536817104e-05,
      "loss": 0.6808,
      "step": 19130
    },
    {
      "epoch": 9.09,
      "learning_rate": 1.8261282660332542e-05,
      "loss": 0.6764,
      "step": 19140
    },
    {
      "epoch": 9.1,
      "learning_rate": 1.8166270783847983e-05,
      "loss": 0.685,
      "step": 19150
    },
    {
      "epoch": 9.1,
      "learning_rate": 1.8071258907363424e-05,
      "loss": 0.6924,
      "step": 19160
    },
    {
      "epoch": 9.11,
      "learning_rate": 1.7976247030878858e-05,
      "loss": 0.6819,
      "step": 19170
    },
    {
      "epoch": 9.11,
      "learning_rate": 1.78812351543943e-05,
      "loss": 0.6868,
      "step": 19180
    },
    {
      "epoch": 9.12,
      "learning_rate": 1.778622327790974e-05,
      "loss": 0.6919,
      "step": 19190
    },
    {
      "epoch": 9.12,
      "learning_rate": 1.7691211401425178e-05,
      "loss": 0.6989,
      "step": 19200
    },
    {
      "epoch": 9.13,
      "learning_rate": 1.759619952494062e-05,
      "loss": 0.6929,
      "step": 19210
    },
    {
      "epoch": 9.13,
      "learning_rate": 1.7501187648456056e-05,
      "loss": 0.6827,
      "step": 19220
    },
    {
      "epoch": 9.14,
      "learning_rate": 1.7406175771971497e-05,
      "loss": 0.6842,
      "step": 19230
    },
    {
      "epoch": 9.14,
      "learning_rate": 1.731116389548694e-05,
      "loss": 0.6927,
      "step": 19240
    },
    {
      "epoch": 9.14,
      "learning_rate": 1.7216152019002376e-05,
      "loss": 0.6898,
      "step": 19250
    },
    {
      "epoch": 9.15,
      "learning_rate": 1.7121140142517817e-05,
      "loss": 0.679,
      "step": 19260
    },
    {
      "epoch": 9.15,
      "learning_rate": 1.7026128266033255e-05,
      "loss": 0.6911,
      "step": 19270
    },
    {
      "epoch": 9.16,
      "learning_rate": 1.6931116389548696e-05,
      "loss": 0.6723,
      "step": 19280
    },
    {
      "epoch": 9.16,
      "learning_rate": 1.6836104513064133e-05,
      "loss": 0.6686,
      "step": 19290
    },
    {
      "epoch": 9.17,
      "learning_rate": 1.674109263657957e-05,
      "loss": 0.7056,
      "step": 19300
    },
    {
      "epoch": 9.17,
      "learning_rate": 1.6646080760095012e-05,
      "loss": 0.6989,
      "step": 19310
    },
    {
      "epoch": 9.18,
      "learning_rate": 1.6551068883610453e-05,
      "loss": 0.7012,
      "step": 19320
    },
    {
      "epoch": 9.18,
      "learning_rate": 1.645605700712589e-05,
      "loss": 0.6846,
      "step": 19330
    },
    {
      "epoch": 9.19,
      "learning_rate": 1.636104513064133e-05,
      "loss": 0.6764,
      "step": 19340
    },
    {
      "epoch": 9.19,
      "learning_rate": 1.626603325415677e-05,
      "loss": 0.6792,
      "step": 19350
    },
    {
      "epoch": 9.2,
      "learning_rate": 1.617102137767221e-05,
      "loss": 0.6926,
      "step": 19360
    },
    {
      "epoch": 9.2,
      "learning_rate": 1.607600950118765e-05,
      "loss": 0.6949,
      "step": 19370
    },
    {
      "epoch": 9.21,
      "learning_rate": 1.598099762470309e-05,
      "loss": 0.6836,
      "step": 19380
    },
    {
      "epoch": 9.21,
      "learning_rate": 1.588598574821853e-05,
      "loss": 0.693,
      "step": 19390
    },
    {
      "epoch": 9.22,
      "learning_rate": 1.5790973871733967e-05,
      "loss": 0.6933,
      "step": 19400
    },
    {
      "epoch": 9.22,
      "learning_rate": 1.5695961995249405e-05,
      "loss": 0.6797,
      "step": 19410
    },
    {
      "epoch": 9.23,
      "learning_rate": 1.5600950118764846e-05,
      "loss": 0.6827,
      "step": 19420
    },
    {
      "epoch": 9.23,
      "learning_rate": 1.5505938242280284e-05,
      "loss": 0.6941,
      "step": 19430
    },
    {
      "epoch": 9.24,
      "learning_rate": 1.5410926365795725e-05,
      "loss": 0.6805,
      "step": 19440
    },
    {
      "epoch": 9.24,
      "learning_rate": 1.5315914489311166e-05,
      "loss": 0.6839,
      "step": 19450
    },
    {
      "epoch": 9.24,
      "learning_rate": 1.5220902612826603e-05,
      "loss": 0.6838,
      "step": 19460
    },
    {
      "epoch": 9.25,
      "learning_rate": 1.5125890736342044e-05,
      "loss": 0.6873,
      "step": 19470
    },
    {
      "epoch": 9.25,
      "learning_rate": 1.5030878859857484e-05,
      "loss": 0.6902,
      "step": 19480
    },
    {
      "epoch": 9.26,
      "learning_rate": 1.4935866983372923e-05,
      "loss": 0.6793,
      "step": 19490
    },
    {
      "epoch": 9.26,
      "learning_rate": 1.4840855106888362e-05,
      "loss": 0.6968,
      "step": 19500
    },
    {
      "epoch": 9.26,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7121268510818481,
      "eval_runtime": 0.4914,
      "eval_samples_per_second": 1774.678,
      "eval_steps_per_second": 14.246,
      "step": 19500
    },
    {
      "epoch": 9.27,
      "learning_rate": 1.4745843230403802e-05,
      "loss": 0.6894,
      "step": 19510
    },
    {
      "epoch": 9.27,
      "learning_rate": 1.465083135391924e-05,
      "loss": 0.6878,
      "step": 19520
    },
    {
      "epoch": 9.28,
      "learning_rate": 1.4555819477434679e-05,
      "loss": 0.6854,
      "step": 19530
    },
    {
      "epoch": 9.28,
      "learning_rate": 1.4460807600950118e-05,
      "loss": 0.682,
      "step": 19540
    },
    {
      "epoch": 9.29,
      "learning_rate": 1.4365795724465559e-05,
      "loss": 0.681,
      "step": 19550
    },
    {
      "epoch": 9.29,
      "learning_rate": 1.4270783847980998e-05,
      "loss": 0.685,
      "step": 19560
    },
    {
      "epoch": 9.3,
      "learning_rate": 1.4175771971496437e-05,
      "loss": 0.6942,
      "step": 19570
    },
    {
      "epoch": 9.3,
      "learning_rate": 1.4080760095011877e-05,
      "loss": 0.6767,
      "step": 19580
    },
    {
      "epoch": 9.31,
      "learning_rate": 1.3985748218527318e-05,
      "loss": 0.6941,
      "step": 19590
    },
    {
      "epoch": 9.31,
      "learning_rate": 1.3890736342042757e-05,
      "loss": 0.6782,
      "step": 19600
    },
    {
      "epoch": 9.32,
      "learning_rate": 1.3795724465558196e-05,
      "loss": 0.6962,
      "step": 19610
    },
    {
      "epoch": 9.32,
      "learning_rate": 1.3700712589073636e-05,
      "loss": 0.684,
      "step": 19620
    },
    {
      "epoch": 9.33,
      "learning_rate": 1.3605700712589075e-05,
      "loss": 0.681,
      "step": 19630
    },
    {
      "epoch": 9.33,
      "learning_rate": 1.3510688836104513e-05,
      "loss": 0.673,
      "step": 19640
    },
    {
      "epoch": 9.33,
      "learning_rate": 1.3415676959619952e-05,
      "loss": 0.6826,
      "step": 19650
    },
    {
      "epoch": 9.34,
      "learning_rate": 1.3320665083135391e-05,
      "loss": 0.6834,
      "step": 19660
    },
    {
      "epoch": 9.34,
      "learning_rate": 1.3225653206650832e-05,
      "loss": 0.6856,
      "step": 19670
    },
    {
      "epoch": 9.35,
      "learning_rate": 1.3130641330166272e-05,
      "loss": 0.6959,
      "step": 19680
    },
    {
      "epoch": 9.35,
      "learning_rate": 1.3035629453681711e-05,
      "loss": 0.6903,
      "step": 19690
    },
    {
      "epoch": 9.36,
      "learning_rate": 1.294061757719715e-05,
      "loss": 0.6762,
      "step": 19700
    },
    {
      "epoch": 9.36,
      "learning_rate": 1.284560570071259e-05,
      "loss": 0.6915,
      "step": 19710
    },
    {
      "epoch": 9.37,
      "learning_rate": 1.275059382422803e-05,
      "loss": 0.6792,
      "step": 19720
    },
    {
      "epoch": 9.37,
      "learning_rate": 1.265558194774347e-05,
      "loss": 0.6807,
      "step": 19730
    },
    {
      "epoch": 9.38,
      "learning_rate": 1.256057007125891e-05,
      "loss": 0.6888,
      "step": 19740
    },
    {
      "epoch": 9.38,
      "learning_rate": 1.2465558194774347e-05,
      "loss": 0.6766,
      "step": 19750
    },
    {
      "epoch": 9.39,
      "learning_rate": 1.2370546318289788e-05,
      "loss": 0.687,
      "step": 19760
    },
    {
      "epoch": 9.39,
      "learning_rate": 1.2275534441805227e-05,
      "loss": 0.6863,
      "step": 19770
    },
    {
      "epoch": 9.4,
      "learning_rate": 1.2180522565320665e-05,
      "loss": 0.6783,
      "step": 19780
    },
    {
      "epoch": 9.4,
      "learning_rate": 1.2085510688836104e-05,
      "loss": 0.6817,
      "step": 19790
    },
    {
      "epoch": 9.41,
      "learning_rate": 1.1990498812351545e-05,
      "loss": 0.6864,
      "step": 19800
    },
    {
      "epoch": 9.41,
      "learning_rate": 1.1895486935866984e-05,
      "loss": 0.6816,
      "step": 19810
    },
    {
      "epoch": 9.42,
      "learning_rate": 1.1800475059382424e-05,
      "loss": 0.6837,
      "step": 19820
    },
    {
      "epoch": 9.42,
      "learning_rate": 1.1705463182897863e-05,
      "loss": 0.6938,
      "step": 19830
    },
    {
      "epoch": 9.43,
      "learning_rate": 1.1610451306413302e-05,
      "loss": 0.684,
      "step": 19840
    },
    {
      "epoch": 9.43,
      "learning_rate": 1.1515439429928742e-05,
      "loss": 0.6804,
      "step": 19850
    },
    {
      "epoch": 9.43,
      "learning_rate": 1.1420427553444181e-05,
      "loss": 0.6993,
      "step": 19860
    },
    {
      "epoch": 9.44,
      "learning_rate": 1.132541567695962e-05,
      "loss": 0.6813,
      "step": 19870
    },
    {
      "epoch": 9.44,
      "learning_rate": 1.123040380047506e-05,
      "loss": 0.6809,
      "step": 19880
    },
    {
      "epoch": 9.45,
      "learning_rate": 1.11353919239905e-05,
      "loss": 0.69,
      "step": 19890
    },
    {
      "epoch": 9.45,
      "learning_rate": 1.1040380047505938e-05,
      "loss": 0.6766,
      "step": 19900
    },
    {
      "epoch": 9.46,
      "learning_rate": 1.0945368171021378e-05,
      "loss": 0.6883,
      "step": 19910
    },
    {
      "epoch": 9.46,
      "learning_rate": 1.0850356294536817e-05,
      "loss": 0.6831,
      "step": 19920
    },
    {
      "epoch": 9.47,
      "learning_rate": 1.0755344418052258e-05,
      "loss": 0.6884,
      "step": 19930
    },
    {
      "epoch": 9.47,
      "learning_rate": 1.0660332541567697e-05,
      "loss": 0.6921,
      "step": 19940
    },
    {
      "epoch": 9.48,
      "learning_rate": 1.0565320665083136e-05,
      "loss": 0.6869,
      "step": 19950
    },
    {
      "epoch": 9.48,
      "learning_rate": 1.0470308788598574e-05,
      "loss": 0.6843,
      "step": 19960
    },
    {
      "epoch": 9.49,
      "learning_rate": 1.0375296912114015e-05,
      "loss": 0.6857,
      "step": 19970
    },
    {
      "epoch": 9.49,
      "learning_rate": 1.0280285035629454e-05,
      "loss": 0.6862,
      "step": 19980
    },
    {
      "epoch": 9.5,
      "learning_rate": 1.0185273159144894e-05,
      "loss": 0.6852,
      "step": 19990
    },
    {
      "epoch": 9.5,
      "learning_rate": 1.0090261282660333e-05,
      "loss": 0.6819,
      "step": 20000
    },
    {
      "epoch": 9.5,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7118961215019226,
      "eval_runtime": 0.5106,
      "eval_samples_per_second": 1707.659,
      "eval_steps_per_second": 13.708,
      "step": 20000
    },
    {
      "epoch": 9.51,
      "learning_rate": 9.995249406175772e-06,
      "loss": 0.6834,
      "step": 20010
    },
    {
      "epoch": 9.51,
      "learning_rate": 9.900237529691212e-06,
      "loss": 0.6765,
      "step": 20020
    },
    {
      "epoch": 9.52,
      "learning_rate": 9.805225653206651e-06,
      "loss": 0.686,
      "step": 20030
    },
    {
      "epoch": 9.52,
      "learning_rate": 9.71021377672209e-06,
      "loss": 0.6807,
      "step": 20040
    },
    {
      "epoch": 9.52,
      "learning_rate": 9.61520190023753e-06,
      "loss": 0.688,
      "step": 20050
    },
    {
      "epoch": 9.53,
      "learning_rate": 9.52019002375297e-06,
      "loss": 0.6792,
      "step": 20060
    },
    {
      "epoch": 9.53,
      "learning_rate": 9.425178147268408e-06,
      "loss": 0.6936,
      "step": 20070
    },
    {
      "epoch": 9.54,
      "learning_rate": 9.330166270783848e-06,
      "loss": 0.6843,
      "step": 20080
    },
    {
      "epoch": 9.54,
      "learning_rate": 9.235154394299287e-06,
      "loss": 0.6858,
      "step": 20090
    },
    {
      "epoch": 9.55,
      "learning_rate": 9.140142517814728e-06,
      "loss": 0.6822,
      "step": 20100
    },
    {
      "epoch": 9.55,
      "learning_rate": 9.045130641330167e-06,
      "loss": 0.6719,
      "step": 20110
    },
    {
      "epoch": 9.56,
      "learning_rate": 8.950118764845607e-06,
      "loss": 0.686,
      "step": 20120
    },
    {
      "epoch": 9.56,
      "learning_rate": 8.855106888361044e-06,
      "loss": 0.6811,
      "step": 20130
    },
    {
      "epoch": 9.57,
      "learning_rate": 8.760095011876485e-06,
      "loss": 0.6786,
      "step": 20140
    },
    {
      "epoch": 9.57,
      "learning_rate": 8.665083135391924e-06,
      "loss": 0.6773,
      "step": 20150
    },
    {
      "epoch": 9.58,
      "learning_rate": 8.570071258907364e-06,
      "loss": 0.6783,
      "step": 20160
    },
    {
      "epoch": 9.58,
      "learning_rate": 8.475059382422803e-06,
      "loss": 0.6789,
      "step": 20170
    },
    {
      "epoch": 9.59,
      "learning_rate": 8.380047505938244e-06,
      "loss": 0.6671,
      "step": 20180
    },
    {
      "epoch": 9.59,
      "learning_rate": 8.285035629453682e-06,
      "loss": 0.6846,
      "step": 20190
    },
    {
      "epoch": 9.6,
      "learning_rate": 8.190023752969121e-06,
      "loss": 0.6839,
      "step": 20200
    },
    {
      "epoch": 9.6,
      "learning_rate": 8.09501187648456e-06,
      "loss": 0.6953,
      "step": 20210
    },
    {
      "epoch": 9.61,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.6876,
      "step": 20220
    },
    {
      "epoch": 9.61,
      "learning_rate": 7.90498812351544e-06,
      "loss": 0.6833,
      "step": 20230
    },
    {
      "epoch": 9.62,
      "learning_rate": 7.80997624703088e-06,
      "loss": 0.6782,
      "step": 20240
    },
    {
      "epoch": 9.62,
      "learning_rate": 7.714964370546318e-06,
      "loss": 0.6906,
      "step": 20250
    },
    {
      "epoch": 9.62,
      "learning_rate": 7.619952494061758e-06,
      "loss": 0.677,
      "step": 20260
    },
    {
      "epoch": 9.63,
      "learning_rate": 7.534441805225653e-06,
      "loss": 0.6892,
      "step": 20270
    },
    {
      "epoch": 9.63,
      "learning_rate": 7.439429928741093e-06,
      "loss": 0.6932,
      "step": 20280
    },
    {
      "epoch": 9.64,
      "learning_rate": 7.344418052256533e-06,
      "loss": 0.6898,
      "step": 20290
    },
    {
      "epoch": 9.64,
      "learning_rate": 7.249406175771972e-06,
      "loss": 0.6979,
      "step": 20300
    },
    {
      "epoch": 9.65,
      "learning_rate": 7.154394299287412e-06,
      "loss": 0.6811,
      "step": 20310
    },
    {
      "epoch": 9.65,
      "learning_rate": 7.0593824228028505e-06,
      "loss": 0.6808,
      "step": 20320
    },
    {
      "epoch": 9.66,
      "learning_rate": 6.96437054631829e-06,
      "loss": 0.6887,
      "step": 20330
    },
    {
      "epoch": 9.66,
      "learning_rate": 6.869358669833729e-06,
      "loss": 0.693,
      "step": 20340
    },
    {
      "epoch": 9.67,
      "learning_rate": 6.774346793349169e-06,
      "loss": 0.68,
      "step": 20350
    },
    {
      "epoch": 9.67,
      "learning_rate": 6.679334916864609e-06,
      "loss": 0.6767,
      "step": 20360
    },
    {
      "epoch": 9.68,
      "learning_rate": 6.584323040380049e-06,
      "loss": 0.6927,
      "step": 20370
    },
    {
      "epoch": 9.68,
      "learning_rate": 6.489311163895486e-06,
      "loss": 0.693,
      "step": 20380
    },
    {
      "epoch": 9.69,
      "learning_rate": 6.394299287410927e-06,
      "loss": 0.682,
      "step": 20390
    },
    {
      "epoch": 9.69,
      "learning_rate": 6.299287410926366e-06,
      "loss": 0.6692,
      "step": 20400
    },
    {
      "epoch": 9.7,
      "learning_rate": 6.204275534441806e-06,
      "loss": 0.6749,
      "step": 20410
    },
    {
      "epoch": 9.7,
      "learning_rate": 6.1092636579572445e-06,
      "loss": 0.6963,
      "step": 20420
    },
    {
      "epoch": 9.71,
      "learning_rate": 6.014251781472685e-06,
      "loss": 0.6761,
      "step": 20430
    },
    {
      "epoch": 9.71,
      "learning_rate": 5.919239904988124e-06,
      "loss": 0.6794,
      "step": 20440
    },
    {
      "epoch": 9.71,
      "learning_rate": 5.824228028503563e-06,
      "loss": 0.6833,
      "step": 20450
    },
    {
      "epoch": 9.72,
      "learning_rate": 5.729216152019003e-06,
      "loss": 0.679,
      "step": 20460
    },
    {
      "epoch": 9.72,
      "learning_rate": 5.634204275534442e-06,
      "loss": 0.6871,
      "step": 20470
    },
    {
      "epoch": 9.73,
      "learning_rate": 5.539192399049881e-06,
      "loss": 0.6996,
      "step": 20480
    },
    {
      "epoch": 9.73,
      "learning_rate": 5.444180522565321e-06,
      "loss": 0.6723,
      "step": 20490
    },
    {
      "epoch": 9.74,
      "learning_rate": 5.349168646080761e-06,
      "loss": 0.6791,
      "step": 20500
    },
    {
      "epoch": 9.74,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7133962512016296,
      "eval_runtime": 0.4913,
      "eval_samples_per_second": 1774.728,
      "eval_steps_per_second": 14.247,
      "step": 20500
    },
    {
      "epoch": 9.74,
      "learning_rate": 5.2541567695962e-06,
      "loss": 0.6673,
      "step": 20510
    },
    {
      "epoch": 9.75,
      "learning_rate": 5.159144893111639e-06,
      "loss": 0.6843,
      "step": 20520
    },
    {
      "epoch": 9.75,
      "learning_rate": 5.064133016627079e-06,
      "loss": 0.6994,
      "step": 20530
    },
    {
      "epoch": 9.76,
      "learning_rate": 4.969121140142518e-06,
      "loss": 0.6845,
      "step": 20540
    },
    {
      "epoch": 9.76,
      "learning_rate": 4.874109263657957e-06,
      "loss": 0.694,
      "step": 20550
    },
    {
      "epoch": 9.77,
      "learning_rate": 4.7790973871733974e-06,
      "loss": 0.6718,
      "step": 20560
    },
    {
      "epoch": 9.77,
      "learning_rate": 4.684085510688836e-06,
      "loss": 0.6926,
      "step": 20570
    },
    {
      "epoch": 9.78,
      "learning_rate": 4.589073634204276e-06,
      "loss": 0.6786,
      "step": 20580
    },
    {
      "epoch": 9.78,
      "learning_rate": 4.4940617577197145e-06,
      "loss": 0.6666,
      "step": 20590
    },
    {
      "epoch": 9.79,
      "learning_rate": 4.399049881235155e-06,
      "loss": 0.6765,
      "step": 20600
    },
    {
      "epoch": 9.79,
      "learning_rate": 4.304038004750594e-06,
      "loss": 0.6727,
      "step": 20610
    },
    {
      "epoch": 9.8,
      "learning_rate": 4.209026128266033e-06,
      "loss": 0.6869,
      "step": 20620
    },
    {
      "epoch": 9.8,
      "learning_rate": 4.114014251781473e-06,
      "loss": 0.6896,
      "step": 20630
    },
    {
      "epoch": 9.81,
      "learning_rate": 4.019002375296913e-06,
      "loss": 0.6904,
      "step": 20640
    },
    {
      "epoch": 9.81,
      "learning_rate": 3.923990498812351e-06,
      "loss": 0.6877,
      "step": 20650
    },
    {
      "epoch": 9.81,
      "learning_rate": 3.8289786223277914e-06,
      "loss": 0.6846,
      "step": 20660
    },
    {
      "epoch": 9.82,
      "learning_rate": 3.7339667458432307e-06,
      "loss": 0.6864,
      "step": 20670
    },
    {
      "epoch": 9.82,
      "learning_rate": 3.6389548693586696e-06,
      "loss": 0.7024,
      "step": 20680
    },
    {
      "epoch": 9.83,
      "learning_rate": 3.5439429928741094e-06,
      "loss": 0.6801,
      "step": 20690
    },
    {
      "epoch": 9.83,
      "learning_rate": 3.448931116389549e-06,
      "loss": 0.69,
      "step": 20700
    },
    {
      "epoch": 9.84,
      "learning_rate": 3.353919239904988e-06,
      "loss": 0.6859,
      "step": 20710
    },
    {
      "epoch": 9.84,
      "learning_rate": 3.2589073634204277e-06,
      "loss": 0.6956,
      "step": 20720
    },
    {
      "epoch": 9.85,
      "learning_rate": 3.1638954869358675e-06,
      "loss": 0.6866,
      "step": 20730
    },
    {
      "epoch": 9.85,
      "learning_rate": 3.0688836104513068e-06,
      "loss": 0.6974,
      "step": 20740
    },
    {
      "epoch": 9.86,
      "learning_rate": 2.973871733966746e-06,
      "loss": 0.7,
      "step": 20750
    },
    {
      "epoch": 9.86,
      "learning_rate": 2.8788598574821854e-06,
      "loss": 0.6934,
      "step": 20760
    },
    {
      "epoch": 9.87,
      "learning_rate": 2.783847980997625e-06,
      "loss": 0.6878,
      "step": 20770
    },
    {
      "epoch": 9.87,
      "learning_rate": 2.6888361045130645e-06,
      "loss": 0.6888,
      "step": 20780
    },
    {
      "epoch": 9.88,
      "learning_rate": 2.5938242280285038e-06,
      "loss": 0.6817,
      "step": 20790
    },
    {
      "epoch": 9.88,
      "learning_rate": 2.498812351543943e-06,
      "loss": 0.6911,
      "step": 20800
    },
    {
      "epoch": 9.89,
      "learning_rate": 2.4038004750593824e-06,
      "loss": 0.6776,
      "step": 20810
    },
    {
      "epoch": 9.89,
      "learning_rate": 2.3087885985748217e-06,
      "loss": 0.687,
      "step": 20820
    },
    {
      "epoch": 9.9,
      "learning_rate": 2.213776722090261e-06,
      "loss": 0.694,
      "step": 20830
    },
    {
      "epoch": 9.9,
      "learning_rate": 2.1187648456057008e-06,
      "loss": 0.679,
      "step": 20840
    },
    {
      "epoch": 9.9,
      "learning_rate": 2.02375296912114e-06,
      "loss": 0.6777,
      "step": 20850
    },
    {
      "epoch": 9.91,
      "learning_rate": 1.9287410926365794e-06,
      "loss": 0.6859,
      "step": 20860
    },
    {
      "epoch": 9.91,
      "learning_rate": 1.8337292161520191e-06,
      "loss": 0.6898,
      "step": 20870
    },
    {
      "epoch": 9.92,
      "learning_rate": 1.7387173396674584e-06,
      "loss": 0.682,
      "step": 20880
    },
    {
      "epoch": 9.92,
      "learning_rate": 1.6437054631828978e-06,
      "loss": 0.6852,
      "step": 20890
    },
    {
      "epoch": 9.93,
      "learning_rate": 1.5486935866983373e-06,
      "loss": 0.7183,
      "step": 20900
    },
    {
      "epoch": 9.93,
      "learning_rate": 1.4536817102137768e-06,
      "loss": 0.6958,
      "step": 20910
    },
    {
      "epoch": 9.94,
      "learning_rate": 1.3586698337292161e-06,
      "loss": 0.6786,
      "step": 20920
    },
    {
      "epoch": 9.94,
      "learning_rate": 1.2636579572446556e-06,
      "loss": 0.6941,
      "step": 20930
    },
    {
      "epoch": 9.95,
      "learning_rate": 1.1686460807600952e-06,
      "loss": 0.6844,
      "step": 20940
    },
    {
      "epoch": 9.95,
      "learning_rate": 1.0736342042755345e-06,
      "loss": 0.6879,
      "step": 20950
    },
    {
      "epoch": 9.96,
      "learning_rate": 9.78622327790974e-07,
      "loss": 0.6835,
      "step": 20960
    },
    {
      "epoch": 9.96,
      "learning_rate": 8.836104513064134e-07,
      "loss": 0.6955,
      "step": 20970
    },
    {
      "epoch": 9.97,
      "learning_rate": 7.885985748218527e-07,
      "loss": 0.6887,
      "step": 20980
    },
    {
      "epoch": 9.97,
      "learning_rate": 6.935866983372923e-07,
      "loss": 0.6748,
      "step": 20990
    },
    {
      "epoch": 9.98,
      "learning_rate": 5.985748218527316e-07,
      "loss": 0.6834,
      "step": 21000
    },
    {
      "epoch": 9.98,
      "eval_accuracy": 0.5091743119266054,
      "eval_loss": 0.7114437222480774,
      "eval_runtime": 0.4908,
      "eval_samples_per_second": 1776.776,
      "eval_steps_per_second": 14.263,
      "step": 21000
    },
    {
      "epoch": 9.98,
      "learning_rate": 5.03562945368171e-07,
      "loss": 0.6942,
      "step": 21010
    },
    {
      "epoch": 9.99,
      "learning_rate": 4.085510688836104e-07,
      "loss": 0.6946,
      "step": 21020
    },
    {
      "epoch": 9.99,
      "learning_rate": 3.135391923990499e-07,
      "loss": 0.678,
      "step": 21030
    },
    {
      "epoch": 10.0,
      "learning_rate": 2.1852731591448934e-07,
      "loss": 0.6817,
      "step": 21040
    },
    {
      "epoch": 10.0,
      "learning_rate": 1.2351543942992876e-07,
      "loss": 0.6817,
      "step": 21050
    },
    {
      "epoch": 10.0,
      "step": 21050,
      "total_flos": 4.475948005653504e+16,
      "train_loss": 0.6394745077713085,
      "train_runtime": 1328.1511,
      "train_samples_per_second": 507.088,
      "train_steps_per_second": 15.849
    }
  ],
  "logging_steps": 10,
  "max_steps": 21050,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 4.475948005653504e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
